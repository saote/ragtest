{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### answer file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_type</th>\n",
       "      <th>evidence_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the individual associated with the cryp...</td>\n",
       "      <td>Sam Bankman-Fried</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which individual is implicated in both inflati...</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is the figure associated with generative A...</td>\n",
       "      <td>Sam Altman</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do the TechCrunch article on software companie...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which online betting platform provides a welco...</td>\n",
       "      <td>Caesars Sportsbook</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query              answer  \\\n",
       "0  Who is the individual associated with the cryp...   Sam Bankman-Fried   \n",
       "1  Which individual is implicated in both inflati...        Donald Trump   \n",
       "2  Who is the figure associated with generative A...          Sam Altman   \n",
       "3  Do the TechCrunch article on software companie...                 Yes   \n",
       "4  Which online betting platform provides a welco...  Caesars Sportsbook   \n",
       "\n",
       "      question_type  evidence_list  \n",
       "0   inference_query              3  \n",
       "1   inference_query              2  \n",
       "2   inference_query              2  \n",
       "3  comparison_query              2  \n",
       "4   inference_query              3  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANSWER_FILE = '../test_results/multi_hop/questions.csv'\n",
    "ans_df = pd.read_csv(ANSWER_FILE)\n",
    "ans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>RAG Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the individual associated with the cryp...</td>\n",
       "      <td>Sam Bankman-Fried</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which individual is implicated in both inflati...</td>\n",
       "      <td>Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is the figure associated with generative A...</td>\n",
       "      <td>Sam Altman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do the TechCrunch article on software companie...</td>\n",
       "      <td>Insufficient information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which online betting platform provides a welco...</td>\n",
       "      <td>BetMGM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question                RAG Answer\n",
       "0  Who is the individual associated with the cryp...         Sam Bankman-Fried\n",
       "1  Which individual is implicated in both inflati...                     Trump\n",
       "2  Who is the figure associated with generative A...                Sam Altman\n",
       "3  Do the TechCrunch article on software companie...  Insufficient information\n",
       "4  Which online betting platform provides a welco...                    BetMGM"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "RAG_ANSWER_FILE = '../test_results/multi_hop/RAG_result.csv'\n",
    "rag_df = pd.read_csv(RAG_ANSWER_FILE)\n",
    "rag_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No context answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>RAG Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the individual associated with the cryp...</td>\n",
       "      <td>Insufficient information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which individual is implicated in both inflati...</td>\n",
       "      <td>Insufficient information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is the figure associated with generative A...</td>\n",
       "      <td>Insufficient information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do the TechCrunch article on software companie...</td>\n",
       "      <td>Insufficient information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which online betting platform provides a welco...</td>\n",
       "      <td>Insufficient information</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question                RAG Answer\n",
       "0  Who is the individual associated with the cryp...  Insufficient information\n",
       "1  Which individual is implicated in both inflati...  Insufficient information\n",
       "2  Who is the figure associated with generative A...  Insufficient information\n",
       "3  Do the TechCrunch article on software companie...  Insufficient information\n",
       "4  Which online betting platform provides a welco...  Insufficient information"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NO_CONTEXT_FILE = '../test_results/multi_hop/no_context_result.csv'\n",
    "no_context_df = pd.read_csv(NO_CONTEXT_FILE)\n",
    "no_context_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph RAG answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Graph RAG answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the individual associated with the cryp...</td>\n",
       "      <td>Sam Bankman-Fried</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which individual is implicated in both inflati...</td>\n",
       "      <td>Donald Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is the figure associated with generative A...</td>\n",
       "      <td>Sam Altman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do the TechCrunch article on software companie...</td>\n",
       "      <td>Insufficient information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which online betting platform provides a welco...</td>\n",
       "      <td>Caesars Sportsbook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question          Graph RAG answer\n",
       "0  Who is the individual associated with the cryp...         Sam Bankman-Fried\n",
       "1  Which individual is implicated in both inflati...              Donald Trump\n",
       "2  Who is the figure associated with generative A...                Sam Altman\n",
       "3  Do the TechCrunch article on software companie...  Insufficient information\n",
       "4  Which online betting platform provides a welco...        Caesars Sportsbook"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdir = ''\n",
    "GRAPH_RAG_FILE = '../test_results/multi_hop/' + subdir + 'GraphRAG_results.csv'\n",
    "graphrag_df = pd.read_csv(GRAPH_RAG_FILE)\n",
    "graphrag_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph RAG with graph explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Graph RAG answer</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the individual associated with the cryp...</td>\n",
       "      <td>Sam Bankman-Fried</td>\n",
       "      <td>0</td>\n",
       "      <td>37.237534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which individual is implicated in both inflati...</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>0</td>\n",
       "      <td>37.965694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is the figure associated with generative A...</td>\n",
       "      <td>Sam Altman</td>\n",
       "      <td>0</td>\n",
       "      <td>41.640990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do the TechCrunch article on software companie...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>48.165514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which online betting platform provides a welco...</td>\n",
       "      <td>BetMGM Sportsbook</td>\n",
       "      <td>0</td>\n",
       "      <td>38.791165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question   Graph RAG answer  \\\n",
       "0  Who is the individual associated with the cryp...  Sam Bankman-Fried   \n",
       "1  Which individual is implicated in both inflati...       Donald Trump   \n",
       "2  Who is the figure associated with generative A...         Sam Altman   \n",
       "3  Do the TechCrunch article on software companie...                Yes   \n",
       "4  Which online betting platform provides a welco...  BetMGM Sportsbook   \n",
       "\n",
       "   Iteration       time  \n",
       "0          0  37.237534  \n",
       "1          0  37.965694  \n",
       "2          0  41.640990  \n",
       "3          0  48.165514  \n",
       "4          0  38.791165  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRAPH_EXPLORE_FILE = '../test_results/multi_hop/graph_explore/GraphRAG_results.csv'\n",
    "graph_explore_df = pd.read_csv(GRAPH_EXPLORE_FILE)\n",
    "graph_explore_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_types = ['inference_query', 'comparison_query', 'temporal_query', 'null_query', 'total']\n",
    "\n",
    "def is_correct(answer1:str, answer2:str):\n",
    "    return str(answer1).strip('.').lower() == str(answer2).strip('.').lower()\n",
    "\n",
    "\n",
    "def add_info_to_test_df(test_df):\n",
    "    num_answers = test_df.shape[0]\n",
    "    test_df['answer'] = ans_df['answer'].iloc[:num_answers]\n",
    "    test_df['question_type'] = ans_df['question_type'].iloc[:num_answers]\n",
    "    test_df['correctness'] = test_df.apply(lambda row: is_correct(row.iloc[1], row['answer']), axis=1)\n",
    "\n",
    "\n",
    "def cal_correct_rate(test_df, question_type = 'total'):\n",
    "    \"\"\"calculate correctness rate of test_df for a specific question type\"\"\"\n",
    "    assert question_type in question_types, \"invalid question type\"\n",
    "\n",
    "    num_answers = test_df.shape[0]\n",
    "\n",
    "    right_answer_count = 0\n",
    "    num_of_type_questions = 0\n",
    "    \n",
    "    for i in range(num_answers):\n",
    "        if question_type == 'total' or test_df['question_type'][i] == question_type:\n",
    "            num_of_type_questions += 1\n",
    "            if test_df['correctness'][i]:\n",
    "                right_answer_count += 1\n",
    "\n",
    "    return right_answer_count / num_of_type_questions, num_of_type_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_rates_test_df(test_df):\n",
    "    add_info_to_test_df(test_df)\n",
    "\n",
    "    columns = ['question type', 'correct rate', 'num of questions']\n",
    "    correct_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for i in range(len(question_types)):\n",
    "        type = question_types[i]\n",
    "        correct_df.loc[i] = [type, cal_correct_rate(test_df, type)[0], cal_correct_rate(test_df, type)[1]]\n",
    "    return correct_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate correctness rate of each data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question type</th>\n",
       "      <th>correct rate</th>\n",
       "      <th>num of questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inference_query</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comparison_query</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>temporal_query</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>null_query</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      question type  correct rate  num of questions\n",
       "0   inference_query      0.848485                33\n",
       "1  comparison_query      0.428571                35\n",
       "2    temporal_query      0.391304                23\n",
       "3        null_query      0.777778                 9\n",
       "4             total      0.590000               100"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_correct_df = correct_rates_test_df(rag_df)\n",
    "rag_correct_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question type</th>\n",
       "      <th>correct rate</th>\n",
       "      <th>num of questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inference_query</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comparison_query</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>temporal_query</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>null_query</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      question type  correct rate  num of questions\n",
       "0   inference_query      0.090909                33\n",
       "1  comparison_query      0.000000                35\n",
       "2    temporal_query      0.000000                23\n",
       "3        null_query      1.000000                 9\n",
       "4             total      0.120000               100"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_context_correct_df = correct_rates_test_df(no_context_df)\n",
    "no_context_correct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question type</th>\n",
       "      <th>correct rate</th>\n",
       "      <th>num of questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inference_query</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comparison_query</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>temporal_query</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>null_query</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      question type  correct rate  num of questions\n",
       "0   inference_query      0.939394                33\n",
       "1  comparison_query      0.457143                35\n",
       "2    temporal_query      0.434783                23\n",
       "3        null_query      1.000000                 9\n",
       "4             total      0.660000               100"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphrag_correct_df = correct_rates_test_df(graphrag_df)\n",
    "graphrag_correct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question type</th>\n",
       "      <th>correct rate</th>\n",
       "      <th>num of questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inference_query</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comparison_query</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>temporal_query</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>null_query</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      question type  correct rate  num of questions\n",
       "0   inference_query      0.909091                33\n",
       "1  comparison_query      0.542857                35\n",
       "2    temporal_query      0.478261                23\n",
       "3        null_query      1.000000                 9\n",
       "4             total      0.690000               100"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore_graph_correct_df = correct_rates_test_df(graph_explore_df)\n",
    "explore_graph_correct_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "metrics = [q.split(\"_\")[0] for q in question_types]\n",
    "rag_correct = rag_correct_df.iloc[:, 1]\n",
    "graph_rag_correct = graphrag_correct_df.iloc[:, 1]\n",
    "no_context_correct = no_context_correct_df.iloc[:, 1]\n",
    "graph_explore_correct = explore_graph_correct_df.iloc[:, 1]\n",
    "\n",
    "x = np.arange(len(metrics))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "labels = ['RAG', 'Graph RAG', 'Graph explore']\n",
    "# labels = ['qwen2', 'gpt-4o', 'llama 3.1']\n",
    "rects1 = ax.bar(x - width, rag_correct, width, label=labels[0])\n",
    "rects2 = ax.bar(x, graph_rag_correct, width, label=labels[1])\n",
    "rects3 = ax.bar(x + width, graph_explore_correct, width, label=labels[2])\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_ylabel('Correctness rate')\n",
    "ax.set_title(f'correctness rate on different LLMs with multi hop dataset')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "\n",
    "# ax.bar_label(rects1, padding=3)\n",
    "# ax.bar_label(rects2, padding=3)\n",
    "# ax.bar_label(rects3, padding=3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Graph RAG answer</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>time</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_type</th>\n",
       "      <th>correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the individual associated with the cryp...</td>\n",
       "      <td>Sam Bankman-Fried</td>\n",
       "      <td>0</td>\n",
       "      <td>37.237534</td>\n",
       "      <td>Sam Bankman-Fried</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which individual is implicated in both inflati...</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>0</td>\n",
       "      <td>37.965694</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is the figure associated with generative A...</td>\n",
       "      <td>Sam Altman</td>\n",
       "      <td>0</td>\n",
       "      <td>41.640990</td>\n",
       "      <td>Sam Altman</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do the TechCrunch article on software companie...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>48.165514</td>\n",
       "      <td>Yes</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which online betting platform provides a welco...</td>\n",
       "      <td>BetMGM Sportsbook</td>\n",
       "      <td>0</td>\n",
       "      <td>38.791165</td>\n",
       "      <td>Caesars Sportsbook</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Who is the individual alleged to have built a ...</td>\n",
       "      <td>Sam Bankman-Fried</td>\n",
       "      <td>0</td>\n",
       "      <td>32.755790</td>\n",
       "      <td>Sam Bankman-Fried</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Does the TechCrunch article on Twitch's subscr...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>46.364660</td>\n",
       "      <td>Yes</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Does 'The New York Times' article attribute th...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>43.760442</td>\n",
       "      <td>Yes</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the name of the organization discussed...</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>0</td>\n",
       "      <td>49.839989</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Which company, as reported by both TechCrunch ...</td>\n",
       "      <td>Google</td>\n",
       "      <td>0</td>\n",
       "      <td>56.891946</td>\n",
       "      <td>Google</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Considering the information from a BBC article...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>2</td>\n",
       "      <td>113.124019</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Does 'The Age' article suggest that Australia'...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>38.367634</td>\n",
       "      <td>Yes</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>After the TechCrunch report on October 7, 2023...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>2</td>\n",
       "      <td>169.425284</td>\n",
       "      <td>Yes</td>\n",
       "      <td>temporal_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What is the first letter of the name of the co...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>74.493813</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Does 'The Independent - Life and Style' articl...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>3</td>\n",
       "      <td>256.141766</td>\n",
       "      <td>Yes</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Which entity is currently engaged with Amazon ...</td>\n",
       "      <td>EUROPEAN UNION REGULATORS</td>\n",
       "      <td>0</td>\n",
       "      <td>64.829352</td>\n",
       "      <td>European Commission</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Which company, known for its dominance in the ...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>5</td>\n",
       "      <td>647.942153</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Was there no change in the portrayal of Google...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>3</td>\n",
       "      <td>273.329597</td>\n",
       "      <td>no</td>\n",
       "      <td>temporal_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Considering the features highlighted in an art...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>56.091380</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Does the Sporting News article suggest that st...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>2</td>\n",
       "      <td>172.714560</td>\n",
       "      <td>no</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Considering the information from an article in...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>66.038777</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Has the advice provided by Sporting News to be...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>48.340851</td>\n",
       "      <td>no</td>\n",
       "      <td>temporal_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Which company, covered by Engadget and Polygon...</td>\n",
       "      <td>Valve</td>\n",
       "      <td>0</td>\n",
       "      <td>49.211265</td>\n",
       "      <td>Valve</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Was there inconsistency in Jada Pinkett Smith'...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>70.829818</td>\n",
       "      <td>no</td>\n",
       "      <td>temporal_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Considering the economic forecasts from a Bloo...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>2</td>\n",
       "      <td>141.434448</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Was the news about Taylor Swift's relationship...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>46.955098</td>\n",
       "      <td>no</td>\n",
       "      <td>temporal_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Has the portrayal of Google's market practices...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>61.100420</td>\n",
       "      <td>no</td>\n",
       "      <td>temporal_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Does the TechCrunch article suggest that Amazo...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>61.083943</td>\n",
       "      <td>Yes</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Did the report from Cnbc | World Business News...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>61.245452</td>\n",
       "      <td>no</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Did the coverage of ski resorts by 'The Indepe...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>3</td>\n",
       "      <td>292.169479</td>\n",
       "      <td>no</td>\n",
       "      <td>temporal_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Which company, according to articles from Tech...</td>\n",
       "      <td>Google</td>\n",
       "      <td>0</td>\n",
       "      <td>58.146347</td>\n",
       "      <td>Google</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Do 'The Verge' and 'Engadget' articles both su...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>45.500387</td>\n",
       "      <td>Yes</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Who is the individual associated with OpenAI, ...</td>\n",
       "      <td>Sam Altman</td>\n",
       "      <td>0</td>\n",
       "      <td>41.050654</td>\n",
       "      <td>Sam Altman</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>What company, recently reported by TechCrunch ...</td>\n",
       "      <td>Uber</td>\n",
       "      <td>0</td>\n",
       "      <td>40.176749</td>\n",
       "      <td>Uber</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>After TechCrunch reported on October 31, 2023,...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>51.005448</td>\n",
       "      <td>no</td>\n",
       "      <td>temporal_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Does the TechCrunch article on GPT-4 suggest a...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>59.749399</td>\n",
       "      <td>Yes</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Does the Sporting News article claim that Caes...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>42.437288</td>\n",
       "      <td>Yes</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Does the TechCrunch article on generative AI i...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>40.673841</td>\n",
       "      <td>Yes</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Considering the information from an article by...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>56.691853</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Considering the information from an article by...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>50.930622</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Between the TechCrunch report on Google's appr...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>57.332239</td>\n",
       "      <td>Yes</td>\n",
       "      <td>temporal_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Did The Independent - Sports report on the All...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>44.933208</td>\n",
       "      <td>no</td>\n",
       "      <td>temporal_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Does the TechCrunch article suggest that Sam A...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>39.303010</td>\n",
       "      <td>Yes</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Did the 'Fortune' report on Donald Trump's rea...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>4</td>\n",
       "      <td>379.932697</td>\n",
       "      <td>no</td>\n",
       "      <td>temporal_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>What entity, discussed in articles from both T...</td>\n",
       "      <td>Alameda Research</td>\n",
       "      <td>0</td>\n",
       "      <td>42.228332</td>\n",
       "      <td>Alameda Research</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Who is the individual associated with the rise...</td>\n",
       "      <td>Sam Altman</td>\n",
       "      <td>0</td>\n",
       "      <td>43.671867</td>\n",
       "      <td>Sam Altman</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Does the article from The Verge suggest that G...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>59.938986</td>\n",
       "      <td>Yes</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Does the TechCrunch article suggest that the s...</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>48.455516</td>\n",
       "      <td>no</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Considering the economic analysis from Bloombe...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>58.491586</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Considering an article from The Times of India...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>2</td>\n",
       "      <td>101.943066</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Question  \\\n",
       "0   Who is the individual associated with the cryp...   \n",
       "1   Which individual is implicated in both inflati...   \n",
       "2   Who is the figure associated with generative A...   \n",
       "3   Do the TechCrunch article on software companie...   \n",
       "4   Which online betting platform provides a welco...   \n",
       "5   Who is the individual alleged to have built a ...   \n",
       "6   Does the TechCrunch article on Twitch's subscr...   \n",
       "7   Does 'The New York Times' article attribute th...   \n",
       "8   What is the name of the organization discussed...   \n",
       "9   Which company, as reported by both TechCrunch ...   \n",
       "10  Considering the information from a BBC article...   \n",
       "11  Does 'The Age' article suggest that Australia'...   \n",
       "12  After the TechCrunch report on October 7, 2023...   \n",
       "13  What is the first letter of the name of the co...   \n",
       "14  Does 'The Independent - Life and Style' articl...   \n",
       "15  Which entity is currently engaged with Amazon ...   \n",
       "16  Which company, known for its dominance in the ...   \n",
       "17  Was there no change in the portrayal of Google...   \n",
       "18  Considering the features highlighted in an art...   \n",
       "19  Does the Sporting News article suggest that st...   \n",
       "20  Considering the information from an article in...   \n",
       "21  Has the advice provided by Sporting News to be...   \n",
       "22  Which company, covered by Engadget and Polygon...   \n",
       "23  Was there inconsistency in Jada Pinkett Smith'...   \n",
       "24  Considering the economic forecasts from a Bloo...   \n",
       "25  Was the news about Taylor Swift's relationship...   \n",
       "26  Has the portrayal of Google's market practices...   \n",
       "27  Does the TechCrunch article suggest that Amazo...   \n",
       "28  Did the report from Cnbc | World Business News...   \n",
       "29  Did the coverage of ski resorts by 'The Indepe...   \n",
       "30  Which company, according to articles from Tech...   \n",
       "31  Do 'The Verge' and 'Engadget' articles both su...   \n",
       "32  Who is the individual associated with OpenAI, ...   \n",
       "33  What company, recently reported by TechCrunch ...   \n",
       "34  After TechCrunch reported on October 31, 2023,...   \n",
       "35  Does the TechCrunch article on GPT-4 suggest a...   \n",
       "36  Does the Sporting News article claim that Caes...   \n",
       "37  Does the TechCrunch article on generative AI i...   \n",
       "38  Considering the information from an article by...   \n",
       "39  Considering the information from an article by...   \n",
       "40  Between the TechCrunch report on Google's appr...   \n",
       "41  Did The Independent - Sports report on the All...   \n",
       "42  Does the TechCrunch article suggest that Sam A...   \n",
       "43  Did the 'Fortune' report on Donald Trump's rea...   \n",
       "44  What entity, discussed in articles from both T...   \n",
       "45  Who is the individual associated with the rise...   \n",
       "46  Does the article from The Verge suggest that G...   \n",
       "47  Does the TechCrunch article suggest that the s...   \n",
       "48  Considering the economic analysis from Bloombe...   \n",
       "49  Considering an article from The Times of India...   \n",
       "\n",
       "             Graph RAG answer  Iteration        time  \\\n",
       "0           Sam Bankman-Fried          0   37.237534   \n",
       "1                Donald Trump          0   37.965694   \n",
       "2                  Sam Altman          0   41.640990   \n",
       "3                         Yes          0   48.165514   \n",
       "4           BetMGM Sportsbook          0   38.791165   \n",
       "5           Sam Bankman-Fried          0   32.755790   \n",
       "6                         Yes          0   46.364660   \n",
       "7                          No          0   43.760442   \n",
       "8                      OpenAI          0   49.839989   \n",
       "9                      Google          0   56.891946   \n",
       "10   Insufficient information          2  113.124019   \n",
       "11                         No          0   38.367634   \n",
       "12   Insufficient information          2  169.425284   \n",
       "13   Insufficient information          1   74.493813   \n",
       "14   Insufficient information          3  256.141766   \n",
       "15  EUROPEAN UNION REGULATORS          0   64.829352   \n",
       "16   Insufficient information          5  647.942153   \n",
       "17   Insufficient information          3  273.329597   \n",
       "18   Insufficient information          1   56.091380   \n",
       "19   Insufficient information          2  172.714560   \n",
       "20   Insufficient information          1   66.038777   \n",
       "21                         No          0   48.340851   \n",
       "22                      Valve          0   49.211265   \n",
       "23   Insufficient information          1   70.829818   \n",
       "24   Insufficient information          2  141.434448   \n",
       "25                         No          0   46.955098   \n",
       "26                         No          0   61.100420   \n",
       "27                        Yes          0   61.083943   \n",
       "28   Insufficient information          1   61.245452   \n",
       "29   Insufficient information          3  292.169479   \n",
       "30                     Google          0   58.146347   \n",
       "31                        Yes          0   45.500387   \n",
       "32                 Sam Altman          0   41.050654   \n",
       "33                       Uber          0   40.176749   \n",
       "34                         No          0   51.005448   \n",
       "35                         No          0   59.749399   \n",
       "36                        Yes          0   42.437288   \n",
       "37                        Yes          0   40.673841   \n",
       "38   Insufficient information          1   56.691853   \n",
       "39   Insufficient information          1   50.930622   \n",
       "40                         No          0   57.332239   \n",
       "41                         No          0   44.933208   \n",
       "42                        Yes          0   39.303010   \n",
       "43   Insufficient information          4  379.932697   \n",
       "44           Alameda Research          0   42.228332   \n",
       "45                 Sam Altman          0   43.671867   \n",
       "46                        Yes          0   59.938986   \n",
       "47                         No          0   48.455516   \n",
       "48   Insufficient information          1   58.491586   \n",
       "49   Insufficient information          2  101.943066   \n",
       "\n",
       "                      answer     question_type  correctness  \n",
       "0          Sam Bankman-Fried   inference_query         True  \n",
       "1               Donald Trump   inference_query         True  \n",
       "2                 Sam Altman   inference_query         True  \n",
       "3                        Yes  comparison_query         True  \n",
       "4         Caesars Sportsbook   inference_query        False  \n",
       "5          Sam Bankman-Fried   inference_query         True  \n",
       "6                        Yes  comparison_query         True  \n",
       "7                        Yes  comparison_query        False  \n",
       "8                     OpenAI   inference_query         True  \n",
       "9                     Google   inference_query         True  \n",
       "10  Insufficient Information        null_query         True  \n",
       "11                       Yes  comparison_query        False  \n",
       "12                       Yes    temporal_query        False  \n",
       "13  Insufficient Information        null_query         True  \n",
       "14                       Yes  comparison_query        False  \n",
       "15       European Commission   inference_query        False  \n",
       "16                    Amazon   inference_query        False  \n",
       "17                        no    temporal_query        False  \n",
       "18  Insufficient Information        null_query         True  \n",
       "19                        no  comparison_query        False  \n",
       "20  Insufficient Information        null_query         True  \n",
       "21                        no    temporal_query         True  \n",
       "22                     Valve   inference_query         True  \n",
       "23                        no    temporal_query        False  \n",
       "24  Insufficient Information        null_query         True  \n",
       "25                        no    temporal_query         True  \n",
       "26                        no    temporal_query         True  \n",
       "27                       Yes  comparison_query         True  \n",
       "28                        no  comparison_query        False  \n",
       "29                        no    temporal_query        False  \n",
       "30                    Google   inference_query         True  \n",
       "31                       Yes  comparison_query         True  \n",
       "32                Sam Altman   inference_query         True  \n",
       "33                      Uber   inference_query         True  \n",
       "34                        no    temporal_query         True  \n",
       "35                       Yes  comparison_query        False  \n",
       "36                       Yes  comparison_query         True  \n",
       "37                       Yes  comparison_query         True  \n",
       "38  Insufficient Information        null_query         True  \n",
       "39  Insufficient Information        null_query         True  \n",
       "40                       Yes    temporal_query        False  \n",
       "41                        no    temporal_query         True  \n",
       "42                       Yes  comparison_query         True  \n",
       "43                        no    temporal_query        False  \n",
       "44          Alameda Research   inference_query         True  \n",
       "45                Sam Altman   inference_query         True  \n",
       "46                       Yes  comparison_query         True  \n",
       "47                        no  comparison_query         True  \n",
       "48  Insufficient Information        null_query         True  \n",
       "49  Insufficient Information        null_query         True  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_explore_df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Graph RAG answer</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>time</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_type</th>\n",
       "      <th>correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Considering the information from a BBC article...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>2</td>\n",
       "      <td>113.124019</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>After the TechCrunch report on October 7, 2023...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>2</td>\n",
       "      <td>169.425284</td>\n",
       "      <td>Yes</td>\n",
       "      <td>temporal_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What is the first letter of the name of the co...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>74.493813</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Does 'The Independent - Life and Style' articl...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>3</td>\n",
       "      <td>256.141766</td>\n",
       "      <td>Yes</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Which company, known for its dominance in the ...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>5</td>\n",
       "      <td>647.942153</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>inference_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Was there no change in the portrayal of Google...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>3</td>\n",
       "      <td>273.329597</td>\n",
       "      <td>no</td>\n",
       "      <td>temporal_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Considering the features highlighted in an art...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>56.091380</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Does the Sporting News article suggest that st...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>2</td>\n",
       "      <td>172.714560</td>\n",
       "      <td>no</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Considering the information from an article in...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>66.038777</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Was there inconsistency in Jada Pinkett Smith'...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>70.829818</td>\n",
       "      <td>no</td>\n",
       "      <td>temporal_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Considering the economic forecasts from a Bloo...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>2</td>\n",
       "      <td>141.434448</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Did the report from Cnbc | World Business News...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>61.245452</td>\n",
       "      <td>no</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Did the coverage of ski resorts by 'The Indepe...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>3</td>\n",
       "      <td>292.169479</td>\n",
       "      <td>no</td>\n",
       "      <td>temporal_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Considering the information from an article by...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>56.691853</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Considering the information from an article by...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>50.930622</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Did the 'Fortune' report on Donald Trump's rea...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>4</td>\n",
       "      <td>379.932697</td>\n",
       "      <td>no</td>\n",
       "      <td>temporal_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Considering the economic analysis from Bloombe...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>58.491586</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Considering an article from The Times of India...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>2</td>\n",
       "      <td>101.943066</td>\n",
       "      <td>Insufficient Information</td>\n",
       "      <td>null_query</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Does the article from Polygon discussing the B...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>3</td>\n",
       "      <td>214.270641</td>\n",
       "      <td>no</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Did the Yardbarker article describe Alex Verdu...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>79.687169</td>\n",
       "      <td>Yes</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Does the CBSSports.com article suggest that th...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>83.827862</td>\n",
       "      <td>Yes</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Did CBSSports.com change its reporting on the ...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>2</td>\n",
       "      <td>169.622060</td>\n",
       "      <td>no</td>\n",
       "      <td>temporal_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Does the 'Live Science: The Most Interesting A...</td>\n",
       "      <td>Insufficient information</td>\n",
       "      <td>1</td>\n",
       "      <td>70.496258</td>\n",
       "      <td>Agree</td>\n",
       "      <td>comparison_query</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Question  \\\n",
       "10  Considering the information from a BBC article...   \n",
       "12  After the TechCrunch report on October 7, 2023...   \n",
       "13  What is the first letter of the name of the co...   \n",
       "14  Does 'The Independent - Life and Style' articl...   \n",
       "16  Which company, known for its dominance in the ...   \n",
       "17  Was there no change in the portrayal of Google...   \n",
       "18  Considering the features highlighted in an art...   \n",
       "19  Does the Sporting News article suggest that st...   \n",
       "20  Considering the information from an article in...   \n",
       "23  Was there inconsistency in Jada Pinkett Smith'...   \n",
       "24  Considering the economic forecasts from a Bloo...   \n",
       "28  Did the report from Cnbc | World Business News...   \n",
       "29  Did the coverage of ski resorts by 'The Indepe...   \n",
       "38  Considering the information from an article by...   \n",
       "39  Considering the information from an article by...   \n",
       "43  Did the 'Fortune' report on Donald Trump's rea...   \n",
       "48  Considering the economic analysis from Bloombe...   \n",
       "49  Considering an article from The Times of India...   \n",
       "51  Does the article from Polygon discussing the B...   \n",
       "72  Did the Yardbarker article describe Alex Verdu...   \n",
       "73  Does the CBSSports.com article suggest that th...   \n",
       "79  Did CBSSports.com change its reporting on the ...   \n",
       "89  Does the 'Live Science: The Most Interesting A...   \n",
       "\n",
       "            Graph RAG answer  Iteration        time                    answer  \\\n",
       "10  Insufficient information          2  113.124019  Insufficient Information   \n",
       "12  Insufficient information          2  169.425284                       Yes   \n",
       "13  Insufficient information          1   74.493813  Insufficient Information   \n",
       "14  Insufficient information          3  256.141766                       Yes   \n",
       "16  Insufficient information          5  647.942153                    Amazon   \n",
       "17  Insufficient information          3  273.329597                        no   \n",
       "18  Insufficient information          1   56.091380  Insufficient Information   \n",
       "19  Insufficient information          2  172.714560                        no   \n",
       "20  Insufficient information          1   66.038777  Insufficient Information   \n",
       "23  Insufficient information          1   70.829818                        no   \n",
       "24  Insufficient information          2  141.434448  Insufficient Information   \n",
       "28  Insufficient information          1   61.245452                        no   \n",
       "29  Insufficient information          3  292.169479                        no   \n",
       "38  Insufficient information          1   56.691853  Insufficient Information   \n",
       "39  Insufficient information          1   50.930622  Insufficient Information   \n",
       "43  Insufficient information          4  379.932697                        no   \n",
       "48  Insufficient information          1   58.491586  Insufficient Information   \n",
       "49  Insufficient information          2  101.943066  Insufficient Information   \n",
       "51  Insufficient information          3  214.270641                        no   \n",
       "72  Insufficient information          1   79.687169                       Yes   \n",
       "73  Insufficient information          1   83.827862                       Yes   \n",
       "79  Insufficient information          2  169.622060                        no   \n",
       "89  Insufficient information          1   70.496258                     Agree   \n",
       "\n",
       "       question_type  correctness  \n",
       "10        null_query         True  \n",
       "12    temporal_query        False  \n",
       "13        null_query         True  \n",
       "14  comparison_query        False  \n",
       "16   inference_query        False  \n",
       "17    temporal_query        False  \n",
       "18        null_query         True  \n",
       "19  comparison_query        False  \n",
       "20        null_query         True  \n",
       "23    temporal_query        False  \n",
       "24        null_query         True  \n",
       "28  comparison_query        False  \n",
       "29    temporal_query        False  \n",
       "38        null_query         True  \n",
       "39        null_query         True  \n",
       "43    temporal_query        False  \n",
       "48        null_query         True  \n",
       "49        null_query         True  \n",
       "51  comparison_query        False  \n",
       "72  comparison_query        False  \n",
       "73  comparison_query        False  \n",
       "79    temporal_query        False  \n",
       "89  comparison_query        False  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_iter_df = graph_explore_df[graph_explore_df['Iteration'] > 0]\n",
    "first_iter_df\n",
    "# first_iter_correct_df = correct_rates_test_df(first_iter_df)\n",
    "# first_iter_correct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
