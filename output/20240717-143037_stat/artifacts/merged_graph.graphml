<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d6" for="edge" attr.name="source_id" attr.type="string" />
  <key id="d5" for="edge" attr.name="description" attr.type="string" />
  <key id="d4" for="edge" attr.name="weight" attr.type="double" />
  <key id="d3" for="node" attr.name="entity_type" attr.type="string" />
  <key id="d2" for="node" attr.name="source_id" attr.type="string" />
  <key id="d1" for="node" attr.name="description" attr.type="string" />
  <key id="d0" for="node" attr.name="type" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="ST231">
      <data key="d0">LECTURE NOTES</data>
      <data key="d1">ST231 is a set of lecture notes that cover various topics in linear regression and related statistical concepts</data>
      <data key="d2">54206a4a813f5be515f41653e9422eeb</data>
    </node>
    <node id="SIMPLE LINEAR REGRESSION">
      <data key="d0">STATISTICAL CONCEPT</data>
      <data key="d1">Simple linear regression is a statistical method used to model the relationship between a dependent variable and one independent variable</data>
      <data key="d2">54206a4a813f5be515f41653e9422eeb</data>
    </node>
    <node id="TERMINOLOGY AND NOTATION">
      <data key="d0">STATISTICAL CONCEPT</data>
      <data key="d1">Terminology and notation are the language and symbols used in the field of statistics, including terms like dependent variable, independent variable, and regression coefficients</data>
      <data key="d2">54206a4a813f5be515f41653e9422eeb</data>
    </node>
    <node id="MULTIPLE REGRESSION">
      <data key="d0">STATISTICAL CONCEPT</data>
      <data key="d1">Multiple regression is a statistical method used to model the relationship between a dependent variable and two or more independent variables</data>
      <data key="d2">54206a4a813f5be515f41653e9422eeb</data>
    </node>
    <node id="LINEAR MODELS">
      <data key="d0">STATISTICAL CONCEPT</data>
      <data key="d1">Linear models are a class of statistical models that assume a linear relationship between the dependent variable and the independent variables</data>
      <data key="d2">54206a4a813f5be515f41653e9422eeb</data>
    </node>
    <node id="ANSCOMBE'S QUARTET">
      <data key="d0">STATISTICAL CONCEPT</data>
      <data key="d1">Anscombe's Quartet is a group of four datasets that have nearly identical simple descriptive statistics but appear very different when graphed</data>
      <data key="d2">54206a4a813f5be515f41653e9422eeb</data>
    </node>
    <node id="POLYNOMIAL REGRESSION">
      <data key="d0">STATISTICAL CONCEPT</data>
      <data key="d1">Polynomial regression is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modeled as an nth degree polynomial</data>
      <data key="d2">54206a4a813f5be515f41653e9422eeb</data>
    </node>
    <node id="LINEARITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Linearity is a fundamental concept in statistical modelling, referring to the relationship between variables where a change in one variable is associated with a proportional change in another variable. It is a key assumption in linear regression models.&gt;
Linearity is the property of a model where the systematic component is a linear function of the explanatory variables, which is a restrictive class of models that can only describe certain types of relationships
Linearity is the property of the relationship between the response and the log-transformed explanatory variable, which appears to be fairly linear
Linearity is the assumption that the linear predictor X&#946; adequately describes the mean function of the response variable
Linearity is an assumption in linear regression models that the relationship between the explanatory variables and the response variable is linear
Linearity is the assumption that the relationship between the response variable and the explanatory variables is linear. Transformations of variables can help meet this assumption.</data>
      <data key="d2">25fce1af816975003128126b5cfea73b,35bac6a2c3eb466ca9fc7b31bf2cc42c,3cbe71f7649e84cd67cb3fa0d3e632cf,6616e10c85e86291147e72776854b8a2,7cd6069e88e81548a237fa937adfecc6,c03eb12d07d48f9e94260f08dae10cdf</data>
    </node>
    <node id="ANSCOMBES_QUARTET">
      <data key="d0">EXAMPLE</data>
      <data key="d1">Anscombe's Quartet is a group of four datasets that have nearly identical simple descriptive statistics, yet appear very different when graphed. Each dataset consists of eleven (x,y) points. They were constructed in 1973 by the statistician Francis Anscombe to demonstrate both the importance of graphing data before analyzing it and the effect of outliers on statistical properties.&gt;</data>
      <data key="d2">35bac6a2c3eb466ca9fc7b31bf2cc42c</data>
    </node>
    <node id="POLYNOMIAL_REGRESSION">
      <data key="d0">MODEL</data>
      <data key="d1">Polynomial regression is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modelled as an nth degree polynomial in x. Polynomial regression fits a nonlinear relationship between the value of x and the corresponding conditional mean of y, denoted E(y |x). Although polynomial regression fits a nonlinear model to the data, as a statistical estimation problem it is linear, in the sense that the regression function E(y | x) is linear in the unknown parameters that are estimated from the data.&gt;
Polynomial regression is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modeled as an nth degree polynomial
Polynomial regression is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modeled as an nth degree polynomial.
Polynomial regression is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modeled as an nth degree polynomial
Polynomial regression is a type of regression analysis that models the relationship between a dependent variable and one or more independent variables using a polynomial function
Polynomial regression is a type of regression analysis where the relationship between the response variable and the predictor variable is modeled using a polynomial function. In this context, it is of order 2, making it a non-linear function in terms of the predictor variable, but still considered a linear model due to its linearity in the parameters.
Polynomial regression is a type of linear model that includes polynomials of the explanatory variables
Polynomial regression is a type of linear model that includes polynomials of the explanatory variables. It is used when the relationship between the dependent and independent variables is not linear.</data>
      <data key="d2">0328e428a30c44572676dd571dd1e9bd,084dadebfca8bcb6377c205c45bee295,11452a08471d93959558de2ece9a69af,188219b9e5b6b6368360840921877de9,35bac6a2c3eb466ca9fc7b31bf2cc42c,87ba4f416a28aabc3b396908f5913b54,b8ec334f8c87bf1d9cb6043fa1a64214,b9af17718641389ba07f53be13f31f8c</data>
    </node>
    <node id="LOG_TRANSFORMED_PREDICTOR">
      <data key="d0">MODEL</data>
      <data key="d1">A linear model with a log-transformed predictor is a type of statistical model where the predictor variable is transformed using the logarithmic function. This transformation is often used when the relationship between the predictor and the response variable is not linear but becomes linear after the transformation.&gt;
The log-transformed predictor is the logarithmic transformation of the diameter used in the linear model</data>
      <data key="d2">35bac6a2c3eb466ca9fc7b31bf2cc42c,656dce234514b9db38b5b5616557c1e9</data>
    </node>
    <node id="STRATEGY_FOR_STATISTICAL_MODELLING">
      <data key="d0">GUIDELINE</data>
      <data key="d1">A strategy for statistical modelling involves a series of steps and considerations to build, validate, and interpret statistical models. This includes defining the research question, choosing the appropriate model, checking model assumptions, interpreting results, and validating the model.&gt;</data>
      <data key="d2">35bac6a2c3eb466ca9fc7b31bf2cc42c</data>
    </node>
    <node id="GOOD_MODEL">
      <data key="d0">CRITERIA</data>
      <data key="d1">What makes a good model in statistical analysis can be determined by several criteria, including the model's ability to accurately predict outcomes, its simplicity, the relevance of the variables included, and its ability to meet the assumptions of the statistical test being used.&gt;
The criteria for a good model include its purpose, such as description, prediction, or inference, and its ability to accurately represent the data and answer the questions of interest</data>
      <data key="d2">35bac6a2c3eb466ca9fc7b31bf2cc42c,bb31f1c77bbba73300f735a100086a67</data>
    </node>
    <node id="SUMMARY_OF_CHAPTER_2">
      <data key="d0">SUMMARY</data>
      <data key="d1">The summary of Chapter 2 likely includes a recap of the topics covered in the chapter, which are related to linearity in statistical models, including Anscombe's Quartet, polynomial regression, models with log-transformed predictors, a strategy for statistical modelling, and criteria for a good model.&gt;</data>
      <data key="d2">35bac6a2c3eb466ca9fc7b31bf2cc42c</data>
    </node>
    <node id="RESIDUAL_ANALYSIS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Residual analysis is a method used in regression analysis to assess the quality of the model and to check the assumptions of linearity, homoscedasticity, independence, and normality of residuals. Residuals are the differences between the observed values and the values predicted by the model.&gt;
Residual analysis is a method used to assess the adequacy of model assumptions in a linear model. It involves examining the residuals, which are the differences between the observed and predicted values, to check for patterns that might indicate violations of model assumptions.
Residual analysis is a method used in regression analysis to assess the fit of a model by examining the residuals, which are the differences between the observed and predicted values
Residual analysis is a statistical method used to evaluate the validity of a model by analyzing the residuals (the difference between the observed and predicted values). It is used to check the assumptions of a regression model, such as linearity, homoscedasticity, independence, and normality of errors.</data>
      <data key="d2">0328e428a30c44572676dd571dd1e9bd,35bac6a2c3eb466ca9fc7b31bf2cc42c,3bfc9b92571973e54c8095302acc1aaa,aa13c33a7e61206e6021e2736002ca9a</data>
    </node>
    <node id="CHAPTER 2">
      <data key="d0">CHAPTER</data>
      <data key="d1">Chapter 2 of a book or document, which is summarized on page 37</data>
      <data key="d2">752d1285c8b1e15a2e175515f77ddd5a</data>
    </node>
    <node id="RESIDUAL ANALYSIS">
      <data key="d0">SECTION</data>
      <data key="d1">Section 3 of the document, which discusses residual analysis starting on page 38</data>
      <data key="d2">752d1285c8b1e15a2e175515f77ddd5a</data>
    </node>
    <node id="DEFINITIONS">
      <data key="d0">SUBSECTION</data>
      <data key="d1">Subsection 3.1 of the document, which provides definitions related to residual analysis on page 38</data>
      <data key="d2">752d1285c8b1e15a2e175515f77ddd5a</data>
    </node>
    <node id="MODEL ASSUMPTIONS">
      <data key="d0">SUBSECTION</data>
      <data key="d1">Subsection 3.2 of the document, which discusses the assumptions of the model on page 40</data>
      <data key="d2">752d1285c8b1e15a2e175515f77ddd5a</data>
    </node>
    <node id="RESIDUAL PLOTS">
      <data key="d0">SUBSECTION</data>
      <data key="d1">Subsection 3.3 of the document, which explains residual plots on page 41</data>
      <data key="d2">752d1285c8b1e15a2e175515f77ddd5a</data>
    </node>
    <node id="ASSESSING NORMALITY">
      <data key="d0">SUBSECTION</data>
      <data key="d1">Subsection 3.4 of the document, which discusses methods for assessing normality on page 47</data>
      <data key="d2">752d1285c8b1e15a2e175515f77ddd5a</data>
    </node>
    <node id="SUMMARY OF CHAPTER 3">
      <data key="d0">SUBSECTION</data>
      <data key="d1">Subsection 3.5 of the document, which summarizes Chapter 3 on page 50</data>
      <data key="d2">752d1285c8b1e15a2e175515f77ddd5a</data>
    </node>
    <node id="NON-LINEAR TRANSFORMATIONS">
      <data key="d0">SECTION</data>
      <data key="d1">Section 4 of the document, which discusses non-linear transformations starting on page 51</data>
      <data key="d2">752d1285c8b1e15a2e175515f77ddd5a</data>
    </node>
    <node id="THE LOG-TRANSFORMATION">
      <data key="d0">SUBSECTION</data>
      <data key="d1">Subsection 4.1 of the document, which discusses the log-transformation</data>
      <data key="d2">752d1285c8b1e15a2e175515f77ddd5a</data>
    </node>
    <node id="CHAPTER_3">
      <data key="d0">CHAPTER</data>
      <data key="d1">Chapter 3 is a section in a document that likely discusses a specific topic or set of topics related to the document's subject matter</data>
      <data key="d2">9846990771550ccdb865e49ecb96e2a3</data>
    </node>
    <node id="NON_LINEAR_TRANSFORMATIONS">
      <data key="d0">TOPIC</data>
      <data key="d1">Non-linear transformations is a topic discussed in Chapter 4, which likely covers methods for transforming data that do not follow a linear relationship
Non-linear transformations are one of the remedial actions that can be taken to address violations of the modelling assumptions
Non-linear transformations are mathematical operations applied to variables to address model violations. They can help meet the assumption of linearity, address heteroscedasticity, and reduce the influence of unusual observations.
Non-linear transformations are adjustments made to the response and/or explanatory variables to resolve violations of model assumptions, such as linearity and heteroscedasticity
Non-linear transformations are mathematical operations applied to variables in a model to address violations of model assumptions, such as non-linearity, heteroscedasticity, or the influence of unusual observations. These transformations can help meet the assumptions of linearity and homoscedasticity, and reduce the impact of outliers.</data>
      <data key="d2">07951ffe6787af44aa60c90c69e62f83,9846990771550ccdb865e49ecb96e2a3,c03eb12d07d48f9e94260f08dae10cdf,d71b402ab9edbb4347e09c7af3257cf5,e361ac139c268d5c3f3623f920e68af2</data>
    </node>
    <node id="LOG_TRANSFORMATION">
      <data key="d0">TRANSFORMATION</data>
      <data key="d1">The log-transformation is a specific type of non-linear transformation discussed in Chapter 4, used to change the scale of data, often to make it more linear or to stabilize variance
Log transformation is a data transformation technique used to stabilize the variance and make the distribution more symmetrical
Log transformation is a specific type of non-linear transformation that is often used to address certain forms of heteroscedasticity and to linearize relationships between variables. It can also help in reducing the influence of outliers.</data>
      <data key="d2">07951ffe6787af44aa60c90c69e62f83,66f7fae9d896ff2b3fd40186cc833503,9846990771550ccdb865e49ecb96e2a3</data>
    </node>
    <node id="MAMMALS_DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The mammals dataset is a set of data that is likely used as an example or case study in Chapter 4 to illustrate the application of non-linear transformations
The mammals dataset is a collection of data from the MASS package, containing the average body weight and average brain weight for 62 species of land mammal
The mammals dataset contains information about body weight and brain weight for various mammal species
Mammals dataset is a dataset from the MASS package, containing information about mammals, including average brain and body weight
The mammals dataset is a dataset from the MASS package in R, containing information about mammals, including average brain weight and average body weight.
Mammals dataset contains data on average brain and body weights for various mammals
The mammals dataset contains data on various mammals, including their average brain and body weights.&gt;
The mammals dataset is a collection of data on mammals, which may contain influential data points, such as elephants</data>
      <data key="d2">66f7fae9d896ff2b3fd40186cc833503,83bb91cf725e5116ca2f5748fddccfae,9846990771550ccdb865e49ecb96e2a3,9e2ebbb113c00fa43f0af3c0696baf95,bd05fe6a05f9a13d33c4f1b5a771ada5,c47968226557bc2eb5aec5bb7994fd0e,f0b1289a0623b82a686b3b7dfb3a6ee8,f9d6c3504b8f8b5c25550076e45f8270</data>
    </node>
    <node id="TREES_DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The trees dataset is another set of data that is likely used as an example or case study in Chapter 4 to illustrate the application of non-linear transformations
Trees dataset contains measurements of 31 felled black cherry trees, including height, girth, and volume
The trees dataset is a collection of data on trees, including measurements such as volume, diameter, and height
The trees dataset is a collection of data on tree dimensions, including volume, diameter, and height</data>
      <data key="d2">9846990771550ccdb865e49ecb96e2a3,a60af43e42c72a41fa90da06beb29d1b,d71b402ab9edbb4347e09c7af3257cf5,efeeb664622c1ee594e6a08a8322ffe3</data>
    </node>
    <node id="CHAPTER_4">
      <data key="d0">CHAPTER</data>
      <data key="d1">Chapter 4 is a section in a document that likely discusses non-linear transformations, including specific examples such as the log-transformation and the use of the mammals and trees datasets</data>
      <data key="d2">9846990771550ccdb865e49ecb96e2a3</data>
    </node>
    <node id="LEAST_SQUARES_ESTIMATION">
      <data key="d0">TOPIC</data>
      <data key="d1">Least squares estimation is a topic discussed in Chapter 5, which likely covers methods for estimating model parameters by minimizing the sum of the squares of the residuals
Least squares estimation is a statistical method for estimating the parameters of a model by minimizing the sum of the squares of the residuals. It is widely used in regression analysis to find the line of best fit.&gt;
Least squares estimation is a method used in regression analysis to find the line or plane of best fit by minimizing the sum of the squared residuals
Least squares estimation is a statistical method used to find the plane of best fit by minimizing the sum of squared distances along the z-axis between the observed datapoints and the corresponding plane
Least squares estimation is a statistical method used to fit models where the systematic component can be written as the product between a design matrix and a parameter vector, allowing for more general models
Least squares estimation is a statistical method used to fit models where the systematic component can be written as the product between a design matrix and a parameter vector
Least squares estimation is a method for fitting a model to data by minimizing the sum of the squares of the residuals (the difference between the observed values and the values predicted by the model).
Least squares estimation is an algorithm used to estimate the parameters of a linear model. It minimizes the sum of the squared differences between the observed values and the values predicted by the model.
Least squares estimation is a method used to estimate the parameters of a statistical model by minimizing the sum of the squares of the residuals. It provides a closed-form expression for the parameter estimates and is the basis for many statistical analyses, particularly in linear regression.
Least squares estimation is a statistical method for estimating the parameters of a model by minimizing the sum of the squares of the residuals. It is widely used in regression analysis to find the best fit line or curve for a set of data points. The method provides a closed-form expression for the parameter vector estimate, which is crucial for understanding the mathematical underpinning of model fitting. In the context of linear models, least squares estimation is used to derive the coefficients of the model that best explain the observed data. The technique is also foundational for re-parameterizations of models and for finding maximum likelihood estimates in normal linear models.&gt;</data>
      <data key="d2">07951ffe6787af44aa60c90c69e62f83,6616e10c85e86291147e72776854b8a2,87ba4f416a28aabc3b396908f5913b54,8a9b984c146f59b2af83d1c2f373d376,924be3e598ffeabd1fbd9b57f033b917,9846990771550ccdb865e49ecb96e2a3,9f335f1ecb85a1427df926df8bb1e89f,b1690cb1a67892245c0665e5099e322d,b9af17718641389ba07f53be13f31f8c,cf6e59c3746d399dc8baf5064f78ac57</data>
    </node>
    <node id="LEAST_SQUARES_ESTIMATE">
      <data key="d0">ESTIMATION_METHOD</data>
      <data key="d1">The least squares estimate is a specific method of estimating model parameters discussed in Chapter 5, which involves minimizing the sum of the squares of the residuals
The least squares estimate for &#181; = (&#181;A, &#181;B, &#181;C) is given by a formula involving the sales of each brand</data>
      <data key="d2">096afa471635bc59c3bfa9af4d04d625,9846990771550ccdb865e49ecb96e2a3</data>
    </node>
    <node id="SIMPLE_LINEAR_REGRESSION">
      <data key="d0">REGRESSION_METHOD</data>
      <data key="d1">Simple linear regression is a statistical method for modeling the relationship between a dependent variable and one independent variable, discussed as an example in Chapter 5
Simple linear regression is a statistical method used to summarize and study relationships between two continuous (real-valued) variables: One variable, denoted x, is regarded as the predictor, explanatory, or independent variable. The other variable, denoted y, is regarded as the response, outcome, or dependent variable.&gt;
Simple linear regression is the simplest form of a linear model, which involves one explanatory variable and one outcome variable
Simple linear regression is a type of linear model that describes the relationship between a dependent variable and a single independent variable
Simple linear regression is a statistical method used to model the relationship between a response variable Y and an explanatory variable X
Simple linear regression is a statistical method used to model the relationship between a dependent variable (response variable) and an independent variable (explanatory variable). It is used to understand how the response variable changes when the explanatory variable is varied.
Simple linear regression is a statistical method used to model the relationship between a dependent variable and one independent variable
The simple linear regression model uses only one predictor variable, in this case price, to predict the dependent variable Y
A simple linear regression model is a statistical method used to analyze the relationship between two continuous variables: a dependent variable and an independent variable. In this case, the model uses price as the only predictor variable.&gt;
Simple linear regression is a statistical method used to model the relationship between a dependent variable Y and an independent variable X. The model assumes that the distribution of Y depends on the value of X, and X is considered non-random. The relationship is described by the equation Yj = &#946;0 + &#946;1xj + &#1013;j, where &#946;0 is the intercept, &#946;1 is the slope, xj is the observed value of X, and &#1013;j is the error term, assumed to be normally distributed with mean zero and variance &#963;^2.
Simple linear regression is the statistical model used to fit the data, assuming a linear relationship between the response and the explanatory variable
Simple linear regression is a statistical method used to model the relationship between a dependent variable and one independent variable
Simple linear regression is a statistical model used to analyze the relationship between a response variable and one or more explanatory variables
Simple linear regression is a statistical method used to model the relationship between a scalar response (or dependent variable) and a single explanatory variable (or independent variable). It assumes a linear relationship between the two variables and aims to find the line of best fit that minimizes the sum of the squared residuals. The method is a special case of multiple linear regression, where there is only one predictor. In the context of least squares estimation, simple linear regression provides an illustrative example of how the least squares estimate of the parameter vector can be derived and used to make predictions.&gt;
Simple linear regression is a specific case of linear regression where there is only one predictor variable
Simple linear regression is a statistical method used to model the relationship between a dependent variable and a single independent variable. The formula for calculating leverages in simple linear regression is provided.
Simple linear regression is a type of statistical model that uses one independent variable to predict a dependent variable.
Simple linear regression is a statistical model used to analyze the relationship between a response variable and a single predictor variable</data>
      <data key="d2">15c7b5750483a382ce59751008e86751,25fce1af816975003128126b5cfea73b,28eee75e95bbbaf143368c3289585670,426434b67f6a287852ab66b82ca873cf,4683e58cf41e5f5d415a63ddb2fe0cac,512d9ffebe309a6f944ebce1ae2ff2a3,74a5a0e8ae0f846240c782cc1a30f82f,7b32c106246576bb451a5a3985914351,86ece4718d27d1a6c6a1f448cc850e2b,8a9b984c146f59b2af83d1c2f373d376,924be3e598ffeabd1fbd9b57f033b917,9846990771550ccdb865e49ecb96e2a3,a4a817bb79d6ae8812c808ca41d47f43,aa13c33a7e61206e6021e2736002ca9a,cf6e59c3746d399dc8baf5064f78ac57,e079b7c92d5c0b009ff02040eb652bc6,e47d573a10e64a657e58218df64d8920,f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </node>
    <node id="CHAPTER_5">
      <data key="d0" />
      <data key="d1">
Chapter 5 is a section in a document that likely discusses a specific topic related to the text's subject matter</data>
      <data key="d2">9133320d451c1c1eddf1438064663b17,9846990771550ccdb865e49ecb96e2a3</data>
    </node>
    <node id="DERIVATION_OF_LSE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Derivation of the least squares estimate (LSE) involves the process of finding the parameters of a model that minimize the sum of the squares of the residuals. This process often involves calculus and linear algebra.&gt;</data>
      <data key="d2">cf6e59c3746d399dc8baf5064f78ac57</data>
    </node>
    <node id="INVERTIBLE_LINEAR_TRANSFORMATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Invertible linear transformations are linear transformations for which there exists an inverse transformation. They are important in linear algebra and are used in various mathematical and statistical contexts, including the transformation of variables in regression analysis.&gt;
Invertible linear transformations are operations that produce re-parameterisations of a model, affecting the interpretation of the parameters but not the fitted values, residuals, or deviance</data>
      <data key="d2">255685e281cc5a9edf073c700f425a6b,cf6e59c3746d399dc8baf5064f78ac57</data>
    </node>
    <node id="SUMMARY_OF_CHAPTER_5">
      <data key="d0">CONCEPT</data>
      <data key="d1">Summary of Chapter 5 refers to a condensed overview of the key points and concepts covered in Chapter 5 of a text, which in this context is about least squares estimation and related topics.&gt;
Summary of Chapter 5 provides a brief overview or recap of the main points covered in Chapter 5</data>
      <data key="d2">9133320d451c1c1eddf1438064663b17,cf6e59c3746d399dc8baf5064f78ac57</data>
    </node>
    <node id="MAXIMUM_LIKELIHOOD_ESTIMATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Maximum likelihood estimation (MLE) is a method of estimating the parameters of a statistical model, given observations. The method chooses the parameter values that maximize the likelihood function, which is a function of the parameters that gives the probability of the observed data.&gt;</data>
      <data key="d2">cf6e59c3746d399dc8baf5064f78ac57</data>
    </node>
    <node id="LIKELIHOOD_FUNCTION_OF_NORMAL_LINEAR_MODEL">
      <data key="d0">CONCEPT</data>
      <data key="d1">The likelihood function of a normal linear model is the function that describes the probability of observing the given data under the assumption that the data follows a normal distribution with a linear relationship between the variables.&gt;</data>
      <data key="d2">cf6e59c3746d399dc8baf5064f78ac57</data>
    </node>
    <node id="CHAPTER_6">
      <data key="d0">CHAPTER</data>
      <data key="d1">Chapter 6 is a section in a document that likely discusses a specific topic related to the text's subject matter, focusing on Maximum likelihood estimation</data>
      <data key="d2">9133320d451c1c1eddf1438064663b17</data>
    </node>
    <node id="LIKELIHOOD_FUNCTION">
      <data key="d0">FUNCTION</data>
      <data key="d1">The likelihood function of a normal linear model is a statistical function used to estimate the parameters of a normal linear model
Likelihood function is a function that describes the probability of obtaining the observed data as a function of the parameters of the model.
The likelihood function is a measure of how likely a set of data is given a specific model and parameters</data>
      <data key="d2">9133320d451c1c1eddf1438064663b17,d738df7d83784c8a41b3948271c537b6,f483798b15ef305e7826fd7142379e03</data>
    </node>
    <node id="MLE_PARAMETER_VECTOR">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">The MLE for the parameter vector is the maximum likelihood estimator for the vector of parameters in a statistical model</data>
      <data key="d2">9133320d451c1c1eddf1438064663b17</data>
    </node>
    <node id="SAMPLING_DISTRIBUTION_LEAST_SQUARES">
      <data key="d0">DISTRIBUTION</data>
      <data key="d1">Sampling distribution of the least squares estimator is the distribution of the least squares estimator over many samples</data>
      <data key="d2">9133320d451c1c1eddf1438064663b17</data>
    </node>
    <node id="UNBIASED_ESTIMATOR_ERROR_VARIANCE">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">Unbiased estimator for the error variance is an estimator of the error variance that is not systematically biased</data>
      <data key="d2">9133320d451c1c1eddf1438064663b17</data>
    </node>
    <node id="SUMMARY_OF_CHAPTER_6">
      <data key="d0">SUMMARY</data>
      <data key="d1">Summary of Chapter 6 provides a brief overview or recap of the main points covered in Chapter 6</data>
      <data key="d2">9133320d451c1c1eddf1438064663b17</data>
    </node>
    <node id="CHAPTER_7">
      <data key="d0">CHAPTER</data>
      <data key="d1">Chapter 7 is a section in a document that likely discusses a specific topic related to the text's subject matter, focusing on the hat matrix</data>
      <data key="d2">9133320d451c1c1eddf1438064663b17</data>
    </node>
    <node id="HAT_MATRIX_PROPERTIES">
      <data key="d0">PROPERTIES</data>
      <data key="d1">Properties of the hat matrix are characteristics or features of the hat matrix in a statistical context</data>
      <data key="d2">9133320d451c1c1eddf1438064663b17</data>
    </node>
    <node id="RESIDUALS_FITTED_VALUES_PROPERTIES">
      <data key="d0">PROPERTIES</data>
      <data key="d1">Properties of the residuals and of the fitted values are characteristics or features of the residuals and fitted values in a statistical context</data>
      <data key="d2">9133320d451c1c1eddf1438064663b17</data>
    </node>
    <node id="HAT_MATRIX">
      <data key="d0">MATRIX</data>
      <data key="d1">The hat matrix is a key concept in regression analysis, used to understand the influence of each observed value on the fitted values in a regression model
The hat matrix is a matrix used in the calculation of the least squares estimator and is the subject of the next chapter
The hat matrix (H) is a projection matrix in linear algebra, used in least squares regression to map the observed values (y) to the fitted values (yb). It is defined as H = X(XTX)^-1XT
The hat matrix is a matrix used in regression analysis to transform the observed response values into fitted values. It is introduced in the last chapter.
Hat matrix is a matrix used in regression analysis to calculate the leverages (hat-values) of data points
The hat matrix is a matrix used in regression analysis to project the observed response values onto the space of the fitted values. It is used to calculate leverages and is central to understanding the influence of each data point on the fitted regression model.
The hat matrix (H) is a matrix used in regression analysis to understand the influence of each data point on the fitted values
The hat matrix (H) is an n x n matrix used in regression analysis, where hii represents the leverage of the ith unit of observation</data>
      <data key="d2">1d52aaeb960f9787b6229e57738f8e47,3fb977ccba63e267d2e7dd4de6479ce1,6ee02b38ae842fd5eac9a11c4fd6659f,7e05f1b457a496c8b3630e7044fc5981,83bb91cf725e5116ca2f5748fddccfae,9923e77ac6b3de95cb5026bc5e7fe8c0,bd05fe6a05f9a13d33c4f1b5a771ada5,f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </node>
    <node id="PROPERTIES_HAT_MATRIX">
      <data key="d0">PROPERTIES</data>
      <data key="d1">Properties of the hat matrix include its role in determining the leverage of data points and its symmetry and idempotence</data>
      <data key="d2">1d52aaeb960f9787b6229e57738f8e47</data>
    </node>
    <node id="RESIDUALS">
      <data key="d0">STATISTICAL_CONCEPT</data>
      <data key="d1">Residuals are the differences between the observed values and the values predicted by the regression model
Residuals are the differences between the observed sales values and the predicted sales values from the line of best fit
Residuals are the differences between the observed values of the dependent variable and the values predicted by the regression model
Residuals are the differences between the observed response values and their fitted values in the linear regression model
Residuals are the signed vertical distances between the observed data points and the fitted model, representing the errors or discrepancies in the model's predictions
Residuals are used as estimates of the errors in the regression model, since the errors themselves are not observed
Residuals are estimates of the errors obtained by subtracting the fitted values from the observed values in a statistical model
Residuals are the differences between the observed values and the values predicted by the regression model
Residuals are the differences between the observed and predicted values
Residuals are the differences between the observed values and the values predicted by the model
Residuals are the differences between the observed values and the values predicted by the model, used to assess the fit of the model.
Residuals are the differences between the observed values and the values predicted by the model
Residuals are the differences between the observed values and the fitted values
Residuals (b&#1013;) are the differences between the observed values and the fitted values in a statistical model, calculated as b&#1013; = y - yb = (In - H)y
Residuals are the differences between the observed response vector y and the fitted values, considered as a random vector when Y replaces y
Residuals are the differences between the observed values and the fitted values in a regression model, and their variances and covariances can be derived</data>
      <data key="d2">0b650eb2f1dcd603b64fec3c4b5cd24b,0da640a09a395a50b6e16e047fa8d0d6,1d52aaeb960f9787b6229e57738f8e47,22093a562f5f05dc9891b45ab9bcbea8,312309b45c59e1c84695ac3c7e202742,3fb977ccba63e267d2e7dd4de6479ce1,5cc49d301d9cd1f8e20b92ab9d8346b0,60cc94e681863c9fcc6f9be1e500f840,674b8d5bb1f830d0fb944942514d1a16,7cd6069e88e81548a237fa937adfecc6,8a9b984c146f59b2af83d1c2f373d376,a60af43e42c72a41fa90da06beb29d1b,d1b6fcd55d937c5fe2d6add69e0bcf05,e361ac139c268d5c3f3623f920e68af2,e593096f3805c2686423cb91ea276fe6,f16299fc00a7a69bdf983dce826b4918</data>
    </node>
    <node id="FITTED_VALUES">
      <data key="d0">STATISTICAL_CONCEPT</data>
      <data key="d1">Fitted values are the predicted values of the dependent variable based on the regression model
Fitted values are the estimates of the expected response for given values of the predictor variables, calculated using the estimated parameters
Fitted values are the predicted values of the response variable based on the simple regression line, calculated by substituting the explanatory variable values into the model equation
Fitted values are the predicted values of the dependent variable based on the regression model
Fitted values are the predicted values of the response variable based on the regression model
Fitted values are the values predicted by the model for the response variable
Fitted values are the values predicted by the model, used to assess the fit of the model.
Fitted values are the predicted values of the dependent variable based on the regression model
Fitted values (yb) are the predicted response values for each observation in a linear model, calculated as yb = Hy, where H is the hat matrix
Fitted values are the predicted values of the response vector Y based on the linear model
These are the predicted values from the regression model, and their variances and covariances can be derived</data>
      <data key="d2">01d5ee79489582b4135fc96f676b24a0,0b650eb2f1dcd603b64fec3c4b5cd24b,1d52aaeb960f9787b6229e57738f8e47,22093a562f5f05dc9891b45ab9bcbea8,3fb977ccba63e267d2e7dd4de6479ce1,60cc94e681863c9fcc6f9be1e500f840,674b8d5bb1f830d0fb944942514d1a16,a60af43e42c72a41fa90da06beb29d1b,aa13c33a7e61206e6021e2736002ca9a,e361ac139c268d5c3f3623f920e68af2,e593096f3805c2686423cb91ea276fe6</data>
    </node>
    <node id="SUMMARY_CHAPTER_7">
      <data key="d0">SUMMARY</data>
      <data key="d1">Summary of Chapter 7 includes a review of the hat matrix and its properties, as well as the properties of residuals and fitted values</data>
      <data key="d2">1d52aaeb960f9787b6229e57738f8e47</data>
    </node>
    <node id="UNUSUAL_OBSERVATIONS">
      <data key="d0">STATISTICAL_CONCEPT</data>
      <data key="d1">Unusual observations refer to data points that do not follow the general pattern of the data, including high leverage points, outliers, and influential points
Unusual observations, also known as outliers, are data points that are significantly different from other observations. Transformations can reduce their influence on the model.
Unusual observations, or outliers, are data points that deviate significantly from the other observations in the dataset
Unusual observations, also known as outliers, are data points that are significantly different from other observations in the dataset. They can have a disproportionate influence on the results of statistical analyses and may indicate errors in data collection or unusual events.
Unusual observations are data points that have a much stronger influence on the fitted model than others, and their removal can cause substantial changes to the model</data>
      <data key="d2">07951ffe6787af44aa60c90c69e62f83,1d52aaeb960f9787b6229e57738f8e47,c03eb12d07d48f9e94260f08dae10cdf,d71b402ab9edbb4347e09c7af3257cf5,e593096f3805c2686423cb91ea276fe6</data>
    </node>
    <node id="LEVERAGES">
      <data key="d0">STATISTICAL_CONCEPT</data>
      <data key="d1">Leverages are a measure of how far an independent variable value of a data point is from the mean of that variable
Leverages are a measure of how much the fitted values rely on the observed values, and they are used to identify influential data points
Leverages are measures of how far an observation deviates from the mean of that explanatory variable. High leverage points are those that are far from the mean and can have a large influence on the fitted values.
Leverages, also known as hat-values, are measures of how far an observation is from the center of the fitted values in the regression space. They are derived from the hat matrix in regression analysis.</data>
      <data key="d2">1d52aaeb960f9787b6229e57738f8e47,6ee02b38ae842fd5eac9a11c4fd6659f,e593096f3805c2686423cb91ea276fe6,f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </node>
    <node id="OUTLIERS">
      <data key="d0">STATISTICAL_CONCEPT</data>
      <data key="d1">Outliers are data points that are significantly different from other observations, potentially due to variability in the measurement or experimental error
Outliers are observations that are significantly different from other observations in a dataset. In regression analysis, outliers can be response values that do not fit the current model.
Outliers are data points that deviate significantly from the other points in a dataset</data>
      <data key="d2">1d52aaeb960f9787b6229e57738f8e47,428db872e71a17a2cf7868b03a52def0,f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </node>
    <node id="INFLUENCE">
      <data key="d0">STATISTICAL_CONCEPT</data>
      <data key="d1">Influence measures the effect of a data point on the regression coefficients and the overall fit of the model

Influence is a statistical concept that measures how much a single data point affects the results of a statistical analysis</data>
      <data key="d2">1d52aaeb960f9787b6229e57738f8e47,428db872e71a17a2cf7868b03a52def0,617760dc9b9682075b10899cc8473dd5</data>
    </node>
    <node id="INFLUENTIAL_DATA_POINTS">
      <data key="d0">DATA_POINTS</data>
      <data key="d1">Influential data points are those that have a significant impact on the regression model, potentially skewing the results
Influential data points are observations that have a high influence on the fitted model and require careful consideration in statistical analysis
Influential data points are observations that have a significant impact on the fitted model, potentially skewing the results</data>
      <data key="d2">1d52aaeb960f9787b6229e57738f8e47,323899f01972255cd3278bccee20d5d8,83bb91cf725e5116ca2f5748fddccfae</data>
    </node>
    <node id="CHAPTER 8">
      <data key="d0">CHAPTER</data>
      <data key="d1">Chapter 8 covers the topic of influence in statistical models, discussing influential data points and summarizing key concepts related to their impact on model outcomes</data>
      <data key="d2">617760dc9b9682075b10899cc8473dd5</data>
    </node>
    <node id="CHAPTER 9">
      <data key="d0">CHAPTER</data>
      <data key="d1">Chapter 9 focuses on categorical predictor variables, including examples such as brand in retail data, alternative parameterizations, and models with interactions, concluding with a summary of the chapter's main points</data>
      <data key="d2">617760dc9b9682075b10899cc8473dd5</data>
    </node>
    <node id="RETAIL DATA">
      <data key="d0">DATA</data>
      <data key="d1">Retail data is used as an example in Chapter 9 to illustrate the inclusion of brand as a predictor variable in statistical models</data>
      <data key="d2">617760dc9b9682075b10899cc8473dd5</data>
    </node>
    <node id="BRAND">
      <data key="d0">PREDICTOR_VARIABLE</data>
      <data key="d1">Brand is a categorical predictor variable discussed in Chapter 9, particularly in the context of retail data
Brand represents the brand of the retail store and is a categorical variable that may influence sales.
Brand is a categorical predictor variable in the Retail dataset that represents the store brand
Brand refers to the different brands of products in the dataset, which are categorical variables used as predictors in the model
Brand is a categorical variable that classifies stores into three categories: A, B, and C
Brand is a categorical predictor variable in the regression model, with categories A, B, and C
Brand is a categorical predictor variable in the model, with categories brandA, brandB, and brandC
Brand is a category variable in the parallel lines model, with different brands (A, B, C) being considered
Brand is a categorical variable that differentiates stores into categories A, B, and C
Brand is a categorical predictor variable in the regression model, representing different product brands.</data>
      <data key="d2">06d5666e6bfdda828b48adba883b4a61,336546bc73cbe1828a0cc1a45faf8f5a,39aef0392258a09378ce45d8b03a268a,617760dc9b9682075b10899cc8473dd5,86ece4718d27d1a6c6a1f448cc850e2b,b0ca3e6c22c4cf884d03b1f6f82be5df,b2c33cb151a8e7724ebfb7b2d88bc45f,b6870535f3975c49d45e62fbe475f198,e800735d6b2a244875f5e0d292de1527,ee295ebc4c2d6a2a5c738796fcc2ab71</data>
    </node>
    <node id="ALTERNATIVE PARAMETERISATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Alternative parameterisations are methods for representing categorical predictor variables in statistical models, discussed in Chapter 9</data>
      <data key="d2">617760dc9b9682075b10899cc8473dd5</data>
    </node>
    <node id="MODEL WITH INTERACTION">
      <data key="d0">MODEL</data>
      <data key="d1">A model with an interaction is a statistical model that includes interaction terms between predictor variables, discussed in Chapter 9</data>
      <data key="d2">617760dc9b9682075b10899cc8473dd5</data>
    </node>
    <node id="SUMMARY OF CHAPTER 8">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">617760dc9b9682075b10899cc8473dd5</data>
    </node>
    <node id="CATEGORICAL PREDICTOR VARIABLES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">617760dc9b9682075b10899cc8473dd5</data>
    </node>
    <node id="SUMMARY OF CHAPTER 9">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">617760dc9b9682075b10899cc8473dd5</data>
    </node>
    <node id="PARAMETERISATIONS">
      <data key="d0">SECTION</data>
      <data key="d1">Parameterisations is a section in the document, likely discussing different ways to represent parameters in statistical models</data>
      <data key="d2">ef68dd0317c62e3cdde00395f7a21bd7</data>
    </node>
    <node id="MODEL_WITH_INTERACTION">
      <data key="d0">SECTION</data>
      <data key="d1">A model with an interaction is a section in the document, probably discussing a statistical model that includes interaction terms between variables</data>
      <data key="d2">ef68dd0317c62e3cdde00395f7a21bd7</data>
    </node>
    <node id="SUMMARY_OF_CHAPTER_9">
      <data key="d0">SECTION</data>
      <data key="d1">Summary of Chapter 9 is a section in the document, summarizing the key points of Chapter 9
The summary of Chapter 9 highlights the introduction of categorical predictors in linear models and the use of indicator variables to accommodate them.</data>
      <data key="d2">b0ca3e6c22c4cf884d03b1f6f82be5df,ef68dd0317c62e3cdde00395f7a21bd7</data>
    </node>
    <node id="THE_T_STATISTIC">
      <data key="d0">SECTION</data>
      <data key="d1">The T-statistic is a section in the document, likely discussing the T-statistic in the context of hypothesis testing</data>
      <data key="d2">ef68dd0317c62e3cdde00395f7a21bd7</data>
    </node>
    <node id="USEFUL_RESULTS_FOR_MULTIVARIATE_NORMAL">
      <data key="d0">SECTION</data>
      <data key="d1">Useful results for the multivariate normal distribution is a section in the document, probably discussing properties and results related to the multivariate normal distribution</data>
      <data key="d2">ef68dd0317c62e3cdde00395f7a21bd7</data>
    </node>
    <node id="DISTRIBUTIONAL_PROPERTIES_OF_BETA_HAT_AND_S_SQUARED">
      <data key="d0">SECTION</data>
      <data key="d1">Distributional properties of &#946;b and s^2 is a section in the document, likely discussing the distributional properties of the least squares estimator and the sample variance</data>
      <data key="d2">ef68dd0317c62e3cdde00395f7a21bd7</data>
    </node>
    <node id="SIMPLE_EXAMPLE_IN_R">
      <data key="d0">SECTION</data>
      <data key="d1">A simple example in R is a section in the document, probably providing an example of how to calculate or use the T-statistic in the R programming language</data>
      <data key="d2">ef68dd0317c62e3cdde00395f7a21bd7</data>
    </node>
    <node id="SUMMARY_OF_CHAPTER_10">
      <data key="d0">SECTION</data>
      <data key="d1">Summary of Chapter 10 is a section in the document, summarizing the key points of Chapter 10</data>
      <data key="d2">ef68dd0317c62e3cdde00395f7a21bd7</data>
    </node>
    <node id="CHAPTER_10">
      <data key="d0">CHAPTER</data>
      <data key="d1">Chapter 10 contains a simple example in R and a summary of the chapter's content</data>
      <data key="d2">0ba6a4dc0ac5f8b86cc2a22fd51b9517</data>
    </node>
    <node id="CHAPTER_11">
      <data key="d0">CHAPTER</data>
      <data key="d1">Chapter 11 discusses interval estimation, including confidence intervals, a simple example continued, estimation and prediction, and a summary of the chapter's content
Chapter 11 covers an unspecified topic related to prediction, likely within the context of statistical analysis or modeling</data>
      <data key="d2">0ba6a4dc0ac5f8b86cc2a22fd51b9517,f087dce67c830cc3152c8d9cbb76cdb8</data>
    </node>
    <node id="CHAPTER_12">
      <data key="d0">CHAPTER</data>
      <data key="d1">Chapter 12 covers the t-test for normal linear models and includes a section on hypothesis testing
Chapter 12 focuses on the t-test for normal linear models, including hypothesis testing, a simple example in R, comparison with other t-tests, limitations of the t-test, and a summary</data>
      <data key="d2">0ba6a4dc0ac5f8b86cc2a22fd51b9517,f087dce67c830cc3152c8d9cbb76cdb8</data>
    </node>
    <node id="CHAPTER_13">
      <data key="d0">CHAPTER</data>
      <data key="d1">Chapter 13 discusses the F-test and ANOVA (Analysis of Variance), likely covering their application in statistical testing and analysis</data>
      <data key="d2">f087dce67c830cc3152c8d9cbb76cdb8</data>
    </node>
    <node id="T_TEST">
      <data key="d0">TEST</data>
      <data key="d1">The t-test is a statistical test used to determine if there is a significant difference between the means of two groups, which may be related to the normal linear models discussed in Chapter 12
The t-test is a statistical hypothesis test used to determine if there is a significant difference between the means of two groups. It is limited in certain scenarios, as discussed in Chapter 12.</data>
      <data key="d2">59ad428bf172e7866861ea44cbe198e2,f087dce67c830cc3152c8d9cbb76cdb8</data>
    </node>
    <node id="F_TEST">
      <data key="d0">TEST</data>
      <data key="d1">The F-test is a statistical test used to compare variances between two or more groups, often associated with ANOVA, which is covered in Chapter 13
The F-test is a statistical test used to determine whether two populations have the same variance. It is also used in the analysis of variance (ANOVA) to compare multiple group means.</data>
      <data key="d2">59ad428bf172e7866861ea44cbe198e2,f087dce67c830cc3152c8d9cbb76cdb8</data>
    </node>
    <node id="ANOVA">
      <data key="d0">ANALYSIS</data>
      <data key="d1">ANOVA (Analysis of Variance) is a statistical method used to test differences between two or more means, which is a topic of Chapter 13
Analysis of Variance (ANOVA) is a statistical method used to test differences between two or more means. It is an extension of the t-test to more than two groups.
ANOVA (Analysis of Variance) is a statistical method used to analyze the differences among group means in a sample</data>
      <data key="d2">59ad428bf172e7866861ea44cbe198e2,f087dce67c830cc3152c8d9cbb76cdb8,fc5b725f3c662c5471af20efdcc2dbff</data>
    </node>
    <node id="R">
      <data key="d0">SOFTWARE</data>
      <data key="d1">R is a programming language and software environment for statistical computing and graphics, used in the simple example of the t-test in Chapter 12
R is a programming language used to fit normal linear models, with well-established functions for this purpose
R is a programming language and software environment for statistical computing and graphics
R is a statistical software environment used for data analysis and visualization
R is a programming language used for statistical computing and graphics&gt;
R is a statistical software used for data analysis and modeling
R is a programming language and software environment for statistical computing and graphics
R is a statistical software environment used for data analysis and graphical representation
R is the programming language used to fit the linear regression model
R is a statistical software used to determine estimates of the parameters in a linear model
R is a statistical software environment used for data analysis and graphical representation
R is a programming language and software environment for statistical computing and graphics, used for obtaining residuals from a linear regression model.
R is a statistical software used for data analysis and visualization
R is a programming language and software environment for statistical computing and graphics.
R is the statistical software used to implement the model and generate the output
R is the statistical software used to verify the design matrix and generate the model.matrix output
R is a statistical software environment used for data analysis and visualization
R is a statistical software used to fit the linear model for the Retail data
R is a programming language and software environment for statistical computing and graphics
R is the statistical software used to fit the model to the Retail data
R is the statistical software used to fit the regression model
R is a programming language and software environment for statistical computing and graphics. It is widely used among statisticians and data miners for developing statistical software and data analysis.</data>
      <data key="d2">01d5ee79489582b4135fc96f676b24a0,06199787dd7f75f7338dd24d4f3dc26e,084dadebfca8bcb6377c205c45bee295,119bc73ddf8eebadfb8eae272fa323a7,25fce1af816975003128126b5cfea73b,28eee75e95bbbaf143368c3289585670,312309b45c59e1c84695ac3c7e202742,48971100deb5bb374a41c1f2b7b2a86a,5cc49d301d9cd1f8e20b92ab9d8346b0,6a6f85d0a6e46196ab3a901fcc82a720,7b32c106246576bb451a5a3985914351,825b600cbab3535ce67e9f561ddcb84b,a1fc936df848a0fbc791e4bcc9b527b6,b99ecc2f79f56198a8c2adbdff95d576,c48bd062d5f6cc20c5df5758d6285562,d7f3a28534ffe830fe6f4cef8c41a9b4,e6f79ceb0df54119a4dc71b2162ac50b,e800735d6b2a244875f5e0d292de1527,eafa2cc6cc64d8bca1c080bdd2ad7654,ee295ebc4c2d6a2a5c738796fcc2ab71,f087dce67c830cc3152c8d9cbb76cdb8,f18bacb0a2fbfea44dd6326224184216</data>
    </node>
    <node id="NESTED_LINEAR_MODELS">
      <data key="d0">MATHEMATICAL_CONCEPT</data>
      <data key="d1">Nested linear models are a type of statistical model where one model is a special case of another model. They are used in the context of the F-test and ANOVA.</data>
      <data key="d2">59ad428bf172e7866861ea44cbe198e2</data>
    </node>
    <node id="TOTAL_SUM_OF_SQUARES">
      <data key="d0">MATHEMATICAL_CONCEPT</data>
      <data key="d1">The total sum of squares is a measure of the total variability in a dataset. It is decomposed into explained and unexplained variability in the context of the F-test and ANOVA.</data>
      <data key="d2">59ad428bf172e7866861ea44cbe198e2</data>
    </node>
    <node id="EXISTENCE_OF_REGRESSION">
      <data key="d0">MATHEMATICAL_CONCEPT</data>
      <data key="d1">The existence of regression refers to the presence of a relationship between a dependent variable and one or more independent variables. The F-test is used to test for this existence.</data>
      <data key="d2">59ad428bf172e7866861ea44cbe198e2</data>
    </node>
    <node id="ANOVA_TABLE">
      <data key="d0">MATHEMATICAL_CONCEPT</data>
      <data key="d1">An ANOVA table is a tabular representation of the results of an analysis of variance. It includes information about the sources of variation, degrees of freedom, sums of squares, mean squares, and F-statistics.
The ANOVA table is used to determine the existence of regression in a dataset, providing a structured way to analyze the variance in the data</data>
      <data key="d2">59ad428bf172e7866861ea44cbe198e2,638b52a0671088c9aa208790411ab898</data>
    </node>
    <node id="ILLUSTRATION_IN_R">
      <data key="d0">SOFTWARE_DEMONSTRATION</data>
      <data key="d1">Illustration in R refers to the demonstration of statistical concepts using the R programming language. It is used to provide practical examples of the F-test and ANOVA.
Illustration in R refers to the demonstration of statistical concepts using the R programming language, which is popular for data analysis</data>
      <data key="d2">59ad428bf172e7866861ea44cbe198e2,638b52a0671088c9aa208790411ab898</data>
    </node>
    <node id="DISTRIBUTION_OF_F_STATISTIC">
      <data key="d0">MATHEMATICAL_CONCEPT</data>
      <data key="d1">The distribution of the F-statistic is a probability distribution used in hypothesis testing. It is used to determine the significance of the F-test results.</data>
      <data key="d2">59ad428bf172e7866861ea44cbe198e2</data>
    </node>
    <node id="F_STATISTIC_DISTRIBUTION">
      <data key="d0">DISTRIBUTION</data>
      <data key="d1">The distribution of the F-statistic is a probability distribution used in hypothesis testing, particularly in ANOVA, to determine if there are significant differences between group means</data>
      <data key="d2">638b52a0671088c9aa208790411ab898</data>
    </node>
    <node id="SUMMARY_OF_CHAPTER_13">
      <data key="d0">SUMMARY</data>
      <data key="d1">Summary of Chapter 13 provides an overview of the key points covered in the chapter, which likely discusses ANOVA and regression analysis</data>
      <data key="d2">638b52a0671088c9aa208790411ab898</data>
    </node>
    <node id="SEQUENTIAL_ANOVA">
      <data key="d0">STATISTICAL_METHOD</data>
      <data key="d1">Sequential ANOVA is a method of analysis of variance where the factors are added to the model one at a time, allowing for the assessment of the incremental effect of each factor</data>
      <data key="d2">638b52a0671088c9aa208790411ab898</data>
    </node>
    <node id="FACTORS">
      <data key="d0">VARIABLES</data>
      <data key="d1">Factors are variables in a statistical model that are categorical, often used in ANOVA to compare the means of different groups
Factors are elements considered in Chapter 14, possibly related to model variables or influences</data>
      <data key="d2">322cf1f37d33953af834b695b7f08b72,638b52a0671088c9aa208790411ab898</data>
    </node>
    <node id="TEST_FOR_NON-LINEARITY">
      <data key="d0">HYPOTHESIS_TEST</data>
      <data key="d1">Test for non-linearity is a statistical test used to determine if the relationship between variables is not linear, which can affect the assumptions of regression analysis</data>
      <data key="d2">638b52a0671088c9aa208790411ab898</data>
    </node>
    <node id="CHAPTER 14">
      <data key="d0">CHAPTER</data>
      <data key="d1">Chapter 14 covers topics including factors, a test for non-linearity, and a summary of the chapter's content</data>
      <data key="d2">322cf1f37d33953af834b695b7f08b72</data>
    </node>
    <node id="CHAPTER 15">
      <data key="d0">CHAPTER</data>
      <data key="d1">Chapter 15 discusses model selection criteria, variable selection, bias and variance, the model hierarchy, and model selection statistics
Chapter 15 covers topics including model selection statistics, variable selection, and multicollinearity</data>
      <data key="d2">322cf1f37d33953af834b695b7f08b72,ad35c05a2497a4e16a014d64483842a8</data>
    </node>
    <node id="TEST FOR NON-LINEARITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">The test for non-linearity is a procedure described in Chapter 14 to assess the linearity of a model or data</data>
      <data key="d2">322cf1f37d33953af834b695b7f08b72</data>
    </node>
    <node id="SUMMARY OF CHAPTER 14">
      <data key="d0">CONCEPT</data>
      <data key="d1">The summary of Chapter 14 provides an overview of the topics covered in the chapter</data>
      <data key="d2">322cf1f37d33953af834b695b7f08b72</data>
    </node>
    <node id="BIAS AND VARIANCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Bias and variance are concepts in Chapter 15 that relate to model performance and error</data>
      <data key="d2">322cf1f37d33953af834b695b7f08b72</data>
    </node>
    <node id="THE MODEL HIERARCHY">
      <data key="d0">CONCEPT</data>
      <data key="d1">The model hierarchy is a structure or classification of models discussed in Chapter 15</data>
      <data key="d2">322cf1f37d33953af834b695b7f08b72</data>
    </node>
    <node id="MODEL SELECTION STATISTICS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Model selection statistics are metrics or criteria used in Chapter 15 to choose among different models
Model selection statistics are used to compare different models and determine the best one based on certain criteria</data>
      <data key="d2">322cf1f37d33953af834b695b7f08b72,ad35c05a2497a4e16a014d64483842a8</data>
    </node>
    <node id="VARIABLE SELECTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Variable selection is a process in Chapter 15 for choosing the most relevant variables for a model
Variable selection is the process of identifying the most relevant variables to include in a model</data>
      <data key="d2">322cf1f37d33953af834b695b7f08b72,ad35c05a2497a4e16a014d64483842a8</data>
    </node>
    <node id="MULTICOLLINEARITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Multicollinearity refers to a situation in which two or more predictor variables in a multiple regression model are highly correlated</data>
      <data key="d2">ad35c05a2497a4e16a014d64483842a8</data>
    </node>
    <node id="SUMMARY OF CHAPTER 15">
      <data key="d0">SUMMARY</data>
      <data key="d1">The summary of Chapter 15 provides a brief overview of the key points covered in the chapter</data>
      <data key="d2">ad35c05a2497a4e16a014d64483842a8</data>
    </node>
    <node id="CHAPTER 16">
      <data key="d0">CHAPTER</data>
      <data key="d1">Chapter 16 discusses the General Linear Model, including the generalised least squares estimator and weighted regression</data>
      <data key="d2">ad35c05a2497a4e16a014d64483842a8</data>
    </node>
    <node id="GENERAL LINEAR MODEL">
      <data key="d0">CONCEPT</data>
      <data key="d1">The General Linear Model is a statistical model that includes a wide range of models, including linear regression, ANOVA, and ANCOVA</data>
      <data key="d2">ad35c05a2497a4e16a014d64483842a8</data>
    </node>
    <node id="GENERALISED LEAST SQUARES ESTIMATOR">
      <data key="d0">CONCEPT</data>
      <data key="d1">The generalised least squares estimator is a method for estimating the parameters of a linear regression model when the errors are not independent</data>
      <data key="d2">ad35c05a2497a4e16a014d64483842a8</data>
    </node>
    <node id="WEIGHTED REGRESSION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Weighted regression is a type of regression analysis where the weights are assigned to each data point based on the precision of its measurements</data>
      <data key="d2">ad35c05a2497a4e16a014d64483842a8</data>
    </node>
    <node id="SERIALLY CORRELATED ERRORS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Serially correlated errors refer to a situation where the errors in a regression model are correlated over time</data>
      <data key="d2">ad35c05a2497a4e16a014d64483842a8</data>
    </node>
    <node id="GLM">
      <data key="d0">MODEL</data>
      <data key="d1">GLM stands for Generalized Linear Model, a flexible generalization of ordinary linear regression that allows for response variables that have error distribution models other than a normal distribution</data>
      <data key="d2">54768ad5bc5877b6bf042aac07fb64d9</data>
    </node>
    <node id="BINARY_RESPONSE_DATA">
      <data key="d0">DATA_TYPE</data>
      <data key="d1">Binary response data refers to data where the response variable can take on only two possible outcomes, often coded as 0 and 1</data>
      <data key="d2">54768ad5bc5877b6bf042aac07fb64d9</data>
    </node>
    <node id="HYPOTHESIS_TESTING">
      <data key="d0">STATISTICAL_METHOD</data>
      <data key="d1">Hypothesis testing is a statistical method used to make decisions or judgments about the probability of the observed data given a null hypothesis</data>
      <data key="d2">54768ad5bc5877b6bf042aac07fb64d9</data>
    </node>
    <node id="SUMMARY_OF_CHAPTER_17">
      <data key="d0">SUMMARY</data>
      <data key="d1">Summary of Chapter 17 provides an overview of the key concepts and topics covered in Chapter 17 of the text</data>
      <data key="d2">54768ad5bc5877b6bf042aac07fb64d9</data>
    </node>
    <node id="APPENDIX_A">
      <data key="d0">APPENDIX</data>
      <data key="d1">Appendix A covers linear algebra and multivariable calculus, providing additional mathematical background for the text</data>
      <data key="d2">54768ad5bc5877b6bf042aac07fb64d9</data>
    </node>
    <node id="APPENDIX_B">
      <data key="d0">APPENDIX</data>
      <data key="d1">Appendix B discusses the concept of generalized expectation, which is relevant to the theory of GLMs
Appendix B discusses Generalised Expectation, a statistical concept</data>
      <data key="d2">54768ad5bc5877b6bf042aac07fb64d9,acead09befa8eb465dd2e8c2d93a43c5</data>
    </node>
    <node id="APPENDIX_C">
      <data key="d0">APPENDIX</data>
      <data key="d1">Appendix C focuses on the distribution of s^2, which is the sample variance, an important statistical measure
Appendix C focuses on the distribution of s^2, a measure of variance</data>
      <data key="d2">54768ad5bc5877b6bf042aac07fb64d9,acead09befa8eb465dd2e8c2d93a43c5</data>
    </node>
    <node id="APPENDIX_D">
      <data key="d0">APPENDIX</data>
      <data key="d1">Appendix D covers M-estimators and robust regression, methods for estimating model parameters that are less sensitive to outliers
Appendix D covers M-estimators and robust regression, methods for dealing with outliers in data</data>
      <data key="d2">54768ad5bc5877b6bf042aac07fb64d9,acead09befa8eb465dd2e8c2d93a43c5</data>
    </node>
    <node id="APPENDIX_E">
      <data key="d0">APPENDIX</data>
      <data key="d1">Appendix E explores the distribution of the F-statistic, a test for the significance of model parameters</data>
      <data key="d2">acead09befa8eb465dd2e8c2d93a43c5</data>
    </node>
    <node id="APPENDIX_F">
      <data key="d0">APPENDIX</data>
      <data key="d1">Appendix F delves into the exponential family of distributions, a class of probability distributions</data>
      <data key="d2">acead09befa8eb465dd2e8c2d93a43c5</data>
    </node>
    <node id="APPENDIX_G">
      <data key="d0">APPENDIX</data>
      <data key="d1">Appendix G discusses Poisson GLM (Generalized Linear Model), a model for count data</data>
      <data key="d2">acead09befa8eb465dd2e8c2d93a43c5</data>
    </node>
    <node id="APPENDIX_H">
      <data key="d0">APPENDIX</data>
      <data key="d1">Appendix H provides a summary of key results from the statistical concepts covered in the appendices</data>
      <data key="d2">acead09befa8eb465dd2e8c2d93a43c5</data>
    </node>
    <node id="PDF_VERSION">
      <data key="d0">DOCUMENT</data>
      <data key="d1">The PDF version of the lecture notes is available for personal use and can be accessed by clicking on the PDF icon in the top bar</data>
      <data key="d2">d1cc8e172b83ff69b921cef864fc09f5</data>
    </node>
    <node id="RIGHTS">
      <data key="d0">LEGAL</data>
      <data key="d1">All rights to the lecture notes are reserved, and they should not be distributed in any format or uploaded to the internet, filesharing sites, or provided to third parties</data>
      <data key="d2">d1cc8e172b83ff69b921cef864fc09f5</data>
    </node>
    <node id="TYPO_REPORTING">
      <data key="d0">PROCEDURE</data>
      <data key="d1">There is a procedure for reporting typos in the lecture notes by submitting details to the ST231 anonymous submission form</data>
      <data key="d2">d1cc8e172b83ff69b921cef864fc09f5</data>
    </node>
    <node id="DIVERSITY_NOTE">
      <data key="d0">STATEMENT</data>
      <data key="d1">The author acknowledges the predominance of European and Anglo-American scientific contributions in the lecture notes and expresses a desire to include more diverse sources over time</data>
      <data key="d2">d1cc8e172b83ff69b921cef864fc09f5</data>
    </node>
    <node id="NORMAL_LINEAR_MODELS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Normal linear models are statistical models that describe the relationship between a single quantitative outcome variable and one or more explanatory variables
Normal linear models are statistical models that describe the relationship between a single quantitative outcome variable and one or more explanatory variables</data>
      <data key="d2">7b32c106246576bb451a5a3985914351,d1cc8e172b83ff69b921cef864fc09f5</data>
    </node>
    <node id="LECTURE_NOTES">
      <data key="d0">DOCUMENT</data>
      <data key="d1">These are the first version of lecture notes that follow the exposition common in many textbooks, with the intention to augment over time with material from more diverse sources</data>
      <data key="d2">7b32c106246576bb451a5a3985914351</data>
    </node>
    <node id="EXPLANATORY_VARIABLES">
      <data key="d0">VARIABLE</data>
      <data key="d1">Explanatory variables are used in normal linear models to explain the variation in the outcome variable
Explanatory variables are non-random variables used in statistical models to explain or predict the response variable. They are considered fixed and the model is developed conditional on their values
Explanatory variables, also known as predictor variables, are used in regression models to explain variations in the dependent variable. In the multiple linear regression model, price and local advertising are considered explanatory variables.&gt;
Explanatory variables are variables in the dataset that are used to explain the variation in the response variable
The explanatory variables are the predictors in the regression model, whose values determine the means of the response variables
Explanatory variables are the independent variables in a regression model that are used to explain or predict the dependent variable</data>
      <data key="d2">0da640a09a395a50b6e16e047fa8d0d6,22478e53f29f16e3eab9d167fea52b22,2ced3e26eaed2dfcd8e4caf49737cab4,426434b67f6a287852ab66b82ca873cf,7b32c106246576bb451a5a3985914351,a60af43e42c72a41fa90da06beb29d1b</data>
    </node>
    <node id="OUTCOME_VARIABLE">
      <data key="d0">VARIABLE</data>
      <data key="d1">The outcome variable is the single quantitative variable that is being predicted or explained by the explanatory variables in normal linear models</data>
      <data key="d2">7b32c106246576bb451a5a3985914351</data>
    </node>
    <node id="ST117">
      <data key="d0">COURSE</data>
      <data key="d1">ST117 is a module that introduced the simplest form of a linear model, a simple linear regression model
ST117 is an educational module that introduced the simplest form of a linear model, a simple linear regression model</data>
      <data key="d2">28eee75e95bbbaf143368c3289585670,7b32c106246576bb451a5a3985914351</data>
    </node>
    <node id="ST121">
      <data key="d0">COURSE</data>
      <data key="d1">ST121 is another module that also introduced the simple linear regression model
ST121 is another educational module that also introduced the simplest form of a linear model, a simple linear regression model</data>
      <data key="d2">28eee75e95bbbaf143368c3289585670,7b32c106246576bb451a5a3985914351</data>
    </node>
    <node id="LINEAR_ALGEBRA">
      <data key="d0">MATHEMATICAL_TOOL</data>
      <data key="d1">Linear algebra is a mathematical tool used in the theory underpinning normal linear models, common for machine learning algorithms
Linear algebra uses small letters to denote vectors and capital letters to denote matrices, which can sometimes lead to notational issues when dealing with both random variables and their realizations
Linear algebra provides the mathematical tools, such as vectors and matrices, needed to represent objects mathematically in an n-dimensional space</data>
      <data key="d2">22478e53f29f16e3eab9d167fea52b22,2ced3e26eaed2dfcd8e4caf49737cab4,7b32c106246576bb451a5a3985914351</data>
    </node>
    <node id="LINEAR_MODEL">
      <data key="d0">STATISTICAL_MODEL</data>
      <data key="d1">A linear model is a statistical model that describes the relationship between a dependent variable and one or more independent variables using a linear function
Linear model is a statistical model that assumes a linear relationship between the response variable and one or more explanatory variables
A linear model is a statistical model that assumes a linear relationship between the dependent variable and one or more explanatory variables
The term "linear model" refers to linearity in the parameters, meaning that as long as the systematic component is linear in the parameters, the model can still be considered a linear model
Linear model refers to a statistical model where the systematic component is linear in the parameters. This allows for the use of the least squares estimation algorithm to produce reasonable estimates of the parameters.
The linear model is a statistical model used to describe the relationship between the height and diameter of the Western red cedar trees
Linear model is a type of statistical model that assumes a linear relationship between the response variable and the explanatory variables, often represented by a linear equation
A linear model is a statistical model where the systematic component is linear in the parameters, but not necessarily a linear function of the explanatory variables
A linear model is a statistical model that assumes a linear relationship between the dependent variable and one or more independent variables. It is often used in regression analysis to predict the value of a dependent variable based on the values of one or more independent variables.
The linear model is a statistical model used to predict the volume of timber from the height and diameter of the tree
Linear model is a statistical model used to analyze the relationship between one or more independent variables and a dependent variable
A linear model is a statistical model that assumes a linear relationship between the response variable and the explanatory variables. It is used to predict the response variable based on the values of the explanatory variables.</data>
      <data key="d2">188219b9e5b6b6368360840921877de9,28eee75e95bbbaf143368c3289585670,3bfc9b92571973e54c8095302acc1aaa,3fb977ccba63e267d2e7dd4de6479ce1,656dce234514b9db38b5b5616557c1e9,7594eee7e77beb023d1cd64aec64920d,9611ea31ff53888971694cdefe806f64,9f335f1ecb85a1427df926df8bb1e89f,ae1e66f5b64284090abc285c1d4389f5,b9af17718641389ba07f53be13f31f8c,c9a01b92d11585f6549f62e8bd78d652,d7f3a28534ffe830fe6f4cef8c41a9b4</data>
    </node>
    <node id="MULTIPLE_LINEAR_REGRESSION">
      <data key="d0">STATISTICAL_MODEL</data>
      <data key="d1">Multiple linear regression is a type of linear model that describes the relationship between a dependent variable and multiple independent variables
The multiple linear regression model uses multiple predictor variables, in this case price and advert, to predict the dependent variable Y
A multiple linear regression model is a statistical method used to analyze the relationship between one continuous dependent variable and two or more independent variables. In this case, the model includes price and local advertising as predictor variables.&gt;
Multiple linear regression is a statistical model that uses several quantitative explanatory variables to predict the response variable</data>
      <data key="d2">28eee75e95bbbaf143368c3289585670,2ced3e26eaed2dfcd8e4caf49737cab4,426434b67f6a287852ab66b82ca873cf,512d9ffebe309a6f944ebce1ae2ff2a3</data>
    </node>
    <node id="DIAMOND_DATA">
      <data key="d0">DATASET</data>
      <data key="d1">Diamond data is a dataset containing information about 48 Solitaire gold rings, including the price and weight of the diamonds
Diamond data is a dataset used to illustrate the fitted models based on equations (1.1) and (1.2). The scatterplots show the relationship between the explanatory and response variables.
Diamond data is a dataset used in the context of regression analysis, containing information about diamonds, including carat weight and price</data>
      <data key="d2">13e6c81b642252522460f4abadaab1cc,28eee75e95bbbaf143368c3289585670,e47d573a10e64a657e58218df64d8920</data>
    </node>
    <node id="SINGAPORE_DOLLARS">
      <data key="d0">CURRENCY</data>
      <data key="d1">Singapore Dollars (S$) is the currency used in Singapore
Singapore Dollars (S$) is the currency used to measure the price of diamond rings in the study.
Singapore Dollars (S$) is the currency used in Singapore and is the unit of measurement for the price of Solitaire rings in this context.&gt;</data>
      <data key="d2">28eee75e95bbbaf143368c3289585670,3e7eef51f3109d60697f3299b541b726,f0e0c5b2deaaf9fc2bc8b63d9ab989b1</data>
    </node>
    <node id="CARAT">
      <data key="d0">UNIT_OF_MEASUREMENT</data>
      <data key="d1">Carat is a unit of measurement used for the weight of diamonds, where one carat corresponds to 20 milligrams
Carat is a predictor variable in the linear regression model, representing the weight of diamonds
carat is a variable in the diamond dataset representing the weight of diamonds, measured in carats
Carat is the explanatory variable in the regression model, representing the weight of the diamond
Carat is the unit of weight for diamonds, with 0.35 carat being mentioned as a specific weight
carat is a variable in the diamond dataset representing the weight of the diamonds in carats.</data>
      <data key="d2">28eee75e95bbbaf143368c3289585670,2b01334fb633566ba368a764ad579fce,35e06960dba699ce0d56fc1e98bdbe96,9fc9b618723695c0c593043162a4084b,b99ecc2f79f56198a8c2adbdff95d576,e1ad57124a08c0e123deda212ea03c32</data>
    </node>
    <node id="SCATTERPLOT">
      <data key="d0">GRAPHICAL_REPRESENTATION</data>
      <data key="d1">A scatterplot is a graphical representation of the relationship between two variables, typically plotted as points on a two-dimensional graph
A scatterplot is a graphical representation of the relationship between two quantitative variables, in this case, the weight of a diamond and the price of a ring.
Scatterplots are graphical representations that depict the relationship between two variables, in this case, the weight of diamonds and the price of Solitaire rings
A scatterplot is a graphical representation of the relationship between two variables. It shows the sales against price together with the line of best fit and the residuals.
A scatterplot is a graphical representation of the relationship between two variables
Scatterplot is a graphical representation of the relationship between X and Y
Scatterplot is a graphical representation of the relationship between x-values and y-values in a dataset
Scatterplot is a graphical representation of the data points, showing the relationship between X and Y
Scatterplot is a graphical representation of the relationship between two variables, often used to visualize the data and the line of best fit in statistical models
A scatterplot is a graphical representation of the relationship between two variables, typically with one variable plotted on the x-axis and the other on the y-axis
A scatterplot is a graphical representation of the relationship between two variables, typically an explanatory variable and a response variable
A scatterplot is a type of plot that displays values for two variables for a set of data, where one variable is plotted on the horizontal axis and the other on the vertical axis
Scatterplot is a graphical representation of the relationship between two variables, showing the pattern of their joint variation
A scatterplot is a graphical representation of the relationship between two variables. It shows the distribution of data points and can reveal patterns or trends.
A scatterplot is a graphical representation of the relationship between the response variable and the explanatory variable
A scatterplot is a graphical representation of the relationship between two variables. It displays the data as a collection of points, each having the value of one variable determining the position on the horizontal axis and the value of the other variable determining the position on the vertical axis.
The scatterplot is a graphical representation of the data, showing the relationship between the predictor and response variables
Scatterplot is a graphical representation of the relationship between the explanatory variable and the response variable
A scatterplot is a graphical representation of the relationship between two quantitative variables. In this context, it is used to visualize the relationship between the response variable and the explanatory variable.
A scatterplot is a type of plot that shows the relationship between two variables, in this case, BRAIN against BODY
A scatterplot is a graphical representation of the relationship between two variables, in this case, brain weight and body weight
Scatterplot is a graphical representation of the relationship between sales and price for each brand, showing the distribution of the data points</data>
      <data key="d2">11452a08471d93959558de2ece9a69af,15c7b5750483a382ce59751008e86751,23fc620f1238c6a1b5c5e3a08e149c53,28eee75e95bbbaf143368c3289585670,2a5997c641e47fc6c32ebf81101c54e0,2e5e1bdaa9fcc7b3391d277fd6bb247a,312309b45c59e1c84695ac3c7e202742,3e7eef51f3109d60697f3299b541b726,521acf88540d5897188c9ec65b17e6a6,66f7fae9d896ff2b3fd40186cc833503,674b8d5bb1f830d0fb944942514d1a16,82cfcd5865cffe55e965a50745656e60,84ffe1b8496dc660c47248c9f7b5bdea,9f335f1ecb85a1427df926df8bb1e89f,aa13c33a7e61206e6021e2736002ca9a,ac15b639b0849006471dfe102376c2c0,ae1e66f5b64284090abc285c1d4389f5,b9eb75001a4f68f7240b2ca9e0d79eb8,b9ec8a6c7960cc6196ec94fd976f05b0,c5b269ff5c94db7ebd2cb9f7be16f171,ef24ca5edd06893b737e6a1c8a9825f6,f9d6c3504b8f8b5c25550076e45f8270</data>
    </node>
    <node id="DIAMOND_RING_PRICING">
      <data key="d0">RESEARCH_TOPIC</data>
      <data key="d1">Diamond ring pricing is the subject of a study using linear regression to analyze the relationship between the weight of a diamond and the price of a solitaire ring.</data>
      <data key="d2">3e7eef51f3109d60697f3299b541b726</data>
    </node>
    <node id="LINEAR_REGRESSION">
      <data key="d0">STATISTICAL_METHOD</data>
      <data key="d1">Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables.
Linear regression is a statistical model used to analyze the relationship between a dependent variable and one or more independent variables</data>
      <data key="d2">3e7eef51f3109d60697f3299b541b726,84ffe1b8496dc660c47248c9f7b5bdea</data>
    </node>
    <node id="JOURNAL_OF_STATISTICS_EDUCATION">
      <data key="d0">ACADEMIC_JOURNAL</data>
      <data key="d1">The Journal of Statistics Education is an academic journal that published a study on diamond ring pricing using linear regression.</data>
      <data key="d2">3e7eef51f3109d60697f3299b541b726</data>
    </node>
    <node id="DIAMOND_WEIGHT">
      <data key="d0">INDEPENDENT_VARIABLE</data>
      <data key="d1">Diamond weight, measured in carats, is the independent variable in the linear regression model used to study diamond ring pricing.
Diamond weight is measured in carats. The weight of a diamond is a significant factor in determining the price of a Solitaire ring.&gt;</data>
      <data key="d2">3e7eef51f3109d60697f3299b541b726,f0e0c5b2deaaf9fc2bc8b63d9ab989b1</data>
    </node>
    <node id="RING_PRICE">
      <data key="d0">DEPENDENT_VARIABLE</data>
      <data key="d1">Ring price, measured in Singapore Dollars (S$), is the dependent variable in the linear regression model used to study diamond ring pricing.</data>
      <data key="d2">3e7eef51f3109d60697f3299b541b726</data>
    </node>
    <node id="LINE_OF_BEST_FIT">
      <data key="d0">MATHEMATICAL_MODEL</data>
      <data key="d1">The line of best fit is a mathematical model that represents the linear relationship between the weight of a diamond and the price of a ring.
The line of best fit is a straight line that represents the systematic component of the relationship between price and weight
The line of best fit is the straight line defined by the equation Price = &#946;0 + &#946;1 weight + &#1013;, which is the model for the price of a Solitaire ring
Line of best fit is the linear regression model that best describes the relationship between the response and predictor variables
The line of best fit is a mathematical model that represents the relationship between the weight deviations from the mean and the price of Solitaire rings
The line of best fit is the linear regression model that best describes the relationship between sales and price
The line of best fit is found by minimising the sum of squared residuals, that is by minimising the sum of squared lengths of the red vertical lines. It is the line that best represents the relationship between two variables in a scatterplot.
Line of best fit is a line that best represents the relationship between two variables in a scatterplot, often calculated using methods like least squares</data>
      <data key="d2">2e5e1bdaa9fcc7b3391d277fd6bb247a,3e7eef51f3109d60697f3299b541b726,6f10cac870c690419e5351e8a6aeae9e,ae1e66f5b64284090abc285c1d4389f5,b99ecc2f79f56198a8c2adbdff95d576,c5b269ff5c94db7ebd2cb9f7be16f171,d4bbb6beb0dd5c40d2941af71b7c1776,f16299fc00a7a69bdf983dce826b4918</data>
    </node>
    <node id="WEIGHT">
      <data key="d0">VARIABLE</data>
      <data key="d1">Weight is a variable that represents the weight of a diamond in a Solitaire ring
Weight is a variable in the simple linear regression model, representing the weight of the diamond in a Solitaire ring
Weight, measured in carats, is a key attribute of a diamond that affects its price&gt;
Weight refers to the carat weight of the diamonds in the Solitaire rings in the dataset, with an average weight of 0.204 carats
Weight is a measurement of the diamonds, with a positive weight of at least 0.12 carat being considered</data>
      <data key="d2">6f10cac870c690419e5351e8a6aeae9e,c5b269ff5c94db7ebd2cb9f7be16f171,d4bbb6beb0dd5c40d2941af71b7c1776,f18bacb0a2fbfea44dd6326224184216,f8a3c7ad2423fe8e91b33ca812ddfeff</data>
    </node>
    <node id="PRICE">
      <data key="d0">VARIABLE</data>
      <data key="d1">Price is a variable that represents the price of a Solitaire ring
Price is a variable in the simple linear regression model, representing the price of a Solitaire ring
Price is the response variable in the linear regression model, representing the price of diamonds
price is a variable in the diamond dataset representing the price of diamonds
Price is the amount of money that is asked for or given for a Solitaire ring, measured in Singapore dollars (S$)
Price is the monetary value of a diamond ring, which can be predicted by a model based on the diamond's weight&gt;
Price is the cost of the Solitaire rings in the dataset, with the estimated intercept suggesting an expected price of approximately S$ 500 for a ring with a 0.204 carat diamond
Price is the cost of the Solitaire rings, which is being analyzed in relation to the weight of the diamonds

Price is the independent variable in the linear regression model, representing the price charged per unit
Price is a variable in the dataset that represents the price charged for the product.
Price is an independent variable in the model, representing the price of the product
Price is an economic variable that represents the amount of money that must be paid for a product or service
Price is one of the explanatory variables in the regression analysis, representing the price of the product
Price is one of the explanatory variables used in the regression model
Price is an explanatory variable in the linear regression model, with a coefficient indicating the average effect on the response variable when its value is increased by one unit
Price is a variable in the regression models, representing the cost of a product or service. The estimated slope coefficient in the simple linear regression was computed as -0.225, indicating the expected change in sales for a unit change in price.&gt;
Price is a variable in the dataset that takes values considerably larger than zero, making the interpretation of the intercept in a regression model require extrapolation
Price is one of the independent variables in the regression model, used to predict sales volume.
Price is a predictor variable in the linear regression model used to predict sales volume.&gt;
Price is a variable in the model that represents the price of the product in the jth store
Price is a quantitative predictor variable in the model, representing the price of the products
Price is the independent variable in the regression analysis, representing the price of the product
Price is an independent variable in the regression model, representing the price of the product
Price is an independent variable in the model, representing the price per unit
Price is a numerical variable representing the price of the product in the dataset
Price is a quantitative variable representing the price of the product
price is the original price variable, with a sample mean of 152.76&gt;
Price is an independent variable in the regression model, representing the price of the product in different stores
Price is a variable in the regression model, representing the price of the product
Price is a variable that influences sales volumes, and is accounted for in the analysis
Price (pricej) is a variable in the model, representing the price at the jth store
Price is an independent variable in the linear regression model, representing the price of the product
Price (pricej) is the independent variable in the model, representing the price at the jth store
Price is a predictor variable in the model, representing the price of the product
Price is the only predictor variable used in the initial simple linear regression model
Price is an explanatory variable in the regression model, representing the price of the product
Price is a variable in the model that affects sales volume
Price is a variable in the model, representing the cost of the product
Price is the independent variable in the regression model, representing the price of the product
Price is the independent variable in the regression model, representing the price of the product in the stores
Price is a quantitative predictor variable in the context of sales volume prediction.</data>
      <data key="d2">06d5666e6bfdda828b48adba883b4a61,0cb40986e6c2bb439e1ffcaae2df96ac,1820d10ee0f23f34b3ea88ba475bc52d,1b523d1edabe381403fc470a9b8d47fa,1d141ab04db553f78a313e430e54abb5,248924760a2bfbc82501fd6b11cfa0aa,250ee5d766c64e7975bcc427b4bf9074,2b01334fb633566ba368a764ad579fce,2ced3e26eaed2dfcd8e4caf49737cab4,2e5e1bdaa9fcc7b3391d277fd6bb247a,336546bc73cbe1828a0cc1a45faf8f5a,3dd24a54028976ba54304ec7169bb74b,426434b67f6a287852ab66b82ca873cf,6f10cac870c690419e5351e8a6aeae9e,7037e0369bfdaad5a730cabb2b44831c,7a605c3b689bec7ab2c46df9c123e3f3,8326c645426789920a99ed373725fa0e,86ece4718d27d1a6c6a1f448cc850e2b,8a9b984c146f59b2af83d1c2f373d376,906eb7d6b49fa360e7e5b65c56cd4d76,93da9813e10a119798de6982977f1239,9854704301b8df256ca1013b8d53dfac,a1fc936df848a0fbc791e4bcc9b527b6,a828fd17fc38e902484872c88a6b242c,ac15b639b0849006471dfe102376c2c0,adbc52b340a69a8633c919c4fd2cd3f6,b0ca3e6c22c4cf884d03b1f6f82be5df,b1690cb1a67892245c0665e5099e322d,b2c33cb151a8e7724ebfb7b2d88bc45f,b6870535f3975c49d45e62fbe475f198,b99ecc2f79f56198a8c2adbdff95d576,c103c6d096d52868eda26d991194b5f2,c48bd062d5f6cc20c5df5758d6285562,c5b269ff5c94db7ebd2cb9f7be16f171,d4bbb6beb0dd5c40d2941af71b7c1776,e079b7c92d5c0b009ff02040eb652bc6,e1ad57124a08c0e123deda212ea03c32,e800735d6b2a244875f5e0d292de1527,ee295ebc4c2d6a2a5c738796fcc2ab71,f16299fc00a7a69bdf983dce826b4918,f18bacb0a2fbfea44dd6326224184216,f8a3c7ad2423fe8e91b33ca812ddfeff</data>
    </node>
    <node id="BETA_0">
      <data key="d0">PARAMETER</data>
      <data key="d1">Beta_0 (&#946;0) is a parameter in the linear regression model, representing the intercept of the line of best fit
Beta_0 is the intercept parameter in the simple linear regression model, representing the value of Price when Weight is zero
Beta_0 (&#946;0) is the intercept parameter in the linear regression model
Beta_0 (&#946;0) is the intercept parameter in the linear regression model
Beta_0 is the intercept parameter in the extended linear regression model
Beta_0 (&#946;0) is the intercept in the linear regression model, representing the expected value of Y when all explanatory variables are zero
Beta_0 (&#946;0) is the intercept in the regression model, representing the expected value of Y when X1 and X2 are zero
Beta_0 (&#946;0) is the intercept parameter in the simple linear regression model, representing the expected value of Y when X is zero.
Beta_0 (&#946;0) is a parameter in the linear regression model, representing the intercept of the systematic component
&#946;0 is the intercept term in the multiple regression model
Beta_0 (&#946;0) is the intercept parameter in the linear regression model
Beta_0 (&#946;0) is a parameter in the linear model, representing the intercept of the mean function of the response
Beta_0 (&#946;0) is a parameter in the linear regression model, representing the intercept of the linear predictor
Beta_0 is the intercept parameter in the linear regression model
Beta_0 (&#946;0) is one of the parameters in the quadratic regression model. It represents the intercept of the model
Beta_0 is a parameter in the quadratic regression model, representing the intercept
Beta_0 is the intercept parameter in the linear model
Beta_0 (&#946;0) is a parameter in the linear regression model, representing the intercept of the model. It is the expected value of the response variable (Height) when the predictor variable (log2(diameter)) is zero.
Beta_0 (&#946;0) is the intercept parameter in the model, representing the expected value of the log-transformed response when all explanatory variables are zero.
&#946;0 is a regression coefficient in the log-transformed regression model
Beta_0 (b&#946;0) is the intercept parameter in the linear regression model
Beta_0 is a parameter in the linear regression model, representing the intercept of the line of best fit when both the response and explanatory variables are log-transformed.&gt;
Beta_0 (b&#946;0) is a parameter in the model, representing the intercept of the regression line
Beta_0 is a parameter in the linear regression model, representing the intercept
Beta_0 (&#946;0) is the intercept parameter in the simple linear regression model
Beta_0 is the intercept parameter in the linear regression model
Beta_0 (&#946;0) is a parameter in the linear regression model, representing the intercept
Beta_0 (&#946;0) is a parameter in the linear regression model, representing the intercept of the regression line
Beta_0 (&#946;0) is a parameter in the simple linear regression model, representing the intercept of the regression line
Beta_0 is a parameter in the original model (2), representing the intercept
Beta_0 is the intercept parameter in the simple linear regression model
BETA_0 (&#946;0) is the intercept parameter in the simple linear regression model
Beta_0 is the intercept parameter in the regression model</data>
      <data key="d2">00e186a86624c01ce873dd577df68d17,0fbc9037ca9a440e79e9ac05664b9b3d,10ac76f99674a01ca0f4a55586dea07e,21e429490eeefe7d9c245058fd48ca68,250ee5d766c64e7975bcc427b4bf9074,2d5cdecc342ddacd2c090f1838430cee,3fdeeb7593174f5e8a9cff55a7cd92e3,416494d940a9f505da9853caca26fe63,50a56c34050fb7f7709300a51399b150,512d9ffebe309a6f944ebce1ae2ff2a3,656dce234514b9db38b5b5616557c1e9,67e4c1866b0c6e162e6e3317949e8da9,69ffba28a61d98d8d18f91c24b74dd4a,6a47154bf457c25f22c3cf9f649c5db0,6f10cac870c690419e5351e8a6aeae9e,74a5a0e8ae0f846240c782cc1a30f82f,75dc4d8cb195a1f969d9e9496631086b,7ad4ccec4c7bb3702aed71c17dc6b96f,8f1d95acff56e1633dceb775fa713174,8f7a05b6d231105a6194eebdb2df372e,90b7e0427699cc1bb461e37939935138,9611ea31ff53888971694cdefe806f64,995fb26a0261f824952fa7b2fac3382e,9a27580975988e83f6e3a0d9010893b5,a828fd17fc38e902484872c88a6b242c,b99ecc2f79f56198a8c2adbdff95d576,d14413709de2897231aaa83be3aa346f,d1b6fcd55d937c5fe2d6add69e0bcf05,d4bbb6beb0dd5c40d2941af71b7c1776,e2422d8b80004aab4ea74d5209587861,e5131a1158e58f1b7b44b21ced7b6f60,efeeb664622c1ee594e6a08a8322ffe3,f16299fc00a7a69bdf983dce826b4918</data>
    </node>
    <node id="BETA_1">
      <data key="d0">PARAMETER</data>
      <data key="d1">Beta_1 (&#946;1) is a parameter in the linear regression model, representing the slope of the line of best fit
Beta_1 is the slope parameter in the simple linear regression model, representing the change in Price for a unit change in Weight
Beta_1 (&#946;1) is the slope parameter in the linear regression model
Beta_1 (&#946;1) is the slope parameter in the linear regression model, representing the change in sales for a unit change in price
Beta_1 is the coefficient for the price variable in the extended linear regression model
Beta_1 (&#946;1) is the coefficient for the explanatory variable X1 in the linear regression model, indicating the average change in Y for a one unit increase in X1, given a fixed value of X2
Beta_1 (&#946;1) is the coefficient for X1 in the regression model, indicating the average change in Y for a one unit increase in X1, given a fixed value of X2
Beta_1 (&#946;1) is the slope parameter in the simple linear regression model, representing the change in the expected value of Y for a one-unit change in X.
Beta_1 (&#946;1) is a parameter in the linear regression model, representing the slope of the systematic component
Beta_1 (&#946;1) is one of the parameters in the linear regression model, representing the coefficient of the first explanatory variable
Beta_1 (&#946;1) is a parameter in the linear model, representing the coefficient of the explanatory variable X1
Beta_1 (&#946;1) is a parameter in the linear regression model, representing the coefficient of the first explanatory variable x1
Beta_1 is one of the parameters in the linear regression model, representing the coefficient of the first explanatory variable
Beta_1 (&#946;1) is one of the parameters in the quadratic regression model. It represents the coefficient of the linear term in the model
Beta_1 is a parameter in the quadratic regression model, representing the coefficient of the linear term
Beta_1 is the slope parameter in the linear model associated with the log-transformed diameter
Beta_1 (&#946;1) is a parameter in the linear regression model, representing the slope of the model. It indicates the change in the response variable (Height) for a one-unit increase in the predictor variable (log2(diameter)).
Beta_1 (&#946;1) is the parameter associated with the explanatory variable X1, indicating the change in the log-transformed response per unit change in X1.
&#946;1 is a regression coefficient in the log-transformed regression model, associated with the predictor X1
Beta_1 (b&#946;1) is the coefficient for predictor X1 in the linear regression model
Beta_1 is a parameter in the linear regression model, representing the slope of the line of best fit when both the response and explanatory variables are log-transformed.&gt;
Beta_1 (b&#946;1) is a parameter in the model, representing the slope of the regression line
Beta_1 is a parameter in the linear regression model, representing the coefficient for the log of Diameter
Beta_1 (&#946;1) is the slope parameter in the simple linear regression model
Beta_1 is the slope parameter for the predictor x in the linear regression model
Beta_1 (&#946;1) is a parameter in the linear regression model, representing the slope
Beta_1 (&#946;1) is a parameter in the linear regression model, representing the slope of the regression line
Beta_1 (&#946;1) is a parameter in the simple linear regression model, representing the slope of the regression line
Beta_1 is a parameter in the original model (2), representing the slope
Beta_1 is the coefficient of the predictor xj in the simple linear regression model
BETA_1 (&#946;1) is the slope parameter in the simple linear regression model
Beta_1 is the slope parameter in the regression model, representing the change in the response variable for a unit change in the predictor variable</data>
      <data key="d2">00e186a86624c01ce873dd577df68d17,0fbc9037ca9a440e79e9ac05664b9b3d,10ac76f99674a01ca0f4a55586dea07e,21e429490eeefe7d9c245058fd48ca68,250ee5d766c64e7975bcc427b4bf9074,2d5cdecc342ddacd2c090f1838430cee,3fdeeb7593174f5e8a9cff55a7cd92e3,416494d940a9f505da9853caca26fe63,50a56c34050fb7f7709300a51399b150,512d9ffebe309a6f944ebce1ae2ff2a3,656dce234514b9db38b5b5616557c1e9,67e4c1866b0c6e162e6e3317949e8da9,69ffba28a61d98d8d18f91c24b74dd4a,6a47154bf457c25f22c3cf9f649c5db0,6f10cac870c690419e5351e8a6aeae9e,74a5a0e8ae0f846240c782cc1a30f82f,7ad4ccec4c7bb3702aed71c17dc6b96f,8f1d95acff56e1633dceb775fa713174,8f7a05b6d231105a6194eebdb2df372e,90b7e0427699cc1bb461e37939935138,9611ea31ff53888971694cdefe806f64,995fb26a0261f824952fa7b2fac3382e,9a27580975988e83f6e3a0d9010893b5,a828fd17fc38e902484872c88a6b242c,b99ecc2f79f56198a8c2adbdff95d576,d14413709de2897231aaa83be3aa346f,d1b6fcd55d937c5fe2d6add69e0bcf05,d4bbb6beb0dd5c40d2941af71b7c1776,e2422d8b80004aab4ea74d5209587861,e5131a1158e58f1b7b44b21ced7b6f60,efeeb664622c1ee594e6a08a8322ffe3,f16299fc00a7a69bdf983dce826b4918</data>
    </node>
    <node id="EPSILON">
      <data key="d0">ERROR</data>
      <data key="d1">epsilon (&#1013;) is the random error term in the linear regression model, describing how the observations scatter around the systematic part
&#1013; is the random error term in the simple linear regression model, representing the deviation of the observed Price from the systematic component
Epsilon represents the error term in the model equation (1.2)&gt;
Epsilon (&#1013;) is the error term in the linear regression model, representing the unexplained variation in sales
Epsilon (&#1013;) is the error term in the extended linear regression model, representing the unexplained variation in sales
&#1013; is the error term in the linear regression model, representing the variability in Y that is not explained by the systematic component of the model
Epsilon (&#1013;) represents the error term in the regression model
&#1013;j is the error term in the simple linear regression model, representing the deviation of the observed value of Y from its expected value. It is assumed to be normally distributed with mean zero and variance &#963;^2.
Epsilon (&#1013;j) represents the errors in the linear model, which are normally distributed random variables with mean zero and variance &#963;^2, independent of each other and of the predictor variable X
Epsilon is the column vector containing the error terms epsilon1 through epsilonn
Vector &#1013; represents the error term in the regression model, assumed to follow a multivariate normal distribution
Epsilon is the column vector of error terms
EPSILON is the vector of error terms in the linear regression model
&#1013; is the error term in the linear regression model, which is assumed to be normally distributed
Epsilon (&#1013;) is the error term in the linear regression model, assumed to be iid and normally distributed with mean 0 and variance &#963;^2
Epsilon is the vector of error terms in the linear regression model
Epsilon (&#1013;) is the error term in the linear regression model, assumed to be normally distributed with mean 0 and variance &#963;^2, and is of dimension n
&#1013; is the error term in the linear model, assumed to follow a multivariate normal distribution with mean 0 and covariance matrix &#963;^2In
Epsilon is the vector of error terms for the linear regression model, representing the unexplained variation in the response variable
Epsilon (&#1013;j) is the error term for the jth unit of observation, assumed to be iid N(0, &#963;^2)
EPSILON is the error term in the quadratic regression model, assumed to be iid N(0, &#963;^2)
Epsilon (&#1013;) is the error term in the linear regression model, representing the difference between the observed values and the values predicted by the model. The errors are assumed to be independent and identically distributed (iid) following a normal distribution with mean 0 and variance &#963;^2.
Epsilon is the vector of random errors in the linear model, represented as a column vector with n elements, where each element corresponds to the error term for a single observation. The errors are assumed to be independent and identically distributed with a mean of zero and a constant variance.
Epsilon (&#1013;) is a vector of errors (&#1013;1, ..., &#1013;n) in the linear model
epsilon (&#1013;) is the vector of additive errors in the linear model
&#1013;1, ..., &#1013;n are the errors in the regression model, assumed to have constant variance and a normal distribution
epsilon (&#1013;) is the error term in the linear regression model, representing the difference between the observed values and the values predicted by the model.&gt;
Epsilon (&#1013;) is the error term in the linear regression model, representing the deviation of the observed data from the model
&#1013;j is the error term for the jth observation in the simple linear regression model
Epsilon (&#1013;) is the error term in the linear regression model, assumed to be independent and identically distributed
Epsilon (&#1013;j) is the error term in the straight line model, representing the deviation of the observed Y from the true regression line
Epsilon (&#1013;) is the error term in the linear regression model
&#1013; is the error term in the linear regression model
Epsilon (&#1013;j) is the error term in the linear regression model
Epsilon_j is the error term in both model (1) and model (2)
Epsilon is the error term in the model, assumed to be random and independent
Epsilon (&#1013;) is the error term in the linear model, assumed to be normally distributed with mean 0 and variance &#963;^2
EPSILON (&#1013;) is the error term in the simple linear regression model
&#1013; is the error term in the linear model
&#1013; is the error term in the linear model
epsilon (&#1013;) is the error term in the regression model
Epsilon is the error term in the model that represents the random variation in sales
Epsilon (&#1013;) is the error term in the linear regression model, representing the difference between the observed and predicted values
Epsilon (&#1013;) is the vector of error terms for each of the 96 observations
Epsilon is the error term in the model equations, representing the unexplained variation in sales
&#1013;j is the error term for the jth store in the regression model&gt;
Epsilon (&#1013;) is a variable representing the error term in the model
Epsilon (&#1013;j) is a random variable representing the error term for the jth store
&#1013;j is the error term in the linear model for the Retail data, representing the deviation of the observed sales from the expected sales
Epsilon (&#1013;) is the error term in the model, representing the deviation of the observed sales volume from the expected sales volume
Epsilon (&#1013;) is the error term in the model
Epsilon (&#1013;) is the error term in the parallel lines model, representing the unexplained variation in sales
Epsilon (&#1013;) is the error term in the regression model, representing the unexplained variation in sales
Epsilon (&#1013;) is the error term in the regression model</data>
      <data key="d2">00e186a86624c01ce873dd577df68d17,01d5ee79489582b4135fc96f676b24a0,06199787dd7f75f7338dd24d4f3dc26e,06d5666e6bfdda828b48adba883b4a61,0cb40986e6c2bb439e1ffcaae2df96ac,0da640a09a395a50b6e16e047fa8d0d6,119bc73ddf8eebadfb8eae272fa323a7,1b523d1edabe381403fc470a9b8d47fa,1d141ab04db553f78a313e430e54abb5,248924760a2bfbc82501fd6b11cfa0aa,250ee5d766c64e7975bcc427b4bf9074,2d5cdecc342ddacd2c090f1838430cee,3cbe71f7649e84cd67cb3fa0d3e632cf,48971100deb5bb374a41c1f2b7b2a86a,50a56c34050fb7f7709300a51399b150,512d9ffebe309a6f944ebce1ae2ff2a3,5609007c6229060ffc85d8056a7fefde,67e4c1866b0c6e162e6e3317949e8da9,69ffba28a61d98d8d18f91c24b74dd4a,6c1684ed2a4840576c6b0f4d1a3a482f,6c66e9414880964ee899ceb0f16d22e9,6f10cac870c690419e5351e8a6aeae9e,74a5a0e8ae0f846240c782cc1a30f82f,74d190f10bf6e6936242ca3cdfc4a09f,75dc4d8cb195a1f969d9e9496631086b,7ad4ccec4c7bb3702aed71c17dc6b96f,7d074208b1259e7d84f9f870d3828bb6,7fc5b8303ab530821bf2140ba6a8a889,82932abd152e0b84a1c26a2daa4c08df,8326c645426789920a99ed373725fa0e,8f1d95acff56e1633dceb775fa713174,906eb7d6b49fa360e7e5b65c56cd4d76,9611ea31ff53888971694cdefe806f64,98d6982108f2d42fe0437bff8c666e17,9a27580975988e83f6e3a0d9010893b5,a1fc936df848a0fbc791e4bcc9b527b6,a828fd17fc38e902484872c88a6b242c,ac15b639b0849006471dfe102376c2c0,aeddef300427d211c74c6008b5b6b328,b5d0a103e1f34a00aef67fedd0e8c693,b6870535f3975c49d45e62fbe475f198,b70a75a6412b2e5c44af50734844f4be,d4bbb6beb0dd5c40d2941af71b7c1776,d94760a5f9f6ea115fcc18024035a627,dd7e7d54883ca0f687568a738b95d4d0,e2422d8b80004aab4ea74d5209587861,e41cc40f061f487b1ea0f256d4a963e4,e4f14e6785c6d7b7469e695aaeb170d0,e7494d6cfc3e38a4d2f3f6b21ef6445d,f16299fc00a7a69bdf983dce826b4918,f18bacb0a2fbfea44dd6326224184216,f2300d613896880cbb7c255a4d858315,f5716ce115458c0652124734ca344806,f9b615b879f72501f338f8983d4cac3d</data>
    </node>
    <node id="DETERMINISTIC_PART">
      <data key="d0">CONCEPT</data>
      <data key="d1">The deterministic or systematic part of the relationship between price and weight is represented by the line of best fit</data>
      <data key="d2">d4bbb6beb0dd5c40d2941af71b7c1776</data>
    </node>
    <node id="RANDOM_ERROR">
      <data key="d0">CONCEPT</data>
      <data key="d1">The random error describes how the observations scatter around the systematic part of the relationship between price and weight
Random error is the part of the model that is unpredictable and represents the variability not explained by the systematic component</data>
      <data key="d2">bb31f1c77bbba73300f735a100086a67,d4bbb6beb0dd5c40d2941af71b7c1776</data>
    </node>
    <node id="SIGMA_SQUARED">
      <data key="d0">VARIANCE</data>
      <data key="d1">&#963;^2 is the variance of the error term &#1013; in the simple linear regression model
&#963;^2 is the variance of the error term &#1013;j in the simple linear regression model, representing the spread of the observed values of Y around their expected values.
Sigma squared (&#963;^2) is the variance of the error term in the linear regression model
Sigma squared (&#963;^2) is the variance component of the variance-covariance matrix of the multivariate normal distribution
&#963;^2 is the variance of the error term in the regression model
Sigma squared (&#963;^2) is the variance of the error term in the multiple regression model
Sigma squared (&#963;^2) is the variance of the error term in the linear regression model
&#963;^2 is the variance of the error term &#1013; in the linear regression model
Sigma squared (&#963;^2) is the variance of the error term in the linear regression model
Sigma squared (&#963;^2) is the variance of the error term in the linear regression model
Sigma squared (&#963;^2) is the variance of the error term in the linear regression model
Sigma squared (&#963;^2) is the variance of the error term in the linear regression model
&#963;^2 is the variance of the error term in the linear model
Sigma squared (&#963;^2) is the variance of the error term in the model
Sigma squared (&#963;^2) is the variance of the error term in the quadratic regression model
&#963;^2 (sigma squared) is the variance of the normal distribution of log(Y)
&#963;^2 is the variance of the error term in the linear regression model.
Sigma squared (&#963;^2) is the variance of the error term in the normal linear model
Sigma squared (&#963;^2) is the variance of the error term in the linear regression model
Sigma squared (&#963;^2) is the variance of the error term in the normal linear model
&#963;^2 is the variance parameter in the normal linear model
Sigma squared (&#963;^2) is the variance of the error term in the linear regression model and is a parameter in the log-likelihood function.
Sigma squared (&#963;^2) is the variance of the error term in the statistical model
Sigma squared (&#963;^2) is the variance of the error term in the linear model
Sigma squared (&#963;^2) is the variance of the error term in the linear model
Sigma squared (&#963;^2) is the variance of the error term in the linear model
Sigma squared (&#963;^2) is the variance of the error term in the linear regression model
Sigma squared (&#963;^2) is the variance of the error term in the linear regression model
SIGMA_SQUARED (&#963;^2) is the variance of the error term in the linear regression model
Sigma squared (&#963;^2) is the variance of the error term in the linear regression model
&#963;^2 is the true variance of the error term in the linear regression model
Sigma squared (&#963;^2) is the error variance in the linear regression model
Sigma squared (&#963;^2) is the variance of the error term in the linear regression model

Sigma squared (&#963;^2) is the variance of the error term in the linear regression model
Sigma squared (&#963;^2) is the variance of the error term in a linear model, for which an unbiased estimate can be computed for a given fitted linear model
Sigma squared (&#963;^2) is the variance of the error term in the linear regression model
Sigma squared (&#963;^2) is the variance of the error term in the linear regression model
Sigma squared (&#963;^2) is the variance of the error term in the linear regression model
Sigma squared (&#963;^2) is the variance of the error term in the linear model
&#963;^2 is the variance of the error term in the linear model
Sigma squared (&#963;^2) is the variance of the error term in the regression model
&#963;^2 is the error variance in the regression model
Sigma squared (&#963;^2) is the true error variance in the regression model</data>
      <data key="d2">0443ab5e20a4f6b2f243c989ef6c723a,09caa54ca1372d152e47051be4d44ede,1da117a2f92b2db00290d2a0bfc06beb,2673d078d29f2af78fab9b6eacd15e37,2d5cdecc342ddacd2c090f1838430cee,2de7a36b32bf79c8f32612c8aaa9daa8,34fceaaf7d835828b5ee2327325c37f8,3d357cfa3ef0d00f49cf4acaeac1c9d1,3fb977ccba63e267d2e7dd4de6479ce1,45f31b040576e9f3b4def6d0466cc016,542f546c5a131196e4701fb33c9b1dee,5a0d392715f06d5e873f45ae06aa729a,6648f0d6deed51fb4fb25e6992a71ddf,679722cf8ce5ce5aee4e379528470efe,67e4c1866b0c6e162e6e3317949e8da9,69ffba28a61d98d8d18f91c24b74dd4a,6c1684ed2a4840576c6b0f4d1a3a482f,6f10cac870c690419e5351e8a6aeae9e,74a5a0e8ae0f846240c782cc1a30f82f,74d190f10bf6e6936242ca3cdfc4a09f,75dc4d8cb195a1f969d9e9496631086b,7ad4ccec4c7bb3702aed71c17dc6b96f,7d074208b1259e7d84f9f870d3828bb6,7fc5b8303ab530821bf2140ba6a8a889,87b717ba065d6d7c7431af284137eb12,8f1d95acff56e1633dceb775fa713174,9005147593b2f27b9e2a5eede3601bdc,90b7e0427699cc1bb461e37939935138,9923e77ac6b3de95cb5026bc5e7fe8c0,9a27580975988e83f6e3a0d9010893b5,9dddcd96af7b557e578b3f5f36efacd7,ad799500572246a07f983a3b92c0e61f,b5d0a103e1f34a00aef67fedd0e8c693,b70a75a6412b2e5c44af50734844f4be,c47968226557bc2eb5aec5bb7994fd0e,d14413709de2897231aaa83be3aa346f,d738df7d83784c8a41b3948271c537b6,dd7e7d54883ca0f687568a738b95d4d0,e41cc40f061f487b1ea0f256d4a963e4,e4f14e6785c6d7b7469e695aaeb170d0,e7edd8b2874a350779ae20f1ecdf4733,f483798b15ef305e7826fd7142379e03,f632f01188d2c6e3091a965580cb4600,fc5b725f3c662c5471af20efdcc2dbff</data>
    </node>
    <node id="LM_FUNCTION">
      <data key="d0">FUNCTION</data>
      <data key="d1">lm() is a function in R used to fit linear models
The lm() function in R is used to fit linear models&gt;
lm() is the function in R used to fit linear models</data>
      <data key="d2">825b600cbab3535ce67e9f561ddcb84b,b99ecc2f79f56198a8c2adbdff95d576,f18bacb0a2fbfea44dd6326224184216</data>
    </node>
    <node id="SUMMARY_FUNCTION">
      <data key="d0">FUNCTION</data>
      <data key="d1">summary() is a function in R used to provide a statistical summary of a fitted model</data>
      <data key="d2">b99ecc2f79f56198a8c2adbdff95d576</data>
    </node>
    <node id="USINGR_PACKAGE">
      <data key="d0">PACKAGE</data>
      <data key="d1">UsingR is an R package that provides datasets for statistical analysis</data>
      <data key="d2">b99ecc2f79f56198a8c2adbdff95d576</data>
    </node>
    <node id="DIAMOND_DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">Diamond is a dataset in the UsingR package, containing information about diamonds
The diamond dataset is a collection of data on diamonds, including their weight and price&gt;
The diamond dataset from the package UsingR is a collection of data used for exploratory analysis and modeling, containing information about diamonds</data>
      <data key="d2">b8ec334f8c87bf1d9cb6043fa1a64214,b99ecc2f79f56198a8c2adbdff95d576,f18bacb0a2fbfea44dd6326224184216</data>
    </node>
    <node id="SLR_DIAMOND">
      <data key="d0">MODEL</data>
      <data key="d1">SLR.diamond is the simple linear regression model fitted using the lm() function with price as the response and carat as the predictor</data>
      <data key="d2">b99ecc2f79f56198a8c2adbdff95d576</data>
    </node>
    <node id="USINGR">
      <data key="d0">R_PACKAGE</data>
      <data key="d1">UsingR is an R package that needs to be installed and loaded to use the diamond dataset and perform linear regression analysis</data>
      <data key="d2">2b01334fb633566ba368a764ad579fce</data>
    </node>
    <node id="INSTALL.PACKAGES">
      <data key="d0">R_FUNCTION</data>
      <data key="d1">install.packages is an R function used to install R packages, in this case, the UsingR package</data>
      <data key="d2">2b01334fb633566ba368a764ad579fce</data>
    </node>
    <node id="LIBRARY">
      <data key="d0">R_FUNCTION</data>
      <data key="d1">library is an R function used to load R packages into the current R session, enabling access to the package's functions and datasets</data>
      <data key="d2">2b01334fb633566ba368a764ad579fce</data>
    </node>
    <node id="SLR.DIAMOND">
      <data key="d0">MODEL</data>
      <data key="d1">SLR.diamond is a simple linear regression model object created by fitting the price of diamonds as a function of their carat weight using the lm function</data>
      <data key="d2">2b01334fb633566ba368a764ad579fce</data>
    </node>
    <node id="LM">
      <data key="d0">R_FUNCTION</data>
      <data key="d1">lm is an R function used to fit linear models, in this case, it is used to fit the simple linear regression model SLR.diamond
lm() is a function in R used to fit linear models. It takes a formula and a data argument, where the formula specifies the response and predictor variables.
lm() is a function in R used to fit linear models
lm() is a function in R used to fit linear models
lm is the function in R used to fit linear models</data>
      <data key="d2">084dadebfca8bcb6377c205c45bee295,25fce1af816975003128126b5cfea73b,2b01334fb633566ba368a764ad579fce,35e06960dba699ce0d56fc1e98bdbe96,c48bd062d5f6cc20c5df5758d6285562</data>
    </node>
    <node id="DIAMOND">
      <data key="d0">DATASET</data>
      <data key="d1">diamond is a dataset used in the linear regression analysis, containing information about diamonds such as their price and carat weight
Diamond is a gemstone that is often used as the main stone in Solitaire rings
A diamond is a precious stone, often used in jewelry, whose price is influenced by its weight (carat)&gt;
diamond is a dataset used in the example, containing information about diamonds, including their price and carat weight.
Diamond is the gemstone set in the Solitaire rings, with weights ranging from 0.12 carats and above in the dataset
Diamonds are the product being analyzed in terms of weight and price in the context of Solitaire rings</data>
      <data key="d2">2b01334fb633566ba368a764ad579fce,35e06960dba699ce0d56fc1e98bdbe96,c5b269ff5c94db7ebd2cb9f7be16f171,e1ad57124a08c0e123deda212ea03c32,f18bacb0a2fbfea44dd6326224184216,f8a3c7ad2423fe8e91b33ca812ddfeff</data>
    </node>
    <node id="SUMMARY">
      <data key="d0">R_FUNCTION</data>
      <data key="d1">summary is an R function used to provide a statistical summary of a fitted model, in this case, it is used to summarize the SLR.diamond model</data>
      <data key="d2">2b01334fb633566ba368a764ad579fce</data>
    </node>
    <node id="RESIDUAL_STANDARD_ERROR">
      <data key="d0">ERROR</data>
      <data key="d1">The residual standard error is 31.84 on 46 degrees of freedom, indicating the standard deviation of the residuals in the regression model</data>
      <data key="d2">9fc9b618723695c0c593043162a4084b</data>
    </node>
    <node id="MULTIPLE_R_SQUARED">
      <data key="d0">STATISTIC</data>
      <data key="d1">Multiple R-squared is 0.9783, a measure of the proportion of the variance in the dependent variable that can be explained by the independent variables</data>
      <data key="d2">9fc9b618723695c0c593043162a4084b</data>
    </node>
    <node id="ADJUSTED_R_SQUARED">
      <data key="d0">STATISTIC</data>
      <data key="d1">Adjusted R-squared is 0.9778, a modified version of R-squared that adjusts for the number of predictors in the model</data>
      <data key="d2">9fc9b618723695c0c593043162a4084b</data>
    </node>
    <node id="F_STATISTIC">
      <data key="d0">STATISTIC</data>
      <data key="d1">F-statistic is 2070 on 1 and 46 DF, a test statistic used to determine the significance of the model</data>
      <data key="d2">9fc9b618723695c0c593043162a4084b</data>
    </node>
    <node id="P_VALUE">
      <data key="d0">SIGNIFICANCE</data>
      <data key="d1">The p-value is &lt; 2.2e-16, indicating the probability of observing the test statistic under the null hypothesis</data>
      <data key="d2">9fc9b618723695c0c593043162a4084b</data>
    </node>
    <node id="ESTIMATE">
      <data key="d0">COEFFICIENT</data>
      <data key="d1">Estimate column in the middle table lists information about the coefficients, including the intercept and slope of the line of best fit</data>
      <data key="d2">9fc9b618723695c0c593043162a4084b</data>
    </node>
    <node id="INTERCEPT">
      <data key="d0">COEFFICIENT</data>
      <data key="d1">Intercept is -259.63, the expected average price of a Solitaire ring with a diamond of zero weight
The intercept in a linear regression model represents the expected price of a Solitaire ring with a diamond of zero weight. In this context, it is interpreted as -260 Singapore Dollars, which is a naive interpretation and may not make practical sense.&gt;
The intercept is a parameter in the model that represents the price of a Solitaire ring when the diamond weight is zero, which is considered nonsensical
The intercept is a parameter in the linear model, representing the expected value of the response variable when all predictor variables are zero or at their mean value.
Intercept is the estimated value in the regression model, representing the predicted price of a Solitaire ring with a diamond of average weight
The intercept is a parameter in the fitted model. It represents the expected value of the response variable when all predictor variables are zero.
The intercept (&#946;0) is a parameter in the linear regression model, representing the expected value of Y when all explanatory variables are zero
The intercept is a parameter in a regression model, representing the expected value of the dependent variable when all independent variables are zero. Its interpretation in this context is limited due to the dataset's range of price values.&gt;
Intercept is a parameter in a regression model that represents the average response value when the explanatory variables take the value zero
Intercept is the estimated coefficient for the intercept in the linear regression model
The intercept is a parameter in the linear regression model, representing the expected value of the response variable when all predictor variables are zero. In this case, it is the estimated value of -463.31.
Intercept is the value of the dependent variable when all independent variables are zero
Intercept (&#181;) is a parameter in the regression model, representing the expected value of sales when all explanatory variables are zero</data>
      <data key="d2">0cb40986e6c2bb439e1ffcaae2df96ac,25fce1af816975003128126b5cfea73b,2ced3e26eaed2dfcd8e4caf49737cab4,2e5e1bdaa9fcc7b3391d277fd6bb247a,35e06960dba699ce0d56fc1e98bdbe96,426434b67f6a287852ab66b82ca873cf,9fc9b618723695c0c593043162a4084b,a60af43e42c72a41fa90da06beb29d1b,a828fd17fc38e902484872c88a6b242c,c619949b08fc2b7edf3a7635b46dc147,e1ad57124a08c0e123deda212ea03c32,f0e0c5b2deaaf9fc2bc8b63d9ab989b1,f8a3c7ad2423fe8e91b33ca812ddfeff</data>
    </node>
    <node id="SLOPE">
      <data key="d0">COEFFICIENT</data>
      <data key="d1">Slope is 3721.02, the coefficient associated with the explanatory variable carat, indicating the average price increase for every additional carat of weight
The slope in a linear regression model represents the change in the price of a Solitaire ring for every additional carat of diamond weight. In this context, it is interpreted as an increase of S$ 3721 for every additional carat.&gt;
The slope is a parameter in the linear model, representing the change in the response variable for a one-unit change in the predictor variable.</data>
      <data key="d2">35e06960dba699ce0d56fc1e98bdbe96,9fc9b618723695c0c593043162a4084b,f0e0c5b2deaaf9fc2bc8b63d9ab989b1</data>
    </node>
    <node id="SOLITAIRE_RING_PRICE">
      <data key="d0">DEPENDENT_VARIABLE</data>
      <data key="d1">The price of a Solitaire ring is the dependent variable in the regression model, influenced by the weight of its diamond</data>
      <data key="d2">9fc9b618723695c0c593043162a4084b</data>
    </node>
    <node id="SOLITAIRE_RING">
      <data key="d0">PRODUCT</data>
      <data key="d1">A Solitaire ring is a type of jewelry that features a single diamond as its centerpiece. The price of a Solitaire ring is influenced by the weight of its diamond.&gt;
A Solitaire ring is a type of jewelry that features a single diamond as its main stone
A Solitaire ring is a type of ring that features a single diamond, used for comparison in the text&gt;
Solitaire ring is the type of jewelry being analyzed in the dataset, featuring a single diamond
Solitaire rings are a type of jewelry that typically features a single diamond as the main stone</data>
      <data key="d2">c5b269ff5c94db7ebd2cb9f7be16f171,e1ad57124a08c0e123deda212ea03c32,f0e0c5b2deaaf9fc2bc8b63d9ab989b1,f18bacb0a2fbfea44dd6326224184216,f8a3c7ad2423fe8e91b33ca812ddfeff</data>
    </node>
    <node id="ROUNDING">
      <data key="d0">PROCESS</data>
      <data key="d1">Rounding of coefficients in a regression model is a process that involves adjusting the numerical values to a more sensible representation in the given context.&gt;
Rounding is the process of approximating a number to a specified number of decimal places
Rounding is a common phenomenon in practice where the response variable is rounded, which can affect the regression analysis</data>
      <data key="d2">312309b45c59e1c84695ac3c7e202742,ef24ca5edd06893b737e6a1c8a9825f6,f0e0c5b2deaaf9fc2bc8b63d9ab989b1</data>
    </node>
    <node id="SLOPE_COEFFICIENT">
      <data key="d0">PARAMETER</data>
      <data key="d1">The slope coefficient represents the change in price of a Solitaire ring for every additional 0.1 carat of diamond weight
The slope coefficient is a parameter in the linear regression model, representing the change in the response variable for a one-unit increase in the predictor variable. In this case, it is the estimated value of 82.84, which can be interpreted as the average increase in height (in decimeters) associated with a doubling of the diameter of a Western red cedar tree.</data>
      <data key="d2">c619949b08fc2b7edf3a7635b46dc147,e1ad57124a08c0e123deda212ea03c32</data>
    </node>
    <node id="NEGATIVE_AVERAGE_PRICE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A negative average price is a nonsensical concept that may arise from the interpretation of the intercept in the model</data>
      <data key="d2">e1ad57124a08c0e123deda212ea03c32</data>
    </node>
    <node id="S_372">
      <data key="d0">CURRENCY</data>
      <data key="d1">S$ 372,- is the predicted increase in price for a diamond ring with a diamond that is 0.1 carat heavier than another&gt;</data>
      <data key="d2">f18bacb0a2fbfea44dd6326224184216</data>
    </node>
    <node id="AVG_WEIGHT">
      <data key="d0">MEASUREMENT</data>
      <data key="d1">Avg_weight denotes the average weight of the diamonds in the dataset&gt;</data>
      <data key="d2">f18bacb0a2fbfea44dd6326224184216</data>
    </node>
    <node id="ALPHA_0">
      <data key="d0">PARAMETER</data>
      <data key="d1">Alpha_0 is the intercept in the model equation (1.2)&gt;
Alpha_0 (&#945;0) is a parameter in the straight line model, representing the intercept
Alpha_0 is a parameter in the reparameterised model (1), representing the intercept</data>
      <data key="d2">d1b6fcd55d937c5fe2d6add69e0bcf05,f18bacb0a2fbfea44dd6326224184216,f2300d613896880cbb7c255a4d858315</data>
    </node>
    <node id="ALPHA_1">
      <data key="d0">PARAMETER</data>
      <data key="d1">Alpha_1 is the coefficient for the predictor variable (weight - avg_weight) in the model equation (1.2)&gt;
Alpha_1 (&#945;1) is a parameter in the straight line model, representing the slope
Alpha_1 is a parameter in the reparameterised model (1), representing the slope</data>
      <data key="d2">d1b6fcd55d937c5fe2d6add69e0bcf05,f18bacb0a2fbfea44dd6326224184216,f2300d613896880cbb7c255a4d858315</data>
    </node>
    <node id="MODEL_EQUATION">
      <data key="d0">MATHEMATICAL_EXPRESSION</data>
      <data key="d1">The model equation is a formula used to predict the price of a diamond ring based on the weight of the diamond&gt;</data>
      <data key="d2">f18bacb0a2fbfea44dd6326224184216</data>
    </node>
    <node id="I_FUNCTION">
      <data key="d0">FUNCTION</data>
      <data key="d1">The I() function in R is used to inhibit the conversion of an expression into an operator&gt;</data>
      <data key="d2">f18bacb0a2fbfea44dd6326224184216</data>
    </node>
    <node id="COEF_FUNCTION">
      <data key="d0">FUNCTION</data>
      <data key="d1">The coef() function in R is used to extract model coefficients&gt;
coef() is the function in R used to extract the coefficients from a model</data>
      <data key="d2">825b600cbab3535ce67e9f561ddcb84b,f18bacb0a2fbfea44dd6326224184216</data>
    </node>
    <node id="SLR_DIAMOND2">
      <data key="d0">MODEL</data>
      <data key="d1">Slr_diamond2 is a linear model fitted using the lm() function in R, with price as the response variable and the deviation of carat from its mean as the predictor&gt;
slr.diamond2 is a linear model object created using the lm() function, with price as the response variable and the centered carat variable as the predictor.</data>
      <data key="d2">35e06960dba699ce0d56fc1e98bdbe96,f18bacb0a2fbfea44dd6326224184216</data>
    </node>
    <node id="I">
      <data key="d0">FUNCTION</data>
      <data key="d1">I() is a function in R used to inhibit the conversion of an expression into an operator. It is used in the formula argument of lm() to evaluate the expression before using it as an explanatory variable.
I is a variable used in the context of a loop, ranging from 1 to n</data>
      <data key="d2">35e06960dba699ce0d56fc1e98bdbe96,bd05fe6a05f9a13d33c4f1b5a771ada5</data>
    </node>
    <node id="COEF">
      <data key="d0">FUNCTION</data>
      <data key="d1">coef() is a function in R used to extract model coefficients from objects returned by modeling functions, such as lm().
coef() is a function in R used to extract the coefficients from a fitted model
coef() is a function in R used to extract model coefficients
coef is the function in R used to extract the coefficients from a fitted model
Coef() is a function used to extract the coefficients of a fitted model
coef is a function that extracts model coefficients from the linear model
Coef is a function in R used to extract model coefficients from the fitted model</data>
      <data key="d2">084dadebfca8bcb6377c205c45bee295,25fce1af816975003128126b5cfea73b,35e06960dba699ce0d56fc1e98bdbe96,6a6f85d0a6e46196ab3a901fcc82a720,9a28a6420fca4405488ca35762f9dc28,a60af43e42c72a41fa90da06beb29d1b,c48bd062d5f6cc20c5df5758d6285562</data>
    </node>
    <node id="MEAN">
      <data key="d0">FUNCTION</data>
      <data key="d1">mean() is a function in R used to calculate the average of a set of numbers. It is used to calculate the average carat weight of diamonds in the dataset.</data>
      <data key="d2">35e06960dba699ce0d56fc1e98bdbe96</data>
    </node>
    <node id="AVERAGE_WEIGHT">
      <data key="d0">QUANTITY</data>
      <data key="d1">Average weight is the mean carat weight of the diamonds in the Solitaire rings in the dataset, which is 0.204 carats</data>
      <data key="d2">f8a3c7ad2423fe8e91b33ca812ddfeff</data>
    </node>
    <node id="SAMPLE_MEAN_PRICE">
      <data key="d0">ESTIMATED_VALUE</data>
      <data key="d1">Sample mean price is the average price of the Solitaire rings in the dataset, which is equal to the estimated intercept of S$ 500.08
The sample mean price of Solitaire rings is a statistical measure that is equal to the estimated intercept of S$ 500.08</data>
      <data key="d2">c5b269ff5c94db7ebd2cb9f7be16f171,f8a3c7ad2423fe8e91b33ca812ddfeff</data>
    </node>
    <node id="AVERAGE_DIAMOND_WEIGHT">
      <data key="d0">MEASUREMENT</data>
      <data key="d1">The average diamond weight is a statistical measure used as a reference point in the analysis</data>
      <data key="d2">c5b269ff5c94db7ebd2cb9f7be16f171</data>
    </node>
    <node id="REGRESSION_LINE">
      <data key="d0">MATHEMATICAL_MODEL</data>
      <data key="d1">The regression line is a mathematical model that represents the relationship between the weight of diamonds and the price of Solitaire rings
The regression line is a line that best fits the data points in a scatterplot, representing the relationship between the dependent and independent variables
Regression line is the fitted line that describes the relationship between X and Y
The regression line is a fitted line that describes the relationship between the explanatory variable and the response variable in a scatterplot
A regression line is a line that best fits the data in a scatterplot, used to predict the response variable based on the explanatory variable
The fitted regression line describes the general trend in the data. However, the average distance of the observations to the fitted line increases with the explanatory variable.
The regression line is the line of best fit calculated from the data, used to describe the relationship between the predictor and response variables
The fitted regression line is a model that describes the relationship between the explanatory variable and the response variable
The regression line is the line of best fit in the scatterplot of sales against price, which is used to visualize the relationship between sales volume and price.&gt;
Regression lines are used in regression analysis to represent the relationship between predictor variables and the response variable.</data>
      <data key="d2">2a5997c641e47fc6c32ebf81101c54e0,312309b45c59e1c84695ac3c7e202742,674b8d5bb1f830d0fb944942514d1a16,7a605c3b689bec7ab2c46df9c123e3f3,82cfcd5865cffe55e965a50745656e60,9f335f1ecb85a1427df926df8bb1e89f,b0ca3e6c22c4cf884d03b1f6f82be5df,b9ec8a6c7960cc6196ec94fd976f05b0,c5b269ff5c94db7ebd2cb9f7be16f171,ef24ca5edd06893b737e6a1c8a9825f6</data>
    </node>
    <node id="FIGURE_1_3">
      <data key="d0">VISUAL_REPRESENTATION</data>
      <data key="d1">Figure 1.3 is a visual representation that shows two scatterplots of the diamond data, illustrating the relationship between diamond weight and ring price</data>
      <data key="d2">c5b269ff5c94db7ebd2cb9f7be16f171</data>
    </node>
    <node id="WEIGHT_DEVIATIONS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">c5b269ff5c94db7ebd2cb9f7be16f171</data>
    </node>
    <node id="REGRESSION_LINES">
      <data key="d0">MODEL</data>
      <data key="d1">Regression lines are used in simple linear regression to model the relationship between an explanatory variable and a response variable. They are identical in relation to the data when the coordinate system shifts horizontally, illustrating that the predictions from the two fitted lines will be identical.
Regression lines are used in statistical analysis to model the relationship between a dependent variable and one or more independent variables</data>
      <data key="d2">13e6c81b642252522460f4abadaab1cc,9854704301b8df256ca1013b8d53dfac</data>
    </node>
    <node id="COORDINATE_SYSTEM">
      <data key="d0">REFERENCE_FRAME</data>
      <data key="d1">The coordinate system is a reference frame used to plot data points and regression lines. When it shifts horizontally, the regression lines remain identical in relation to the data.</data>
      <data key="d2">13e6c81b642252522460f4abadaab1cc</data>
    </node>
    <node id="PREDICTIONS">
      <data key="d0">FORECASTS</data>
      <data key="d1">Predictions are the estimated values of the response variable based on the fitted regression lines. They are identical when the coordinate system shifts horizontally.</data>
      <data key="d2">13e6c81b642252522460f4abadaab1cc</data>
    </node>
    <node id="PARAMETERISATION">
      <data key="d0">MODEL_SPECIFICATION</data>
      <data key="d1">Parameterisation refers to the specific form or specification of a model. Different parameterisations can represent the same model, just using different parameters or equations.
Parameterisation refers to the way parameters are defined or expressed in a statistical model
Parameterisation refers to the different ways the model can be specified, including the choice of reference category
Parameterisation refers to the specific way in which the model parameters are defined or specified</data>
      <data key="d2">13e6c81b642252522460f4abadaab1cc,86ece4718d27d1a6c6a1f448cc850e2b,9854704301b8df256ca1013b8d53dfac,a1fc936df848a0fbc791e4bcc9b527b6</data>
    </node>
    <node id="RE_PARAMETERISATIONS">
      <data key="d0">MODEL_REFORMULATION</data>
      <data key="d1">Re-parameterisations are reformulations of a model using different parameters or equations. They can represent the same model but from a different perspective or with a different focus.</data>
      <data key="d2">13e6c81b642252522460f4abadaab1cc</data>
    </node>
    <node id="MATHEMATICAL_DESCRIPTION">
      <data key="d0">MODEL_DEFINITION</data>
      <data key="d1">Mathematical description is the formal definition or specification of a model using mathematical equations and symbols. It provides a precise and unambiguous representation of the model.</data>
      <data key="d2">13e6c81b642252522460f4abadaab1cc</data>
    </node>
    <node id="R_IMPLEMENTATION">
      <data key="d0">CODE</data>
      <data key="d1">R implementation is the code written in the R programming language to implement the mathematical model. It translates the mathematical description into a computational form.</data>
      <data key="d2">13e6c81b642252522460f4abadaab1cc</data>
    </node>
    <node id="INTERPRETATION">
      <data key="d0">MODEL_EXPLANATION</data>
      <data key="d1">Interpretation is the explanation or understanding of the model within the context of the data and the problem being studied. It involves translating the mathematical and computational aspects of the model into meaningful insights.</data>
      <data key="d2">13e6c81b642252522460f4abadaab1cc</data>
    </node>
    <node id="REPARAMETERISATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Re-parameterisations refer to the process of changing the parameters of a model while keeping the model's predictions the same. This concept will be formally defined later in the module.</data>
      <data key="d2">ccced70c40ef9105ac2f7a9bfd151125</data>
    </node>
    <node id="MATERIAL_COVERED">
      <data key="d0">CURRICULUM</data>
      <data key="d1">The material covered so far in the module is familiar to most students, but it exemplifies the skills needed to move confidently between mathematical descriptions, R implementation, and interpretation in the application context.</data>
      <data key="d2">ccced70c40ef9105ac2f7a9bfd151125</data>
    </node>
    <node id="SKILLS">
      <data key="d0">ABILITY</data>
      <data key="d1">Skills required for the module include the ability to move confidently between the mathematical description of a model, its implementation in R, and its interpretation within the application context.</data>
      <data key="d2">ccced70c40ef9105ac2f7a9bfd151125</data>
    </node>
    <node id="EXERCISES">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Exercises are provided to help students assimilate and practice the material discussed so far. The solutions can be found in the ST231 Exercise Booklet on moodle.</data>
      <data key="d2">ccced70c40ef9105ac2f7a9bfd151125</data>
    </node>
    <node id="EXERCISE_1">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Exercise 1 requires students to derive the mathematical relationship between the parameters in the model formulation in (1.1) and the one in (1.2).</data>
      <data key="d2">ccced70c40ef9105ac2f7a9bfd151125</data>
    </node>
    <node id="EXERCISE_2">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Exercise 2 involves using R to show numerically that the fitted model based on (1.2) leads to the same predictions as the fitted model based on (1.1). This demonstrates that the model in (1.2) is a reparameterisation of the model in (1.1).</data>
      <data key="d2">ccced70c40ef9105ac2f7a9bfd151125</data>
    </node>
    <node id="EXERCISE_3">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Exercise 3 addresses the issue of negative price predictions for Solitaire rings with very small diamonds by fitting a model with the intercept fixed to zero. The model is Price = &#946;1 weight.
Exercise 3 involves fitting a regression through the origin model to the diamond data and comparing its fit to the model in (1.1) that does not restrict the intercept</data>
      <data key="d2">ccced70c40ef9105ac2f7a9bfd151125,e47d573a10e64a657e58218df64d8920</data>
    </node>
    <node id="MODEL_1_1">
      <data key="d0">REGRESSION_MODEL</data>
      <data key="d1">Model (1.1) is a regression model that describes the relationship between the price of diamonds and their carat weight, without restricting the intercept to be equal to zero</data>
      <data key="d2">e47d573a10e64a657e58218df64d8920</data>
    </node>
    <node id="MODEL_1_2">
      <data key="d0">REGRESSION_MODEL</data>
      <data key="d1">Model (1.2) is a reparameterisation of model (1.1), leading to the same predictions</data>
      <data key="d2">e47d573a10e64a657e58218df64d8920</data>
    </node>
    <node id="REPARAMETERISATION">
      <data key="d0">MODEL_TRANSFORMATION</data>
      <data key="d1">Reparameterisation is the process of transforming a model into a different form that leads to the same predictions, as seen between models (1.1) and (1.2)
Reparameterisation is a mathematical transformation that changes the parameterisation of a model
Reparameterisation is a technique used to improve the interpretability of parameters and their estimates in a statistical model</data>
      <data key="d2">9854704301b8df256ca1013b8d53dfac,9fc2b1e8b2b61b557f88eb9e9c708597,e47d573a10e64a657e58218df64d8920</data>
    </node>
    <node id="REGRESSION_THROUGH_ORIGIN">
      <data key="d0">REGRESSION_MODEL</data>
      <data key="d1">Regression through the origin is a type of regression model where the intercept is fixed to be equal to zero, as in the model Price = &#946;1 weight + &#1013;</data>
      <data key="d2">e47d573a10e64a657e58218df64d8920</data>
    </node>
    <node id="R_COMMAND">
      <data key="d0">PROGRAMMING_COMMAND</data>
      <data key="d1">The R command lm(price ~ 0 + carat, data = diamond) is used to fit a regression through the origin model to the diamond data</data>
      <data key="d2">e47d573a10e64a657e58218df64d8920</data>
    </node>
    <node id="OUTCOME_VARIABLE_Y">
      <data key="d0">VARIABLE</data>
      <data key="d1">Outcome variable Y is the variable of interest in a regression model, which is affected by and responds to the explanatory variable X</data>
      <data key="d2">e47d573a10e64a657e58218df64d8920</data>
    </node>
    <node id="EXPLANATORY_VARIABLE_X">
      <data key="d0">VARIABLE</data>
      <data key="d1">Explanatory variable X is the variable that is used to explain the variation in the outcome variable Y in a regression model</data>
      <data key="d2">e47d573a10e64a657e58218df64d8920</data>
    </node>
    <node id="Y">
      <data key="d0">RESPONSE_VARIABLE</data>
      <data key="d1">Y is the response variable in the linear regression model, which is affected by and responds to the explanatory variable X
Y is the response variable in the linear regression model, which is expected to change in response to changes in the explanatory variables
Y is the dependent variable in the regression model, which in the sales example is the sales volume
Y is the dependent variable in the simple linear regression model, representing the response or outcome variable. Its observed values are denoted as y1, y2, ..., yn for n paired observations.
Y is the dependent variable in the linear regression model, whose mean is determined by the systematic component and whose variance is equal to &#963;^2
Y is the column vector containing the observed values Y1 through Yn
Y is the column vector of observed response values
Y is the vector of dependent variables in the linear regression model
Y is the response variable in the linear model, whose expectation is specified by the linear predictor
Y is the response variable in the linear regression model, which is a function of the values of the explanatory variables
Y is the vector of n random variables representing the responses in the linear regression model
Y is the response variable, which is dependent on the explanatory variables and the error termy represents the observed values of the response variable Y
Y is the vector of observed values in the linear regression model
Y is a vector of observed response values in the linear regression model, of dimension n
Y is the response vector in the linear model, which is assumed to follow a multivariate normal distribution with mean X&#946; and covariance matrix &#963;^2In
Y is another variable in the dataset, used in the regression analysis
Y is the response variable in the regression model
Y is the response variable in the quadratic regression model
Y is the response variable in the linear regression model
Y is a vector of observed values in the quadratic regression model
Y is the vector of observed responses in the linear model, represented as a column vector with n elements, where each element corresponds to the response variable for a single observation.
Y is the vector of observed values of the response variable in the linear model
Y is a random variable that, when log-transformed, follows a normal distribution with mean &#181; and variance &#963;^2
Y is the vector of observed values in the simple linear regression model
Y is the vector of observed values for the n units of observation
y is a vector of observed values in the linear regression model
y is a vector of observed values in the linear regression model
Y is a vector of observed values in the linear regression model
Y is a vector used in the expression of S(&#946;)
Y is a vector of observed values in the linear regression model
Y is a vector of observed values in the linear regression model
Y is a vector of observed values in the linear regression model
Y is the vector of observed values in the linear regression model
Y is a vector of observed values in the linear regression model
Y is a vector of observed values in the simple linear regression model
Y is a vector of observed values in the linear regression model
Vector Y is a column vector of the observed y variable values
Y is a vector of observed values in the linear regression model
y is a vector of observed values in the linear regression model
Y is a variable in the straight line model, representing the response or dependent variable
Y is the vector of observed values in a linear regression model
Y is the vector of observed values in the linear regression model
Y is a vector of observed values in the linear regression model
Y_j is the dependent variable in both model (1) and model (2)
Y is the vector of observed response values in the model
Y is the vector of observed values in the linear regression model
Y is the vector of observed values in the linear model
Y is a vector of observed values in the normal linear model
Y is a vector of observed values in the normal linear model
Y is the vector of observed values in the normal linear model
Y is the vector of observed values in the statistical model
Y is the random vector whose entries are the response random variables Y1, ..., Yn in the linear model
Y is the random vector whose entries are the response random variables Y1, ..., Yn in the linear model
Y is a vector of observed values in the linear model, following a multivariate normal distribution Nn(X&#946;, &#963;^2In)
Y is a vector of observed values in the linear regression model
Y is the vector of observed values in the linear regression model
Y is a vector of observed values in the linear regression model
Y is the response vector in the linear regression model
Y is the vector of observed values in the linear regression model
Y is a vector of observed values in the linear regression model
Y is a vector of observed values in the linear regression model
Y is a vector of observed values in the linear regression model
Y is the vector of observed values in the statistical model.
Y is the vector of response random variables in the linear model
Y is the vector of response random variables in the linear regression model
Y is the vector of observed values in the linear regression model
Y is the vector of response variables in the regression model
Y is the vector of response variables in the linear model
Y is the vector of observed values in the linear model
Y is a vector of observed values in the linear regression model.
Y is the vector of observed values for the dependent variable in the linear regression model
Y is a vector of observed values in the linear regression model</data>
      <data key="d2">070499b11a2fc1530fd2751d0920ad31,084dadebfca8bcb6377c205c45bee295,09caa54ca1372d152e47051be4d44ede,0ac60299320c55d642b3e38440c25f90,0b650eb2f1dcd603b64fec3c4b5cd24b,10ac76f99674a01ca0f4a55586dea07e,11452a08471d93959558de2ece9a69af,2167274129d4cfa74a002c4cc39df8a8,21e429490eeefe7d9c245058fd48ca68,21ec28dfe2b2c18030d541d63e51f45e,248924760a2bfbc82501fd6b11cfa0aa,254a8a17b1be06702934341e3bf41e85,255685e281cc5a9edf073c700f425a6b,2673d078d29f2af78fab9b6eacd15e37,2685edb9e8031c8ea725c43a40af22a8,28cf5ff0c09fa5c0390267bb9aa3ce47,2a5997c641e47fc6c32ebf81101c54e0,2d5cdecc342ddacd2c090f1838430cee,2de7a36b32bf79c8f32612c8aaa9daa8,2f2523c52c6d2869fb19f77b66ce8259,3cbe71f7649e84cd67cb3fa0d3e632cf,3d357cfa3ef0d00f49cf4acaeac1c9d1,416494d940a9f505da9853caca26fe63,45f31b040576e9f3b4def6d0466cc016,50a56c34050fb7f7709300a51399b150,512d9ffebe309a6f944ebce1ae2ff2a3,542f546c5a131196e4701fb33c9b1dee,5609007c6229060ffc85d8056a7fefde,56ff186fc629e1e42f2759fc4b984199,5a0d392715f06d5e873f45ae06aa729a,6648f0d6deed51fb4fb25e6992a71ddf,679722cf8ce5ce5aee4e379528470efe,67e4c1866b0c6e162e6e3317949e8da9,69ffba28a61d98d8d18f91c24b74dd4a,6a47154bf457c25f22c3cf9f649c5db0,6b55b41598d5264f8dc6b72769748722,6c66e9414880964ee899ceb0f16d22e9,6ee02b38ae842fd5eac9a11c4fd6659f,74a5a0e8ae0f846240c782cc1a30f82f,74d190f10bf6e6936242ca3cdfc4a09f,7955aae3fd4ca51b9ef8843e13c1f517,7ad4ccec4c7bb3702aed71c17dc6b96f,7d074208b1259e7d84f9f870d3828bb6,7fc5b8303ab530821bf2140ba6a8a889,82932abd152e0b84a1c26a2daa4c08df,8f1d95acff56e1633dceb775fa713174,9005147593b2f27b9e2a5eede3601bdc,9923e77ac6b3de95cb5026bc5e7fe8c0,9a27580975988e83f6e3a0d9010893b5,9d300fc83afb3261af61b2ab9721cadc,9dddcd96af7b557e578b3f5f36efacd7,9fc2b1e8b2b61b557f88eb9e9c708597,a4a817bb79d6ae8812c808ca41d47f43,a828fd17fc38e902484872c88a6b242c,aa195e72eb5285a4bcae9c856af30a87,b5d0a103e1f34a00aef67fedd0e8c693,b70a75a6412b2e5c44af50734844f4be,c9a01b92d11585f6549f62e8bd78d652,d94760a5f9f6ea115fcc18024035a627,dd7e7d54883ca0f687568a738b95d4d0,e41cc40f061f487b1ea0f256d4a963e4,e4f14e6785c6d7b7469e695aaeb170d0,e7494d6cfc3e38a4d2f3f6b21ef6445d,e7edd8b2874a350779ae20f1ecdf4733,eac62cdd5518e1269fed150639331c2c,f2300d613896880cbb7c255a4d858315,f470791d2d3fedede166f9bb11598c9c,f483798b15ef305e7826fd7142379e03,f5716ce115458c0652124734ca344806,f632f01188d2c6e3091a965580cb4600,f9b615b879f72501f338f8983d4cac3d,fc5b725f3c662c5471af20efdcc2dbff</data>
    </node>
    <node id="X">
      <data key="d0">EXPLANATORY_VARIABLE</data>
      <data key="d1">X is the explanatory variable in the linear regression model, which is useful in explaining the variation in Y
X is the independent variable in the simple linear regression model, representing the predictor or explanatory variable. Its observed values are denoted as x1, x2, ..., xn for n paired observations.
X is the predictor variable in the linear regression model, influencing the mean of Y
X is the n x 2 design matrix, with each row containing a 1 and the corresponding x value
Matrix X is the design or model matrix used in regression analysis, distinguished from the variable X
X is the matrix of explanatory variables in the linear regression model, including a column of ones for the intercept
X is the design matrix containing the values of the explanatory variables in the linear regression model
X is the design matrix containing the values of the explanatory variables
X is the design matrix in the linear regression model, containing the values of the explanatory variables
X is the design matrix in the linear regression model, an n x p matrix where n is the number of observations and p is the number of parameters, including the intercept and explanatory variables
X is the design matrix in the linear model, containing the values of the explanatory variables
X is one of the variables in the dataset, used in the regression analysis
X is the design matrix for the linear regression model, consisting of a column of ones and columns for the predictor variables and their squares
X is a vector of predictor variables, including x1, x2, ..., x11, and their squared terms
X is the explanatory variable in the quadratic regression model
X is the explanatory variable in the linear regression model, with its value influencing the expected response
X is the design matrix used in least squares estimation, containing the values of the explanatory variables for all units of observation
X is a vector containing the predictor variables x1, x2, ..., xq for the quadratic regression model
X is the design matrix used in the linear regression model. It contains the values of the predictor variable (log2(diameter)) for each observation. The matrix has 139 rows, each corresponding to a different tree, and two columns: the first column is a vector of 1s (for the intercept term) and the second column contains the log2(diameter) values.
X is the design matrix containing the values of the predictor variables
X is the design matrix in the linear regression model, containing the values of the explanatory variables
X is the matrix of explanatory variables in the linear model
X is the vector of predictor variables in the simple linear regression model
X is the n x p design matrix, where each row represents the predictor variables for a single observation
X is the design matrix in the linear regression model, assumed to be of full rank
X is a matrix of predictor variables in the linear regression model
X is a matrix of predictor variables in the linear regression model
X is a matrix used in the expression of S(&#946;) and is noted to be of full rank
X is a matrix in the context of linear regression, where rank(X) = p indicates that X has full column rank
X is the design matrix in the linear regression model, containing the predictor variables
X is the design matrix in simple linear regression, consisting of a column of ones and a column of predictor variable values
X is a matrix of predictor variables in the linear regression model
X is a vector of predictor variables in the simple linear regression model
X is a matrix with elements including 1s and xj values, used in the calculation of the least squares estimator
Matrix X is a 2xN matrix with the first row being a vector of ones and the second row being the x variable values
X is a matrix with dimensions n x 2, where the first column is a vector of ones and the second column is the vector of observed values X1 to Xn
x is a vector of predictor variables in the linear regression model
X is a variable in the straight line model, representing the predictor or independent variable
X is the design matrix for the straight line model Yj = &#945;0 + &#945;1 (xj &#8722; x) + &#1013;j, j = 1, ..., n
X is the design matrix in a linear regression model, containing the predictor variables
X is the design matrix in the linear regression model
X is a matrix of explanatory variables in the linear regression model
X is the design matrix of the model parameterisation, containing the intercept and the explanatory variable observations
X is the design matrix in the linear regression model, with rows representing observations and columns representing predictor variables
X is the design matrix in the normal linear model, containing the predictor variables
X is the design matrix in the statistical model, containing the predictor variables
X is the design matrix in the linear model, assumed to be of full rank
X is the design matrix in the linear model with n rows and p columns
X is the design matrix in the linear model, assumed to be of full rank
X is the design matrix in the linear regression model, containing the explanatory variable(s)
X is the matrix of predictor variables in the linear regression model
X is the matrix of predictor variables in the linear regression model
X is the design matrix in the linear regression model, containing the predictor variables
X is the design matrix in the linear regression model, used to calculate the least squares estimate and the maximum likelihood estimate
Matrix X contains the predictor variables in the linear regression model
Matrix X is the design matrix in regression analysis, containing the predictor variables.
X is a matrix used in the linear regression model, containing the predictor variables
X is the design matrix in the linear regression model
X is the design matrix in the linear model, of rank p
X is the design matrix of the linear model, with rank p
X is the design matrix in the linear regression model, containing the values of the explanatory variables.
X is the design matrix in the linear regression model, defining the linear relationship between the dependent and independent variables
X is the design matrix with 96 rows and 4 columns, containing the indicator variables and price for each store
X is the design matrix with 96 rows and 4 columns, containing the values of the predictors for each observation
X is the design matrix for the regression model, containing columns for brandA, brandB, brandC, and price, with n = 96 rows</data>
      <data key="d2">00e186a86624c01ce873dd577df68d17,070499b11a2fc1530fd2751d0920ad31,084dadebfca8bcb6377c205c45bee295,09caa54ca1372d152e47051be4d44ede,10ac76f99674a01ca0f4a55586dea07e,11452a08471d93959558de2ece9a69af,119bc73ddf8eebadfb8eae272fa323a7,1303b66694a101878ca530c0b41cf5ef,1da117a2f92b2db00290d2a0bfc06beb,2167274129d4cfa74a002c4cc39df8a8,21ec28dfe2b2c18030d541d63e51f45e,228bdca7843406def245d755e8df49f6,248924760a2bfbc82501fd6b11cfa0aa,254a8a17b1be06702934341e3bf41e85,255685e281cc5a9edf073c700f425a6b,2673d078d29f2af78fab9b6eacd15e37,28cf5ff0c09fa5c0390267bb9aa3ce47,2a5997c641e47fc6c32ebf81101c54e0,2b6d31b6bff4eae3a4809451c4fb9fa6,2d5cdecc342ddacd2c090f1838430cee,2de7a36b32bf79c8f32612c8aaa9daa8,2f2523c52c6d2869fb19f77b66ce8259,3cbe71f7649e84cd67cb3fa0d3e632cf,3d357cfa3ef0d00f49cf4acaeac1c9d1,416494d940a9f505da9853caca26fe63,45f31b040576e9f3b4def6d0466cc016,46629f2efc6c82e81265a131b4bab2ee,50a56c34050fb7f7709300a51399b150,56ff186fc629e1e42f2759fc4b984199,5a0d392715f06d5e873f45ae06aa729a,5cc49d301d9cd1f8e20b92ab9d8346b0,69ffba28a61d98d8d18f91c24b74dd4a,6b55b41598d5264f8dc6b72769748722,6c1684ed2a4840576c6b0f4d1a3a482f,6c66e9414880964ee899ceb0f16d22e9,6ee02b38ae842fd5eac9a11c4fd6659f,74a5a0e8ae0f846240c782cc1a30f82f,74d190f10bf6e6936242ca3cdfc4a09f,75dc4d8cb195a1f969d9e9496631086b,7955aae3fd4ca51b9ef8843e13c1f517,7ad4ccec4c7bb3702aed71c17dc6b96f,7d074208b1259e7d84f9f870d3828bb6,7fc5b8303ab530821bf2140ba6a8a889,82932abd152e0b84a1c26a2daa4c08df,8f1d95acff56e1633dceb775fa713174,9005147593b2f27b9e2a5eede3601bdc,9923e77ac6b3de95cb5026bc5e7fe8c0,9a27580975988e83f6e3a0d9010893b5,9d300fc83afb3261af61b2ab9721cadc,aa195e72eb5285a4bcae9c856af30a87,aeddef300427d211c74c6008b5b6b328,b70a75a6412b2e5c44af50734844f4be,c9a01b92d11585f6549f62e8bd78d652,d94760a5f9f6ea115fcc18024035a627,dd7e7d54883ca0f687568a738b95d4d0,e41cc40f061f487b1ea0f256d4a963e4,e4f14e6785c6d7b7469e695aaeb170d0,e7edd8b2874a350779ae20f1ecdf4733,e800735d6b2a244875f5e0d292de1527,eac62cdd5518e1269fed150639331c2c,f2300d613896880cbb7c255a4d858315,f5716ce115458c0652124734ca344806,f632f01188d2c6e3091a965580cb4600,f9b615b879f72501f338f8983d4cac3d,fc5b725f3c662c5471af20efdcc2dbff</data>
    </node>
    <node id="LINEAR_REGRESSION_MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">Linear regression model describes the relationship between an outcome variable Y and an explanatory variable X</data>
      <data key="d2">070499b11a2fc1530fd2751d0920ad31</data>
    </node>
    <node id="STATISTICAL_INDEPENDENCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Statistical independence is a fundamental concept in probability and statistics, referring to the lack of connection between events or variables. In the context of the text, it is mentioned as a term that might be misinterpreted.</data>
      <data key="d2">4683e58cf41e5f5d415a63ddb2fe0cac</data>
    </node>
    <node id="OBSERVATIONS">
      <data key="d0">DATA</data>
      <data key="d1">Observations are the data points collected in a study, consisting of paired measurements (x, y) for each unit of observation. In the context of simple linear regression, these are the (x1, y1), (x2, y2), ..., (xn, yn) pairs.
Number of observations is a metric that indicates the size of the dataset
Observations are the data points in the scatterplot and residual plot. Their variation along the horizontal axis appears constant.
Observations are the data points in a scatterplot, representing the values of the response and explanatory variables
Observations are the individual data points used in the regression analysis</data>
      <data key="d2">2a5997c641e47fc6c32ebf81101c54e0,312309b45c59e1c84695ac3c7e202742,4683e58cf41e5f5d415a63ddb2fe0cac,82cfcd5865cffe55e965a50745656e60,b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </node>
    <node id="XJ">
      <data key="d0">VARIABLE</data>
      <data key="d1">Xj is the measurement of the explanatory variable X for the jth unit of observation. It represents the value of the independent variable for a specific observation.
xj represents the jth explanatory variable in the linear regression model
xj is the value of the explanatory variable for the jth unit of observation
Xj is the predictor value for the jth data point in the linear regression model
Xj is a variable representing the jth predictor value in the linear regression model
Xj represents the jth observed value of the independent variable in a dataset
Xj is a variable representing the jth value of a predictor in a dataset
x_j is the independent variable in both model (1) and model (2)
Xj is the explanatory variable in the models, which is multiplied by C in the reparameterised model
Xj is the jth predictor value in the simple linear regression model
Xj represents the jth x value in the dataset</data>
      <data key="d2">3fdeeb7593174f5e8a9cff55a7cd92e3,4683e58cf41e5f5d415a63ddb2fe0cac,5609007c6229060ffc85d8056a7fefde,6c1684ed2a4840576c6b0f4d1a3a482f,7fc5b8303ab530821bf2140ba6a8a889,8f7a05b6d231105a6194eebdb2df372e,90b7e0427699cc1bb461e37939935138,d14413709de2897231aaa83be3aa346f,d1b6fcd55d937c5fe2d6add69e0bcf05,f5716ce115458c0652124734ca344806,f9e7b2eac9f82681301da3d1e2f23328</data>
    </node>
    <node id="YJ">
      <data key="d0">VARIABLE</data>
      <data key="d1">Yj is the measurement of the response variable Y for the jth unit of observation. It represents the value of the dependent variable for a specific observation.
Yj is the observed response value for the jth unit of observation in the regression model
YJ is the observed response value for the jth unit of observation
Yj is the jth response variable in the linear regression model
Yj is the jth observed value in the linear regression model, given by the linear combination of the parameters and the explanatory variables plus the error term
Yj represents the dependent variable in the model equation for the jth unit of observation
Yj is the jth observed response value in the linear regression model
Yj is the jth observed value in the dataset, representing the actual response for the jth observation.
Yj is the observed value for the jth data point in the linear regression model
Yj is a variable representing the jth response value in the linear regression model
Yj represents the jth observed value of the dependent variable in a dataset
Yj is the dependent variable in the straight line model, representing the observed values
Yj is a variable representing the jth observed value in a dataset
Yj is the dependent variable in the models
Yj is the jth observed value in the linear regression model
Yj is the jth observed value in the simple linear regression model</data>
      <data key="d2">1303b66694a101878ca530c0b41cf5ef,3fdeeb7593174f5e8a9cff55a7cd92e3,4683e58cf41e5f5d415a63ddb2fe0cac,5cc49d301d9cd1f8e20b92ab9d8346b0,6c1684ed2a4840576c6b0f4d1a3a482f,75dc4d8cb195a1f969d9e9496631086b,7ad4ccec4c7bb3702aed71c17dc6b96f,7fc5b8303ab530821bf2140ba6a8a889,87b717ba065d6d7c7431af284137eb12,8f7a05b6d231105a6194eebdb2df372e,b5d0a103e1f34a00aef67fedd0e8c693,d14413709de2897231aaa83be3aa346f,d1b6fcd55d937c5fe2d6add69e0bcf05,e6f79ceb0df54119a4dc71b2162ac50b,f5716ce115458c0652124734ca344806,f9e7b2eac9f82681301da3d1e2f23328</data>
    </node>
    <node id="SOLITAIRE_RING_EXAMPLE">
      <data key="d0">EXAMPLE</data>
      <data key="d1">The Solitaire ring example is used to illustrate the application of simple linear regression. In this example, yj is the price of the jth ring and xj is the weight of its diamond.</data>
      <data key="d2">4683e58cf41e5f5d415a63ddb2fe0cac</data>
    </node>
    <node id="VARIABLES">
      <data key="d0">FEATURES</data>
      <data key="d1">Variables (or variates) are features in the system of interest that are quantifiable. They are the aspects of the system that can be measured and analyzed.</data>
      <data key="d2">4683e58cf41e5f5d415a63ddb2fe0cac</data>
    </node>
    <node id="DATA">
      <data key="d0">MEASUREMENTS</data>
      <data key="d1">Data are the realized values obtained when variates are measured on specific units of observation. They are the actual numbers or values that result from the measurement of variables.
The data is the collection of observations or measurements that needs to be analyzed and understood
The data refers to the observations used in the regression analysis, which are relatively evenly distributed on either side of the fitted regression line
Data refers to the collection of observations or measurements that are analyzed in statistical studies.</data>
      <data key="d2">312309b45c59e1c84695ac3c7e202742,4683e58cf41e5f5d415a63ddb2fe0cac,bb31f1c77bbba73300f735a100086a67,eafa2cc6cc64d8bca1c080bdd2ad7654</data>
    </node>
    <node id="RANDOM_VARIABLE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Random variable is a concept from probability theory, referring to a variable whose possible values are outcomes of a random phenomenon. It is distinguished from its realization, which is the actual value observed.
Random variable is a variable whose possible values are outcomes of a random phenomenon, often denoted with capital letters in probability theory</data>
      <data key="d2">4683e58cf41e5f5d415a63ddb2fe0cac,7594eee7e77beb023d1cd64aec64920d</data>
    </node>
    <node id="APPLIED_STATISTICS">
      <data key="d0">FIELD</data>
      <data key="d1">Applied statistics is a field of study that applies statistical methods to real-world problems. It has a tradition of being less consistent in terminology and notation than mathematics.
Applied statistics is a field that uses statistical methods to analyze data and solve real-world problems, often with less consistency in terminology and notation than mathematics</data>
      <data key="d2">4683e58cf41e5f5d415a63ddb2fe0cac,7594eee7e77beb023d1cd64aec64920d</data>
    </node>
    <node id="UNITS_OF_OBSERVATION">
      <data key="d0">OBSERVATION</data>
      <data key="d1">Units of observation are the specific instances or subjects on which data are collected in a statistical study</data>
      <data key="d2">7594eee7e77beb023d1cd64aec64920d</data>
    </node>
    <node id="REALISATION">
      <data key="d0">OBSERVED_VALUE</data>
      <data key="d1">Realisation is the actual value observed for a random variable in a particular instance</data>
      <data key="d2">7594eee7e77beb023d1cd64aec64920d</data>
    </node>
    <node id="THEORY_UNDERNEATH">
      <data key="d0">CONCEPT</data>
      <data key="d1">Theory underneath refers to the foundational principles and concepts that underpin statistical methods and models</data>
      <data key="d2">7594eee7e77beb023d1cd64aec64920d</data>
    </node>
    <node id="PRECISION_OF_LANGUAGE_AND_NOTATION">
      <data key="d0">STANDARD</data>
      <data key="d1">Precision of language and notation is the clarity and consistency in terminology and symbols used in statistical communication and documentation</data>
      <data key="d2">7594eee7e77beb023d1cd64aec64920d</data>
    </node>
    <node id="RESPONSE_VARIABLE_Y">
      <data key="d0">VARIABLE</data>
      <data key="d1">Response variable Y is the variable of primary interest in a statistical model, whose values are influenced by the explanatory variables</data>
      <data key="d2">7594eee7e77beb023d1cd64aec64920d</data>
    </node>
    <node id="EXPLANATORY_VARIABLES_X">
      <data key="d0">VARIABLE</data>
      <data key="d1">Explanatory variables X are the variables that are used to explain or predict the response variable in a statistical model, treated as fixed rather than random</data>
      <data key="d2">7594eee7e77beb023d1cd64aec64920d</data>
    </node>
    <node id="DESIGNED_EXPERIMENT">
      <data key="d0">STUDY_TYPE</data>
      <data key="d1">Designed experiment is a type of study where the values of the explanatory variables are chosen by the experimenter to test specific hypotheses</data>
      <data key="d2">7594eee7e77beb023d1cd64aec64920d</data>
    </node>
    <node id="OBSERVATIONAL_STUDIES">
      <data key="d0">STUDY_TYPE</data>
      <data key="d1">Observational studies are studies where the data are collected without manipulation by the researcher, often to explore associations between variables
Observational studies are research designs where the data is measured or observed at the same time as the response variable, without any intervention from the researcher</data>
      <data key="d2">22478e53f29f16e3eab9d167fea52b22,7594eee7e77beb023d1cd64aec64920d</data>
    </node>
    <node id="NONRANDOM_VARIABLES">
      <data key="d0">VARIABLE</data>
      <data key="d1">Nonrandom variables are variables that are not considered to have a probability distribution, often because their values are fixed or determined by the study design</data>
      <data key="d2">7594eee7e77beb023d1cd64aec64920d</data>
    </node>
    <node id="CONDITIONAL_MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">Conditional model is a statistical model that is developed based on the values taken by the explanatory variables, treating them as fixed</data>
      <data key="d2">7594eee7e77beb023d1cd64aec64920d</data>
    </node>
    <node id="RESPONSE_VARIABLE">
      <data key="d0">VARIABLE_TYPE</data>
      <data key="d1">The response variable is the variable of interest in a statistical model, which is often predicted or explained by the explanatory variables
Response variable (Y) is the variable being predicted in the model. Its values are modeled as a function of the explanatory variable and the parameters of the model.
The response variable is the outcome or dependent variable that the model aims to predict or explain
The response variable is the dependent variable in a statistical model that is being predicted by the predictor variables
The response variable is the variable being predicted or explained in a regression model
The response variable is the variable being predicted or explained in the regression model.
The response variable is the variable being predicted or explained by the explanatory variable
Response variable is the outcome or dependent variable in a statistical model
The response variable is the variable being predicted by the predictor variable
Response variable is the dependent variable in the regression model, whose variation is explained by the explanatory variable
The response variable is the variable being predicted or explained in a regression model</data>
      <data key="d2">22478e53f29f16e3eab9d167fea52b22,312309b45c59e1c84695ac3c7e202742,7347b44ffb25a066e43321f4eaf5a806,768c516c8b27fb9800427e848f02fc33,82cfcd5865cffe55e965a50745656e60,b9af17718641389ba07f53be13f31f8c,b9eb75001a4f68f7240b2ca9e0d79eb8,b9ec8a6c7960cc6196ec94fd976f05b0,bb31f1c77bbba73300f735a100086a67,e361ac139c268d5c3f3623f920e68af2,ef24ca5edd06893b737e6a1c8a9825f6</data>
    </node>
    <node id="DATA_MEASUREMENT">
      <data key="d0">SOURCE</data>
      <data key="d1">Data in observational studies might be simply measured or observed at the same time as the response variable</data>
      <data key="d2">22478e53f29f16e3eab9d167fea52b22</data>
    </node>
    <node id="PROBABILITY_THEORY">
      <data key="d0">THEORY</data>
      <data key="d1">Probability theory uses capital letters to denote random variables and small letters for their realizations, to distinguish between the two</data>
      <data key="d2">22478e53f29f16e3eab9d167fea52b22</data>
    </node>
    <node id="RANDOM_VARIABLES">
      <data key="d0">VARIABLE_TYPE</data>
      <data key="d1">Random variables are variables whose values are determined by chance, and are denoted by capital letters in probability theory</data>
      <data key="d2">22478e53f29f16e3eab9d167fea52b22</data>
    </node>
    <node id="VECTORS">
      <data key="d0">DATA_STRUCTURE</data>
      <data key="d1">Vectors are one-dimensional arrays of numbers, which can be random or not, and are denoted by small letters in linear algebra
Vectors are used to represent quantities that have both magnitude and direction, such as sales, price, and advertising budget in the context of retail stores.</data>
      <data key="d2">22478e53f29f16e3eab9d167fea52b22,336546bc73cbe1828a0cc1a45faf8f5a</data>
    </node>
    <node id="MATRICES">
      <data key="d0">DATA_STRUCTURE</data>
      <data key="d1">Matrices are two-dimensional arrays of numbers, which can be random or not, and are denoted by capital letters in linear algebra</data>
      <data key="d2">22478e53f29f16e3eab9d167fea52b22</data>
    </node>
    <node id="SIMULATED_DATASET">
      <data key="d0">DATA_TYPE</data>
      <data key="d1">A simulated dataset is a set of data that has been artificially created for the purpose of testing or demonstrating statistical methods or models</data>
      <data key="d2">22478e53f29f16e3eab9d167fea52b22</data>
    </node>
    <node id="RETAIL_STORES">
      <data key="d0">ENTITY</data>
      <data key="d1">Retail stores are physical or online establishments where products are sold to consumers</data>
      <data key="d2">22478e53f29f16e3eab9d167fea52b22</data>
    </node>
    <node id="PRODUCT_SALES">
      <data key="d0">DATA_TYPE</data>
      <data key="d1">Product sales data refers to the number of units of a product sold, often used as a response variable in statistical models</data>
      <data key="d2">22478e53f29f16e3eab9d167fea52b22</data>
    </node>
    <node id="SIMPLE_REGRESSION">
      <data key="d0">MODEL_TYPE</data>
      <data key="d1">Simple regression is a statistical model that uses one explanatory variable to predict the response variable
Simple regression is a statistical method used to analyze the relationship between two variables: one response variable and one explanatory variable.</data>
      <data key="d2">22478e53f29f16e3eab9d167fea52b22,336546bc73cbe1828a0cc1a45faf8f5a</data>
    </node>
    <node id="MULTIPLE_REGRESSION">
      <data key="d0">MODEL_TYPE</data>
      <data key="d1">Multiple regression is a statistical model that uses two or more explanatory variables to predict the response variable
Multiple regression is a statistical method used to analyze the relationship between one response variable and two or more explanatory variables.
Multiple regression is a statistical method used to model the relationship between a dependent variable and two or more independent variables
Multiple regression is a statistical method used to model the relationship between a dependent variable and two or more independent variables.
Multiple regression is a statistical technique used to model the relationship between a dependent variable and two or more independent variables</data>
      <data key="d2">22478e53f29f16e3eab9d167fea52b22,336546bc73cbe1828a0cc1a45faf8f5a,60cc94e681863c9fcc6f9be1e500f840,a60af43e42c72a41fa90da06beb29d1b,aa13c33a7e61206e6021e2736002ca9a</data>
    </node>
    <node id="MATRIX">
      <data key="d0">MATRIX</data>
      <data key="d1">A matrix object is used in the context of data representation and analysis, often in the form of a table with rows and columns.
Matrix is a data structure used to represent the relationship between brand, price, and sales volume in the dataset</data>
      <data key="d2">336546bc73cbe1828a0cc1a45faf8f5a,6a6f85d0a6e46196ab3a901fcc82a720</data>
    </node>
    <node id="SALES">
      <data key="d0">RESPONSE_VARIABLE</data>
      <data key="d1">Sales represent the number of units of a product sold, measured in thousands, and is the response variable in the regression analysis.
Sales is the dependent variable in the linear regression model, representing the sales volume
Sales is a variable in the dataset that represents the number of units sold. It is measured in thousands.
Sales is the dependent variable in the model, representing the number of units sold, measured in thousands
Sales is an economic variable that represents the total amount of goods or services sold over a specific period of time
Sales is the response variable in the regression analysis, representing the sales volume
Sales volume (sales) is the response variable in the regression model
Sales represent the total number of units sold or the revenue generated from selling products or services. An increase in sales by 544 units is associated with a &#163;1000 increase in the local advertising budget.&gt;
Sales is a variable in the model that represents the sales volume in the jth store
Sales is the dependent variable in the model, representing the sales figures of the products
Sales is the dependent variable in the regression analysis, representing the sales figures of stores
Sales is the dependent variable in the regression model, recorded in thousands
Sales is the dependent variable in the model, recorded in thousands
Sales is a vector of 96 rows representing sales data for 96 different observations
Sales is a quantitative variable representing the sales of the product
Salesj is the dependent variable in the model, representing sales at the jth store&gt;
Sales is the dependent variable in the regression model, representing the sales data for different stores
Sales is the response variable of interest, representing the sales volumes of the stores
Sales (Salesj) is a variable in the model, representing the sales at the jth store
Sales is the dependent variable in the linear regression model, representing the sales figures of stores
Sales is the dependent variable in the linear model for the Retail data, which is influenced by the categorical predictor brand
Sales (Salesj) is the dependent variable in the model, representing sales at the jth store
Sales is the response variable in the model, representing the sales of the product
Sales is the dependent variable in the regression models, representing the sales volume
Sales is the response variable in the regression model, representing the sales volume
Sales is the response variable in the regression model
Sales is the dependent variable in the regression model, representing the sales volume of the stores
Sales is the dependent variable in the regression model, representing the sales volume of the stores</data>
      <data key="d2">06d5666e6bfdda828b48adba883b4a61,0cb40986e6c2bb439e1ffcaae2df96ac,1820d10ee0f23f34b3ea88ba475bc52d,1b523d1edabe381403fc470a9b8d47fa,1d141ab04db553f78a313e430e54abb5,248924760a2bfbc82501fd6b11cfa0aa,250ee5d766c64e7975bcc427b4bf9074,2e5e1bdaa9fcc7b3391d277fd6bb247a,336546bc73cbe1828a0cc1a45faf8f5a,3dd24a54028976ba54304ec7169bb74b,426434b67f6a287852ab66b82ca873cf,48971100deb5bb374a41c1f2b7b2a86a,7037e0369bfdaad5a730cabb2b44831c,825b600cbab3535ce67e9f561ddcb84b,8326c645426789920a99ed373725fa0e,86ece4718d27d1a6c6a1f448cc850e2b,8a9b984c146f59b2af83d1c2f373d376,906eb7d6b49fa360e7e5b65c56cd4d76,93da9813e10a119798de6982977f1239,a1fc936df848a0fbc791e4bcc9b527b6,ac15b639b0849006471dfe102376c2c0,aeddef300427d211c74c6008b5b6b328,b1690cb1a67892245c0665e5099e322d,b2c33cb151a8e7724ebfb7b2d88bc45f,c103c6d096d52868eda26d991194b5f2,c48bd062d5f6cc20c5df5758d6285562,ee295ebc4c2d6a2a5c738796fcc2ab71,f16299fc00a7a69bdf983dce826b4918</data>
    </node>
    <node id="ADVERT">
      <data key="d0">EXPLANATORY_VARIABLE</data>
      <data key="d1">Advert is the local advertising budget spent on promoting the product, measured in thousands of pounds, and is an explanatory variable in the regression analysis.
Advert is a variable in the dataset that represents the amount spent on local advertising for the product. It may also have an influence on the sales volume.
Advert is an independent variable in the model, representing the amount spent on local advertising for the product
Advert, or advertising, is an economic variable that represents the promotion of products or services to potential customers
Advert is one of the explanatory variables in the regression analysis, representing the advertising budget
Advertising budget (advert) is another explanatory variable used in the regression model
Advert is an explanatory variable in the linear regression model, with a coefficient indicating the average effect on the response variable when its value is increased by one unit
Advert is another independent variable that was considered in a more complex model but is not discussed in the simple linear regression context.</data>
      <data key="d2">250ee5d766c64e7975bcc427b4bf9074,2e5e1bdaa9fcc7b3391d277fd6bb247a,336546bc73cbe1828a0cc1a45faf8f5a,8a9b984c146f59b2af83d1c2f373d376,a828fd17fc38e902484872c88a6b242c,b1690cb1a67892245c0665e5099e322d,c48bd062d5f6cc20c5df5758d6285562,e079b7c92d5c0b009ff02040eb652bc6</data>
    </node>
    <node id="RESIDUAL">
      <data key="d0">STATISTICAL_CONCEPT</data>
      <data key="d1">A residual is the difference between an observation and the point on the line that has the same x-coordinate as the observation. It is used to measure the discrepancy between the observed data and the values predicted by the model.
ri is the residual for the ith observation, used in identifying unusual observations</data>
      <data key="d2">09391efd3b8c510205098b548bc8dc74,2e5e1bdaa9fcc7b3391d277fd6bb247a</data>
    </node>
    <node id="RED_LINES">
      <data key="d0">GRAPHICAL_ELEMENT</data>
      <data key="d1">The red lines in the scatterplot illustrate the residuals. They are vertical lines that represent the difference between an observation and the point on the line that has the same x-coordinate as the observation.</data>
      <data key="d2">2e5e1bdaa9fcc7b3391d277fd6bb247a</data>
    </node>
    <node id="SLR_MODEL">
      <data key="d0">STATISTICAL_MODEL</data>
      <data key="d1">The simple linear regression model (slr.model) is computed using the lm() command in R. It is used to predict the number of units sold based on the price charged for the product.</data>
      <data key="d2">2e5e1bdaa9fcc7b3391d277fd6bb247a</data>
    </node>
    <node id="COEFFICIENT">
      <data key="d0">MODEL_PARAMETER</data>
      <data key="d1">The coefficient is a parameter in the fitted model. It represents the change in the expected value of the response variable for a one unit change in the predictor variable.</data>
      <data key="d2">2e5e1bdaa9fcc7b3391d277fd6bb247a</data>
    </node>
    <node id="BETA_2">
      <data key="d0">PARAMETER</data>
      <data key="d1">Beta_2 is the coefficient for the advert variable in the extended linear regression model
Beta_2 (&#946;2) is the coefficient for the explanatory variable X2 in the linear regression model, indicating the average change in Y for a one unit increase in X2, assuming the value of X1 is fixed
Beta_2 (&#946;2) is the coefficient for X2 in the regression model, indicating the average change in Y for a one unit increase in X2, assuming X1 is held constant
Beta_2 is one of the parameters in the linear regression model, representing the coefficient of the second explanatory variable
BETA_2 (&#946;2) is one of the parameters in the quadratic regression model. It represents the coefficient of the quadratic term in the model
Beta_2 is a parameter in the quadratic regression model, representing the coefficient of the quadratic term
Beta_2 (&#946;2) is the parameter associated with the explanatory variable X2, showing the change in the log-transformed response per unit change in X2.
&#946;2 is a regression coefficient in the log-transformed regression model, associated with the predictor X2
Beta_2 (b&#946;2) is the coefficient for predictor X2 in the linear regression model
Beta_2 is a parameter in the linear regression model, representing the coefficient for the log of Height</data>
      <data key="d2">0fbc9037ca9a440e79e9ac05664b9b3d,21e429490eeefe7d9c245058fd48ca68,250ee5d766c64e7975bcc427b4bf9074,2d5cdecc342ddacd2c090f1838430cee,512d9ffebe309a6f944ebce1ae2ff2a3,7ad4ccec4c7bb3702aed71c17dc6b96f,9611ea31ff53888971694cdefe806f64,995fb26a0261f824952fa7b2fac3382e,a828fd17fc38e902484872c88a6b242c,e5131a1158e58f1b7b44b21ced7b6f60</data>
    </node>
    <node id="FIGURE_1_6">
      <data key="d0">FIGURE</data>
      <data key="d1">Figure 1.6 is a scatterplot showing the relationship between sales volume and the local advertising budget, with the line of best fit added to the plot</data>
      <data key="d2">250ee5d766c64e7975bcc427b4bf9074</data>
    </node>
    <node id="R_2">
      <data key="d0">SPACE</data>
      <data key="d1">R^2 is the two-dimensional space in which the simple linear regression model is represented</data>
      <data key="d2">250ee5d766c64e7975bcc427b4bf9074</data>
    </node>
    <node id="R_3">
      <data key="d0">SPACE</data>
      <data key="d1">R^3 is the three-dimensional space in which the extended linear regression model is represented</data>
      <data key="d2">250ee5d766c64e7975bcc427b4bf9074</data>
    </node>
    <node id="R2">
      <data key="d0">MATHEMATICAL_CONCEPT</data>
      <data key="d1">R2, or R squared, is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model
Points in R2 represent the observed data when there is one explanatory variable
r2 is a variable representing the squared standardised residual for the ith observation</data>
      <data key="d2">8a9b984c146f59b2af83d1c2f373d376,98d6982108f2d42fe0437bff8c666e17,c48bd062d5f6cc20c5df5758d6285562</data>
    </node>
    <node id="R3">
      <data key="d0">MATHEMATICAL_CONCEPT</data>
      <data key="d1">R3, or R cubed, is a three-dimensional Euclidean space where points are represented by three coordinates (x, y, z)
Points in R3 represent the observed data when there are two explanatory variables</data>
      <data key="d2">8a9b984c146f59b2af83d1c2f373d376,c48bd062d5f6cc20c5df5758d6285562</data>
    </node>
    <node id="GRAPHICAL_ILLUSTRATION">
      <data key="d0">VISUALIZATION</data>
      <data key="d1">Graphical illustration refers to a visual representation of data or concepts, often used to explain complex ideas or relationships</data>
      <data key="d2">8a9b984c146f59b2af83d1c2f373d376</data>
    </node>
    <node id="HTML_VERSION">
      <data key="d0">DOCUMENT_FORMAT</data>
      <data key="d1">HTML version is a format of a document that can be displayed in a web browser and supports interactive graphics</data>
      <data key="d2">8a9b984c146f59b2af83d1c2f373d376</data>
    </node>
    <node id="3D_GRAPHICAL_REPRESENTATION">
      <data key="d0">VISUALIZATION</data>
      <data key="d1">3D graphical representation is a type of visualization that uses three dimensions to display data or concepts</data>
      <data key="d2">8a9b984c146f59b2af83d1c2f373d376</data>
    </node>
    <node id="DATAPPOINTS">
      <data key="d0">DATA</data>
      <data key="d1">Datapoints are individual pieces of data that are plotted in a graph or used in statistical analysis
Datapoints are represented as spheres in the 3D scatterplot, with those above the plane shown in black and those below the plane in grey</data>
      <data key="d2">8a9b984c146f59b2af83d1c2f373d376,b1690cb1a67892245c0665e5099e322d</data>
    </node>
    <node id="REGRESSION_PLANE">
      <data key="d0">MATHEMATICAL_CONCEPT</data>
      <data key="d1">Regression plane is a plane in a multidimensional space that best fits the data points in a multiple regression analysis
The regression plane is a concept in statistics used to illustrate the relationship between variables in a 3D scatterplot, in this case, the relationship between sales, price, and advert</data>
      <data key="d2">8a9b984c146f59b2af83d1c2f373d376,b1690cb1a67892245c0665e5099e322d</data>
    </node>
    <node id="PDF_FORMAT">
      <data key="d0">DOCUMENT_FORMAT</data>
      <data key="d1">PDF format is a document format that is used to present and exchange documents reliably, independent of the application, hardware, or operating system in which they were created
PDF format is a document format that does not support interactive graphics, only static images</data>
      <data key="d2">8a9b984c146f59b2af83d1c2f373d376,b1690cb1a67892245c0665e5099e322d</data>
    </node>
    <node id="STATIC_GRAPHIC">
      <data key="d0">VISUALIZATION</data>
      <data key="d1">Static graphic is a type of visualization that does not change or respond to user input, often used in documents or presentations</data>
      <data key="d2">8a9b984c146f59b2af83d1c2f373d376</data>
    </node>
    <node id="PLANE">
      <data key="d0">GEOMETRIC_SHAPE</data>
      <data key="d1">The plane is a geometric shape used to represent the relationship between the response variable (sales) and the two explanatory variables (price and advert) in a 3D scatterplot
A plane is used to summarize the relationship between the response variable and two explanatory variables</data>
      <data key="d2">b1690cb1a67892245c0665e5099e322d,c48bd062d5f6cc20c5df5758d6285562</data>
    </node>
    <node id="Z_AXIS">
      <data key="d0">COORDINATE_AXIS</data>
      <data key="d1">The z-axis is one of the three axes in a 3D coordinate system, used to measure the distance between the observed datapoints and the regression plane</data>
      <data key="d2">b1690cb1a67892245c0665e5099e322d</data>
    </node>
    <node id="FIGURE_1_7">
      <data key="d0">GRAPHICAL_REPRESENTATION</data>
      <data key="d1">Figure 1.7 is a 3D scatterplot of the Retail data including the plane of best fit describing the relationship between sales, price, and advert</data>
      <data key="d2">b1690cb1a67892245c0665e5099e322d</data>
    </node>
    <node id="RETAIL_DATA">
      <data key="d0">DATA_SET</data>
      <data key="d1">Retail data is a data set that includes information about sales, price, and advert
Retail data is a specific dataset that can be used to practice reparameterising a multiple regression model
Retail data is the dataset used in the model fitting process
Retail data is the dataset used in the analysis, containing information about sales, price, and brand
Retail data is a dataset used for analysis, containing information about sales, prices, and brands
Retail is the dataset used in the regression model</data>
      <data key="d2">2ced3e26eaed2dfcd8e4caf49737cab4,825b600cbab3535ce67e9f561ddcb84b,86ece4718d27d1a6c6a1f448cc850e2b,a1fc936df848a0fbc791e4bcc9b527b6,ac15b639b0849006471dfe102376c2c0,b1690cb1a67892245c0665e5099e322d</data>
    </node>
    <node id="EXPLANATORY_VARIABLE">
      <data key="d0">VARIABLE</data>
      <data key="d1">Explanatory variables are used to predict or explain the variation in the response variable in a regression model
Explanatory variable (x) is the predictor variable in the model. Its values for each unit of observation (xj) are used in the model equation to predict the response variable.
The explanatory variable is the independent variable that is used to predict or explain the response variable
The explanatory variable is the variable used to predict or explain the response variable in a regression model
The explanatory variable is one of the variables in the regression model, used to predict or explain the response variable.
The explanatory variable is the variable used to predict or explain the response variable
Explanatory variable is the predictor or independent variable in a statistical model
Explanatory variable is a predictor in the regression model, used to explain the variation in the response variable
Explanatory variable, in this context, refers to brand, which is considered as a potential predictor of sales volume.</data>
      <data key="d2">7347b44ffb25a066e43321f4eaf5a806,82cfcd5865cffe55e965a50745656e60,b9af17718641389ba07f53be13f31f8c,b9eb75001a4f68f7240b2ca9e0d79eb8,b9ec8a6c7960cc6196ec94fd976f05b0,bb31f1c77bbba73300f735a100086a67,c48bd062d5f6cc20c5df5758d6285562,e079b7c92d5c0b009ff02040eb652bc6,ef24ca5edd06893b737e6a1c8a9825f6</data>
    </node>
    <node id="OBSERVED_DATA">
      <data key="d0">DATA</data>
      <data key="d1">Observed data consists of values for the response variable and one or more explanatory variables</data>
      <data key="d2">c48bd062d5f6cc20c5df5758d6285562</data>
    </node>
    <node id="MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">Model is the result of fitting a linear model using the lm() function
A model is a parametric formula that links the response variable with the explanatory variables, taking into account the stochastic nature of the response
Model is a representation of reality used for description, prediction, or explanation.
Model in this context refers to a statistical model used to describe the relationship between a response variable and one or more explanatory variables</data>
      <data key="d2">22061b1108c7f9963497b7a320be22b8,7cd6069e88e81548a237fa937adfecc6,bb31f1c77bbba73300f735a100086a67,c48bd062d5f6cc20c5df5758d6285562</data>
    </node>
    <node id="BETA0">
      <data key="d0">PARAMETER</data>
      <data key="d1">Beta0 (&#946;0) is the intercept parameter in the linear regression model
Beta0 is the intercept term in the multiple regression model
Beta0 (&#946;0) is a parameter in the statistical models, representing the intercept
Beta0 (&#946;0) is a parameter in the model, representing the intercept of the linear combination
Beta0 is the intercept parameter in the linear regression model
&#946;0 is a parameter in the model, representing the intercept term in the log-transformed model.
Beta0 (b&#946;0) is the intercept parameter estimate in simple linear regression, calculated as y&#175; - b&#946;1x&#175;
Beta0 is the intercept parameter in the linear regression model
Beta0 (b&#946;0) is another parameter in the linear regression model, calculated as the intercept in the least squares estimation, specifically ybar - (Sxy/Sxx)xbar
Beta0 is the intercept parameter in the linear regression model
Beta0 (&#946;0) is a parameter in the linear regression model, representing the intercept of the model</data>
      <data key="d2">09caa54ca1372d152e47051be4d44ede,254a8a17b1be06702934341e3bf41e85,28cf5ff0c09fa5c0390267bb9aa3ce47,34fceaaf7d835828b5ee2327325c37f8,5b24b5382abe9d1898810b3e4b9b455a,60cc94e681863c9fcc6f9be1e500f840,86c401dda130c2d201c3339526062a24,87b717ba065d6d7c7431af284137eb12,90ed6030c5a5a0764b7dcd4115b4d4d3,b5d0a103e1f34a00aef67fedd0e8c693,c48bd062d5f6cc20c5df5758d6285562</data>
    </node>
    <node id="BETA1">
      <data key="d0">PARAMETER</data>
      <data key="d1">Beta1 (&#946;1) is the coefficient for the first explanatory variable in the linear regression model
Beta1 is one of the parameters in the multiple regression model, representing the coefficient of the first explanatory variable
Beta1 is the coefficient of the linear term in the quadratic regression model
Beta1 is a parameter in the polynomial regression model, contributing to the linear term of the relationship between Y and X
Beta1 (&#946;1) is a parameter in the statistical models, representing the coefficient of the explanatory variable xi,1
Beta1 (&#946;1) is a parameter in the model, representing the coefficient of the first predictor variable xi1
Beta1 is the slope coefficient parameter in the linear regression model, representing the relationship between log(BODYi) and log(BRAINi)
&#946;1 is a parameter in the model, representing the coefficient for the diameter of the tree in the log-transformed model.
Beta1 (b&#946;1) is the slope parameter estimate in simple linear regression, calculated as Sxy/Sxx
Beta1 is the slope parameter in the linear regression model
Beta1 (b&#946;1) is a parameter in the linear regression model, calculated as the solution to the partial derivatives set to zero, specifically Sxy/Sxx
Beta1 is one of the slope parameters in the linear regression model
Beta1 (&#946;1) is a parameter in the linear regression model, representing the coefficient of one of the predictors
Beta1 (&#946;1) is a parameter in the linear regression model</data>
      <data key="d2">09caa54ca1372d152e47051be4d44ede,11452a08471d93959558de2ece9a69af,254a8a17b1be06702934341e3bf41e85,28cf5ff0c09fa5c0390267bb9aa3ce47,34fceaaf7d835828b5ee2327325c37f8,45f31b040576e9f3b4def6d0466cc016,5b24b5382abe9d1898810b3e4b9b455a,60cc94e681863c9fcc6f9be1e500f840,86c401dda130c2d201c3339526062a24,87b717ba065d6d7c7431af284137eb12,90ed6030c5a5a0764b7dcd4115b4d4d3,b5d0a103e1f34a00aef67fedd0e8c693,c48bd062d5f6cc20c5df5758d6285562,c9a01b92d11585f6549f62e8bd78d652</data>
    </node>
    <node id="BETA2">
      <data key="d0">PARAMETER</data>
      <data key="d1">Beta2 (&#946;2) is the coefficient for the second explanatory variable in the linear regression model
Beta2 is the coefficient of the quadratic term in the quadratic regression model
Beta2 is a parameter in the polynomial regression model, contributing to the quadratic term of the relationship between Y and X
Beta2 (&#946;2) is a parameter in the statistical models, representing the coefficient of the explanatory variable xi,2 in the logarithmic form
Beta2 (&#946;2) is a parameter in the model, representing the coefficient of the second predictor variable xi2
&#946;2 is a parameter in the model, representing the coefficient for the height of the tree in the log-transformed model.
Beta2 is one of the slope parameters in the linear regression model
Beta2 (&#946;2) is a parameter in the linear regression model</data>
      <data key="d2">11452a08471d93959558de2ece9a69af,34fceaaf7d835828b5ee2327325c37f8,45f31b040576e9f3b4def6d0466cc016,60cc94e681863c9fcc6f9be1e500f840,87b717ba065d6d7c7431af284137eb12,90ed6030c5a5a0764b7dcd4115b4d4d3,c48bd062d5f6cc20c5df5758d6285562,c9a01b92d11585f6549f62e8bd78d652</data>
    </node>
    <node id="MLR_MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">Mlr.model is the multiple linear regression model fitted using the lm() function</data>
      <data key="d2">c48bd062d5f6cc20c5df5758d6285562</data>
    </node>
    <node id="AVERAGE_EFFECT">
      <data key="d0">CONCEPT</data>
      <data key="d1">The average effect of an explanatory variable is the change in the response variable when the explanatory variable is increased by one unit, assuming all other variables are held constant</data>
      <data key="d2">c48bd062d5f6cc20c5df5758d6285562</data>
    </node>
    <node id="X1">
      <data key="d0">EXPLANATORY_VARIABLE</data>
      <data key="d1">X1 is an explanatory variable in the linear regression model, with a coefficient (&#946;1) indicating the average effect on the response variable when its value is increased by one unit
X1 is a predictor variable in the regression model, which in the sales example is the price of the product
Variable X1 is one of the k quantitative explanatory variables in multiple regression
X1 is one of the k quantitative explanatory variables in the linear model, which can take various values x1
X1 is one of the two explanatory variables in the model, representing a factor that may influence the response variable.
X1 is a predictor variable in the log-transformed regression model
X1 is a predictor variable in the linear regression model
X1 to Xn represent a series of observed values or predictors in the least squares estimation process</data>
      <data key="d2">0fbc9037ca9a440e79e9ac05664b9b3d,21e429490eeefe7d9c245058fd48ca68,512d9ffebe309a6f944ebce1ae2ff2a3,56ff186fc629e1e42f2759fc4b984199,6a47154bf457c25f22c3cf9f649c5db0,75dc4d8cb195a1f969d9e9496631086b,995fb26a0261f824952fa7b2fac3382e,a828fd17fc38e902484872c88a6b242c</data>
    </node>
    <node id="X2">
      <data key="d0">EXPLANATORY_VARIABLE</data>
      <data key="d1">X2 is an explanatory variable in the linear regression model, with a coefficient (&#946;2) indicating the average effect on the response variable when its value is increased by one unit
X2 is a predictor variable in the regression model, which in the sales example is the local advertising budget
X2 is one of the k quantitative explanatory variables in the linear model, which can take various values x2
X2 is the second explanatory variable in the model, also potentially affecting the response variable.
X2 is a predictor variable in the log-transformed regression model
X2 is a predictor variable in the linear regression model, assumed to stay fixed in the given scenario</data>
      <data key="d2">0fbc9037ca9a440e79e9ac05664b9b3d,21e429490eeefe7d9c245058fd48ca68,512d9ffebe309a6f944ebce1ae2ff2a3,6a47154bf457c25f22c3cf9f649c5db0,995fb26a0261f824952fa7b2fac3382e,a828fd17fc38e902484872c88a6b242c</data>
    </node>
    <node id="ADVERTISING_BUDGET">
      <data key="d0">BUDGET</data>
      <data key="d1">The local advertising budget is a financial allocation for promoting products or services in a specific area. An increase in this budget is associated with an increase in sales.&gt;</data>
      <data key="d2">426434b67f6a287852ab66b82ca873cf</data>
    </node>
    <node id="PARTIAL_REGRESSION_COEFFICIENTS">
      <data key="d0">PARAMETERS</data>
      <data key="d1">Partial regression coefficients are parameters in a multiple regression model that represent the expected change in the dependent variable for a unit change in an explanatory variable, adjusting for the effects of other explanatory variables.&gt;</data>
      <data key="d2">426434b67f6a287852ab66b82ca873cf</data>
    </node>
    <node id="DATASET">
      <data key="d0">DATA</data>
      <data key="d1">The dataset contains paired observations of price and other explanatory variables for a set of units of observation
The dataset consists of pairs of xi and yi values for simple linear regression
</data>
      <data key="d2">2ced3e26eaed2dfcd8e4caf49737cab4,428db872e71a17a2cf7868b03a52def0,5b24b5382abe9d1898810b3e4b9b455a</data>
    </node>
    <node id="EXERCISE_4">
      <data key="d0">EXERCISE</data>
      <data key="d1">Exercise 4 is a practice exercise that involves reparameterising the multiple regression model for the Retail data to give the intercept an interpretation without the need for extrapolation</data>
      <data key="d2">2ced3e26eaed2dfcd8e4caf49737cab4</data>
    </node>
    <node id="LINEAR_MODELS">
      <data key="d0">CLASS_OF_MODELS</data>
      <data key="d1">The class of linear models includes simple linear regression and multiple linear regression, which use data consisting of paired observations to model the relationship between a response variable and one or more explanatory variables
Linear models are statistical models that assume a linear relationship between the dependent variable and one or more independent variables.
Linear models are statistical models that are linear in the parameters, but not necessarily in the explanatory variables. They can include polynomials of the explanatory variables, known as polynomial regression, or other non-linear functions such as logarithms.
Linear models are statistical models that assume a linear relationship between the dependent and independent variables
Linear models are statistical models used to analyze the relationship between one or more independent variables and a dependent variable. They assume a linear relationship between the variables. The results of linear models can be interpreted to understand the effect of each independent variable on the dependent variable.
Linear models are statistical models that describe the relationship between a dependent variable and one or more independent variables. They can accommodate both quantitative and categorical predictor variables.</data>
      <data key="d2">0328e428a30c44572676dd571dd1e9bd,07951ffe6787af44aa60c90c69e62f83,2ced3e26eaed2dfcd8e4caf49737cab4,77e76692753fdf53493182b09018e6bc,87ba4f416a28aabc3b396908f5913b54,d71b402ab9edbb4347e09c7af3257cf5</data>
    </node>
    <node id="Y_GIVEN_X">
      <data key="d0">CONDITIONAL_EXPECTATION</data>
      <data key="d1">E(Y|X=x) is the conditional expectation of Y given X, which is equal to &#946;0 + &#946;1x</data>
      <data key="d2">9a27580975988e83f6e3a0d9010893b5</data>
    </node>
    <node id="Y_VECTOR">
      <data key="d0">VECTOR</data>
      <data key="d1">Y is the column vector of observed values of Y in the linear regression model</data>
      <data key="d2">9a27580975988e83f6e3a0d9010893b5</data>
    </node>
    <node id="X_MATRIX">
      <data key="d0">MATRIX</data>
      <data key="d1">X is the n x 2 matrix in the linear regression model, containing the predictor variable X and a column of ones for the intercept</data>
      <data key="d2">9a27580975988e83f6e3a0d9010893b5</data>
    </node>
    <node id="BETA">
      <data key="d0">PARAMETER_VECTOR</data>
      <data key="d1">Beta (&#946;) is the vector of parameters in the linear regression model, consisting of &#946;0 and &#946;1
Beta is the column vector containing the parameters beta0 and beta1
Beta is the column vector of regression parameters
BETA is the vector of parameters in the linear regression model, including the intercept and coefficients of the explanatory variables
Beta is the parameter vector in the linear regression model, representing the coefficients of the explanatory variables
Beta (&#946;) represents the coefficients of the explanatory variables in the linear regression model
Beta is the vector of parameters in the linear regression model
Beta is the vector of parameters in the linear regression model, including the intercept and coefficients for each explanatory variable
&#946; is the parameter vector in the linear model, representing the coefficients of the explanatory variables
Beta is the parameter vector for the linear regression model, consisting of the intercept (&#946;0), the coefficient for the predictor variable (&#946;1), and the coefficient for the squared predictor variable (&#946;2)
Beta (&#946;0, &#946;1, ..., &#946;q) are the parameters of the model, where &#946;0 is the intercept and &#946;1, ..., &#946;q are the coefficients for the explanatory variables
Beta is the vector of unknown parameters in the linear model, represented as a column vector with p elements, where each element corresponds to the coefficient of a predictor variable.
Beta is a vector of parameters (&#946;1, ..., &#946;p) in a linear model, assumed to be unknown but fixed
Beta (&#946;) is the true parameter vector in the linear regression model
Beta is the vector of parameters in the linear model, representing the coefficients of the explanatory variables
Beta is the p-dimensional parameter vector in the linear regression model
Beta is a parameter in the linear regression model
&#946; is a parameter in the linear regression model, representing the coefficients of the predictors
Beta is a parameter vector in the linear regression model
Beta (&#946;) is a parameter in the context of a function or equation
Beta is a parameter in the linear regression model, representing the coefficients of the predictors
Beta (&#946;) is a parameter in the linear regression model, representing the true coefficients of the predictors
Beta is a parameter in the linear regression model, representing the coefficients of the predictors
Beta (&#946;) is the parameter vector in simple linear regression, consisting of the intercept (&#946;0) and the slope (&#946;1)
Beta is a parameter vector in the linear regression model, consisting of Beta0 and Beta1
Beta is the parameter vector in a linear regression model, representing the coefficients of the predictors
Beta is a parameter vector in the linear regression model
Beta is a parameter in the linear regression model, representing the coefficients of the predictors
Beta is a parameter in the original model (2), consisting of beta_0 and beta_1
Beta is the parameter vector in the original model parameterisation
Beta is the true parameter vector in the linear regression model, representing the coefficients of the predictor variables
Beta is the parameter vector in a linear model
&#946; is the parameter vector in the linear regression model.
Beta (&#946;) is a parameter in the normal linear model, representing the coefficients of the predictors
Beta is a parameter vector in the normal linear model, representing the coefficients of the predictors
&#946; is the parameter vector in the normal linear model, representing the coefficients of the predictors
Beta is a parameter in the linear regression model, representing the coefficients of the predictors.
Beta (&#946;) is a parameter in the statistical model, representing the coefficients of the predictors
Beta is the parameter vector in the linear model
Beta is the parameter vector of dimension p in the linear model
Beta is the parameter in the linear model, representing the coefficients of the predictors
Beta is a parameter in the linear regression model, representing the coefficients of the predictors
Beta is a parameter in the linear regression model, representing the coefficients of the predictors
Beta is a parameter in the linear regression model, representing the coefficients of the predictors
Beta (&#946;) is a parameter in the linear regression model, representing the coefficients of the predictors
Beta is the parameter vector in the linear regression model
Beta is the vector of parameters in the linear model
Beta is the vector of p parameters in the linear model
Beta is the parameter vector in the regression model
&#946; is the coefficient of the price variable in the linear regression model, representing the change in sales volume for a unit change in price.&gt;
Beta is the parameter in the model that represents the effect of price on sales volume
Beta is a parameter in the model, representing the coefficient of the price variable
Beta is a parameter in the linear regression model, representing the coefficients of the predictors
beta is a parameter in the model, representing the effect of price on sales
Beta (&#946;) is a parameter in the linear regression model, representing the effect of the price predictor
Beta is a parameter in the model equations, representing the effect of the price deviation on sales
Beta is the parameter associated with the c_price predictor in the regression model&gt;
Beta is the parameter for price in the regression model, with an estimate of -0.539
Beta (&#946;) is a parameter in the regression model, representing the coefficient of the price variable
Beta (&#946;) is a parameter in the reparameterised model, representing the effect of price on sales volume
Beta (&#946;) is a parameter in the model, representing the coefficient of the price variable
beta is the slope parameter for price in the parallel lines model
Beta (&#946;) is the coefficient for the price variable in the model
Beta (&#946;) is a parameter in the parallel lines model, representing the effect of price on sales
Beta (&#946;) is a parameter in the regression model, representing the effect of price on sales
Beta (&#946;) is the parameter that represents the effect of price on sales volume for brand A
Beta (&#946;) is the coefficient for the price predictor in the regression model
Beta is a parameter in a statistical model, typically representing the coefficients of the predictors</data>
      <data key="d2">01d5ee79489582b4135fc96f676b24a0,06d5666e6bfdda828b48adba883b4a61,0cb40986e6c2bb439e1ffcaae2df96ac,119bc73ddf8eebadfb8eae272fa323a7,1b523d1edabe381403fc470a9b8d47fa,1d141ab04db553f78a313e430e54abb5,2167274129d4cfa74a002c4cc39df8a8,21ec28dfe2b2c18030d541d63e51f45e,228bdca7843406def245d755e8df49f6,248924760a2bfbc82501fd6b11cfa0aa,255685e281cc5a9edf073c700f425a6b,2673d078d29f2af78fab9b6eacd15e37,28cf5ff0c09fa5c0390267bb9aa3ce47,2b6d31b6bff4eae3a4809451c4fb9fa6,2de7a36b32bf79c8f32612c8aaa9daa8,3cbe71f7649e84cd67cb3fa0d3e632cf,3d357cfa3ef0d00f49cf4acaeac1c9d1,542f546c5a131196e4701fb33c9b1dee,5609007c6229060ffc85d8056a7fefde,5a0d392715f06d5e873f45ae06aa729a,6b55b41598d5264f8dc6b72769748722,6c1684ed2a4840576c6b0f4d1a3a482f,6c66e9414880964ee899ceb0f16d22e9,74d190f10bf6e6936242ca3cdfc4a09f,7955aae3fd4ca51b9ef8843e13c1f517,7a605c3b689bec7ab2c46df9c123e3f3,7ad4ccec4c7bb3702aed71c17dc6b96f,7d074208b1259e7d84f9f870d3828bb6,7fc5b8303ab530821bf2140ba6a8a889,825b600cbab3535ce67e9f561ddcb84b,82932abd152e0b84a1c26a2daa4c08df,8326c645426789920a99ed373725fa0e,8f1d95acff56e1633dceb775fa713174,9005147593b2f27b9e2a5eede3601bdc,906eb7d6b49fa360e7e5b65c56cd4d76,925e17c26fb7d979f52538f4632333e7,93da9813e10a119798de6982977f1239,9854704301b8df256ca1013b8d53dfac,9a27580975988e83f6e3a0d9010893b5,9d300fc83afb3261af61b2ab9721cadc,9dddcd96af7b557e578b3f5f36efacd7,9fc2b1e8b2b61b557f88eb9e9c708597,a1fc936df848a0fbc791e4bcc9b527b6,a4a817bb79d6ae8812c808ca41d47f43,aa195e72eb5285a4bcae9c856af30a87,aac5b4f040b9c773bd1aa696dec469f6,ac15b639b0849006471dfe102376c2c0,ad799500572246a07f983a3b92c0e61f,aeddef300427d211c74c6008b5b6b328,b5d0a103e1f34a00aef67fedd0e8c693,b6870535f3975c49d45e62fbe475f198,b70a75a6412b2e5c44af50734844f4be,bd05fe6a05f9a13d33c4f1b5a771ada5,d14413709de2897231aaa83be3aa346f,d738df7d83784c8a41b3948271c537b6,d94760a5f9f6ea115fcc18024035a627,dd7e7d54883ca0f687568a738b95d4d0,e41cc40f061f487b1ea0f256d4a963e4,e4f14e6785c6d7b7469e695aaeb170d0,e7494d6cfc3e38a4d2f3f6b21ef6445d,e7edd8b2874a350779ae20f1ecdf4733,eac62cdd5518e1269fed150639331c2c,ee295ebc4c2d6a2a5c738796fcc2ab71,f483798b15ef305e7826fd7142379e03,f5716ce115458c0652124734ca344806,f632f01188d2c6e3091a965580cb4600,f9b615b879f72501f338f8983d4cac3d,fc5b725f3c662c5471af20efdcc2dbff</data>
    </node>
    <node id="EPSILON_VECTOR">
      <data key="d0">RANDOM_VARIABLE_VECTOR</data>
      <data key="d1">Epsilon (&#1013;) is the vector of errors in the linear regression model, corresponding to the error term in the equation Y = X&#946; + &#1013;</data>
      <data key="d2">9a27580975988e83f6e3a0d9010893b5</data>
    </node>
    <node id="NN">
      <data key="d0">DISTRIBUTION</data>
      <data key="d1">Nn is the multivariate normal distribution of dimension n, with mean equal to the n-vector of zeros and variance-covariance matrix equal to &#963;^2In
Nn is the multivariate normal distribution of dimension n, with mean equal to the n-vector of zeros and variance-covariance matrix equal to &#963;^2In
Nn is the multivariate normal distribution with mean 0 and covariance matrix &#963;^2In
Nn is the multivariate normal distribution with mean X&#946; and covariance matrix &#963;^2In
Nn is the multivariate normal distribution with mean X&#946; and covariance matrix &#963;^2In
Normal distribution Nn with mean 0 and covariance matrix &#963;^2In, assumed for the error term epsilon (&#1013;)
Nn is the multivariate normal distribution with mean 0 and covariance matrix &#963;^2In, representing the distribution of the error term &#1013;
Nn is the multivariate normal distribution with mean X&#946; and covariance matrix &#963;^2In
Nn is the multivariate normal distribution with mean X&#946; and covariance matrix &#963;^2In
Nn is the multivariate normal distribution with mean X&#946; and covariance matrix &#963;^2In
Nn is the multivariate normal distribution with mean X&#946; and covariance matrix &#963;^2In
Nn is the multivariate normal distribution with mean 0 and covariance matrix &#963;^2In
Y is assumed to follow a multivariate normal distribution with mean vector X&#946; and covariance matrix &#963;^2In</data>
      <data key="d2">0ac60299320c55d642b3e38440c25f90,3d357cfa3ef0d00f49cf4acaeac1c9d1,45f31b040576e9f3b4def6d0466cc016,542f546c5a131196e4701fb33c9b1dee,67e4c1866b0c6e162e6e3317949e8da9,75dc4d8cb195a1f969d9e9496631086b,8f1d95acff56e1633dceb775fa713174,9005147593b2f27b9e2a5eede3601bdc,9dddcd96af7b557e578b3f5f36efacd7,b70a75a6412b2e5c44af50734844f4be,dd7e7d54883ca0f687568a738b95d4d0,e41cc40f061f487b1ea0f256d4a963e4,e4f14e6785c6d7b7469e695aaeb170d0</data>
    </node>
    <node id="IN">
      <data key="d0">MATRIX</data>
      <data key="d1">In is the n x n identity matrix used in the variance-covariance matrix of the multivariate normal distribution
In is the n x n identity matrix used in the variance-covariance matrix of the error term
In is the n x n identity matrix used in the covariance matrix of the error term
In is the n x n identity matrix used in the covariance matrix of the linear regression model
In is the n x n identity matrix used in the covariance matrix of the linear regression model
In is the n x n identity matrix used in the covariance matrix of the linear regression model
Identity matrix In is an n x n matrix with ones on the diagonal and zeros elsewhere, used in the covariance matrix of the linear regression model
In is the n x n identity matrix used in the covariance matrix of the linear model
In is the n x n identity matrix used in the covariance matrix of the normal linear model
In is the n x n identity matrix used in the covariance matrix of the normal linear model
In is the n x n identity matrix used in the covariance matrix of the normal linear model
In is the n x n identity matrix used in the covariance matrix of the linear model
In is the n x n identity matrix used in the covariance matrix of the linear model
In is the n x n identity matrix used in the covariance matrix of the linear regression model
In is the n x n identity matrix used in the covariance matrix of the linear regression model
In is the n x n identity matrix used in the calculation of residuals as (In - H)y
In is the n x n identity matrix used in the calculation of the residuals and in the properties of the hat matrix H.
Matrix In is the n x n identity matrix, where n is the number of observations.
In is the n x n identity matrix, whose trace is equal to n
In is the n x n identity matrix used in the covariance matrix of the linear regression model
In is the n x n identity matrix used in the calculation of the residual vector Eb
In is the n x n identity matrix used in the calculation of the residual vector Eb
In is the n x n identity matrix
In is the n x n identity matrix used in the calculation of EB and in the covariance matrix
In is the n x n identity matrix
In is the n x n identity matrix, used in the calculation of the influence of data points on the fitted model</data>
      <data key="d2">1da117a2f92b2db00290d2a0bfc06beb,2685edb9e8031c8ea725c43a40af22a8,3d357cfa3ef0d00f49cf4acaeac1c9d1,3fb977ccba63e267d2e7dd4de6479ce1,45f31b040576e9f3b4def6d0466cc016,46629f2efc6c82e81265a131b4bab2ee,542f546c5a131196e4701fb33c9b1dee,5a0d392715f06d5e873f45ae06aa729a,679722cf8ce5ce5aee4e379528470efe,67e4c1866b0c6e162e6e3317949e8da9,74d190f10bf6e6936242ca3cdfc4a09f,75dc4d8cb195a1f969d9e9496631086b,7ad4ccec4c7bb3702aed71c17dc6b96f,7d074208b1259e7d84f9f870d3828bb6,8f1d95acff56e1633dceb775fa713174,9005147593b2f27b9e2a5eede3601bdc,9dddcd96af7b557e578b3f5f36efacd7,b70a75a6412b2e5c44af50734844f4be,bd98ac7b4b5df4f63e7ecc8f4a821f57,dd7e7d54883ca0f687568a738b95d4d0,e41cc40f061f487b1ea0f256d4a963e4,e4f14e6785c6d7b7469e695aaeb170d0,e593096f3805c2686423cb91ea276fe6,e7edd8b2874a350779ae20f1ecdf4733,f470791d2d3fedede166f9bb11598c9c,f483798b15ef305e7826fd7142379e03</data>
    </node>
    <node id="XK">
      <data key="d0">PREDICTOR_VARIABLE</data>
      <data key="d1">Variable Xk is one of the k quantitative explanatory variables in multiple regression
Xk is one of the k quantitative explanatory variables in the linear model, which can take various values xk</data>
      <data key="d2">6a47154bf457c25f22c3cf9f649c5db0,75dc4d8cb195a1f969d9e9496631086b</data>
    </node>
    <node id="XJM">
      <data key="d0">PREDICTOR_VARIABLE_VALUE</data>
      <data key="d1">xjm is the value of the mth explanatory variable Xm for the jth unit of observation
XJM is the value of the mth explanatory variable Xm for the jth unit of observation</data>
      <data key="d2">75dc4d8cb195a1f969d9e9496631086b,b5d0a103e1f34a00aef67fedd0e8c693</data>
    </node>
    <node id="BETA_M">
      <data key="d0">PARAMETER</data>
      <data key="d1">&#946;m is one of the coefficients for the mth explanatory variable in the multiple regression model</data>
      <data key="d2">75dc4d8cb195a1f969d9e9496631086b</data>
    </node>
    <node id="XN">
      <data key="d0">VECTOR</data>
      <data key="d1">XN represents the vector of explanatory variables x1, x2, ..., xk for a given observation
Xn represents the summation operation over n elements
Xn is a function that sums over the elements of a vector or matrix</data>
      <data key="d2">10ac76f99674a01ca0f4a55586dea07e,3fdeeb7593174f5e8a9cff55a7cd92e3,b5d0a103e1f34a00aef67fedd0e8c693</data>
    </node>
    <node id="BETAK">
      <data key="d0">PARAMETER</data>
      <data key="d1">Betak is one of the parameters in the multiple regression model, representing the coefficient of the kth explanatory variable
Beta_k is one of the slope parameters in the linear regression model</data>
      <data key="d2">87b717ba065d6d7c7431af284137eb12,b5d0a103e1f34a00aef67fedd0e8c693</data>
    </node>
    <node id="EPSILONJ">
      <data key="d0">ERROR_TERM</data>
      <data key="d1">Epsilonj is the error term for the jth unit of observation, assumed to be iid N(0, &#963;^2)
Epsilon j (&#1013;j) is the jth error term in the linear regression model, representing the unobserved random error for the jth observation.
Epsilon_j is the error term in the models
Epsilon_j is the error term for the jth observation, assumed to be iid N(0, &#963;^2)
epsilonj is the error term for the jth store in the parallel lines model</data>
      <data key="d2">87b717ba065d6d7c7431af284137eb12,925e17c26fb7d979f52538f4632333e7,b5d0a103e1f34a00aef67fedd0e8c693,d1b6fcd55d937c5fe2d6add69e0bcf05,e6f79ceb0df54119a4dc71b2162ac50b</data>
    </node>
    <node id="N">
      <data key="d0">DISTRIBUTION</data>
      <data key="d1">N is the normal distribution with mean 0 and variance &#963;^2
Dimension n is the number of units of observation in the dataset
N is the normal distribution with mean 0 and variance &#963;^2, assumed for the error terms
N is the normal distribution with mean 0 and variance &#963;^2
N is the normal distribution with mean 0 and variance &#963;^2, which is assumed for the error term (epsilon) in the regression model.
N is the normal distribution with mean 0 and variance &#963;^2, assumed for the errors in the linear regression model
N is the number of data points, specifically 200, used in the simulation
N is the sample size, the number of data points in the linear regression model
N is the number of observations or the length of the vector X1 to Xn
N is the normal distribution, with mean 0 and variance &#963;^2, assumed for the errors in the linear regression model.
N is the normal distribution with mean 0 and variance &#963;^2
N is the number of observations in the dataset
N represents the total number of observations in the sample
N (n) is the total number of observations in the dataset
N is the total number of observations in the dataset
n is the number of units of observation in the linear model
n is the number of units of observation in the linear model
N is the total number of data points or observations
N is the sample size, the number of observations in the dataset
n is a variable representing the number of observations in the regression model
n is the sample size of the dataset
n is the number of units of observation, which is 96 in this case
N is the number of observations in the dataset, which is 96</data>
      <data key="d2">00e186a86624c01ce873dd577df68d17,09391efd3b8c510205098b548bc8dc74,0b650eb2f1dcd603b64fec3c4b5cd24b,228bdca7843406def245d755e8df49f6,25fce1af816975003128126b5cfea73b,2d5cdecc342ddacd2c090f1838430cee,56ff186fc629e1e42f2759fc4b984199,6648f0d6deed51fb4fb25e6992a71ddf,6a6f85d0a6e46196ab3a901fcc82a720,6c1684ed2a4840576c6b0f4d1a3a482f,87b717ba065d6d7c7431af284137eb12,8f7a05b6d231105a6194eebdb2df372e,90b7e0427699cc1bb461e37939935138,98d6982108f2d42fe0437bff8c666e17,9923e77ac6b3de95cb5026bc5e7fe8c0,b5d0a103e1f34a00aef67fedd0e8c693,bd05fe6a05f9a13d33c4f1b5a771ada5,bd98ac7b4b5df4f63e7ecc8f4a821f57,d738df7d83784c8a41b3948271c537b6,e4f14e6785c6d7b7469e695aaeb170d0,e7edd8b2874a350779ae20f1ecdf4733,ee22e1f5947947f9bd3f7f8922745e48,fc5b725f3c662c5471af20efdcc2dbff</data>
    </node>
    <node id="YN">
      <data key="d0">DEPENDENT_VARIABLE</data>
      <data key="d1">Yn is the dependent variable in the linear regression model for the nth observation
Yn is one of the n independent random variables representing the responses in the linear regression model
Y1, ..., Yn are the response variables in the regression model, assumed to have constant variance and a normal distribution</data>
      <data key="d2">0da640a09a395a50b6e16e047fa8d0d6,8f1d95acff56e1633dceb775fa713174,9005147593b2f27b9e2a5eede3601bdc</data>
    </node>
    <node id="BETA_K">
      <data key="d0">PARAMETER</data>
      <data key="d1">Beta_k (&#946;k) is one of the parameters in the linear regression model, representing the coefficient of the kth explanatory variable
Beta_k (&#946;k) is a parameter in the linear model, representing the coefficient of the explanatory variable Xk
Beta_k (&#946;k) is a parameter in the linear regression model, representing the coefficient of the kth explanatory variable xk
Beta_k is one of the parameters in the linear regression model, representing the coefficient of the kth explanatory variable</data>
      <data key="d2">67e4c1866b0c6e162e6e3317949e8da9,6a47154bf457c25f22c3cf9f649c5db0,7ad4ccec4c7bb3702aed71c17dc6b96f,8f1d95acff56e1633dceb775fa713174</data>
    </node>
    <node id="EPSILON_N">
      <data key="d0">ERROR_TERM</data>
      <data key="d1">EPSILON_n (&#1013;n) is the error term for the nth observation in the linear regression model</data>
      <data key="d2">8f1d95acff56e1633dceb775fa713174</data>
    </node>
    <node id="LINEAR_PREDICTOR">
      <data key="d0">FUNCTION</data>
      <data key="d1">Linear predictor is the function &#946;0 + &#946;1x1 + ... + &#946;kxk, which is linear in the parameters &#946;0, &#946;1, ..., &#946;k and represents the mean function of the response
Linear predictor is the expression given by &#946;0 + &#946;1x1 + ... + &#946;kxk, which is linear in the parameters &#946;0, &#946;1, ..., &#946;k</data>
      <data key="d2">67e4c1866b0c6e162e6e3317949e8da9,6a47154bf457c25f22c3cf9f649c5db0</data>
    </node>
    <node id="X_1">
      <data key="d0">EXPLANATORY_VARIABLE</data>
      <data key="d1">X_1 (x1) is the first explanatory variable in the linear regression model</data>
      <data key="d2">67e4c1866b0c6e162e6e3317949e8da9</data>
    </node>
    <node id="X_K">
      <data key="d0">EXPLANATORY_VARIABLE</data>
      <data key="d1">X_k (xk) is the kth explanatory variable in the linear regression model</data>
      <data key="d2">67e4c1866b0c6e162e6e3317949e8da9</data>
    </node>
    <node id="VARIANCE_FUNCTION">
      <data key="d0">FUNCTION</data>
      <data key="d1">Variance function of the response is given by Var (Y | X1 = x1, ..., Xk = xk) = Var (&#1013;) = &#963;^2, and is constant</data>
      <data key="d2">67e4c1866b0c6e162e6e3317949e8da9</data>
    </node>
    <node id="Y1">
      <data key="d0">RANDOM_VARIABLE</data>
      <data key="d1">Y1 is one of the n independent random variables representing the responses in the linear regression model</data>
      <data key="d2">9005147593b2f27b9e2a5eede3601bdc</data>
    </node>
    <node id="E_Y">
      <data key="d0">EXPECTED_VALUE</data>
      <data key="d1">Expected value of Y, denoted as E(Y), is the mean of the response variable
E(Y) is the mean function of the response vector Y, which is given by X&#946;
E(Y) is the expected value of Y, which can be calculated as exp(&#181; + &#963;^2/2) when Y is lognormally distributed</data>
      <data key="d2">21e429490eeefe7d9c245058fd48ca68,7fc5b8303ab530821bf2140ba6a8a889,e41cc40f061f487b1ea0f256d4a963e4</data>
    </node>
    <node id="X_BETA">
      <data key="d0">PRODUCT</data>
      <data key="d1">Product of the design matrix X and the parameter vector Beta (X&#946;)
The mean function of the response vector Y is given by X&#946;, where X is the design matrix and &#946; is the vector of parameters
X_beta is the design matrix of the model parameterisation in (2)</data>
      <data key="d2">5609007c6229060ffc85d8056a7fefde,7fc5b8303ab530821bf2140ba6a8a889,e4f14e6785c6d7b7469e695aaeb170d0</data>
    </node>
    <node id="XJ1">
      <data key="d0">EXPLANATORY_VARIABLE</data>
      <data key="d1">Xj1 is the value of the first explanatory variable for the jth observation
Xj1 is the first predictor variable for the jth observation</data>
      <data key="d2">7ad4ccec4c7bb3702aed71c17dc6b96f,87b717ba065d6d7c7431af284137eb12</data>
    </node>
    <node id="XJ2">
      <data key="d0">EXPLANATORY_VARIABLE</data>
      <data key="d1">Xj2 is the value of the second explanatory variable for the jth observation
Xj2 is the second predictor variable for the jth observation</data>
      <data key="d2">7ad4ccec4c7bb3702aed71c17dc6b96f,87b717ba065d6d7c7431af284137eb12</data>
    </node>
    <node id="XJK">
      <data key="d0">EXPLANATORY_VARIABLE</data>
      <data key="d1">Xjk is the value of the kth explanatory variable for the jth observation
Xjk is the kth predictor variable for the jth observation</data>
      <data key="d2">7ad4ccec4c7bb3702aed71c17dc6b96f,87b717ba065d6d7c7431af284137eb12</data>
    </node>
    <node id="EPSILON_J">
      <data key="d0">ERROR_TERM</data>
      <data key="d1">Epsilon_j is the error term for the jth observation, assumed to be independently and identically distributed (iid) and following a normal distribution with mean 0 and variance &#963;^2
Epsilon_j is the error term in the linear model, representing the deviation of the observed height from the model prediction
&#1013;j is the error term for the jth observation in the simple linear regression model
Epsilon j (&#1013;j) is the error term specific to store j in the regression model</data>
      <data key="d2">656dce234514b9db38b5b5616557c1e9,7ad4ccec4c7bb3702aed71c17dc6b96f,825b600cbab3535ce67e9f561ddcb84b,d14413709de2897231aaa83be3aa346f</data>
    </node>
    <node id="P">
      <data key="d0">DIMENSION</data>
      <data key="d1">Dimension p refers to the number of parameters in the linear regression model, including the intercept and explanatory variables
P represents the number of parameters in the model
P (p) is the number of parameters in the linear regression model
P is the number of parameters in the linear regression model
p is the number of parameters in the linear model
p is the number of parameters in the linear model
P is the dimension of the parameter vector Beta, representing the number of explanatory variables
p is the number of parameters in the regression model.&gt;
P is the number of parameters in the regression model
p is a variable representing the number of predictors in the regression model
p is the number of predictors in the regression model</data>
      <data key="d2">0443ab5e20a4f6b2f243c989ef6c723a,09391efd3b8c510205098b548bc8dc74,0b650eb2f1dcd603b64fec3c4b5cd24b,6648f0d6deed51fb4fb25e6992a71ddf,98d6982108f2d42fe0437bff8c666e17,9923e77ac6b3de95cb5026bc5e7fe8c0,9e2ebbb113c00fa43f0af3c0696baf95,bd05fe6a05f9a13d33c4f1b5a771ada5,bd98ac7b4b5df4f63e7ecc8f4a821f57,e4f14e6785c6d7b7469e695aaeb170d0,fc5b725f3c662c5471af20efdcc2dbff</data>
    </node>
    <node id="K">
      <data key="d0">NUMBER_OF_EXPLANATORY_VARIABLES</data>
      <data key="d1">Number of explanatory variables k in the multiple linear regression model, excluding the intercept</data>
      <data key="d2">e4f14e6785c6d7b7469e695aaeb170d0</data>
    </node>
    <node id="KTH_EXPLANATORY_VARIABLE">
      <data key="d0">EXPLANATORY_VARIABLE</data>
      <data key="d1">The kth explanatory variable is a feature used in the linear model to explain the response variable</data>
      <data key="d2">e41cc40f061f487b1ea0f256d4a963e4</data>
    </node>
    <node id="JTH_UNIT_OBSERVATION">
      <data key="d0">UNIT_OF_OBSERVATION</data>
      <data key="d1">The jth unit of observation is a specific instance or subject in the dataset for which the response and explanatory variables are measured</data>
      <data key="d2">e41cc40f061f487b1ea0f256d4a963e4</data>
    </node>
    <node id="VAR_Y">
      <data key="d0">VARIANCE_COVARIANCE_MATRIX</data>
      <data key="d1">Var(Y) is the variance-covariance matrix of the response vector Y, which is given by &#963;^2In</data>
      <data key="d2">e41cc40f061f487b1ea0f256d4a963e4</data>
    </node>
    <node id="RESPONSE_RANDOM_VECTOR">
      <data key="d0">VECTOR</data>
      <data key="d1">The response random vector is a vector of random variables that represents the outcomes of interest in a statistical model</data>
      <data key="d2">6616e10c85e86291147e72776854b8a2</data>
    </node>
    <node id="MODEL_DESCRIPTION">
      <data key="d0">DESCRIPTION</data>
      <data key="d1">Model description refers to the ability to describe a statistical model both in vector/matrix notation and in terms of its model equation for the jth unit of observation</data>
      <data key="d2">6616e10c85e86291147e72776854b8a2</data>
    </node>
    <node id="ESTIMATED_COEFFICIENTS">
      <data key="d0">PARAMETERS</data>
      <data key="d1">Estimated coefficients are the parameters of a model that are estimated from the data, representing the effect of each explanatory variable on the response variable</data>
      <data key="d2">6616e10c85e86291147e72776854b8a2</data>
    </node>
    <node id="TEXTBOOK_RECOMMENDATION">
      <data key="d0">REFERENCE</data>
      <data key="d1">Textbook recommendation refers to a suggested reading material for further understanding of the topics covered in the chapter, specifically "Generalized linear models with examples in R" by Dunn and Smyth</data>
      <data key="d2">6616e10c85e86291147e72776854b8a2</data>
    </node>
    <node id="GRAPHICAL_EXPLORATION">
      <data key="d0">ANALYSIS</data>
      <data key="d1">Graphical exploration is the process of visually analyzing the data and the fitted models to identify whether the systematic component of the linear model is an adequate description of the relationship within the data
Graphical exploration is a method of analyzing data through visual representations to understand patterns and relationships</data>
      <data key="d2">6616e10c85e86291147e72776854b8a2,9f335f1ecb85a1427df926df8bb1e89f</data>
    </node>
    <node id="DESIGN_MATRIX">
      <data key="d0">MATRIX</data>
      <data key="d1">Design matrix is a matrix that contains the values of the explanatory variables for each observation, used in least squares estimation to fit models
The design matrix is a matrix that contains the values of the explanatory variables in a linear model
The design matrix is the matrix that contains the predictor variables and their transformations. It is used in the matrix notation of the model equations
Design matrix (X) is a matrix that contains the values of the predictor variables for all observations in the dataset. It is used in conjunction with the parameter vector (&#946;) to calculate the linear predictor for the given dataset.
The design matrix, denoted as X, is an n x p matrix in the context of a linear model, where n is the number of observations and p is the number of parameters. It contains the values of the predictor variables for each observation, with each row representing a single observation and each column representing a predictor variable.
The design matrix is a matrix that contains the values of the predictor variables for each observation in the data set, used in the linear model for the Retail data
The design matrix is a matrix used in regression analysis to represent the data in a form suitable for estimating the model parameters
The design matrix is a matrix that contains the values of the predictor variables for each observation in the dataset
The design matrix is a matrix that contains the values of the predictor variables for all observations in a regression model.</data>
      <data key="d2">06199787dd7f75f7338dd24d4f3dc26e,48971100deb5bb374a41c1f2b7b2a86a,6616e10c85e86291147e72776854b8a2,86ece4718d27d1a6c6a1f448cc850e2b,9f335f1ecb85a1427df926df8bb1e89f,b0ca3e6c22c4cf884d03b1f6f82be5df,b9af17718641389ba07f53be13f31f8c,e5131a1158e58f1b7b44b21ced7b6f60,e7494d6cfc3e38a4d2f3f6b21ef6445d</data>
    </node>
    <node id="PARAMETER_VECTOR">
      <data key="d0">VECTOR</data>
      <data key="d1">Parameter vector is a vector of parameters in a statistical model, used in least squares estimation to fit models
The parameter vector contains the coefficients of the explanatory variables in a linear model
Parameter vector (&#946;) is a vector containing the coefficients of the predictor variables in the linear model. These coefficients are estimated using the least squares estimation algorithm.
Parameter vector refers to the set of parameters in a statistical model, such as the coefficients in a linear regression model. The least squares estimate of the parameter vector is the set of values that minimizes the sum of the squared residuals.
The parameter vector, denoted as &#946;, is a set of parameters in a statistical model. In the context of linear models, these parameters represent the coefficients of the predictors. The least squares estimate of the parameter vector, &#946;b, is the vector of dimension p that minimizes the sum of squared differences between the observed data and the model predictions. This estimate is crucial for understanding the relationship between the predictors and the response variable in a linear model.&gt;
The parameter vector [&#181;, &#945;B, &#945;C, &#946;]T represents the coefficients of the intercept and the independent variables in the linear regression model</data>
      <data key="d2">07951ffe6787af44aa60c90c69e62f83,6616e10c85e86291147e72776854b8a2,924be3e598ffeabd1fbd9b57f033b917,9f335f1ecb85a1427df926df8bb1e89f,b9af17718641389ba07f53be13f31f8c,c103c6d096d52868eda26d991194b5f2</data>
    </node>
    <node id="ANSCOMBE_S_QUARTET">
      <data key="d0">EXAMPLE</data>
      <data key="d1">Anscombe's Quartet is a set of four datasets that have nearly identical simple descriptive statistics, yet have very different graphical representations, illustrating the importance of graphical exploration in statistical analysis</data>
      <data key="d2">6616e10c85e86291147e72776854b8a2</data>
    </node>
    <node id="SYSTEMATIC_COMPONENT">
      <data key="d0">FUNCTION</data>
      <data key="d1">The systematic component is a function of the explanatory variables that is linear in the parameters
The systematic component of the fitted model is given by -5.9957 + 2.7808x - 0.1267x^2, which is an upturned parabola that takes its maximum value of about 9.26 around x = 11
The systematic component is the part of the model that is deterministic and follows a specific pattern or rule</data>
      <data key="d2">9f335f1ecb85a1427df926df8bb1e89f,bb31f1c77bbba73300f735a100086a67,c9a01b92d11585f6549f62e8bd78d652</data>
    </node>
    <node id="ANSCOMBE_QUARTET">
      <data key="d0">DATASET</data>
      <data key="d1">Anscombe's Quartet is a collection of four datasets that have the same summary statistics and corresponding regression line, but very different scatterplots
Anscombe&#8217;s quartet is a collection of four datasets that have nearly identical simple descriptive statistics, yet appear very different when graphed.</data>
      <data key="d2">87ba4f416a28aabc3b396908f5913b54,9f335f1ecb85a1427df926df8bb1e89f</data>
    </node>
    <node id="STATISTICAL_ANALYSIS">
      <data key="d0">METHOD</data>
      <data key="d1">Statistical analysis is the process of collecting, exploring, and presenting data to uncover patterns and trends</data>
      <data key="d2">9f335f1ecb85a1427df926df8bb1e89f</data>
    </node>
    <node id="SUMMARY_STATISTICS">
      <data key="d0">DATA</data>
      <data key="d1">Summary statistics are measures that describe the central tendency, dispersion, and shape of a dataset</data>
      <data key="d2">9f335f1ecb85a1427df926df8bb1e89f</data>
    </node>
    <node id="ANSCOMBE">
      <data key="d0">AUTHOR</data>
      <data key="d1">Anscombe is the author of the paper "Graphs in statistical analysis" which discusses the use of graphs in statistical analysis</data>
      <data key="d2">2a5997c641e47fc6c32ebf81101c54e0</data>
    </node>
    <node id="AMERICAN_STATISTICIAN">
      <data key="d0">JOURNAL</data>
      <data key="d1">The American Statistician is the journal where Anscombe's paper was published</data>
      <data key="d2">2a5997c641e47fc6c32ebf81101c54e0</data>
    </node>
    <node id="DOI">
      <data key="d0">REFERENCE</data>
      <data key="d1">DOI is the digital object identifier for Anscombe's paper</data>
      <data key="d2">2a5997c641e47fc6c32ebf81101c54e0</data>
    </node>
    <node id="DATASET_1">
      <data key="d0">DATASET</data>
      <data key="d1">Dataset 1 is one of the four datasets discussed in the text, with specific summary statistics
Dataset 1 is a collection of data points with evenly spread x-values and y-values scattered randomly about the regression line</data>
      <data key="d2">2a5997c641e47fc6c32ebf81101c54e0,84ffe1b8496dc660c47248c9f7b5bdea</data>
    </node>
    <node id="DATASET_2">
      <data key="d0">DATASET</data>
      <data key="d1">Dataset 2 is another one of the four datasets discussed in the text, with specific summary statistics
Dataset 2 has evenly spread x-values, but the y-values indicate a poor fit for a simple linear regression model, suggesting a curved relationship
Dataset 2 is one of the datasets in Anscombe&#8217;s quartet, characterized by a parabolic relationship between the response and the explanatory variable.</data>
      <data key="d2">2a5997c641e47fc6c32ebf81101c54e0,84ffe1b8496dc660c47248c9f7b5bdea,87ba4f416a28aabc3b396908f5913b54</data>
    </node>
    <node id="SAMPLE_MEAN_X">
      <data key="d0">METRIC</data>
      <data key="d1">Sample mean of x is a metric that indicates the average value of the x variable in the dataset</data>
      <data key="d2">2a5997c641e47fc6c32ebf81101c54e0</data>
    </node>
    <node id="SAMPLE_VARIANCE_X">
      <data key="d0">METRIC</data>
      <data key="d1">Sample variance of x is a metric that indicates the spread of the x variable in the dataset</data>
      <data key="d2">2a5997c641e47fc6c32ebf81101c54e0</data>
    </node>
    <node id="SAMPLE_MEAN_Y">
      <data key="d0">METRIC</data>
      <data key="d1">Sample mean of y is a metric that indicates the average value of the y variable in the dataset</data>
      <data key="d2">2a5997c641e47fc6c32ebf81101c54e0</data>
    </node>
    <node id="SAMPLE_VARIANCE_Y">
      <data key="d0">METRIC</data>
      <data key="d1">Sample variance of y is a metric that indicates the spread of the y variable in the dataset</data>
      <data key="d2">2a5997c641e47fc6c32ebf81101c54e0</data>
    </node>
    <node id="CORRELATION_COEFFICIENT">
      <data key="d0">METRIC</data>
      <data key="d1">Correlation coefficient of x and y is a metric that indicates the strength and direction of the linear relationship between x and y</data>
      <data key="d2">2a5997c641e47fc6c32ebf81101c54e0</data>
    </node>
    <node id="FITTED_REGRESSION_LINE">
      <data key="d0">MODEL</data>
      <data key="d1">Fitted regression line is the equation that describes the relationship between x and y in the dataset
The fitted regression line is the line that best represents the relationship between the independent and dependent variables in a linear regression model. It is calculated using the least squares method to minimize the sum of the squared residuals.</data>
      <data key="d2">23fc620f1238c6a1b5c5e3a08e149c53,2a5997c641e47fc6c32ebf81101c54e0</data>
    </node>
    <node id="DATASET_3">
      <data key="d0">DATASET</data>
      <data key="d1">Dataset 3 appears to follow a simple linear regression model except for one outlier that significantly influences the fitted line
Dataset 3 is part of Anscombe's quartet, characterized by a unique set of data points that challenge the assumptions of simple linear models</data>
      <data key="d2">84ffe1b8496dc660c47248c9f7b5bdea,b8ec334f8c87bf1d9cb6043fa1a64214</data>
    </node>
    <node id="DATASET_4">
      <data key="d0">DATASET</data>
      <data key="d1">Dataset 4 has all but one of the x-values the same, with the slope of the line dependent on the single unusual data point
Dataset 4, also from Anscombe's quartet, features all but one x-value being the same, with the slope of the line heavily dependent on a single unusual data point</data>
      <data key="d2">84ffe1b8496dc660c47248c9f7b5bdea,b8ec334f8c87bf1d9cb6043fa1a64214</data>
    </node>
    <node id="OUTLIER">
      <data key="d0">DATA_POINT</data>
      <data key="d1">An outlier is a data point that differs significantly from other observations, potentially affecting the results of statistical analyses</data>
      <data key="d2">84ffe1b8496dc660c47248c9f7b5bdea</data>
    </node>
    <node id="SIMPLE_LINEAR_MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">A simple linear model is a type of linear regression model that assumes a linear relationship between the dependent and independent variables
A simple linear model is a statistical model that assumes a linear relationship between the response variable and the explanatory variable(s)</data>
      <data key="d2">84ffe1b8496dc660c47248c9f7b5bdea,b8ec334f8c87bf1d9cb6043fa1a64214</data>
    </node>
    <node id="ANSCOME_QUARTET">
      <data key="d0">DATASET</data>
      <data key="d1">Anscombe's quartet consists of four datasets that have nearly identical simple descriptive statistics, yet have very different distributions and appear very different when graphed</data>
      <data key="d2">b8ec334f8c87bf1d9cb6043fa1a64214</data>
    </node>
    <node id="DATASAUROS_DOZEN">
      <data key="d0">DATASET</data>
      <data key="d1">The Datasaurus Dozen is a set of 12 datasets that have the same summary statistics but very different distributions, created by Alberto Cairo to highlight the importance of visualizing data</data>
      <data key="d2">b8ec334f8c87bf1d9cb6043fa1a64214</data>
    </node>
    <node id="HISTOGRAMS">
      <data key="d0">TOOL</data>
      <data key="d1">Histograms are graphical representations of the distribution of numerical data, used for exploratory data analysis.
Histograms are graphical representations of the distribution of the variables, showing the frequency of occurrence of different values.</data>
      <data key="d2">60cc94e681863c9fcc6f9be1e500f840,87ba4f416a28aabc3b396908f5913b54</data>
    </node>
    <node id="SCATTERPLOTS">
      <data key="d0">TOOL</data>
      <data key="d1">Scatterplots are graphs that display the relationship between two variables, often used to identify patterns or trends in data.</data>
      <data key="d2">87ba4f416a28aabc3b396908f5913b54</data>
    </node>
    <node id="PARABOLA">
      <data key="d0">SHAPE</data>
      <data key="d1">A parabola is a curve where any point is at an equal distance from a fixed point (the focus) and a fixed straight line (the directrix).
Parabola is the curve of best fit for the quadratic regression model, representing the relationship between X and Y</data>
      <data key="d2">11452a08471d93959558de2ece9a69af,87ba4f416a28aabc3b396908f5913b54</data>
    </node>
    <node id="QUADRATIC_REGRESSION">
      <data key="d0">MODEL</data>
      <data key="d1">Quadratic regression is a type of polynomial regression where the model includes a squared term of the independent variable to capture a parabolic relationship.
Quadratic regression is the approach used when a quadratic term is added to the model. It is used to model non-linear relationships between the predictor and the response variable
Quadratic regression model is a more complex model that can describe curved relationships between variables</data>
      <data key="d2">15c7b5750483a382ce59751008e86751,87ba4f416a28aabc3b396908f5913b54,e5131a1158e58f1b7b44b21ced7b6f60</data>
    </node>
    <node id="PARAMETERS">
      <data key="d0">MODEL_COMPONENT</data>
      <data key="d1">Parameters are the coefficients or variables in a statistical model, such as &#946;0, &#946;1, and &#946;2 in the context of polynomial regression.
Parameters are the values in the model that need to be estimated or optimized</data>
      <data key="d2">87ba4f416a28aabc3b396908f5913b54,bb31f1c77bbba73300f735a100086a67</data>
    </node>
    <node id="SUM_OF_SQUARED_DISTANCES">
      <data key="d0">METRIC</data>
      <data key="d1">The sum of squared distances is a metric used in least squares estimation to quantify the difference between the observed values and the values predicted by the model.
The sum of squared vertical distances between the observations and the parabola given by &#946;0 + &#946;1x + &#946;2x^2 is the criterion used in least squares estimation to determine the parameters of the model</data>
      <data key="d2">87ba4f416a28aabc3b396908f5913b54,e5131a1158e58f1b7b44b21ced7b6f60</data>
    </node>
    <node id="ERRORS">
      <data key="d0">ERRORS</data>
      <data key="d1">Errors in the model are assumed to be iid (independent and identically distributed) N (0, &#963;^2). They represent the difference between the observed values and the values predicted by the model
Errors in the linear regression model are assumed to be independent and identically distributed (iid) following a normal distribution with mean 0 and variance &#963;^2
Errors in the context of statistical models are the differences between the observed values and the values predicted by the model
Errors in a statistical model refer to the differences between the observed values and the values predicted by the model. In the context of a linear model, errors are assumed to be independent, have constant variance, and follow a normal distribution.
Errors (&#1013;1, . . . , &#1013;n) are the discrepancies between the observed values and the values predicted by the model
Errors are the differences between the observed values and the values predicted by the model, assumed to be iid N(0, &#963;^2).</data>
      <data key="d2">25fce1af816975003128126b5cfea73b,3bfc9b92571973e54c8095302acc1aaa,7cd6069e88e81548a237fa937adfecc6,d738df7d83784c8a41b3948271c537b6,e361ac139c268d5c3f3623f920e68af2,e5131a1158e58f1b7b44b21ced7b6f60</data>
    </node>
    <node id="QUADRATIC_TERM">
      <data key="d0">PREDICTOR</data>
      <data key="d1">Quadratic term is an additional predictor term added to the systematic component of the model. It is used to model the curvature in the relationship between the predictor and the response variable</data>
      <data key="d2">e5131a1158e58f1b7b44b21ced7b6f60</data>
    </node>
    <node id="MODEL_EQUATIONS">
      <data key="d0">EQUATIONS</data>
      <data key="d1">The model equations in (2.1) expressed in matrix notation are the equations that describe the relationship between the response variable and the predictor variables in the model</data>
      <data key="d2">e5131a1158e58f1b7b44b21ced7b6f60</data>
    </node>
    <node id="PLR_MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">plr.model is the quadratic regression model fitted using the lm() function</data>
      <data key="d2">084dadebfca8bcb6377c205c45bee295</data>
    </node>
    <node id="FIGURE_2_5">
      <data key="d0">FIGURE</data>
      <data key="d1">Figure 2.5 is a scatterplot of Anscombe&#8217;s Dataset 2 with the parabola of best fit</data>
      <data key="d2">084dadebfca8bcb6377c205c45bee295</data>
    </node>
    <node id="QUADRATIC_CURVE">
      <data key="d0">CURVE</data>
      <data key="d1">Quadratic curve is the curve of best fit for the quadratic regression model, representing the relationship between X and Y</data>
      <data key="d2">11452a08471d93959558de2ece9a69af</data>
    </node>
    <node id="EXPECTED_CHANGE">
      <data key="d0">EXPECTED_VALUE</data>
      <data key="d1">Expected change in the response due to a unit change in the explanatory variable is given by the formula (Y |X = x + 1) &#8722; E(Y |X = x) = &#946;1 + &#946;2 + 2&#946;2x, which is not constant but depends on the current value x of the predictor variable</data>
      <data key="d2">c9a01b92d11585f6549f62e8bd78d652</data>
    </node>
    <node id="PLOT">
      <data key="d0">VISUALIZATION</data>
      <data key="d1">A plot, such as the one in Figure 2.5, is usually helpful when there is only one explanatory variable, to visualize the relationship between the expected response and the explanatory variable
A plot is a graphical representation of data, typically showing the relationship between two variables</data>
      <data key="d2">b9ec8a6c7960cc6196ec94fd976f05b0,c9a01b92d11585f6549f62e8bd78d652</data>
    </node>
    <node id="QUADRATIC_RELATIONSHIP">
      <data key="d0">RELATIONSHIP</data>
      <data key="d1">The expected response has a quadratic relationship with the explanatory variable, as described by the systematic component of the fitted model</data>
      <data key="d2">c9a01b92d11585f6549f62e8bd78d652</data>
    </node>
    <node id="POLYNOMIAL_MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">The model describing the relationship between the response variable and the predictor variable is a polynomial of order 2, which is a non-linear function of the predictor variable</data>
      <data key="d2">c9a01b92d11585f6549f62e8bd78d652</data>
    </node>
    <node id="ERROR_TERM">
      <data key="d0">VARIABLE</data>
      <data key="d1">Error term (&#1013;) represents the difference between the observed values of the response variable and the values predicted by the model. It is assumed to be random and independent for each observation.
&#1013;j is the error term in the linear regression model, representing the difference between the observed sales volume and the predicted sales volume.&gt;</data>
      <data key="d2">7a605c3b689bec7ab2c46df9c123e3f3,b9af17718641389ba07f53be13f31f8c</data>
    </node>
    <node id="YI">
      <data key="d0">DEPENDENT_VARIABLE</data>
      <data key="d1">Yi represents the dependent variable in the quadratic regression model for the ith unit of observation
Yi represents the response variable in the statistical models, which is a function of the explanatory variables and random error
Yi is the response variable in the dataset provided for Exercise 9, with values 1, 2, 4, 7, 12
Yi is the response variable in the model, which is transformed using the log-transform.
Yi represents the response variable in the non-linear transformation model, given by the exponential of the linear combination of predictors and error term
Yi is the ith observation in the vector Y
yi is the observed value for the ith observation in the linear regression model
yi is the observed value for the ith observation in the regression model
Yi is the response variable for the ith observation in the regression model</data>
      <data key="d2">0fbc9037ca9a440e79e9ac05664b9b3d,1da117a2f92b2db00290d2a0bfc06beb,22093a562f5f05dc9891b45ab9bcbea8,2685edb9e8031c8ea725c43a40af22a8,34fceaaf7d835828b5ee2327325c37f8,5a0d392715f06d5e873f45ae06aa729a,6c1684ed2a4840576c6b0f4d1a3a482f,90b7e0427699cc1bb461e37939935138,90ed6030c5a5a0764b7dcd4115b4d4d3</data>
    </node>
    <node id="XI">
      <data key="d0">EXPLANATORY_VARIABLE</data>
      <data key="d1">xi is the value of the explanatory variable for the ith unit of observation in the quadratic regression model
Xi is the ith observation of the explanatory variable in the simple linear regression model.</data>
      <data key="d2">6c1684ed2a4840576c6b0f4d1a3a482f,6ee02b38ae842fd5eac9a11c4fd6659f</data>
    </node>
    <node id="EXERCISE_7">
      <data key="d0">EXERCISE</data>
      <data key="d1">Exercise 7 is a quadratic regression model exercise where the model equation and assumptions about the errors are given</data>
      <data key="d2">6c1684ed2a4840576c6b0f4d1a3a482f</data>
    </node>
    <node id="DBH">
      <data key="d0">DIAMETER</data>
      <data key="d1">Dbh is the diameter of the tree (in mm) measured 137 cm from the ground
Dbh is the diameter of the tree measured 137 cm from the ground in millimeters</data>
      <data key="d2">2d5cdecc342ddacd2c090f1838430cee,656dce234514b9db38b5b5616557c1e9</data>
    </node>
    <node id="HEIGHT">
      <data key="d0">HEIGHT</data>
      <data key="d1">Height is the height of the tree in decimetres (dm)
Height is the height of the tree measured in decimeters
Height is a variable that represents the height of the tree, which is the response variable in the regression model. The observed heights are plotted against the log2-diameters, and the relationship appears fairly linear.
Height is the response variable in the linear regression model. It represents the height of Western red cedar trees.
Height is a variable in the trees dataset, measured in feet
Height is the measurement of the tree from the ground to its top</data>
      <data key="d2">00e186a86624c01ce873dd577df68d17,2d5cdecc342ddacd2c090f1838430cee,656dce234514b9db38b5b5616557c1e9,9611ea31ff53888971694cdefe806f64,c619949b08fc2b7edf3a7635b46dc147,efeeb664622c1ee594e6a08a8322ffe3</data>
    </node>
    <node id="UFCWC">
      <data key="d0">DATASET</data>
      <data key="d1">ufcwc is a dataset from the alr4 package containing information on a sample of 139 Western cedar trees</data>
      <data key="d2">2d5cdecc342ddacd2c090f1838430cee</data>
    </node>
    <node id="ALR4">
      <data key="d0">PACKAGE</data>
      <data key="d1">alr4 is a package containing the ufcwc dataset</data>
      <data key="d2">2d5cdecc342ddacd2c090f1838430cee</data>
    </node>
    <node id="WEISBERG">
      <data key="d0">AUTHOR</data>
      <data key="d1">Weisberg is the author of the book "Applied Linear Regression, 4th edition"</data>
      <data key="d2">2d5cdecc342ddacd2c090f1838430cee</data>
    </node>
    <node id="UNIVERSITY IDAHO EXPERIMENTAL FOREST">
      <data key="d0">LOCATION</data>
      <data key="d1">University Idaho Experimental Forest is the location where the data for the ufcwc dataset were collected</data>
      <data key="d2">2d5cdecc342ddacd2c090f1838430cee</data>
    </node>
    <node id="UPPER FLAT CREEK STAND">
      <data key="d0">LOCATION</data>
      <data key="d1">Upper Flat Creek stand is the specific location within the University Idaho Experimental Forest where the data for the ufcwc dataset were collected</data>
      <data key="d2">2d5cdecc342ddacd2c090f1838430cee</data>
    </node>
    <node id="CREEK_STAND">
      <data key="d0">LOCATION</data>
      <data key="d1">Creek stand is the location where the Western red cedar trees are found</data>
      <data key="d2">656dce234514b9db38b5b5616557c1e9</data>
    </node>
    <node id="FIGURE_2_6">
      <data key="d0">PLOT</data>
      <data key="d1">Figure 2.6 is a scatterplot showing the relationship between height and diameter of the Western red cedar trees, with the line of best fit</data>
      <data key="d2">656dce234514b9db38b5b5616557c1e9</data>
    </node>
    <node id="WEISBERG_S_2014">
      <data key="d0">REFERENCE</data>
      <data key="d1">Weisberg, S. (2014). Applied Linear Regression, 4th edition. New York: Wiley is a reference for the linear regression model</data>
      <data key="d2">656dce234514b9db38b5b5616557c1e9</data>
    </node>
    <node id="DIAMETER">
      <data key="d0">VARIABLE</data>
      <data key="d1">Diameter is a variable that represents the size of the tree, which is used in the regression model to predict the height of the tree. It is transformed using the logarithm of base 2 (log2) for the model. The relationship between diameter and height is curved but monotonic, suggesting that larger diameters are associated with taller trees. The data points for very small or very large diameters tend to lie below the regression line.
Diameter is the measurement of the tree's width, taken at 4 ft 6 inches from the ground, originally mislabelled as girth</data>
      <data key="d2">00e186a86624c01ce873dd577df68d17,9611ea31ff53888971694cdefe806f64</data>
    </node>
    <node id="LOG2">
      <data key="d0">FUNCTION</data>
      <data key="d1">Log2 is the logarithm function of base 2 used to transform the diameter variable in the regression model. The transformation is applied to each diameter value to obtain the log2-diameter values used in the design matrix.
Log2 is a mathematical function that calculates the base 2 logarithm of a number. It is used in the transformation of the predictor variable in the linear regression model to make the interpretation of the coefficients easier.</data>
      <data key="d2">00e186a86624c01ce873dd577df68d17,c619949b08fc2b7edf3a7635b46dc147</data>
    </node>
    <node id="BASE_2">
      <data key="d0">LOGARITHM_BASE</data>
      <data key="d1">Base 2 is the logarithm base used in the transformation of the diameters for the linear regression model</data>
      <data key="d2">25fce1af816975003128126b5cfea73b</data>
    </node>
    <node id="HEIGHTS">
      <data key="d0">OBSERVED_VARIABLE</data>
      <data key="d1">Heights are the observed response variable in the linear regression model</data>
      <data key="d2">25fce1af816975003128126b5cfea73b</data>
    </node>
    <node id="LOG2_DIAMETERS">
      <data key="d0">TRANSFORMED_VARIABLE</data>
      <data key="d1">Log2-diameters are the explanatory variable transformed using the base 2 logarithm for the linear regression model</data>
      <data key="d2">25fce1af816975003128126b5cfea73b</data>
    </node>
    <node id="TREE_MODEL">
      <data key="d0">FITTED_MODEL</data>
      <data key="d1">Tree.model is the fitted linear regression model using the Height as the response variable and the log2(Dbh) as the predictor
Tree.model is a linear regression model that predicts the Height of Western red cedar trees using the log2-transformed Dbh as the predictor variable.</data>
      <data key="d2">25fce1af816975003128126b5cfea73b,c619949b08fc2b7edf3a7635b46dc147</data>
    </node>
    <node id="LOG2_DBH">
      <data key="d0">MODEL_PARAMETER</data>
      <data key="d1">Log2(Dbh) is the estimated coefficient for the log2-transformed diameter at breast height (Dbh) in the linear regression model</data>
      <data key="d2">25fce1af816975003128126b5cfea73b</data>
    </node>
    <node id="NATURAL_LOGARITHM">
      <data key="d0">LOGARITHM_BASE</data>
      <data key="d1">Natural logarithm is the logarithm with base e, which could have been used but was not chosen for this model</data>
      <data key="d2">25fce1af816975003128126b5cfea73b</data>
    </node>
    <node id="LOG2_X_PLUS_1">
      <data key="d0">MATHEMATICAL_EXPRESSION</data>
      <data key="d1">Log2(x) + 1 is the mathematical expression that shows the relationship between the base 2 logarithm and the natural logarithm, used to explain the choice of base 2</data>
      <data key="d2">25fce1af816975003128126b5cfea73b</data>
    </node>
    <node id="PREDICTOR">
      <data key="d0">VARIABLE</data>
      <data key="d1">Dbh (Diameter at Breast Height) is the predictor variable in the linear regression model. It is transformed using the log2 function to improve the model fit and ease of interpretation.
Predictor variables are used in regression models to predict the response variable. They can be quantitative or categorical.</data>
      <data key="d2">b0ca3e6c22c4cf884d03b1f6f82be5df,c619949b08fc2b7edf3a7635b46dc147</data>
    </node>
    <node id="NATURAL_LOG">
      <data key="d0">FUNCTION</data>
      <data key="d1">Natural log is a mathematical function that calculates the logarithm of a number with base e. It is mentioned as an alternative to the log2 function but is not used in the current model.</data>
      <data key="d2">c619949b08fc2b7edf3a7635b46dc147</data>
    </node>
    <node id="LOG10">
      <data key="d0">FUNCTION</data>
      <data key="d1">Log10 is a mathematical function that calculates the logarithm of a number with base 10. It is mentioned as another common choice in statistical practice for transforming predictor variables, where for interpretation, we consider a ten-fold increase in the predictor variable.</data>
      <data key="d2">c619949b08fc2b7edf3a7635b46dc147</data>
    </node>
    <node id="VARIABLE">
      <data key="d0">VARIABLE</data>
      <data key="d1">The term 'variable' refers to a quantity that can change or vary, such as the response variable Y and the explanatory variables X1 and X2 in a statistical model</data>
      <data key="d2">ae1e66f5b64284090abc285c1d4389f5</data>
    </node>
    <node id="LOG_TRANSFORMED_VARIABLE">
      <data key="d0">VARIABLE</data>
      <data key="d1">Log-transformed variable is an explanatory variable that has been transformed using a logarithmic function, often to improve the fit of a statistical model</data>
      <data key="d2">ae1e66f5b64284090abc285c1d4389f5</data>
    </node>
    <node id="FIT">
      <data key="d0">FIT</data>
      <data key="d1">Fit refers to how well a statistical model describes the relationship between variables. A better fit indicates that the model more accurately represents the data</data>
      <data key="d2">ae1e66f5b64284090abc285c1d4389f5</data>
    </node>
    <node id="ARITHMETIC_OPERATORS">
      <data key="d0">OPERATOR</data>
      <data key="d1">Arithmetic operators are symbols that represent mathematical operations such as addition, subtraction, multiplication, and division</data>
      <data key="d2">ae1e66f5b64284090abc285c1d4389f5</data>
    </node>
    <node id="INHIBITOR_FUNCTION_I">
      <data key="d0">FUNCTION</data>
      <data key="d1">The inhibitor function I() is used in R to treat certain operators as arithmetic operators, allowing for proper mathematical operations in statistical models</data>
      <data key="d2">ae1e66f5b64284090abc285c1d4389f5</data>
    </node>
    <node id="LOGARITHM_BASE_10">
      <data key="d0">FUNCTION</data>
      <data key="d1">Logarithm with base 10 is a mathematical function that is often used in statistical practice for interpretation, especially when considering a ten-fold increase in the predictor variable</data>
      <data key="d2">ae1e66f5b64284090abc285c1d4389f5</data>
    </node>
    <node id="WESTERN_RED_CEDAR_DATA">
      <data key="d0">DATA</data>
      <data key="d1">Western red cedar data is a dataset that includes measurements such as height and diameter of Western red cedar trees, used for statistical analysis
The Western red cedar data is a dataset that was used as an example in Section 2.3. The explanatory variable was log-transformed to address model violations.
Western red cedar data is a dataset used in an example in Section 2.3 where the explanatory variable was log-transformed.</data>
      <data key="d2">0fbc9037ca9a440e79e9ac05664b9b3d,ae1e66f5b64284090abc285c1d4389f5,c03eb12d07d48f9e94260f08dae10cdf</data>
    </node>
    <node id="LOGARITHMIC_CURVE_OF_BEST_FIT">
      <data key="d0">FIT</data>
      <data key="d1">Logarithmic curve of best fit is a curve that best represents the relationship between a log-transformed variable and another variable, often used when the relationship is not linear</data>
      <data key="d2">ae1e66f5b64284090abc285c1d4389f5</data>
    </node>
    <node id="EXERCISE_8">
      <data key="d0">EXERCISE</data>
      <data key="d1">Exercise 8 is a problem or task designed to test understanding or skills in statistical modelling, involving observations of a response variable Y and two explanatory variables X1 and X2</data>
      <data key="d2">ae1e66f5b64284090abc285c1d4389f5</data>
    </node>
    <node id="PARAMETER_VECTOR_BETA">
      <data key="d0">VECTOR</data>
      <data key="d1">Parameter vector &#946; is a vector that contains the parameters of a statistical model, such as &#946;0, &#946;1, and &#946;2, which are coefficients that determine the relationship between variables</data>
      <data key="d2">ae1e66f5b64284090abc285c1d4389f5</data>
    </node>
    <node id="EPSILONI">
      <data key="d0">ERROR_TERM</data>
      <data key="d1">Epsiloni (&#1013;i) is the random error term in the statistical models, representing the unexplained variation
epsiloni (&#1013;i) is the error term in the model, assumed to be normally distributed
EPSILONi is the error term for the ith species in the linear regression model</data>
      <data key="d2">34fceaaf7d835828b5ee2327325c37f8,86c401dda130c2d201c3339526062a24,90ed6030c5a5a0764b7dcd4115b4d4d3</data>
    </node>
    <node id="XI,1">
      <data key="d0">EXPLANATORY_VARIABLE</data>
      <data key="d1">xi,1 is an explanatory variable in the statistical models, used in various forms to explain the response variable</data>
      <data key="d2">90ed6030c5a5a0764b7dcd4115b4d4d3</data>
    </node>
    <node id="XI,2">
      <data key="d0">EXPLANATORY_VARIABLE</data>
      <data key="d1">xi,2 is an explanatory variable in the statistical models, used in the logarithmic form to explain the response variable</data>
      <data key="d2">90ed6030c5a5a0764b7dcd4115b4d4d3</data>
    </node>
    <node id="FEATURES">
      <data key="d0">FEATURES</data>
      <data key="d1">Features are the characteristics or variables within the data that are relevant for analysis</data>
      <data key="d2">bb31f1c77bbba73300f735a100086a67</data>
    </node>
    <node id="STOCHASTIC_NATURE">
      <data key="d0">PROPERTY</data>
      <data key="d1">The stochastic nature of the response refers to the inherent randomness or variability in the data</data>
      <data key="d2">bb31f1c77bbba73300f735a100086a67</data>
    </node>
    <node id="FITTING_MODEL">
      <data key="d0">PROCEDURE</data>
      <data key="d1">Fitting the model involves finding the best set of values for the parameters that minimize the difference between the model predictions and the actual data</data>
      <data key="d2">bb31f1c77bbba73300f735a100086a67</data>
    </node>
    <node id="MODEL_ADEQUACY">
      <data key="d0">CRITERION</data>
      <data key="d1">Model adequacy refers to the evaluation of whether the model is consistent with the data, correctly specified, and allows the main questions of the analysis to be answered
Model adequacy refers to the suitability of a statistical model for a given purpose, such as description, estimation, or prediction</data>
      <data key="d2">768c516c8b27fb9800427e848f02fc33,bb31f1c77bbba73300f735a100086a67</data>
    </node>
    <node id="PLAUSIBLE_MODELS">
      <data key="d0">MODELS</data>
      <data key="d1">Plausible models are alternative models that are also consistent with the data and can be compared to choose the most appropriate one</data>
      <data key="d2">bb31f1c77bbba73300f735a100086a67</data>
    </node>
    <node id="CHOSEN_MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">The chosen model is the model that is selected as the most appropriate for answering the questions of interest</data>
      <data key="d2">bb31f1c77bbba73300f735a100086a67</data>
    </node>
    <node id="QUESTIONS_OF_INTEREST">
      <data key="d0">QUESTIONS</data>
      <data key="d1">Questions of interest are the specific research questions that the analysis aims to answer</data>
      <data key="d2">bb31f1c77bbba73300f735a100086a67</data>
    </node>
    <node id="GEORGE_BOX">
      <data key="d0">PERSON</data>
      <data key="d1">George E. Box is an eminent statistician who made significant contributions to the field of statistics and is known for his quote about models being wrong but useful</data>
      <data key="d2">bb31f1c77bbba73300f735a100086a67</data>
    </node>
    <node id="WASSERSTEIN_PAPER">
      <data key="d0">PAPER</data>
      <data key="d1">The Wasserstein paper is a publication that provides more information about George Box and his contributions to statistics</data>
      <data key="d2">bb31f1c77bbba73300f735a100086a67</data>
    </node>
    <node id="SIGNIFICANCE_JOURNAL">
      <data key="d0">JOURNAL</data>
      <data key="d1">Significance is a journal of the Royal Statistical Society that publishes articles on statistical topics</data>
      <data key="d2">bb31f1c77bbba73300f735a100086a67</data>
    </node>
    <node id="ROYAL_STATISTICAL_SOCIETY">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">The Royal Statistical Society is a professional organization for statisticians that publishes journals and promotes the development of statistical science</data>
      <data key="d2">bb31f1c77bbba73300f735a100086a67</data>
    </node>
    <node id="GEORGE E. BOX">
      <data key="d0">PERSON</data>
      <data key="d1">George E. Box is a statistician known for the quote "Essentially all models are wrong, but some are useful."</data>
      <data key="d2">22061b1108c7f9963497b7a320be22b8</data>
    </node>
    <node id="WASSERSTEIN6">
      <data key="d0">PAPER</data>
      <data key="d1">Wasserstein6 is a paper that provides more information about George E. Box, published in Significance, a journal of the Royal Statistical Society.</data>
      <data key="d2">22061b1108c7f9963497b7a320be22b8</data>
    </node>
    <node id="SIGNIFICANCE">
      <data key="d0">JOURNAL</data>
      <data key="d1">Significance is a journal of the Royal Statistical Society where the paper Wasserstein6 was published.</data>
      <data key="d2">22061b1108c7f9963497b7a320be22b8</data>
    </node>
    <node id="ROYAL STATISTICAL SOCIETY">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">The Royal Statistical Society is an organization that publishes the journal Significance.</data>
      <data key="d2">22061b1108c7f9963497b7a320be22b8</data>
    </node>
    <node id="GAPMINDER">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Gapminder is an organization that provides data and visualizations on various economic indices for comparisons between countries.</data>
      <data key="d2">22061b1108c7f9963497b7a320be22b8</data>
    </node>
    <node id="ECONOMIC INDICES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Economic indices are measures used to compare economic conditions between countries.</data>
      <data key="d2">22061b1108c7f9963497b7a320be22b8</data>
    </node>
    <node id="PARSIMONY">
      <data key="d0">CRITERION</data>
      <data key="d1">Parsimony is a criterion for evaluating models, favoring simplicity and avoiding unnecessary complexity.
Parsimony is a principle that suggests choosing the simplest explanation or model that adequately fits the data
Parsimony is a principle in science and statistics that directs us to choose the simplest explanation or model</data>
      <data key="d2">188219b9e5b6b6368360840921877de9,22061b1108c7f9963497b7a320be22b8,768c516c8b27fb9800427e848f02fc33</data>
    </node>
    <node id="PLAUSIBILITY">
      <data key="d0">CRITERION</data>
      <data key="d1">Plausibility is a criterion for evaluating models, favoring those that make most sense scientifically.
Plausibility is a criterion that assesses whether a model makes practical sense in the context of the data and scientific knowledge</data>
      <data key="d2">22061b1108c7f9963497b7a320be22b8,768c516c8b27fb9800427e848f02fc33</data>
    </node>
    <node id="DESCRIPTION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">22061b1108c7f9963497b7a320be22b8</data>
    </node>
    <node id="PREDICTION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">22061b1108c7f9963497b7a320be22b8</data>
    </node>
    <node id="EXPLANATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">22061b1108c7f9963497b7a320be22b8</data>
    </node>
    <node id="PREDICTOR_VARIABLES">
      <data key="d0">VARIABLES</data>
      <data key="d1">Predictor variables are the independent variables in a statistical model that are used to predict the response variable</data>
      <data key="d2">768c516c8b27fb9800427e848f02fc33</data>
    </node>
    <node id="PARAMETER_ESTIMATION">
      <data key="d0">STATISTICAL_METHOD</data>
      <data key="d1">Parameter estimation is the process of using data to estimate the values of unknown parameters in a statistical model</data>
      <data key="d2">768c516c8b27fb9800427e848f02fc33</data>
    </node>
    <node id="SIMPLER_MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">A simpler model is a model with fewer parameters or assumptions, often preferred for its ease of interpretation and prediction</data>
      <data key="d2">768c516c8b27fb9800427e848f02fc33</data>
    </node>
    <node id="TRUE_MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">The true model is the model that accurately represents the underlying data-generating process</data>
      <data key="d2">768c516c8b27fb9800427e848f02fc33</data>
    </node>
    <node id="ACCELERATION_DUE_TO_GRAVITY">
      <data key="d0">PHYSICAL_QUANTITY</data>
      <data key="d1">Acceleration due to gravity is the acceleration experienced by an object due to the gravitational force of the Earth</data>
      <data key="d2">768c516c8b27fb9800427e848f02fc33</data>
    </node>
    <node id="WASSERSTEIN_R">
      <data key="d0">AUTHOR</data>
      <data key="d1">R. Wasserstein is the author of the article "George Box: A model statistician" published in Significance in 2010</data>
      <data key="d2">768c516c8b27fb9800427e848f02fc33</data>
    </node>
    <node id="BALL">
      <data key="d0">OBJECT</data>
      <data key="d1">The ball is an object whose path is being modelled under the influence of gravity</data>
      <data key="d2">188219b9e5b6b6368360840921877de9</data>
    </node>
    <node id="GRAVITY">
      <data key="d0">FORCE</data>
      <data key="d1">Gravity is the force that causes the ball to fall, with an acceleration that is assumed to be constant in a room</data>
      <data key="d2">188219b9e5b6b6368360840921877de9</data>
    </node>
    <node id="ROOM">
      <data key="d0">ENVIRONMENT</data>
      <data key="d1">Room is the environment where the ball is falling, and where the acceleration due to gravity is assumed to be constant</data>
      <data key="d2">188219b9e5b6b6368360840921877de9</data>
    </node>
    <node id="SPACE">
      <data key="d0">ENVIRONMENT</data>
      <data key="d1">Space is an environment where the assumption of constant gravity does not hold, and the relationship between gravity and the path of objects is only valid locally</data>
      <data key="d2">188219b9e5b6b6368360840921877de9</data>
    </node>
    <node id="OCKHAMS_RAZOR">
      <data key="d0">PHILOSOPHICAL_PRINCIPLE</data>
      <data key="d1">Ockham's razor is a philosophical principle that states that the simplest explanation is usually the best</data>
      <data key="d2">188219b9e5b6b6368360840921877de9</data>
    </node>
    <node id="SIMPLE_MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">A simple model is a statistical model with the fewest parameters that still adequately fits the data and captures its essential features</data>
      <data key="d2">188219b9e5b6b6368360840921877de9</data>
    </node>
    <node id="COMPLEX_MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">A complex model is a statistical model with many parameters, which can decrease the precision of estimation and prediction
A complex model, such as a quadratic regression model, is considered when a simple linear regression does not adequately describe the relationship between variables
A complex model is a model that includes more terms or interactions to better fit the data
Complex model is a statistical model that includes more terms or interactions to better fit the data</data>
      <data key="d2">15c7b5750483a382ce59751008e86751,188219b9e5b6b6368360840921877de9,7347b44ffb25a066e43321f4eaf5a806,b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </node>
    <node id="TRANSFORMED_EXPLANATORY_VARIABLES">
      <data key="d0">VARIABLES</data>
      <data key="d1">Transformed explanatory variables are explanatory variables that have been modified using functions such as logarithms
Transformed explanatory variables are the result of applying a non-linear transformation, such as logarithm, to the original explanatory variables in a linear model. This is done to better fit the data or to satisfy model assumptions.</data>
      <data key="d2">0328e428a30c44572676dd571dd1e9bd,188219b9e5b6b6368360840921877de9</data>
    </node>
    <node id="MODEL_DEVELOPMENT_STRATEGY">
      <data key="d0">CONCEPT</data>
      <data key="d1">A model development strategy is a set of guidelines for building and refining statistical models. It includes principles of plausibility and parsimony, which suggest that models should be both realistic and as simple as possible.</data>
      <data key="d2">0328e428a30c44572676dd571dd1e9bd</data>
    </node>
    <node id="RESIDUAL_PLOTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Residual plots are graphical representations used in residual analysis to visualize the residuals of a linear model. They help identify patterns or trends in the residuals that might indicate violations of model assumptions.
Residual plots are graphical representations used to assess the validity of model assumptions by plotting the residuals (differences between observed and predicted values) against the predicted values or other variables. They help identify patterns that may indicate violations of assumptions such as non-linearity, heteroscedasticity, or non-normality.
Residual plots are scatterplots of the residuals against the fitted values and explanatory variables, used to check for violations of model assumptions
Residual plots are graphical tools used to assess the fit of a statistical model by plotting the residuals against the fitted values or explanatory variables
Residual plots are graphs used in regression analysis to check the assumptions of a regression model, particularly the assumption of constant variance and linearity
Residual plots are graphical representations used to assess the fit of a regression model by plotting the residuals (differences between observed and predicted values) against the fitted values or other variables. They help in identifying patterns that may indicate violations of model assumptions, such as non-constant variance or non-linearity.
Residual plots are graphical representations used to assess the fit of a regression model by plotting the residuals against fitted values or explanatory variables</data>
      <data key="d2">0328e428a30c44572676dd571dd1e9bd,0da640a09a395a50b6e16e047fa8d0d6,23fc620f1238c6a1b5c5e3a08e149c53,7cd6069e88e81548a237fa937adfecc6,a60af43e42c72a41fa90da06beb29d1b,b9ec8a6c7960cc6196ec94fd976f05b0,e7494d6cfc3e38a4d2f3f6b21ef6445d</data>
    </node>
    <node id="Q_Q_PLOTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Q-Q plots, or quantile-quantile plots, are used in residual analysis to compare the distribution of the residuals to a theoretical distribution, such as the normal distribution. They help assess whether the residuals are normally distributed.
Q-Q plots (Quantile-Quantile plots) are graphical tools used to compare the distribution of a dataset to a theoretical distribution, typically the normal distribution. They are used to assess the normality assumption by plotting the quantiles of the observed data against the quantiles of a theoretical distribution. If the points on the plot form a straight line, it suggests that the data follow the theoretical distribution.</data>
      <data key="d2">0328e428a30c44572676dd571dd1e9bd,e7494d6cfc3e38a4d2f3f6b21ef6445d</data>
    </node>
    <node id="MODEL_ASSUMPTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Model assumptions are the underlying conditions or hypotheses that are supposed to hold true for a statistical model to be valid and meaningful. These assumptions include linearity, independence, homoscedasticity, and normality of errors. They are crucial for the model's reliability and the validity of the inferences drawn from it.
Model assumptions are the conditions under which a linear model is valid, including the assumption that the response variable is measured on a continuous scale
Model assumptions are the conditions that must be met for a statistical model to be valid, such as linearity, independence, homoscedasticity, and normality of residuals
Model assumptions are the conditions that must hold for a regression model to be valid and for the results to be reliable
Model assumptions are the conditions that are supposed to be met for a statistical model to be valid and reliable. In the context of the normal linear model, these include linearity, normality of errors, homoscedasticity, and independence.</data>
      <data key="d2">22093a562f5f05dc9891b45ab9bcbea8,674b8d5bb1f830d0fb944942514d1a16,aa13c33a7e61206e6021e2736002ca9a,c03eb12d07d48f9e94260f08dae10cdf,e7494d6cfc3e38a4d2f3f6b21ef6445d</data>
    </node>
    <node id="VIOLATIONS_OF_ASSUMPTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Violations of assumptions refer to situations where the underlying conditions required for a statistical model to be valid are not met. This can lead to biased or inefficient parameter estimates, incorrect standard errors, and invalid hypothesis tests. Common violations include non-linearity, heteroscedasticity, non-normality, and autocorrelation.</data>
      <data key="d2">e7494d6cfc3e38a4d2f3f6b21ef6445d</data>
    </node>
    <node id="BETA_HAT">
      <data key="d0">ESTIMATOR VECTOR</data>
      <data key="d1">Beta hat (&#946;&#710;1, ..., &#946;&#710;p) is the vector of estimates for the parameters Beta, calculated using R
Beta hat (&#946;b) is the estimated parameter vector obtained from the data
Beta hat (&#946;b) is the least squares estimator of the parameter Beta, calculated as (XTX)^-1XTY
Beta hat (&#946;b) is the vector of dimension p that minimizes the sum of squared differences S(&#946;) in the least squares estimation
Beta hat (&#946;b) is the least squares estimator of the parameter Beta, calculated as (XTX)^-1XTY
Beta hat (&#946;b) is the least squares estimator of the parameter Beta
&#946;b is the stationary point of S(&#946;) that satisfies XTX&#946;b &#8722; XT y = 0
Beta hat (&#946;b) is the least squares estimator of the parameter Beta, calculated as (XTX)^-1XTy
Beta hat (&#946;b) is the least squares estimator of the parameter Beta, calculated to minimize the sum of squared residuals
Beta hat (&#946;b) is the least squares estimator of the parameter Beta, calculated as (XTX)^-1XTY and is the solution to the normal equations
Beta hat (&#946;b) is the least squares estimator of Beta, calculated as (XTX)^-1XTy
Beta hat (b&#946;) is the least squares estimator of the parameter Beta, calculated using the partial derivatives set to zero
Beta hat (&#946;b) is the least squares estimator of the parameter Beta, calculated as (XTX)^-1XTy
Beta hat (&#946;b) is the least squares estimator of the parameter Beta, calculated as (XTX)^-1XTy
Beta hat (&#946;b) is the least squares estimator of Beta
Beta hat (&#946;b) is the least squares estimator of the parameter Beta, calculated as (XTX)^-1XTY
Beta hat (&#946;b) is the least squares estimate of the parameter vector Beta, calculated to minimize the sum of squared differences
Beta hat (&#946;b) is the least squares estimator for the parameter vector Beta
&#946;b (Beta hat) is the least squares estimate for the parameter vector &#946;.
Beta hat (&#946;b) is the maximum likelihood estimate (MLE) of the parameter vector Beta
&#946;b is the maximum likelihood estimate of &#946;, calculated as (XTX)^-1XTy
Beta hat (&#946;b) is the least squares estimator of the parameter Beta, which minimises the residual sum of squares function S(&#946;) and is the maximum likelihood estimate for &#946;.
Beta hat (&#946;b) is the least squares estimate of the parameter Beta
Beta hat (&#946;b) is the least squares estimate of the parameter vector Beta, calculated as (XTX)^-1XTy
Beta hat (&#946;b) is the estimator of Beta, calculated as (XTX)^-1XTY
Beta hat (&#946;b) is the least squares/maximum likelihood estimator of the parameter Beta, calculated as (XTX)^-1XTY
Beta hat (&#946;b) is the least squares estimator of the parameter Beta, calculated as (XTX)^-1XTY
Beta hat (&#946;b) is the least squares estimator of the parameter Beta, calculated as (XTX)^-1XTY
BETA_HAT (&#946;b) is the least squares estimator for the parameters in a linear regression model
&#946;b is the estimator for the parameter &#946; in the linear regression model
Beta hat (&#946;b) is the least squares estimator for the parameter Beta in the linear regression model
Beta hat (&#946;b) is the least squares estimator of the parameter Beta, calculated from the observed data Y and the design matrix X
Beta hat (&#946;b) is the least squares and maximum likelihood estimator of the parameter Beta
Beta hat (&#946;b) is the least squares/maximum likelihood estimator of the parameter Beta, calculated from the observed data
Beta hat (&#946;b) is the least squares estimator of the parameter Beta in the linear model
Beta hat (&#946;b) is the least squares estimator of the parameter Beta, calculated as (XTX)^-1XTY
Beta hat (&#946;b) is the least squares estimator of the parameter Beta, calculated as (XTX)^-1XTY.
Beta hat (&#946;b) is the least squares estimator of the parameter Beta, calculated from the full dataset
Beta hat (&#946;&#710;) is the estimated regression coefficient for the price variable in the parallel lines model
Beta hat (&#946;&#710;) is the estimated coefficient for the price variable in the regression model
Beta hat (&#946;) is the estimated coefficient for the parameter Beta in the linear regression model
Beta_hat (-0.539) is the estimated parameter for price in the linear model
Beta hat (b&#946;) is the maximum likelihood estimator for the parameter Beta
Beta hat (&#946;b) is the least squares estimator of the parameter Beta in a linear regression model</data>
      <data key="d2">01d5ee79489582b4135fc96f676b24a0,0443ab5e20a4f6b2f243c989ef6c723a,0ac60299320c55d642b3e38440c25f90,0b650eb2f1dcd603b64fec3c4b5cd24b,21ec28dfe2b2c18030d541d63e51f45e,248924760a2bfbc82501fd6b11cfa0aa,255685e281cc5a9edf073c700f425a6b,2673d078d29f2af78fab9b6eacd15e37,28cf5ff0c09fa5c0390267bb9aa3ce47,2b6d31b6bff4eae3a4809451c4fb9fa6,2de7a36b32bf79c8f32612c8aaa9daa8,2f2523c52c6d2869fb19f77b66ce8259,3d357cfa3ef0d00f49cf4acaeac1c9d1,45f31b040576e9f3b4def6d0466cc016,50a56c34050fb7f7709300a51399b150,542f546c5a131196e4701fb33c9b1dee,56ff186fc629e1e42f2759fc4b984199,5cc49d301d9cd1f8e20b92ab9d8346b0,6648f0d6deed51fb4fb25e6992a71ddf,679722cf8ce5ce5aee4e379528470efe,69ffba28a61d98d8d18f91c24b74dd4a,6a6f85d0a6e46196ab3a901fcc82a720,6b55b41598d5264f8dc6b72769748722,6ee02b38ae842fd5eac9a11c4fd6659f,7037e0369bfdaad5a730cabb2b44831c,7955aae3fd4ca51b9ef8843e13c1f517,82932abd152e0b84a1c26a2daa4c08df,9923e77ac6b3de95cb5026bc5e7fe8c0,9d300fc83afb3261af61b2ab9721cadc,9dddcd96af7b557e578b3f5f36efacd7,9fc2b1e8b2b61b557f88eb9e9c708597,a4a817bb79d6ae8812c808ca41d47f43,aa195e72eb5285a4bcae9c856af30a87,aac5b4f040b9c773bd1aa696dec469f6,ad799500572246a07f983a3b92c0e61f,b2c33cb151a8e7724ebfb7b2d88bc45f,b70a75a6412b2e5c44af50734844f4be,d14413709de2897231aaa83be3aa346f,d738df7d83784c8a41b3948271c537b6,d94760a5f9f6ea115fcc18024035a627,e7edd8b2874a350779ae20f1ecdf4733,f632f01188d2c6e3091a965580cb4600,f9b615b879f72501f338f8983d4cac3d,fc5b725f3c662c5471af20efdcc2dbff</data>
    </node>
    <node id="BETA_BAR">
      <data key="d0">ESTIMATED PARAMETER VECTOR</data>
      <data key="d1">Beta bar (&#946;b) is the notation used for the estimated parameter vector Beta</data>
      <data key="d2">01d5ee79489582b4135fc96f676b24a0</data>
    </node>
    <node id="COEF_MODEL">
      <data key="d0">FUNCTION</data>
      <data key="d1">coef(model) is an R function that returns the estimate of the parameter vector for a linear model object</data>
      <data key="d2">01d5ee79489582b4135fc96f676b24a0</data>
    </node>
    <node id="YB">
      <data key="d0">FITTED VALUES VECTOR</data>
      <data key="d1">Yb is the vector of fitted values, estimated expected responses for given values of the predictor variables
YB is a vector of fitted values in the linear regression model, calculated as X&#946;b
YB is the back-transformed prediction for Y when X1 increases by one unit while X2 stays fixed
YB is the predicted response in the original scale when X1 increases by one unit and X2 stays fixed
Yb is the vector of fitted values in the linear regression model
Yb is the vector of fitted values in the regression model, calculated as X&#946;b or Hy.
Yb is the fitted value of the response variable in the regression model
yb is the vector of fitted values from the regression model</data>
      <data key="d2">0443ab5e20a4f6b2f243c989ef6c723a,09391efd3b8c510205098b548bc8dc74,21e429490eeefe7d9c245058fd48ca68,2b6d31b6bff4eae3a4809451c4fb9fa6,5cc49d301d9cd1f8e20b92ab9d8346b0,6ee02b38ae842fd5eac9a11c4fd6659f,82932abd152e0b84a1c26a2daa4c08df,995fb26a0261f824952fa7b2fac3382e</data>
    </node>
    <node id="ZJ">
      <data key="d0">EXPLANATORY VARIABLE</data>
      <data key="d1">zj is the jth observation of the explanatory variable in simple linear regression
Zj is the jth observation of the explanatory variable in the simple linear regression model</data>
      <data key="d2">2b6d31b6bff4eae3a4809451c4fb9fa6,5cc49d301d9cd1f8e20b92ab9d8346b0</data>
    </node>
    <node id="YBJ">
      <data key="d0">FITTED VALUE</data>
      <data key="d1">ybj is the fitted value for the jth unit of observation, estimated expected response for given values of the predictor variables
Ybj is the jth fitted value, the predicted response for the jth observation based on the linear regression model.</data>
      <data key="d2">2b6d31b6bff4eae3a4809451c4fb9fa6,e6f79ceb0df54119a4dc71b2162ac50b</data>
    </node>
    <node id="EPSILON_BJ">
      <data key="d0">RESIDUAL</data>
      <data key="d1">Epsilon bj (&#1013;bj) is the jth residual in the linear regression model, calculated as the difference between the jth observed response value and its fitted value
Epsilon bj (&#1013;bj) is the jth residual, calculated as the difference between the jth observed value (yj) and its fitted value (ybj), which is the predicted value based on the linear regression model. It is an estimate of the error (&#1013;j) in the model.
The residuals (&#1013;bj) are the differences between the observed values (yj) and the fitted values (ybj), calculated as yj - xTj &#946;b</data>
      <data key="d2">255685e281cc5a9edf073c700f425a6b,5cc49d301d9cd1f8e20b92ab9d8346b0,e6f79ceb0df54119a4dc71b2162ac50b</data>
    </node>
    <node id="XTJ">
      <data key="d0">PREDICTOR</data>
      <data key="d1">XTj is the transpose of the jth row of the predictor matrix X, used in the calculation of the fitted value Ybj.</data>
      <data key="d2">e6f79ceb0df54119a4dc71b2162ac50b</data>
    </node>
    <node id="BETA_B">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">Beta b (&#946;b) is the least squares estimator of the parameter Beta, used in the calculation of the fitted values Ybj.
Beta hat (b&#946;) is the coefficient for the price variable, representing the average reduction in sales for Brand A with every additional pound charged</data>
      <data key="d2">adbc52b340a69a8633c919c4fd2cd3f6,e6f79ceb0df54119a4dc71b2162ac50b</data>
    </node>
    <node id="RESIDUALS_COMMAND">
      <data key="d0">FUNCTION</data>
      <data key="d1">Residuals(model) is a command in R used to obtain the residuals from a fitted model.</data>
      <data key="d2">e6f79ceb0df54119a4dc71b2162ac50b</data>
    </node>
    <node id="DEVIANCE">
      <data key="d0">SUM_OF_SQUARES</data>
      <data key="d1">Deviance or Residual Sum of Squares (ResidSS) is a measure of the goodness of fit of a model, calculated as the sum of the squared residuals. It is used to assess how well the model fits the data.</data>
      <data key="d2">e6f79ceb0df54119a4dc71b2162ac50b</data>
    </node>
    <node id="PARAMETER_ESTIMATES">
      <data key="d0">ESTIMATION</data>
      <data key="d1">Parameter estimates are the values chosen to minimize the sum of squared residuals, aiming to improve the model's fit to the data
Parameter estimates are the estimated values of the model parameters based on the data
Parameter estimates are the values of the model parameters that are estimated from the data</data>
      <data key="d2">06199787dd7f75f7338dd24d4f3dc26e,22093a562f5f05dc9891b45ab9bcbea8,86ece4718d27d1a6c6a1f448cc850e2b</data>
    </node>
    <node id="RESIDUAL_SUM_OF_SQUARES">
      <data key="d0">STATISTICAL_MEASURE</data>
      <data key="d1">Residual sum of squares (ResidSS) is the sum of the squared residuals, a measure of the total deviation of the observed data points from the fitted model</data>
      <data key="d2">22093a562f5f05dc9891b45ab9bcbea8</data>
    </node>
    <node id="MODEL_DEVIANCE">
      <data key="d0">STATISTICAL_MEASURE</data>
      <data key="d1">Model deviance is another term for the residual sum of squares, indicating the discrepancy between the observed data and the model's predictions</data>
      <data key="d2">22093a562f5f05dc9891b45ab9bcbea8</data>
    </node>
    <node id="SIMPLE_REGRESSION_LINE">
      <data key="d0">MATHEMATICAL_MODEL</data>
      <data key="d1">The simple regression line y&#710; = 0.34 + 1.52z is a linear model that describes the relationship between the response variable y and the explanatory variable z</data>
      <data key="d2">22093a562f5f05dc9891b45ab9bcbea8</data>
    </node>
    <node id="EXERCISE_9">
      <data key="d0">EXERCISE</data>
      <data key="d1">Exercise 9 involves calculating the fitted values, residuals, and deviance for a given simple regression line and dataset</data>
      <data key="d2">22093a562f5f05dc9891b45ab9bcbea8</data>
    </node>
    <node id="ZI">
      <data key="d0">EXPLANATORY_VARIABLE</data>
      <data key="d1">Zi is the explanatory variable in the dataset provided for Exercise 9, with values 1, 2, 2, 3, 8</data>
      <data key="d2">22093a562f5f05dc9891b45ab9bcbea8</data>
    </node>
    <node id="NORMAL_LINEAR_MODEL">
      <data key="d0">MATHEMATICAL_MODEL</data>
      <data key="d1">A normal linear model is a statistical model that assumes the response variable Y is a linear combination of the explanatory variables X and an error term epsilon, expressed as Y = X&#946; + epsilon
The normal linear model is a statistical model that assumes the relationship between the response variable and the explanatory variables is linear, and the errors are normally distributed.
Normal linear model is a statistical model that assumes the errors are normally distributed.
The normal linear model is a statistical model that assumes the data follows a normal distribution and is linearly related to the parameters</data>
      <data key="d2">22093a562f5f05dc9891b45ab9bcbea8,c03eb12d07d48f9e94260f08dae10cdf,d738df7d83784c8a41b3948271c537b6,f483798b15ef305e7826fd7142379e03</data>
    </node>
    <node id="INDEPENDENCE">
      <data key="d0">ASSUMPTION</data>
      <data key="d1">Independence is the assumption that the errors &#1013;1, . . . , &#1013;n are independent of each other
Independence is the assumption that the errors are independent, which is crucial for the validity of the regression model
Independence is the property of the errors in a regression model being independent of each other</data>
      <data key="d2">0da640a09a395a50b6e16e047fa8d0d6,3cbe71f7649e84cd67cb3fa0d3e632cf,e361ac139c268d5c3f3623f920e68af2</data>
    </node>
    <node id="HOMOSCEDASTICITY">
      <data key="d0">ASSUMPTION</data>
      <data key="d1">Homoscedasticity is the assumption that the errors &#1013;1, . . . , &#1013;n have constant variance
Homoscedasticity is the assumption that the errors have constant variance, which is also assumed for the response variables
Homoscedasticity is an assumption in linear regression models that the variance of the errors is constant across all levels of the explanatory variables
Homoscedasticity refers to the property of the errors in a regression model having constant variance
Homoscedasticity is a property of a set of random variables where the variance is the same for all values of the independent variable.
Homoscedasticity is the assumption that the variance of the residuals is constant across all levels of the independent variables</data>
      <data key="d2">0da640a09a395a50b6e16e047fa8d0d6,3cbe71f7649e84cd67cb3fa0d3e632cf,60cc94e681863c9fcc6f9be1e500f840,7cd6069e88e81548a237fa937adfecc6,a60af43e42c72a41fa90da06beb29d1b,e361ac139c268d5c3f3623f920e68af2</data>
    </node>
    <node id="NORMALITY">
      <data key="d0">ASSUMPTION</data>
      <data key="d1">Normality is the assumption that the errors have a normal distribution
Normality is the assumption that the errors have a normal distribution, which is also assumed for the response variables
Normality is an assumption in linear regression models that the errors are normally distributed
Normality is an assumption in regression analysis that the errors are normally distributed
Normality is the property of the errors in a regression model having a normal distribution</data>
      <data key="d2">0da640a09a395a50b6e16e047fa8d0d6,3cbe71f7649e84cd67cb3fa0d3e632cf,7cd6069e88e81548a237fa937adfecc6,e361ac139c268d5c3f3623f920e68af2,ef24ca5edd06893b737e6a1c8a9825f6</data>
    </node>
    <node id="HETEROSCEDASTICITY">
      <data key="d0">VIOLATION</data>
      <data key="d1">Heteroscedasticity is a violation of the homoscedasticity assumption, where the variance of the errors is not constant
Heteroscedasticity refers to the condition where the variance of the error terms is not constant across the range of the explanatory variable
Heteroscedasticity refers to the condition where the variance of the error terms is not constant across the range of the explanatory variables
Heteroscedasticity refers to the condition where the variance of the errors is not constant across the range of the explanatory variables. A transformation of the response variable can address this issue.
Heteroscedasticity is a violation of the model assumption that the variance of the error terms is constant across all levels of the independent variables
Heteroscedasticity refers to a condition in which the variance of the error term in a regression model is not constant across all levels of the independent variables. This violates one of the assumptions of linear regression models and can lead to biased standard errors and unreliable hypothesis tests.</data>
      <data key="d2">07951ffe6787af44aa60c90c69e62f83,0da640a09a395a50b6e16e047fa8d0d6,7347b44ffb25a066e43321f4eaf5a806,b9eb75001a4f68f7240b2ca9e0d79eb8,c03eb12d07d48f9e94260f08dae10cdf,d71b402ab9edbb4347e09c7af3257cf5</data>
    </node>
    <node id="IDENTICALLY_DISTRIBUTED">
      <data key="d0">ASSUMPTION</data>
      <data key="d1">Identically distributed is the assumption that the errors are identically distributed, which is not true for the response variables due to their dependence on the explanatory variables</data>
      <data key="d2">0da640a09a395a50b6e16e047fa8d0d6</data>
    </node>
    <node id="DATA_COLLECTION">
      <data key="d0">PROCESS</data>
      <data key="d1">The data collection process should ensure that the errors are independent, and potential violations of this assumption can be identified by considering the process</data>
      <data key="d2">0da640a09a395a50b6e16e047fa8d0d6</data>
    </node>
    <node id="SEQUENTIAL_DATA">
      <data key="d0">VIOLATION</data>
      <data key="d1">Sequential data collection can lead to errors that are correlated in time, violating the assumption of independence
Sequential data refers to data points that are collected in a sequence, potentially leading to time-correlated errors if not properly accounted for in the model</data>
      <data key="d2">0da640a09a395a50b6e16e047fa8d0d6,7cd6069e88e81548a237fa937adfecc6</data>
    </node>
    <node id="SPATIAL_DATA">
      <data key="d0">VIOLATION</data>
      <data key="d1">Spatial data can lead to nearby observations being correlated, violating the assumption of independence
Spatial data refers to data points that have a geographical or spatial component, where nearby observations might be correlated</data>
      <data key="d2">0da640a09a395a50b6e16e047fa8d0d6,7cd6069e88e81548a237fa937adfecc6</data>
    </node>
    <node id="NORMAL_Q_Q_PLOTS">
      <data key="d0">ANALYSIS_TOOL</data>
      <data key="d1">Normal Q-Q plots are graphical tools used to assess the normality assumption in statistical models by comparing the quantiles of the observed residuals to the quantiles of a normal distribution
Normal Q-Q plots are graphical tools used to assess the normality of the residuals</data>
      <data key="d2">7cd6069e88e81548a237fa937adfecc6,e361ac139c268d5c3f3623f920e68af2</data>
    </node>
    <node id="R_SOFTWARE">
      <data key="d0">SOFTWARE</data>
      <data key="d1">R is a programming language and software environment for statistical computing and graphics</data>
      <data key="d2">7cd6069e88e81548a237fa937adfecc6</data>
    </node>
    <node id="NULL_PLOT">
      <data key="d0">ANALYSIS_TOOL</data>
      <data key="d1">A null plot is a residual plot that shows no distinct patterns, indicating that the model assumptions are satisfied
A null plot is a residual plot that shows no distinct patterns, with residuals randomly scattering around a horizontal line, indicating that the model assumptions are satisfied</data>
      <data key="d2">7cd6069e88e81548a237fa937adfecc6,aa13c33a7e61206e6021e2736002ca9a</data>
    </node>
    <node id="DISCRETE">
      <data key="d0">PROPERTY</data>
      <data key="d1">Discrete refers to data that can only take certain values, typically integers or categories</data>
      <data key="d2">aa13c33a7e61206e6021e2736002ca9a</data>
    </node>
    <node id="SMOOTHER">
      <data key="d0">ANALYSIS_TOOL</data>
      <data key="d1">A smoother is a non-parametric estimate of the mean of the residuals as a function of the fitted values, used to help evaluate the residual plot
The smoother is a function used in residual analysis to identify patterns in the residuals. It has the shape of an upturned parabola in the given context.</data>
      <data key="d2">82cfcd5865cffe55e965a50745656e60,aa13c33a7e61206e6021e2736002ca9a</data>
    </node>
    <node id="HORIZONTAL_LINE">
      <data key="d0">PLOT_ELEMENT</data>
      <data key="d1">A horizontal line is a line that runs parallel to the x-axis in a plot, often used as a reference line in residual plots to indicate no systematic pattern in the residuals</data>
      <data key="d2">aa13c33a7e61206e6021e2736002ca9a</data>
    </node>
    <node id="VARIABILITY">
      <data key="d0">PROPERTY</data>
      <data key="d1">Variability refers to the spread or dispersion of data points around a central value, often measured by the standard deviation or variance</data>
      <data key="d2">aa13c33a7e61206e6021e2736002ca9a</data>
    </node>
    <node id="SMOOTHED_RESIDUAL_PLOT">
      <data key="d0">PLOT</data>
      <data key="d1">A smoothed residual plot is a graphical representation of the residuals from a regression model, with a smoother added to estimate the mean of the residuals as a function of the fitted values</data>
      <data key="d2">674b8d5bb1f830d0fb944942514d1a16</data>
    </node>
    <node id="SMOOTHING_CURVE">
      <data key="d0">CURVE</data>
      <data key="d1">A smoothing curve is a non-parametric estimate of the mean of the residuals as a function of the fitted values
A smoothing curve is a function used in data analysis to smooth out fluctuations in data, often used in regression analysis to identify trends
A smoothing curve is a curve fitted to a set of data points to reveal underlying trends or patterns. It is often used in residual plots to help visualize the overall pattern of the residuals.
The smoothing curve is a curve fitted to the data in the residual plot, used to assess the constant variance assumption</data>
      <data key="d2">23fc620f1238c6a1b5c5e3a08e149c53,312309b45c59e1c84695ac3c7e202742,674b8d5bb1f830d0fb944942514d1a16,b9ec8a6c7960cc6196ec94fd976f05b0</data>
    </node>
    <node id="HORIZONTAL_LINE_AT_ZERO">
      <data key="d0">LINE</data>
      <data key="d1">A horizontal line at zero is the expected pattern of the smoothing curve if the model assumptions hold</data>
      <data key="d2">674b8d5bb1f830d0fb944942514d1a16</data>
    </node>
    <node id="WELL_FITTING_MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">A well-fitting model is a regression model that adequately describes the relationship between the explanatory variable and the response variable</data>
      <data key="d2">674b8d5bb1f830d0fb944942514d1a16</data>
    </node>
    <node id="UNACCEPTABLE_RESIDUAL_PLOTS">
      <data key="d0">PLOT</data>
      <data key="d1">Unacceptable residual plots are residual plots that indicate that the model assumptions do not hold</data>
      <data key="d2">674b8d5bb1f830d0fb944942514d1a16</data>
    </node>
    <node id="WESTERN_CEDAR_TREE_DATA">
      <data key="d0">DATA</data>
      <data key="d1">Western cedar tree data is a dataset that was considered in the last chapter and is used as an example of an unacceptable residual plot
Western cedar tree data is a dataset that was considered in the last chapter, used as an example in the context of residual plots
Western cedar tree data is an example where a transformation was applied to the explanatory variable</data>
      <data key="d2">15c7b5750483a382ce59751008e86751,674b8d5bb1f830d0fb944942514d1a16,b9ec8a6c7960cc6196ec94fd976f05b0</data>
    </node>
    <node id="CURVED_RELATIONSHIP">
      <data key="d0">CONCEPT</data>
      <data key="d1">A curved relationship is a non-linear relationship between the explanatory variable and the response variable</data>
      <data key="d2">674b8d5bb1f830d0fb944942514d1a16</data>
    </node>
    <node id="LINEARITY_ASSUMPTION">
      <data key="d0">ASSUMPTION</data>
      <data key="d1">The linearity assumption is an assumption in regression analysis that the relationship between the response and explanatory variables is linear
The linearity assumption is the assumption that the relationship between the response variable and the explanatory variable is linear
Linearity assumption is the condition that the relationship between the response and explanatory variables is linear in a statistical model
The assumption of linearity is a fundamental principle in regression analysis, stating that the relationship between the explanatory variables and the response variable is linear.</data>
      <data key="d2">0fbc9037ca9a440e79e9ac05664b9b3d,7347b44ffb25a066e43321f4eaf5a806,b9eb75001a4f68f7240b2ca9e0d79eb8,b9ec8a6c7960cc6196ec94fd976f05b0</data>
    </node>
    <node id="TRANSFORMATION">
      <data key="d0">FUNCTION</data>
      <data key="d1">A transformation is a mathematical operation applied to a variable to change its scale or distribution, often used to meet the assumptions of a statistical model
Transformation is a method applied to the response or explanatory variable to stabilize the variance or address non-linearity
Transformation is a technique used in regression analysis to address issues such as heteroscedasticity and to reduce the influence of unusual observations.</data>
      <data key="d2">0fbc9037ca9a440e79e9ac05664b9b3d,7347b44ffb25a066e43321f4eaf5a806,b9ec8a6c7960cc6196ec94fd976f05b0</data>
    </node>
    <node id="SQUARE_ROOT_TRANSFORM">
      <data key="d0">FUNCTION</data>
      <data key="d1">The square root transform is a transformation that takes the square root of a variable, often used when the variable is non-negative
Square root transform is a common transformation applied to non-negative explanatory variables to address non-linearity</data>
      <data key="d2">15c7b5750483a382ce59751008e86751,b9ec8a6c7960cc6196ec94fd976f05b0</data>
    </node>
    <node id="LOG_TRANSFORM">
      <data key="d0">FUNCTION</data>
      <data key="d1">The log transform is a transformation that takes the logarithm of a variable, often used when the variable is positive
Log-transform is a common transformation applied to positive explanatory variables to address non-linearity
The log-transform is a common non-linear transformation that can be applied to the response or explanatory variables. It can help meet the assumption of linearity, address heteroscedasticity, and reduce the influence of outliers.
Log-transform is a common transformation method that involves taking the logarithm of the response variable to stabilize variance and linearize relationships.
Log-transform is a mathematical operation often applied to response variables to stabilize variance and make the distribution more symmetrical
Log transformation is a common approach to reducing the positive skew of a distribution and thus reduce the influence of unusual observations</data>
      <data key="d2">0fbc9037ca9a440e79e9ac05664b9b3d,15c7b5750483a382ce59751008e86751,995fb26a0261f824952fa7b2fac3382e,b9ec8a6c7960cc6196ec94fd976f05b0,c03eb12d07d48f9e94260f08dae10cdf,f9d6c3504b8f8b5c25550076e45f8270</data>
    </node>
    <node id="MONOTONIC_NON_LINEAR">
      <data key="d0">CONCEPT</data>
      <data key="d1">Describes a relationship between variables that is consistently increasing or decreasing but not following a straight line</data>
      <data key="d2">15c7b5750483a382ce59751008e86751</data>
    </node>
    <node id="TRANSFORM">
      <data key="d0">METHOD</data>
      <data key="d1">Transformation is a remedial action applied to the explanatory variable to address non-linearity, such as square root or log-transform</data>
      <data key="d2">15c7b5750483a382ce59751008e86751</data>
    </node>
    <node id="NON_MONOTONIC_NON_LINEAR">
      <data key="d0">CONCEPT</data>
      <data key="d1">Describes a relationship between variables that is not consistently increasing or decreasing and not following a straight line</data>
      <data key="d2">15c7b5750483a382ce59751008e86751</data>
    </node>
    <node id="RESIDUAL_PLOT">
      <data key="d0">PLOT</data>
      <data key="d1">Residual plot is a graphical tool used to check the assumptions of a regression model, showing the difference between observed and predicted values
A residual plot is a graph that displays the residuals (differences between observed and predicted values) against the fitted values. It helps to identify patterns in the residuals.
A residual plot is a graphical representation of the differences between the observed values and the values predicted by the model
Residual plot is a graphical tool used to assess the fit of a statistical model by plotting the residuals against the fitted values
The residual plot is a graphical representation of the residuals, which are the differences between the observed and predicted values
Residual plot is a diagnostic tool used to assess the fit of a regression model by plotting the residuals against the fitted values
A residual plot is a graph that shows the residuals on the vertical axis and the independent variable on the horizontal axis. It is used to assess the fit of a model and to check for patterns that might indicate non-linearity or heteroscedasticity.</data>
      <data key="d2">15c7b5750483a382ce59751008e86751,312309b45c59e1c84695ac3c7e202742,521acf88540d5897188c9ec65b17e6a6,7347b44ffb25a066e43321f4eaf5a806,82cfcd5865cffe55e965a50745656e60,b9eb75001a4f68f7240b2ca9e0d79eb8,ef24ca5edd06893b737e6a1c8a9825f6</data>
    </node>
    <node id="VARIATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Variation describes the spread or dispersion of data points around a central value
Variation describes how the spread of the observations changes along the horizontal axis, often increasing as we move along it</data>
      <data key="d2">15c7b5750483a382ce59751008e86751,7347b44ffb25a066e43321f4eaf5a806</data>
    </node>
    <node id="HORIZONTAL_AXIS">
      <data key="d0">AXIS</data>
      <data key="d1">Horizontal axis is the x-axis in a scatterplot or residual plot, typically representing the explanatory variable</data>
      <data key="d2">15c7b5750483a382ce59751008e86751</data>
    </node>
    <node id="FIGURE_3_3">
      <data key="d0">FIGURE</data>
      <data key="d1">Figure 3.3 is a visual representation showing a scatterplot and residual plot of an example where the relationship between the response variable and the explanatory variable is non-monotonic and non-linear</data>
      <data key="d2">15c7b5750483a382ce59751008e86751</data>
    </node>
    <node id="NON_MONOTONIC_NON_LINEAR_RELATIONSHIP">
      <data key="d0">RELATIONSHIP_TYPE</data>
      <data key="d1">The relationship between the response variable and the explanatory variable is non-monotonic and non-linear, meaning it does not follow a consistent increasing or decreasing pattern.</data>
      <data key="d2">82cfcd5865cffe55e965a50745656e60</data>
    </node>
    <node id="QUADRATIC_REGRESSION_MODEL">
      <data key="d0">MODEL_TYPE</data>
      <data key="d1">A quadratic regression model is a statistical model that uses a quadratic function to fit the data. It is likely to work well when the relationship between variables is non-linear.</data>
      <data key="d2">82cfcd5865cffe55e965a50745656e60</data>
    </node>
    <node id="VARIANCE_INCREASING_WITH_FITTED_VALUES">
      <data key="d0">VARIANCE_PATTERN</data>
      <data key="d1">The variance of the residuals is increasing with the fitted values, which can be observed in the residual plot resembling a 'right-opening megaphone'.</data>
      <data key="d2">82cfcd5865cffe55e965a50745656e60</data>
    </node>
    <node id="TRANSFORM_RESPONSE_VARIABLE">
      <data key="d0">DATA_TRANSFORMATION</data>
      <data key="d1">Transforming the response variable is an approach to correct for increasing variance. Common transformations include taking the square-root or logarithm of the response variable.</data>
      <data key="d2">82cfcd5865cffe55e965a50745656e60</data>
    </node>
    <node id="VARIANCE">
      <data key="d0">STATISTICAL_MEASURE</data>
      <data key="d1">Variance is a measure of the spread or dispersion of a set of values
Variance is a statistical measure that describes the spread of data points around the mean. It is increasing with the mean in certain cases</data>
      <data key="d2">66f7fae9d896ff2b3fd40186cc833503,b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </node>
    <node id="SQUARE_ROOT_TRANSFORMATION">
      <data key="d0">TRANSFORMATION_METHOD</data>
      <data key="d1">Square root transformation is a method used to stabilize the variance of the response variable</data>
      <data key="d2">b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </node>
    <node id="LOGARITHM_TRANSFORMATION">
      <data key="d0">TRANSFORMATION_METHOD</data>
      <data key="d1">Logarithm transformation is a method used to stabilize the variance of the response variable, particularly when the response variable is positive</data>
      <data key="d2">b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </node>
    <node id="MEGAPHONE_SHAPE_RESIDUAL_PLOT">
      <data key="d0">PLOT_TYPE</data>
      <data key="d1">A megaphone shape residual plot is a common pattern in residual plots, indicating increasing variance with the explanatory variable</data>
      <data key="d2">b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </node>
    <node id="NON-LINEARITY">
      <data key="d0">STATISTICAL_TERM</data>
      <data key="d1">Non-linearity refers to the condition where the relationship between the response variable and the explanatory variable is not linear
Non-linearity is a condition where the relationship between the response and explanatory variables is not linear</data>
      <data key="d2">7347b44ffb25a066e43321f4eaf5a806,b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </node>
    <node id="TRANSFORMATION_OF_EXPLANATORY_VARIABLE">
      <data key="d0">TRANSFORMATION_METHOD</data>
      <data key="d1">Transformation of the explanatory variable is a method used to address non-linearity in the relationship between the response and explanatory variables</data>
      <data key="d2">b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </node>
    <node id="CURVE">
      <data key="d0">SHAPE</data>
      <data key="d1">Curve refers to a non-linear relationship between the response and explanatory variables, as opposed to a straight line</data>
      <data key="d2">7347b44ffb25a066e43321f4eaf5a806</data>
    </node>
    <node id="REMEDIAL_ACTION">
      <data key="d0">ACTION</data>
      <data key="d1">Remedial action is a step taken to address issues in a statistical model, such as non-linearity or heteroscedasticity
Remedial action refers to the steps taken when a model assumption is violated. This can include transformations of variables, using a different model, or collecting more data.</data>
      <data key="d2">7347b44ffb25a066e43321f4eaf5a806,c03eb12d07d48f9e94260f08dae10cdf</data>
    </node>
    <node id="RANDOM_VARIATION">
      <data key="d0">STATISTICAL_VARIATION</data>
      <data key="d1">Random variation is the natural fluctuation in data that is not systematic and cannot be explained by the model</data>
      <data key="d2">7347b44ffb25a066e43321f4eaf5a806</data>
    </node>
    <node id="COURSEWORK">
      <data key="d0">ACADEMIC_WORK</data>
      <data key="d1">Coursework refers to the assignments or projects given to students as part of their academic program</data>
      <data key="d2">7347b44ffb25a066e43321f4eaf5a806</data>
    </node>
    <node id="ACCEPTABILITY">
      <data key="d0">CRITERION</data>
      <data key="d1">Acceptability is a standard used to judge whether a statistical model or its residual plot meets the necessary criteria for validity</data>
      <data key="d2">7347b44ffb25a066e43321f4eaf5a806</data>
    </node>
    <node id="ACCEPTABLE_RESIDUAL_PLOTS">
      <data key="d0">PLOTS</data>
      <data key="d1">Acceptable residual plots are those that do not show any systematic patterns, suggesting that the model assumptions are met. They typically exhibit a random scatter of points around the horizontal line at zero, indicating no bias in the residuals and constant variance.</data>
      <data key="d2">23fc620f1238c6a1b5c5e3a08e149c53</data>
    </node>
    <node id="REMEDIAL_ACTIONS">
      <data key="d0">ACTIONS</data>
      <data key="d1">Remedial actions are steps taken to address issues identified in residual plots that indicate violations of model assumptions. These can include transformations of the data, adding or removing variables, or using a different model.
Remedial actions are steps taken to address violations of the modelling assumptions</data>
      <data key="d2">23fc620f1238c6a1b5c5e3a08e149c53,e361ac139c268d5c3f3623f920e68af2</data>
    </node>
    <node id="SIMULATED_DATA">
      <data key="d0">DATA</data>
      <data key="d1">Simulated data are artificial data sets created to test statistical methods or models. They are often used to verify that a model or method works as expected under known conditions.
Simulated data is data that has been artificially generated to test the regression model</data>
      <data key="d2">23fc620f1238c6a1b5c5e3a08e149c53,312309b45c59e1c84695ac3c7e202742</data>
    </node>
    <node id="LINEAR_REGRESSION_MODELS">
      <data key="d0">MODELS</data>
      <data key="d1">Linear regression models are statistical models used to analyze the relationship between one or more independent variables and a dependent variable. They assume a linear relationship between the variables and are used to predict the dependent variable based on the independent variables.</data>
      <data key="d2">23fc620f1238c6a1b5c5e3a08e149c53</data>
    </node>
    <node id="LINEAR_MODEL_ASSUMPTIONS">
      <data key="d0">ASSUMPTIONS</data>
      <data key="d1">Linear model assumptions are the conditions that need to be met for linear regression models to provide valid and reliable results. These include assumptions of linearity, independence, homoscedasticity (constant variance), and normality of residuals.</data>
      <data key="d2">23fc620f1238c6a1b5c5e3a08e149c53</data>
    </node>
    <node id="CONSTANT_VARIANCE_ASSUMPTION">
      <data key="d0">ASSUMPTION</data>
      <data key="d1">The constant variance assumption, also known as homoscedasticity, is one of the assumptions of linear regression models. It states that the variance of the residuals should be constant across all levels of the independent variables.</data>
      <data key="d2">23fc620f1238c6a1b5c5e3a08e149c53</data>
    </node>
    <node id="DISTRIBUTION">
      <data key="d0">DISTRIBUTION</data>
      <data key="d1">The distribution refers to the statistical distribution of the data, which can be skewed or normal
The distribution on p and n - p degrees of freedom is used to identify influential observations in a dataset</data>
      <data key="d2">312309b45c59e1c84695ac3c7e202742,323899f01972255cd3278bccee20d5d8</data>
    </node>
    <node id="VARIANCE_ASSUMPTION">
      <data key="d0">VARIANCE_ASSUMPTION</data>
      <data key="d1">The constant variance assumption is one of the assumptions of the regression model, which states that the variance of the residuals is constant across the range of the predictor variable</data>
      <data key="d2">312309b45c59e1c84695ac3c7e202742</data>
    </node>
    <node id="PREDICTOR_VARIABLE">
      <data key="d0">PREDICTOR_VARIABLE</data>
      <data key="d1">The predictor variable is the variable used to predict the response variable</data>
      <data key="d2">312309b45c59e1c84695ac3c7e202742</data>
    </node>
    <node id="STATISTICAL_INFERENCE">
      <data key="d0">ANALYSIS_METHOD</data>
      <data key="d1">Statistical inference is a method used to draw conclusions about a population based on sample data
Statistical inference is the process of using data analysis to infer properties of an underlying distribution of probability. It is used to make conclusions about the population from which the data was drawn.</data>
      <data key="d2">521acf88540d5897188c9ec65b17e6a6,ef24ca5edd06893b737e6a1c8a9825f6</data>
    </node>
    <node id="ROBUSTNESS">
      <data key="d0">PROPERTY</data>
      <data key="d1">Robustness is a property of statistical inference that it is not greatly affected by departures from the normality assumption, especially for large sample sizes</data>
      <data key="d2">ef24ca5edd06893b737e6a1c8a9825f6</data>
    </node>
    <node id="SAMPLE_SIZE">
      <data key="d0">QUANTITY</data>
      <data key="d1">Sample size (n) is the number of observations in the sample used for regression analysis</data>
      <data key="d2">ef24ca5edd06893b737e6a1c8a9825f6</data>
    </node>
    <node id="REPEATED_VALUES">
      <data key="d0">DATA</data>
      <data key="d1">Repeated values of the explanatory variable refer to instances where the same value of the explanatory variable occurs more than once in the dataset.</data>
      <data key="d2">521acf88540d5897188c9ec65b17e6a6</data>
    </node>
    <node id="ASSESSING_NORMALITY">
      <data key="d0">STATISTICAL_METHOD</data>
      <data key="d1">Assessing normality involves checking whether the data or the errors in a statistical model are normally distributed. This is important for the validity of certain statistical tests and inferences.</data>
      <data key="d2">521acf88540d5897188c9ec65b17e6a6</data>
    </node>
    <node id="NORMALITY_ASSUMPTION">
      <data key="d0">ASSUMPTION</data>
      <data key="d1">The normality assumption is the hypothesis that the errors in a statistical model are normally distributed. This is a common assumption in many statistical methods, particularly in regression analysis.</data>
      <data key="d2">521acf88540d5897188c9ec65b17e6a6</data>
    </node>
    <node id="NORMAL_Q_Q_PLOT">
      <data key="d0">PLOT</data>
      <data key="d1">A normal Quantile-Quantile (Q-Q) plot is a graphical technique for determining if two data sets come from populations with a common distribution. In this context, it is used to assess the normality of the data or errors.
Normal Q-Q plot is a graphical technique for determining if a data set is approximately normally distributed. It is a plot of the observed values against the expected values under the assumption of normality.</data>
      <data key="d2">521acf88540d5897188c9ec65b17e6a6,eafa2cc6cc64d8bca1c080bdd2ad7654</data>
    </node>
    <node id="LARGE_SAMPLE_SIZES">
      <data key="d0">DATA</data>
      <data key="d1">Large sample sizes refer to datasets with a large number of observations. In statistical analysis, larger sample sizes can make certain assumptions, such as normality, less critical.</data>
      <data key="d2">521acf88540d5897188c9ec65b17e6a6</data>
    </node>
    <node id="DEPARTURES_FROM_NORMALITY">
      <data key="d0">DATA</data>
      <data key="d1">Departures from normality refer to situations where the distribution of the data or errors deviates from a normal distribution. This can affect the validity of statistical inferences and tests.</data>
      <data key="d2">521acf88540d5897188c9ec65b17e6a6</data>
    </node>
    <node id="PERCENTAGE_SCALE">
      <data key="d0">SCALE</data>
      <data key="d1">Percentage scale is a type of scale used for representing data, often in the context of statistical analysis and plotting.</data>
      <data key="d2">eafa2cc6cc64d8bca1c080bdd2ad7654</data>
    </node>
    <node id="NORMAL_SCORE_SCALE">
      <data key="d0">SCALE</data>
      <data key="d1">Normal score scale is a scale used for representing data in terms of their normal distribution, often used in the vertical axis of plots.</data>
      <data key="d2">eafa2cc6cc64d8bca1c080bdd2ad7654</data>
    </node>
    <node id="NORMAL_DISTRIBUTION">
      <data key="d0">DISTRIBUTION</data>
      <data key="d1">Normal distribution, also known as the Gaussian distribution, is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean.
Normal distribution is a probability distribution used to simulate the data points
The normal distribution is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean. In a normal distribution, 68% of the data fall within one standard deviation of the mean, 95% within two standard deviations, and 99.7% within three standard deviations. It is often referred to as the bell curve.
A normal distribution, also known as a Gaussian distribution, is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean. It is often used to model real-world phenomena.</data>
      <data key="d2">3bfc9b92571973e54c8095302acc1aaa,d7f3a28534ffe830fe6f4cef8c41a9b4,eafa2cc6cc64d8bca1c080bdd2ad7654,ee22e1f5947947f9bd3f7f8922745e48</data>
    </node>
    <node id="STANDARDISED_RESIDUALS">
      <data key="d0">RESIDUALS</data>
      <data key="d1">Standardised residuals are residuals that have been scaled by dividing by an estimate of their standard deviation. They are used in statistical analysis to assess the fit of a model.
Standardised residuals are residuals that have been scaled to have a mean of 0 and a standard deviation of 1
Standardised residuals are the residuals from a regression analysis that have been scaled to have unit variance
Standardised residuals are residuals that have been scaled by dividing by their estimated standard deviation, providing a measure of the size of the residual relative to the variability of the residuals</data>
      <data key="d2">428db872e71a17a2cf7868b03a52def0,629ce6550294d332948e19171a4acd2d,e361ac139c268d5c3f3623f920e68af2,eafa2cc6cc64d8bca1c080bdd2ad7654</data>
    </node>
    <node id="FITTED_MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">Fitted model is a statistical model that has been estimated or fit to a set of data. It represents the relationship between the variables in the data.
The fitted model is the statistical model that is estimated from the data, potentially affected by influential data points</data>
      <data key="d2">83bb91cf725e5116ca2f5748fddccfae,eafa2cc6cc64d8bca1c080bdd2ad7654</data>
    </node>
    <node id="FIGURE_3_9">
      <data key="d0">FIGURE</data>
      <data key="d1">Figure 3.9 is a graphical representation showing two Normal Q-Q plots. The left plot shows data from a standard normal distribution, while the right plot shows data from a t-distribution on 2 degrees of freedom.</data>
      <data key="d2">eafa2cc6cc64d8bca1c080bdd2ad7654</data>
    </node>
    <node id="T_DISTRIBUTION">
      <data key="d0">DISTRIBUTION</data>
      <data key="d1">T-distribution, also known as Student's t-distribution, is a probability distribution that arises in the estimation of the mean of a normally distributed population in situations where the sample size is small and the population standard deviation is unknown.
The t-distribution, also known as Student's t-distribution, is a probability distribution that is used to estimate population parameters when the sample size is small and/or when the population variance is unknown. It is similar to the normal distribution but has heavier tails, meaning it is more prone to producing values that are far from its mean.</data>
      <data key="d2">3bfc9b92571973e54c8095302acc1aaa,eafa2cc6cc64d8bca1c080bdd2ad7654</data>
    </node>
    <node id="T2_DISTRIBUTION">
      <data key="d0">DISTRIBUTION</data>
      <data key="d1">T2 distribution is a probability distribution with 2 degrees of freedom, used to simulate data points</data>
      <data key="d2">ee22e1f5947947f9bd3f7f8922745e48</data>
    </node>
    <node id="Q_Q_PLOT">
      <data key="d0">PLOT</data>
      <data key="d1">Q-Q plot is a graphical method for comparing two probability distributions by plotting their quantiles against each other
A Q-Q (Quantile-Quantile) plot is a graphical method for testing whether a dataset follows a given distribution. It plots the quantiles of the first data set against the quantiles of the second data set. If the two sets come from a common distribution, the points should fall approximately along the line y = x. Deviations from this straight line indicate departures from the hypothesized distribution.</data>
      <data key="d2">3bfc9b92571973e54c8095302acc1aaa,ee22e1f5947947f9bd3f7f8922745e48</data>
    </node>
    <node id="REFERENCE_LINE">
      <data key="d0">LINE</data>
      <data key="d1">Reference line is a line on the Q-Q plot that represents the expected quantiles of the theoretical distribution</data>
      <data key="d2">ee22e1f5947947f9bd3f7f8922745e48</data>
    </node>
    <node id="SAMPLE_QUANTILES">
      <data key="d0">QUANTILES</data>
      <data key="d1">Sample quantiles are the observed quantiles of the data, used in the Q-Q plot to compare with the theoretical quantiles</data>
      <data key="d2">ee22e1f5947947f9bd3f7f8922745e48</data>
    </node>
    <node id="LEFT_TAIL">
      <data key="d0">REGION</data>
      <data key="d1">Left tail is the lower end of the distribution, where the sample quantiles are smaller than expected under a normal distribution</data>
      <data key="d2">ee22e1f5947947f9bd3f7f8922745e48</data>
    </node>
    <node id="RIGHT_TAIL">
      <data key="d0">REGION</data>
      <data key="d1">Right tail is the upper end of the distribution, where the sample quantiles are larger than expected under a normal distribution</data>
      <data key="d2">ee22e1f5947947f9bd3f7f8922745e48</data>
    </node>
    <node id="STANDARD_NORMAL_DENSITY">
      <data key="d0">DENSITY</data>
      <data key="d1">Standard normal density is the density function of the standard normal distribution</data>
      <data key="d2">ee22e1f5947947f9bd3f7f8922745e48</data>
    </node>
    <node id="T2_DENSITY">
      <data key="d0">DENSITY</data>
      <data key="d1">T2 density is the density function of the t2 distribution</data>
      <data key="d2">ee22e1f5947947f9bd3f7f8922745e48</data>
    </node>
    <node id="MORE_COMPLEX_MODELS">
      <data key="d0">ACTION</data>
      <data key="d1">Using more complex models is another remedial action that can be taken to address violations of the modelling assumptions</data>
      <data key="d2">e361ac139c268d5c3f3623f920e68af2</data>
    </node>
    <node id="DIAGNOSIS">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Diagnosis refers to the process of checking whether the model assumptions are met. This involves analyzing residuals, checking for patterns, and using diagnostic plots.</data>
      <data key="d2">c03eb12d07d48f9e94260f08dae10cdf</data>
    </node>
    <node id="TEXTBOOKS">
      <data key="d0">RESOURCE</data>
      <data key="d1">Textbooks are educational resources that provide in-depth information on various topics. The recommended textbooks for this module include "A Modern Approach to Regression with R" by Sheather and "Generalized linear models with examples in R" by Dunn and Smyth.</data>
      <data key="d2">c03eb12d07d48f9e94260f08dae10cdf</data>
    </node>
    <node id="EPSILON_I">
      <data key="d0">ERROR_TERM</data>
      <data key="d1">Epsilon_i (&#1013;i) is the error term in the model, representing the deviation of the observed log-transformed response from the expected value.
Epsilon_i is the error term for the ith observation in the regression model</data>
      <data key="d2">0fbc9037ca9a440e79e9ac05664b9b3d,90b7e0427699cc1bb461e37939935138</data>
    </node>
    <node id="EXP">
      <data key="d0">FUNCTION</data>
      <data key="d1">Exp is the exponential function used to transform the log-transformed response back to its original scale.</data>
      <data key="d2">0fbc9037ca9a440e79e9ac05664b9b3d</data>
    </node>
    <node id="MULTIPLICATIVE_ERRORS">
      <data key="d0">ERRORS</data>
      <data key="d1">Multiplicative errors are the errors in the original scale of the response variable, which act multiplicatively rather than additively.</data>
      <data key="d2">0fbc9037ca9a440e79e9ac05664b9b3d</data>
    </node>
    <node id="XI1">
      <data key="d0">PREDICTOR</data>
      <data key="d1">xi1 is the first predictor variable in the model</data>
      <data key="d2">34fceaaf7d835828b5ee2327325c37f8</data>
    </node>
    <node id="XI2">
      <data key="d0">PREDICTOR</data>
      <data key="d1">xi2 is the second predictor variable in the model</data>
      <data key="d2">34fceaaf7d835828b5ee2327325c37f8</data>
    </node>
    <node id="E">
      <data key="d0">EXPECTATION</data>
      <data key="d1">E denotes the expectation operator, used to calculate the expected value of a random variable
e is the base of the natural logarithm, used in the exponential function to transform the error term &#1013;i.
E is the expectation operator, used to calculate the expected value of a random variable</data>
      <data key="d2">1da117a2f92b2db00290d2a0bfc06beb,34fceaaf7d835828b5ee2327325c37f8,60cc94e681863c9fcc6f9be1e500f840</data>
    </node>
    <node id="LOG">
      <data key="d0">FUNCTION</data>
      <data key="d1">log is the natural logarithm function, used to transform the response variable in the model
Logarithmic function is used in the model to transform the average body weight
Logarithmic function used in the calculation of the likelihood function</data>
      <data key="d2">34fceaaf7d835828b5ee2327325c37f8,e7edd8b2874a350779ae20f1ecdf4733,efeeb664622c1ee594e6a08a8322ffe3</data>
    </node>
    <node id="ZB0">
      <data key="d0">PREDICTION</data>
      <data key="d1">zb0 is the prediction for the logged response from the model</data>
      <data key="d2">34fceaaf7d835828b5ee2327325c37f8</data>
    </node>
    <node id="M">
      <data key="d0">MEAN</data>
      <data key="d1">&#181; (mu) is the mean of the normal distribution of log(Y)</data>
      <data key="d2">34fceaaf7d835828b5ee2327325c37f8</data>
    </node>
    <node id="LOG_Y">
      <data key="d0">TRANSFORMED_RANDOM_VARIABLE</data>
      <data key="d1">log(Y) is the natural logarithm of Y, which follows a normal distribution with mean &#181; and variance &#963;^2</data>
      <data key="d2">21e429490eeefe7d9c245058fd48ca68</data>
    </node>
    <node id="LOGNORMAL_DISTRIBUTION">
      <data key="d0">DISTRIBUTION</data>
      <data key="d1">Lognormal(&#181;, &#963;^2) is the lognormal distribution that Y follows, characterized by parameters &#181; and &#963;^2</data>
      <data key="d2">21e429490eeefe7d9c245058fd48ca68</data>
    </node>
    <node id="GEOMETRIC_MEAN_Y">
      <data key="d0">STATISTIC</data>
      <data key="d1">The geometric mean of Y is equal to exp[E(log(Y))], which is also the median of Y when Y is lognormally distributed</data>
      <data key="d2">21e429490eeefe7d9c245058fd48ca68</data>
    </node>
    <node id="YA">
      <data key="d0">PREDICTED_VALUE</data>
      <data key="d1">YA is the back-transformed prediction for Y before the change in X1
YA is the predicted response in the original scale before the increase in X1</data>
      <data key="d2">21e429490eeefe7d9c245058fd48ca68,995fb26a0261f824952fa7b2fac3382e</data>
    </node>
    <node id="POSITIVE_MEASUREMENTS">
      <data key="d0">VARIABLE_TYPE</data>
      <data key="d1">Positive physical measurements like weights or lengths are variables that are often log-transformed</data>
      <data key="d2">995fb26a0261f824952fa7b2fac3382e</data>
    </node>
    <node id="PRECISION_OF_MEASUREMENT">
      <data key="d0">MEASUREMENT</data>
      <data key="d1">The precision of measurement is higher for smaller observations, indicating that the accuracy of measurement is better for lower values</data>
      <data key="d2">66f7fae9d896ff2b3fd40186cc833503</data>
    </node>
    <node id="RIGHT_SKEWED_DISTRIBUTION">
      <data key="d0">DISTRIBUTION</data>
      <data key="d1">A right skewed distribution is a type of distribution where the tail is longer on the right side, indicating that most of the data is concentrated on the left side</data>
      <data key="d2">66f7fae9d896ff2b3fd40186cc833503</data>
    </node>
    <node id="POSITIVE_RESPONSE_VARIABLE">
      <data key="d0">VARIABLE</data>
      <data key="d1">A positive response variable is a variable in a statistical model that only takes positive values</data>
      <data key="d2">66f7fae9d896ff2b3fd40186cc833503</data>
    </node>
    <node id="BODY_WEIGHT">
      <data key="d0">WEIGHT</data>
      <data key="d1">Body weight is the weight of the body, measured in kilograms for the mammals dataset
Body weight is a variable in the mammals data, representing the weight of the animals. It is observed that the distribution of the log-transformed body weight is much less skewed than the original distribution.&gt;</data>
      <data key="d2">66f7fae9d896ff2b3fd40186cc833503,e2422d8b80004aab4ea74d5209587861</data>
    </node>
    <node id="BRAIN_WEIGHT">
      <data key="d0">WEIGHT</data>
      <data key="d1">Brain weight is the weight of the brain, measured in grams for the mammals dataset
Brain weight is a variable in the mammals data, representing the weight of the animals' brains. The relationship between body weight and brain weight is non-linear, and a transformation may help improve linearity.&gt;
Brain weight is the dependent variable in the model, predicted based on the average body weight</data>
      <data key="d2">66f7fae9d896ff2b3fd40186cc833503,e2422d8b80004aab4ea74d5209587861,efeeb664622c1ee594e6a08a8322ffe3</data>
    </node>
    <node id="AFRICAN_ELEPHANT">
      <data key="d0">SPECIES</data>
      <data key="d1">The African elephant is a species of elephant with an unusually high average body weight and average brain weight
The African elephant is a mammal species with an unusually high average body weight and brain weight</data>
      <data key="d2">66f7fae9d896ff2b3fd40186cc833503,f9d6c3504b8f8b5c25550076e45f8270</data>
    </node>
    <node id="ASIAN_ELEPHANT">
      <data key="d0">SPECIES</data>
      <data key="d1">The Asian elephant is a species of elephant with an unusually high average body weight and average brain weight
The Asian elephant is a mammal species with an unusually high average body weight and brain weight</data>
      <data key="d2">66f7fae9d896ff2b3fd40186cc833503,f9d6c3504b8f8b5c25550076e45f8270</data>
    </node>
    <node id="HUMAN">
      <data key="d0">SPECIES</data>
      <data key="d1">The human is a species with an average body weight that stands out in the mammals dataset
The human is a mammal species with an average body weight but an unusually high average brain weight relative to the average body weight
Human is a species of animal that is flagged as an influential observation in the mammals dataset</data>
      <data key="d2">428db872e71a17a2cf7868b03a52def0,66f7fae9d896ff2b3fd40186cc833503,f9d6c3504b8f8b5c25550076e45f8270</data>
    </node>
    <node id="BRAIN">
      <data key="d0">VARIABLE</data>
      <data key="d1">Brain weight is one of the variables in the mammals dataset, representing the weight of the brain of different mammal species</data>
      <data key="d2">f9d6c3504b8f8b5c25550076e45f8270</data>
    </node>
    <node id="BODY">
      <data key="d0">VARIABLE</data>
      <data key="d1">Body weight is another variable in the mammals dataset, representing the weight of the body of different mammal species</data>
      <data key="d2">f9d6c3504b8f8b5c25550076e45f8270</data>
    </node>
    <node id="FIGURE_4_1">
      <data key="d0">FIGURE</data>
      <data key="d1">Figure 4.1 is a scatterplot of the mammals dataset, showing the relationship between brain weight and body weight</data>
      <data key="d2">f9d6c3504b8f8b5c25550076e45f8270</data>
    </node>
    <node id="FIGURE_4_2">
      <data key="d0">FIGURE</data>
      <data key="d1">Figure 4.2 is a comparison of the histogram of body weight and the histogram of log(body weight) for the mammals data, showing that the distribution of the log-transformed variable is much less skewed</data>
      <data key="d2">f9d6c3504b8f8b5c25550076e45f8270</data>
    </node>
    <node id="LOG_BODY_WEIGHT">
      <data key="d0">TRANSFORMED_VARIABLE</data>
      <data key="d1">Log(body weight) is the logarithmically transformed version of the body weight variable. The distribution of log(body weight) is much less skewed than the original body weight distribution.&gt;
Log body weight is the logarithm of the average body weight of mammals
Logarithm of average body weight is the independent variable in the regression model
Logarithm of average body weight is a transformed variable used as the predictor variable in the regression analysis.&gt;</data>
      <data key="d2">9e2ebbb113c00fa43f0af3c0696baf95,bd05fe6a05f9a13d33c4f1b5a771ada5,c47968226557bc2eb5aec5bb7994fd0e,e2422d8b80004aab4ea74d5209587861</data>
    </node>
    <node id="LOG_BRAIN_WEIGHT">
      <data key="d0">TRANSFORMED_VARIABLE</data>
      <data key="d1">Log(brain weight) is the logarithmically transformed version of the brain weight variable. The scatterplot of log(brain weight) against log(body weight) shows improved linearity.&gt;
Log brain weight is the logarithm of the average brain weight of mammals
Logarithm of average brain weight is the dependent variable in the regression model
Logarithm of average brain weight is a transformed variable used as the response variable in the regression analysis.&gt;</data>
      <data key="d2">9e2ebbb113c00fa43f0af3c0696baf95,bd05fe6a05f9a13d33c4f1b5a771ada5,c47968226557bc2eb5aec5bb7994fd0e,e2422d8b80004aab4ea74d5209587861</data>
    </node>
    <node id="BRAINI">
      <data key="d0">VARIABLE</data>
      <data key="d1">BRAINi represents the brain weight of the ith species in the dataset</data>
      <data key="d2">86c401dda130c2d201c3339526062a24</data>
    </node>
    <node id="BODYI">
      <data key="d0">VARIABLE</data>
      <data key="d1">BODYi represents the body weight of the ith species in the dataset</data>
      <data key="d2">86c401dda130c2d201c3339526062a24</data>
    </node>
    <node id="LOG_BRAINI">
      <data key="d0">TRANSFORMED_VARIABLE</data>
      <data key="d1">LOG_BRAINi is the logarithm of the brain weight of the ith species</data>
      <data key="d2">86c401dda130c2d201c3339526062a24</data>
    </node>
    <node id="LOG_BODYI">
      <data key="d0">TRANSFORMED_VARIABLE</data>
      <data key="d1">LOG_BODYi is the logarithm of the body weight of the ith species</data>
      <data key="d2">86c401dda130c2d201c3339526062a24</data>
    </node>
    <node id="BETA_HAT1">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">BETA_HAT1 is the estimated value of the slope coefficient Beta1, calculated as 0.75
Beta hat 1 (b&#946;1) is the estimator of the parameter Beta1, calculated using the maximum likelihood estimation method</data>
      <data key="d2">09caa54ca1372d152e47051be4d44ede,86c401dda130c2d201c3339526062a24</data>
    </node>
    <node id="YBA">
      <data key="d0">PREDICTED_VALUE</data>
      <data key="d1">YbA is the predicted average brain weight for species A with average body weight x</data>
      <data key="d2">86c401dda130c2d201c3339526062a24</data>
    </node>
    <node id="YBB">
      <data key="d0">PREDICTED_VALUE</data>
      <data key="d1">YbB is the predicted average brain weight for species B with average body weight 1.1x</data>
      <data key="d2">86c401dda130c2d201c3339526062a24</data>
    </node>
    <node id="AVERAGE_BODY_WEIGHT">
      <data key="d0">MEASUREMENT</data>
      <data key="d1">Average body weight is the independent variable in the model, used to predict the brain weight</data>
      <data key="d2">efeeb664622c1ee594e6a08a8322ffe3</data>
    </node>
    <node id="GIRTH">
      <data key="d0">MEASUREMENT</data>
      <data key="d1">Girth is a variable in the trees dataset, measured as the diameter of the tree in inches</data>
      <data key="d2">efeeb664622c1ee594e6a08a8322ffe3</data>
    </node>
    <node id="VOLUME">
      <data key="d0">MEASUREMENT</data>
      <data key="d1">Volume is a variable in the trees dataset, representing the volume of timber in cubic feet
Volume is the quantity of timber that the tree produced, measured in cubic feet</data>
      <data key="d2">9611ea31ff53888971694cdefe806f64,efeeb664622c1ee594e6a08a8322ffe3</data>
    </node>
    <node id="TREE">
      <data key="d0">PLANT</data>
      <data key="d1">The tree is the subject of the study, measured at 4 ft 6 inches from the ground, with its diameter (wrongly labelled as girth) and height recorded</data>
      <data key="d2">9611ea31ff53888971694cdefe806f64</data>
    </node>
    <node id="VOLUMEI">
      <data key="d0">VARIABLE</data>
      <data key="d1">Volumei is the dependent variable in the model, representing the volume of a tree, calculated as exp(&#946;0) * Diameter&#946;1 * Height&#946;2 * exp(e &#1013;i).</data>
      <data key="d2">60cc94e681863c9fcc6f9be1e500f840</data>
    </node>
    <node id="DIAMETERI">
      <data key="d0">VARIABLE</data>
      <data key="d1">Di is the diameter of the tree, an independent variable in the model, raised to the power of &#946;1.</data>
      <data key="d2">60cc94e681863c9fcc6f9be1e500f840</data>
    </node>
    <node id="HEIGHTI">
      <data key="d0">VARIABLE</data>
      <data key="d1">Heighti is the height of the tree, an independent variable in the model, raised to the power of &#946;2.</data>
      <data key="d2">60cc94e681863c9fcc6f9be1e500f840</data>
    </node>
    <node id="&#917;I">
      <data key="d0">ERROR_TERM</data>
      <data key="d1">&#1013;i is the error term in the model, representing the deviation of the observed volume from the expected volume.</data>
      <data key="d2">60cc94e681863c9fcc6f9be1e500f840</data>
    </node>
    <node id="SCATTERPLOT_MATRIX">
      <data key="d0">PLOT</data>
      <data key="d1">Scatterplot matrix is a graphical representation of the pairwise scatterplots of the variables, including histograms of the variables, used for initial exploratory analysis.</data>
      <data key="d2">60cc94e681863c9fcc6f9be1e500f840</data>
    </node>
    <node id="FIGURE_4_5">
      <data key="d0">PLOT</data>
      <data key="d1">Figure 4.5 is a plot of residuals versus fitted values for the linear model fitted to the log-transformed tree data</data>
      <data key="d2">a60af43e42c72a41fa90da06beb29d1b</data>
    </node>
    <node id="LOG_TRANSFORMED_TREE_DATA">
      <data key="d0">DATA</data>
      <data key="d1">Log-transformed tree data is the dataset used in the regression analysis, where the dependent and independent variables have been log-transformed</data>
      <data key="d2">a60af43e42c72a41fa90da06beb29d1b</data>
    </node>
    <node id="FIGURE_4_6">
      <data key="d0">PLOT</data>
      <data key="d1">Figure 4.6 is a plot of residuals versus log-height and versus log-diameter for the model fitted to the log-transformed tree data</data>
      <data key="d2">a60af43e42c72a41fa90da06beb29d1b</data>
    </node>
    <node id="LOGTREES">
      <data key="d0">DATA_FRAME</data>
      <data key="d1">LogTrees is a data frame consisting of the log-transformed tree data
logTrees is a data frame consisting of log-transformed tree data</data>
      <data key="d2">9a28a6420fca4405488ca35762f9dc28,a60af43e42c72a41fa90da06beb29d1b</data>
    </node>
    <node id="TREES_MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">Trees.model is the linear model fitted to the log-transformed tree data using the lm() function in R</data>
      <data key="d2">a60af43e42c72a41fa90da06beb29d1b</data>
    </node>
    <node id="LOG_DIAMETER">
      <data key="d0">PARAMETER</data>
      <data key="d1">Log-diameter is the log-transformed diameter of the tree, used as an independent variable in the regression model
Log-diameter is an independent variable in the regression model, representing the logarithm of the diameter of trees</data>
      <data key="d2">a60af43e42c72a41fa90da06beb29d1b,d71b402ab9edbb4347e09c7af3257cf5</data>
    </node>
    <node id="LOG_HEIGHT">
      <data key="d0">PARAMETER</data>
      <data key="d1">Log-height is the log-transformed height of the tree, used as an independent variable in the regression model
Log-height is an independent variable in the regression model, representing the logarithm of the height of trees</data>
      <data key="d2">a60af43e42c72a41fa90da06beb29d1b,d71b402ab9edbb4347e09c7af3257cf5</data>
    </node>
    <node id="TREES.MODEL">
      <data key="d0">LINEAR_MODEL</data>
      <data key="d1">trees.model is a linear model that regresses logVolume on logDiameter and logHeight using the logTrees data frame</data>
      <data key="d2">9a28a6420fca4405488ca35762f9dc28</data>
    </node>
    <node id="(INTERCEPT)">
      <data key="d0">INTERCEPT</data>
      <data key="d1">(Intercept) is the intercept coefficient in the linear model</data>
      <data key="d2">9a28a6420fca4405488ca35762f9dc28</data>
    </node>
    <node id="LOGDIAMETER">
      <data key="d0">PREDICTOR</data>
      <data key="d1">logDiameter is a predictor variable in the linear model, representing the log-transformed diameter of the tree</data>
      <data key="d2">9a28a6420fca4405488ca35762f9dc28</data>
    </node>
    <node id="LOGHEIGHT">
      <data key="d0">PREDICTOR</data>
      <data key="d1">logHeight is a predictor variable in the linear model, representing the log-transformed height of the tree</data>
      <data key="d2">9a28a6420fca4405488ca35762f9dc28</data>
    </node>
    <node id="LOGVOLUME">
      <data key="d0">RESPONSE</data>
      <data key="d1">logVolume is the response variable in the linear model, representing the log-transformed volume of the tree</data>
      <data key="d2">9a28a6420fca4405488ca35762f9dc28</data>
    </node>
    <node id="LOG_VOLUME">
      <data key="d0">DEPENDENT_VARIABLE</data>
      <data key="d1">Log-volume is the dependent variable in the regression model, representing the logarithm of the volume of trees</data>
      <data key="d2">d71b402ab9edbb4347e09c7af3257cf5</data>
    </node>
    <node id="COEFFICIENT_LOG_DIAMETER">
      <data key="d0">REGRESSION_COEFFICIENT</data>
      <data key="d1">The coefficient for log-diameter in the regression model represents the change in log-volume associated with a one-unit change in log-diameter</data>
      <data key="d2">d71b402ab9edbb4347e09c7af3257cf5</data>
    </node>
    <node id="INTERCEPT_CYLINDER">
      <data key="d0">REGRESSION_INTERCEPT</data>
      <data key="d1">The intercept for the regression when the shape of a tree is approximated by a cylinder represents the expected log-volume when log-diameter and log-height are zero</data>
      <data key="d2">d71b402ab9edbb4347e09c7af3257cf5</data>
    </node>
    <node id="INTERCEPT_CONE">
      <data key="d0">REGRESSION_INTERCEPT</data>
      <data key="d1">The intercept for the regression when the shape of a tree is approximated by a cone represents the expected log-volume when log-diameter and log-height are zero</data>
      <data key="d2">d71b402ab9edbb4347e09c7af3257cf5</data>
    </node>
    <node id="ESTIMATED_INTERCEPT">
      <data key="d0">REGRESSION_INTERCEPT</data>
      <data key="d1">The estimated intercept in the regression model of log-volume on log-diameter and log-height represents the expected log-volume when log-diameter and log-height are zero</data>
      <data key="d2">d71b402ab9edbb4347e09c7af3257cf5</data>
    </node>
    <node id="DUNN_AND_SMYTH_BOOK">
      <data key="d0">REFERENCE_MATERIAL</data>
      <data key="d1">Generalized linear models with examples in R (2018) by Dunn and Smyth is a reference book that discusses the regression problem presented</data>
      <data key="d2">d71b402ab9edbb4347e09c7af3257cf5</data>
    </node>
    <node id="LOG_TRANSFORMED_VARIABLES">
      <data key="d0">TRANSFORMED_DATA</data>
      <data key="d1">Log-transformed variables are variables that have been transformed using the logarithmic function to address certain model assumptions
Log-transformed variables are variables that have been transformed using the logarithmic function, which can reduce the influence of data points</data>
      <data key="d2">83bb91cf725e5116ca2f5748fddccfae,d71b402ab9edbb4347e09c7af3257cf5</data>
    </node>
    <node id="TRANSFORMATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Transformations refer to mathematical operations applied to variables in a model to address violations of model assumptions. They can include logarithmic, power, or other types of transformations.
Transformations are mathematical operations applied to the data to change its scale or distribution, potentially reducing the influence of data points</data>
      <data key="d2">07951ffe6787af44aa60c90c69e62f83,83bb91cf725e5116ca2f5748fddccfae</data>
    </node>
    <node id="MODEL_REPARAMETERISATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Model reparameterisations are changes made to the structure of a statistical model to improve its fit to the data or to make it more interpretable. This can involve transformations of variables, changes in the functional form of the model, or the inclusion of additional parameters.</data>
      <data key="d2">07951ffe6787af44aa60c90c69e62f83</data>
    </node>
    <node id="SUM_OF_SQUARED_DIFFERENCES">
      <data key="d0">CONCEPT</data>
      <data key="d1">The sum of squared differences, S(&#946;), is a measure of the total squared error between the observed data and the predictions made by a model. It is defined as the sum over all observations of the squared differences between the observed values and the values predicted by the model. In the context of least squares estimation, the goal is to find the parameter vector &#946; that minimizes this sum, leading to the least squares estimate &#946;b.&gt;</data>
      <data key="d2">924be3e598ffeabd1fbd9b57f033b917</data>
    </node>
    <node id="S">
      <data key="d0">FUNCTION</data>
      <data key="d1">S(&#946;) is the sum of squared differences function used in the least squares estimation, calculated as the sum over j from 1 to n of (yj - xj^T &#946;)^2
S(&#946;) is the function used to find the least squares estimator, which is minimized at &#946;b
S(&#946;) is a function that measures the squared error between the observed values y and the predicted values X&#946;
S is a function that represents the sum of squared errors in the linear regression model
S(&#946;) is a function used to determine the goodness of fit of the linear regression model, where &#946; is a parameter vector
S(&#946;) is a function used to measure the goodness of fit of the linear regression model, specifically the sum of squared residuals
S(&#946;) is a function used to measure the goodness of fit of the model, where Beta is a parameter
S(&#946;) is the function used to measure the goodness of fit of the linear regression model, which is minimized to find the least squares estimator
S(&#946;) is the sum of squared residuals function used to find the least squares estimates of the parameters
S(&#946;) is the sum of squared residuals function in the simple linear regression model, which is minimized to find the least squares estimates of Beta_0 and Beta_1
The sum of squared differences (S) is the function that the least squares estimate of Beta (&#946;b) minimizes, defined as the sum from j=1 to n of (yj - xTj &#946;)^2
S(&#946;) is the residual sum of squares function, which is minimized by the MLE &#946;b for a given value of &#963;^2
S(&#946;) is the residual sum of squares, a measure of the total squared difference between the observed values and the values predicted by the model
S is the estimated standard deviation of the error term in the regression model
s is the unbiased estimate of the error variance &#963;^2</data>
      <data key="d2">10ac76f99674a01ca0f4a55586dea07e,2167274129d4cfa74a002c4cc39df8a8,255685e281cc5a9edf073c700f425a6b,416494d940a9f505da9853caca26fe63,50a56c34050fb7f7709300a51399b150,6b55b41598d5264f8dc6b72769748722,7955aae3fd4ca51b9ef8843e13c1f517,90b7e0427699cc1bb461e37939935138,9d300fc83afb3261af61b2ab9721cadc,9dddcd96af7b557e578b3f5f36efacd7,a4a817bb79d6ae8812c808ca41d47f43,aa195e72eb5285a4bcae9c856af30a87,c47968226557bc2eb5aec5bb7994fd0e,eac62cdd5518e1269fed150639331c2c,f632f01188d2c6e3091a965580cb4600</data>
    </node>
    <node id="S_BETA">
      <data key="d0">FUNCTION</data>
      <data key="d1">S(&#946;) is the sum of squared residuals function used to determine the least squares estimate
S(&#946;) is a function derived from yT y + &#946;TXTX&#946; &#8722; 2&#946;TXT y</data>
      <data key="d2">21ec28dfe2b2c18030d541d63e51f45e,8f7a05b6d231105a6194eebdb2df372e</data>
    </node>
    <node id="BETA_HAT_0">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">Beta_hat_0 (b&#946;0) is the least squares estimate of the intercept parameter Beta_0
Beta_hat_0 is the least squares estimate of Beta_0</data>
      <data key="d2">8f7a05b6d231105a6194eebdb2df372e,d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </node>
    <node id="BETA_HAT_1">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">Beta_hat_1 (b&#946;1) is the least squares estimate of the slope parameter Beta_1
Beta_hat_1 is the least squares estimate of Beta_1</data>
      <data key="d2">8f7a05b6d231105a6194eebdb2df372e,d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </node>
    <node id="Y_BAR">
      <data key="d0">MEAN</data>
      <data key="d1">Y_bar is the mean of the observed values Y
Y_bar (y&#175;) is the mean of the response values Yj
Y_bar is the mean of the dependent variable Y
y&#175; is the mean of the response variable y
Y_bar is the mean of y values
y_bar is the mean of the y variable
Bar Y (y&#175;) is the mean of the Y variable
Y_bar is the mean of the yj values, calculated as 1/n * &#931;yj
Y_bar is the mean of the response variable y</data>
      <data key="d2">1303b66694a101878ca530c0b41cf5ef,28cf5ff0c09fa5c0390267bb9aa3ce47,2f2523c52c6d2869fb19f77b66ce8259,3fdeeb7593174f5e8a9cff55a7cd92e3,5b24b5382abe9d1898810b3e4b9b455a,8f7a05b6d231105a6194eebdb2df372e,f2300d613896880cbb7c255a4d858315,f5716ce115458c0652124734ca344806,f9e7b2eac9f82681301da3d1e2f23328</data>
    </node>
    <node id="X_BAR">
      <data key="d0">MEAN</data>
      <data key="d1">X_bar is the mean of the predictor values X
X_bar (x&#175;) is the mean of the predictor values Xj
X_bar is the mean of the independent variable X
x&#175; is the mean of the predictor variable x
X_bar is the mean of x values
X_bar is the mean of the observed values X1 to Xn
x_bar is the mean of the x variable
Bar X (x&#175;) is the mean of the X variable
X_bar is the mean of the xj values, calculated as 1/n * &#931;xj
X_bar is the mean of the predictor variable x
Bar X (x&#175;) is the sample mean of the explanatory variable
X_bar is the sample mean of the x values in the dataset
X_bar is the mean of the explanatory variable observations
X_bar is the sample mean of the explanatory variable in the simple linear regression model.
X_bar is the sample mean of the explanatory variable
X_bar is the mean of the x values in the dataset</data>
      <data key="d2">1303b66694a101878ca530c0b41cf5ef,28cf5ff0c09fa5c0390267bb9aa3ce47,2f2523c52c6d2869fb19f77b66ce8259,3fdeeb7593174f5e8a9cff55a7cd92e3,5609007c6229060ffc85d8056a7fefde,56ff186fc629e1e42f2759fc4b984199,5b24b5382abe9d1898810b3e4b9b455a,6c66e9414880964ee899ceb0f16d22e9,6ee02b38ae842fd5eac9a11c4fd6659f,82932abd152e0b84a1c26a2daa4c08df,8f7a05b6d231105a6194eebdb2df372e,90b7e0427699cc1bb461e37939935138,bd05fe6a05f9a13d33c4f1b5a771ada5,f2300d613896880cbb7c255a4d858315,f5716ce115458c0652124734ca344806,f9e7b2eac9f82681301da3d1e2f23328</data>
    </node>
    <node id="BETA_0_HAT">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">Beta_0 hat (b&#946;0) is the least squares estimator of the intercept parameter Beta_0
BETA_0_HAT (b&#946;0) is the least squares estimate of the intercept parameter BETA_0</data>
      <data key="d2">3fdeeb7593174f5e8a9cff55a7cd92e3,69ffba28a61d98d8d18f91c24b74dd4a</data>
    </node>
    <node id="BETA_1_HAT">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">Beta_1 hat (b&#946;1) is the least squares estimator of the slope parameter Beta_1
BETA_1_HAT (b&#946;1) is the least squares estimate of the slope parameter BETA_1</data>
      <data key="d2">3fdeeb7593174f5e8a9cff55a7cd92e3,69ffba28a61d98d8d18f91c24b74dd4a</data>
    </node>
    <node id="SXX">
      <data key="d0">VARIABLE</data>
      <data key="d1">Sxx is a variable representing the sum of squares of deviations of predictor values from their mean
Sxx is the variance of the independent variable X
Sxx is the variance of the predictor variable x
Sxx is the variance of x, used in the calculation of Beta1
Sxx is the variance of the x variable, calculated as the sum of the squared deviations from the mean for x divided by n
Sxx is the sum of squares of deviations of the observed values X1 to Xn from their mean X_bar
Sxx is the variance of the x variable, calculated as the sum of the squared deviations of x from its mean divided by n
Sxx is the variance of the X variable, calculated as the sum of the squared deviations of X from its mean
Sxx is the variance of the xj values, calculated as &#931;(xj - X_bar)^2
Sxx is the variance of the predictor variable x</data>
      <data key="d2">1303b66694a101878ca530c0b41cf5ef,254a8a17b1be06702934341e3bf41e85,28cf5ff0c09fa5c0390267bb9aa3ce47,2f2523c52c6d2869fb19f77b66ce8259,3fdeeb7593174f5e8a9cff55a7cd92e3,56ff186fc629e1e42f2759fc4b984199,5b24b5382abe9d1898810b3e4b9b455a,f2300d613896880cbb7c255a4d858315,f5716ce115458c0652124734ca344806,f9e7b2eac9f82681301da3d1e2f23328</data>
    </node>
    <node id="SXY">
      <data key="d0">VARIABLE</data>
      <data key="d1">Sxy is a variable representing the sum of products of deviations of predictor and response values from their respective means
Sxy is the covariance between the independent variable X and the dependent variable Y
Sxy is the covariance between the predictor variable x and the response variable y
Sxy is the covariance between x and y, used in the calculation of Beta1
Sxy is the covariance between the x and y variables, calculated as the sum of the product of deviations from the mean for x and y divided by n
Sxy is the covariance between the X and Y variables, calculated as the sum of the products of the deviations of X and Y from their respective means
Sxy is the covariance between the xj and yj values, calculated as &#931;(xj - X_bar)(yj - Y_bar)
Sxy is the covariance between two variables x and y, calculated as the sum of the products of the deviations of x and y from their respective means</data>
      <data key="d2">1303b66694a101878ca530c0b41cf5ef,254a8a17b1be06702934341e3bf41e85,28cf5ff0c09fa5c0390267bb9aa3ce47,3fdeeb7593174f5e8a9cff55a7cd92e3,5b24b5382abe9d1898810b3e4b9b455a,f2300d613896880cbb7c255a4d858315,f5716ce115458c0652124734ca344806,f9e7b2eac9f82681301da3d1e2f23328</data>
    </node>
    <node id="BETA1_HAT">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">Beta1_hat (b&#946;1) is the least squares estimator for the slope parameter &#946;1 in a simple linear regression model
Beta1 hat is the least squares estimate of one of the slope parameters</data>
      <data key="d2">87b717ba065d6d7c7431af284137eb12,f9e7b2eac9f82681301da3d1e2f23328</data>
    </node>
    <node id="BETA0_HAT">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">Beta0_hat (b&#946;0) is the least squares estimator for the intercept parameter &#946;0 in a simple linear regression model
Beta0 hat is the least squares estimate of the intercept parameter</data>
      <data key="d2">87b717ba065d6d7c7431af284137eb12,f9e7b2eac9f82681301da3d1e2f23328</data>
    </node>
    <node id="EXERCISE_12">
      <data key="d0">EXERCISE</data>
      <data key="d1">Exercise 12 asks to show that the fitted regression line goes through the point (x&#175;, y&#175;)</data>
      <data key="d2">5b24b5382abe9d1898810b3e4b9b455a</data>
    </node>
    <node id="EXERCISE_13">
      <data key="d0">EXERCISE</data>
      <data key="d1">Exercise 13 involves a specific dataset and asks to complete a table, compute parameter estimates, fitted values, residuals, and the deviance of the model</data>
      <data key="d2">5b24b5382abe9d1898810b3e4b9b455a</data>
    </node>
    <node id="XT">
      <data key="d0">TRANSPOSE_MATRIX</data>
      <data key="d1">XT is the transpose of the design matrix X
XT is a matrix used in the calculation of the least squares estimator
XT is the transpose of the design matrix X, used in the calculation of the least squares estimator and in the normal equations
XT is a matrix used in the calculation of the least squares estimator and in the normal equations
XT is the transpose of the design matrix X, used in the calculation of the least squares estimator
Matrix XT is the transpose of matrix X, used in the least squares estimation
XT is the transpose of the matrix X, used in the calculation of the least squares estimator
XT is the transpose of the design matrix X
XT is the transpose of the design matrix X in a linear regression model
XT is the transpose of matrix X
XT is the transpose of the design matrix X, used in the calculation of the least squares estimate of Beta (&#946;b)
XT is a matrix used in the calculation of the least squares estimator
XT is a matrix used in the calculation of the maximum likelihood estimate &#946;b
XT is a p x n matrix of constants used in the calculation of the least squares estimator
Matrix XT is the transpose of matrix X.</data>
      <data key="d2">1303b66694a101878ca530c0b41cf5ef,254a8a17b1be06702934341e3bf41e85,255685e281cc5a9edf073c700f425a6b,2f2523c52c6d2869fb19f77b66ce8259,46629f2efc6c82e81265a131b4bab2ee,542f546c5a131196e4701fb33c9b1dee,6b55b41598d5264f8dc6b72769748722,7955aae3fd4ca51b9ef8843e13c1f517,82932abd152e0b84a1c26a2daa4c08df,9dddcd96af7b557e578b3f5f36efacd7,9fc2b1e8b2b61b557f88eb9e9c708597,a4a817bb79d6ae8812c808ca41d47f43,aa195e72eb5285a4bcae9c856af30a87,f5716ce115458c0652124734ca344806,f9b615b879f72501f338f8983d4cac3d</data>
    </node>
    <node id="XTX">
      <data key="d0">PRODUCT_MATRIX</data>
      <data key="d1">XTX is the product of the transpose of the design matrix X and the design matrix X itself
XTX is the product of the transpose of matrix X and matrix X, which is a symmetric matrix
XTX is the product of matrix X transposed (XT) and matrix X, which is used in the calculation of the least squares estimator
XTX is the product of the matrix XT and itself, used in the calculation of the least squares estimator and in the normal equations
XTX is the product of the transpose of matrix X and matrix X, used in the calculation of the least squares estimator
Matrix XTX is the product of matrix XT and matrix X, used in the least squares estimation
XTX is the product of the transpose of matrix X and matrix X, resulting in a 2x2 matrix
XTX is the product of the transpose of the matrix X and the matrix X itself
XTX is the matrix product of the transpose of X and X, resulting in a matrix with elements n and Sxx
XTX is a matrix resulting from the multiplication of matrix XT by itself, used in the calculation of the least squares estimator and its variance
Matrix XTX is the product of matrix X and its transpose XT, often used in the calculation of regression coefficients.
XTX is a matrix resulting from the multiplication of the transpose of a matrix X with itself, used in the calculation of the trace of the hat matrix H
XTX is the result of multiplying the transpose of matrix X by X itself</data>
      <data key="d2">1303b66694a101878ca530c0b41cf5ef,1da117a2f92b2db00290d2a0bfc06beb,254a8a17b1be06702934341e3bf41e85,28cf5ff0c09fa5c0390267bb9aa3ce47,2f2523c52c6d2869fb19f77b66ce8259,46629f2efc6c82e81265a131b4bab2ee,56ff186fc629e1e42f2759fc4b984199,9d300fc83afb3261af61b2ab9721cadc,a4a817bb79d6ae8812c808ca41d47f43,bd98ac7b4b5df4f63e7ecc8f4a821f57,d14413709de2897231aaa83be3aa346f,eac62cdd5518e1269fed150639331c2c,f9b615b879f72501f338f8983d4cac3d</data>
    </node>
    <node id="XTX_INVERSE">
      <data key="d0">INVERSE_MATRIX</data>
      <data key="d1">(XTX)^-1 is the inverse of the matrix XTX</data>
      <data key="d2">f9b615b879f72501f338f8983d4cac3d</data>
    </node>
    <node id="RANK_X">
      <data key="d0">RANK</data>
      <data key="d1">Rank (X) is the rank of the design matrix X, which is equal to p if X is of full rank</data>
      <data key="d2">f9b615b879f72501f338f8983d4cac3d</data>
    </node>
    <node id="A">
      <data key="d0">VECTOR</data>
      <data key="d1">a is a vector of dimension m used in various vector operationsA is a matrix that is conformable with B for multiplication
A is a matrix used in the function f(&#946;) = &#946;T A&#946;
A is a p x p non-singular matrix used to reparameterize the model
A is a p x p non-singular matrix used to transform Beta into Gamma
A is an invertible matrix used in the reparameterisation of the model
A is the non-singular matrix used to transform Beta into Alpha
Matrix A is used to transform the design matrix X from the original to the reparameterised model
A is a p x n matrix of constants used to transform Z into a new distribution
A is a square matrix used in the context of the trace operation, where the trace of A is equal to the sum of its diagonal elements
Matrix A is a q x n matrix used in transforming the vector Z
Matrix A is used in the transformation of Z to obtain U</data>
      <data key="d2">0ac60299320c55d642b3e38440c25f90,2167274129d4cfa74a002c4cc39df8a8,21ec28dfe2b2c18030d541d63e51f45e,542f546c5a131196e4701fb33c9b1dee,5609007c6229060ffc85d8056a7fefde,6c66e9414880964ee899ceb0f16d22e9,82932abd152e0b84a1c26a2daa4c08df,aac5b4f040b9c773bd1aa696dec469f6,bd98ac7b4b5df4f63e7ecc8f4a821f57,d94760a5f9f6ea115fcc18024035a627,f5716ce115458c0652124734ca344806</data>
      <data key="d3">MATRIX</data>
    </node>
    <node id="B">
      <data key="d0">VECTOR</data>
      <data key="d1">B is a matrix that is conformable with A for multiplicationb is a vector of dimension m used in various vector operations
B is a matrix that, when conformable with A, satisfies the property tr(AB) = tr(BA)
Matrix B is a p x n matrix used in transforming the vector Z
Matrix B is used in the transformation of Z to obtain V</data>
      <data key="d2">0ac60299320c55d642b3e38440c25f90,2167274129d4cfa74a002c4cc39df8a8,aac5b4f040b9c773bd1aa696dec469f6,bd98ac7b4b5df4f63e7ecc8f4a821f57</data>
      <data key="d3">MATRIX</data>
    </node>
    <node id="J">
      <data key="d0">VECTOR</data>
      <data key="d1">J is a vector used in the calculation of the squared error</data>
      <data key="d2">eac62cdd5518e1269fed150639331c2c</data>
    </node>
    <node id="XTY">
      <data key="d0">VECTOR</data>
      <data key="d1">XTY is the product of the transpose of matrix X and vector Y
XTY is the product of the transpose of matrix X and vector Y, used in the calculation of the least squares estimator
Vector XTY is the product of matrix XT and vector Y, used in the least squares estimation
XTY is the matrix product of the transpose of X and Y, used in the calculation of the least squares estimate</data>
      <data key="d2">1303b66694a101878ca530c0b41cf5ef,254a8a17b1be06702934341e3bf41e85,28cf5ff0c09fa5c0390267bb9aa3ce47,eac62cdd5518e1269fed150639331c2c</data>
    </node>
    <node id="F_BETA">
      <data key="d0">FUNCTION</data>
      <data key="d1">f(&#946;) is a function defined as &#946;T A&#946;</data>
      <data key="d2">21ec28dfe2b2c18030d541d63e51f45e</data>
    </node>
    <node id="NORMAL_EQUATIONS">
      <data key="d0">EQUATION</data>
      <data key="d1">The normal equations are the set of equations in (5.3) that &#946;b satisfies
The normal equations are a set of equations derived from the log-likelihood function that are solved by the least squares estimate &#946;b.
The normal equations are a set of equations derived from the likelihood function, which are solved to find the least squares estimate Beta hat (&#946;b)</data>
      <data key="d2">21ec28dfe2b2c18030d541d63e51f45e,ad799500572246a07f983a3b92c0e61f,f632f01188d2c6e3091a965580cb4600</data>
    </node>
    <node id="S_BETA_BETA_HAT">
      <data key="d0">FUNCTION_VALUE</data>
      <data key="d1">S(&#946;b) is the value of the function S(&#946;) at the stationary point &#946;b</data>
      <data key="d2">21ec28dfe2b2c18030d541d63e51f45e</data>
    </node>
    <node id="RANK">
      <data key="d0">PROPERTY</data>
      <data key="d1">Rank is a property of a matrix that indicates the maximum number of linearly independent rows or columns</data>
      <data key="d2">9d300fc83afb3261af61b2ab9721cadc</data>
    </node>
    <node id="PARTIAL_DERIVATIVE">
      <data key="d0">FUNCTION</data>
      <data key="d1">Partial derivative of S(&#946;) with respect to Beta_0 is used to find the least squares estimate of Beta_0</data>
      <data key="d2">10ac76f99674a01ca0f4a55586dea07e</data>
    </node>
    <node id="PARTIAL_DERIVATIVES">
      <data key="d0">FUNCTION</data>
      <data key="d1">Partial derivatives of S(&#946;) with respect to Beta_0 and Beta_1 are used to find the least squares estimates of Beta_0 and Beta_1</data>
      <data key="d2">416494d940a9f505da9853caca26fe63</data>
    </node>
    <node id="ALPHA0">
      <data key="d0">PARAMETER</data>
      <data key="d1">Alpha0 is a parameter in the straight line model, representing the intercept</data>
      <data key="d2">1303b66694a101878ca530c0b41cf5ef</data>
    </node>
    <node id="ALPHA1">
      <data key="d0">PARAMETER</data>
      <data key="d1">Alpha1 is a parameter in the straight line model, representing the slope</data>
      <data key="d2">1303b66694a101878ca530c0b41cf5ef</data>
    </node>
    <node id="ALPHA_HAT">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">Alpha hat is the least squares estimate for the parameters Alpha0 and Alpha1 in the straight line model
Alpha hat (&#945;b) is the least squares estimator of the parameter alpha in the reparameterized model</data>
      <data key="d2">1303b66694a101878ca530c0b41cf5ef,f5716ce115458c0652124734ca344806</data>
    </node>
    <node id="GAMMA">
      <data key="d0">PARAMETER</data>
      <data key="d1">Gamma is the new parameter vector obtained by reparameterizing the model using matrix A
Gamma is another parameter vector related to Beta through the transformation Gamma = A&#946;
Gamma is a parameter in the reparameterised model, related to Beta through the invertible matrix A</data>
      <data key="d2">82932abd152e0b84a1c26a2daa4c08df,d94760a5f9f6ea115fcc18024035a627,f5716ce115458c0652124734ca344806</data>
    </node>
    <node id="Z">
      <data key="d0">DESIGN_MATRIX</data>
      <data key="d1">Z is the new design matrix obtained by applying the transformation XA^-1 to the original design matrix X
Z is the design matrix in the transformed model, given by Z = XA^-1
Z is a matrix used in the calculation of the fitted values in the reparameterised model
Z is a vector that follows a multivariate normal distribution with mean &#181; and covariance matrix &#931;
Z is a vector of iid (independent and identically distributed) samples used in estimating the variance
z1, ..., zn is a vector of observed values from an iid sample used to estimate the variance
Z is a vector that follows a multivariate normal distribution with mean &#181; and covariance matrix &#931;
Vector Z is a vector of independent standard normal random variables used in the definition of U and V</data>
      <data key="d2">09caa54ca1372d152e47051be4d44ede,0ac60299320c55d642b3e38440c25f90,542f546c5a131196e4701fb33c9b1dee,6648f0d6deed51fb4fb25e6992a71ddf,82932abd152e0b84a1c26a2daa4c08df,aac5b4f040b9c773bd1aa696dec469f6,d94760a5f9f6ea115fcc18024035a627,f5716ce115458c0652124734ca344806</data>
    </node>
    <node id="GAMMA_HAT">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">Gamma hat (&#947;b) is the least squares estimator of Gamma
Gamma hat (&#947;b) is the least squares estimator of the parameter Gamma, calculated as A(XTX)^-1XTY</data>
      <data key="d2">82932abd152e0b84a1c26a2daa4c08df,d94760a5f9f6ea115fcc18024035a627</data>
    </node>
    <node id="AT">
      <data key="d0">MATRIX</data>
      <data key="d1">AT is the transpose of matrix A</data>
      <data key="d2">82932abd152e0b84a1c26a2daa4c08df</data>
    </node>
    <node id="ALPHA">
      <data key="d0">PARAMETER</data>
      <data key="d1">Alpha is a parameter in the reparameterised model (1), related to Beta through the transformation xj - x&#175;
Alpha is a parameter in the reparameterised model (1), consisting of alpha_0 and alpha_1
Alpha is the parameter vector in the reparameterised model</data>
      <data key="d2">5609007c6229060ffc85d8056a7fefde,6c66e9414880964ee899ceb0f16d22e9,82932abd152e0b84a1c26a2daa4c08df</data>
    </node>
    <node id="A_INVERSE">
      <data key="d0">INVERSE_MATRIX</data>
      <data key="d1">A_inverse is the inverse of matrix A, used to transform Alpha back into Beta</data>
      <data key="d2">5609007c6229060ffc85d8056a7fefde</data>
    </node>
    <node id="X_ALPHA">
      <data key="d0">DESIGN_MATRIX</data>
      <data key="d1">X_alpha is the design matrix of the model parameterisation in (1), obtained by transforming X_beta using A_inverse
X_alpha is the design matrix of the reparameterised model, obtained by transforming X using A</data>
      <data key="d2">5609007c6229060ffc85d8056a7fefde,6c66e9414880964ee899ceb0f16d22e9</data>
    </node>
    <node id="C">
      <data key="d0">CONSTANT</data>
      <data key="d1">Constant c is a non-zero value by which all observations of the explanatory variable are multiplied in the reparameterised model
C is a constant by which we multiply all observations of the explanatory variable in the reparameterised model</data>
      <data key="d2">6c66e9414880964ee899ceb0f16d22e9,d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </node>
    <node id="ALPHA_HAT_0">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">Alpha_hat_0 is the least squares estimate of Alpha_0</data>
      <data key="d2">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </node>
    <node id="ALPHA_HAT_1">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">Alpha_hat_1 is the least squares estimate of Alpha_1</data>
      <data key="d2">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </node>
    <node id="MAYA">
      <data key="d0">PERSON</data>
      <data key="d1">Maya is a person who has fitted a simple linear regression model to a set of data</data>
      <data key="d2">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </node>
    <node id="AMBIENT_TEMPERATURE">
      <data key="d0">EXPLANATORY_VARIABLE</data>
      <data key="d1">Ambient temperature is the explanatory variable in Maya's model, measured in Celsius</data>
      <data key="d2">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </node>
    <node id="FAHRENHEIT">
      <data key="d0">UNIT</data>
      <data key="d1">Fahrenheit is a unit of measurement for temperature</data>
      <data key="d2">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </node>
    <node id="Y_HAT_J">
      <data key="d0">FITTED_VALUE</data>
      <data key="d1">Y_hat_j is the fitted value for the jth observation, calculated as xT_j &#946;_hat</data>
      <data key="d2">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </node>
    <node id="RESIDSS">
      <data key="d0">STATISTIC</data>
      <data key="d1">ResidSS is the residual sum of squares, a measure of the goodness of fit of the model
The residual sum of squares (ResidSS) or deviance (D) is the sum of the squared residuals, defined as the sum from i=1 to n of (yi - ybi)^2
ResidSS is the residual sum of squares, a measure of the total squared difference between the observed values and the values predicted by the model</data>
      <data key="d2">255685e281cc5a9edf073c700f425a6b,d1b6fcd55d937c5fe2d6add69e0bcf05,fc5b725f3c662c5471af20efdcc2dbff</data>
    </node>
    <node id="LSE">
      <data key="d0">ESTIMATION_METHOD</data>
      <data key="d1">Least squares estimation (LSE) is a method for estimating the parameters of a linear model
LSE (Least Squares Estimate) is the estimate for the parameter vector &#946; derived without assuming the errors are iid N(0, &#963;^2).</data>
      <data key="d2">9fc2b1e8b2b61b557f88eb9e9c708597,d738df7d83784c8a41b3948271c537b6</data>
    </node>
    <node id="MLE">
      <data key="d0">ESTIMATION_METHOD</data>
      <data key="d1">Maximum likelihood estimation (MLE) is a method for estimating the parameters of a statistical model
MLE (Maximum Likelihood Estimate) is the estimate for the parameter vector &#946; derived by maximizing the likelihood function under the assumption that errors are iid N(0, &#963;^2).
Maximum Likelihood Estimate (MLE) is a method used to estimate the parameters of a statistical model, in this case, the parameter vector &#946; in a normal linear model</data>
      <data key="d2">9dddcd96af7b557e578b3f5f36efacd7,9fc2b1e8b2b61b557f88eb9e9c708597,d738df7d83784c8a41b3948271c537b6</data>
    </node>
    <node id="SHEATHER_BOOK">
      <data key="d0">REFERENCE</data>
      <data key="d1">A Modern Approach to Regression with R (2009) by Sheather is a book that provides further reading on regression analysis</data>
      <data key="d2">9fc2b1e8b2b61b557f88eb9e9c708597</data>
    </node>
    <node id="MULTIVARIATE_NORMAL_DISTRIBUTION">
      <data key="d0">DISTRIBUTION</data>
      <data key="d1">The multivariate normal distribution Nn(&#181;, &#931;) is a probability distribution over vectors in R^n, characterized by a mean vector &#181; and a covariance matrix &#931;
The multivariate normal distribution is a generalization of the univariate normal distribution to higher dimensions, characterized by a mean vector and a covariance matrix</data>
      <data key="d2">aac5b4f040b9c773bd1aa696dec469f6,f483798b15ef305e7826fd7142379e03</data>
    </node>
    <node id="LOG_LIKELIHOOD">
      <data key="d0">FUNCTION</data>
      <data key="d1">Log-likelihood function for the linear regression model
&#8467; is the log-likelihood function of the normal linear model, derived from the likelihood function L
The log-likelihood function is a measure used in statistical inference to estimate the parameters of a model. It is maximised by the vector &#946; that minimises the residual sum of squares function S(&#946;) for a given value of &#963;^2.</data>
      <data key="d2">87b717ba065d6d7c7431af284137eb12,9dddcd96af7b557e578b3f5f36efacd7,ad799500572246a07f983a3b92c0e61f</data>
    </node>
    <node id="BETAK_HAT">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">Beta_k hat is the least squares estimate of one of the slope parameters</data>
      <data key="d2">87b717ba065d6d7c7431af284137eb12</data>
    </node>
    <node id="PI">
      <data key="d0">CONSTANT</data>
      <data key="d1">Pi (&#960;) is a mathematical constant used in the calculation of the likelihood function</data>
      <data key="d2">e7edd8b2874a350779ae20f1ecdf4733</data>
    </node>
    <node id="D">
      <data key="d0">DEVIANCE</data>
      <data key="d1">D is the deviance or residual sum of squares of the fitted model</data>
      <data key="d2">e7edd8b2874a350779ae20f1ecdf4733</data>
    </node>
    <node id="L">
      <data key="d0">LIKELIHOOD</data>
      <data key="d1">L is the likelihood function of the normal linear model
L is the likelihood function of the normal linear model, which is a function of &#946; and &#963;^2 given the observed data y
L(&#946;, &#963;^2|y) is the likelihood function for the parameters Beta and Sigma squared given the observed data Y</data>
      <data key="d2">9dddcd96af7b557e578b3f5f36efacd7,e7edd8b2874a350779ae20f1ecdf4733,f632f01188d2c6e3091a965580cb4600</data>
    </node>
    <node id="RESIDUAL_SUM_SQUARES">
      <data key="d0">FUNCTION</data>
      <data key="d1">The residual sum of squares function S(&#946;) is a measure of the difference between the observed data and the values predicted by the model. It is minimised by the least squares estimate &#946;b.</data>
      <data key="d2">ad799500572246a07f983a3b92c0e61f</data>
    </node>
    <node id="SIGMA_HAT_SQUARED">
      <data key="d0">MLE</data>
      <data key="d1">Sigma hat squared (&#963;b^2MLE) is the maximum likelihood estimate of the variance Sigma squared
&#963;b^2 is the unbiased estimator of the variance, calculated as (1/(n-1)) * &#931;(zi - z_bar)^2</data>
      <data key="d2">6648f0d6deed51fb4fb25e6992a71ddf,f632f01188d2c6e3091a965580cb4600</data>
    </node>
    <node id="BIAS">
      <data key="d0">BIAS</data>
      <data key="d1">Bias refers to the difference between the expected value of an estimator and the true value of the parameter being estimated</data>
      <data key="d2">f632f01188d2c6e3091a965580cb4600</data>
    </node>
    <node id="ERROR_VARIANCE">
      <data key="d0">VARIANCE</data>
      <data key="d1">Error variance (&#963;^2) is the variance of the error term in the statistical model
Error variance (&#963;^2) is the variance of the error term in the regression model, estimated by s^2
&#963;^2 is the error variance in the regression model
Error variance is the variance of the error term in a statistical model. It represents the amount of variation in the response variable that is not explained by the model.</data>
      <data key="d2">09391efd3b8c510205098b548bc8dc74,7e05f1b457a496c8b3630e7044fc5981,d7f3a28534ffe830fe6f4cef8c41a9b4,f632f01188d2c6e3091a965580cb4600</data>
    </node>
    <node id="BETA_HAT_Y">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">Beta hat (&#946;b(Y)) is the estimator of Beta, a function of the random vector Y</data>
      <data key="d2">2de7a36b32bf79c8f32612c8aaa9daa8</data>
    </node>
    <node id="NP">
      <data key="d0">DISTRIBUTION</data>
      <data key="d1">Np is the multivariate normal distribution with mean &#946; and covariance matrix &#963;^2(XTX)^-1
Np is the multivariate normal distribution with mean AX&#946; and covariance matrix A&#963;^2InAT
Np is the multivariate normal distribution with mean &#946; and covariance matrix &#963;^2(XTX)^-1
Np is the multivariate normal distribution with mean AX&#946; and covariance matrix A&#963;^2InAT</data>
      <data key="d2">3d357cfa3ef0d00f49cf4acaeac1c9d1,45f31b040576e9f3b4def6d0466cc016,542f546c5a131196e4701fb33c9b1dee,d14413709de2897231aaa83be3aa346f</data>
    </node>
    <node id="AZ">
      <data key="d0">TRANSFORMED VECTOR</data>
      <data key="d1">AZ is the transformed vector obtained by multiplying Z by A, following a multivariate normal distribution with mean A&#181; and covariance matrix A&#931;AT</data>
      <data key="d2">542f546c5a131196e4701fb33c9b1dee</data>
    </node>
    <node id="MU">
      <data key="d0">MEAN</data>
      <data key="d1">&#181; is the mean vector of the multivariate normal distribution that Z follows
Mu is a parameter in the model equations, representing the baseline sales for each brand
Mu (&#181;) is a parameter in the reparameterised model, representing the baseline sales volume
Mu (&#181;) is a parameter in the model, representing the intercept for the regression line of Brand A
Mu (&#181;) is a parameter in the model representing the average sales volume for Brand A stores
&#181; = (&#181;A, &#181;B, &#181;C) is a parameter vector representing the mean sales for each brand
Mu (&#181;) is the intercept parameter in the model equations for all brands
Mu (&#181;) is a parameter in the parallel lines model, representing the baseline sales level
Mu (&#181;) is the intercept of the regression model for brand A
Mu (&#181;) is the intercept parameter in the regression model</data>
      <data key="d2">06199787dd7f75f7338dd24d4f3dc26e,06d5666e6bfdda828b48adba883b4a61,096afa471635bc59c3bfa9af4d04d625,1d141ab04db553f78a313e430e54abb5,542f546c5a131196e4701fb33c9b1dee,825b600cbab3535ce67e9f561ddcb84b,906eb7d6b49fa360e7e5b65c56cd4d76,a1fc936df848a0fbc791e4bcc9b527b6,ac15b639b0849006471dfe102376c2c0,b6870535f3975c49d45e62fbe475f198</data>
    </node>
    <node id="SIGMA">
      <data key="d0">COVARIANCE MATRIX</data>
      <data key="d1">&#931; is the covariance matrix of the multivariate normal distribution that Z follows
Sigma is the covariance matrix of the multivariate normal distribution</data>
      <data key="d2">542f546c5a131196e4701fb33c9b1dee,aac5b4f040b9c773bd1aa696dec469f6</data>
    </node>
    <node id="VARIANCE_BETA_HAT">
      <data key="d0">VARIANCE</data>
      <data key="d1">VARIANCE_BETA_HAT is the variance of the least squares estimator BETA_HAT, calculated as &#963;^2(XTX)^-1</data>
      <data key="d2">69ffba28a61d98d8d18f91c24b74dd4a</data>
    </node>
    <node id="COVARIANCE_BETA_HAT">
      <data key="d0">COVARIANCE</data>
      <data key="d1">COVARIANCE_BETA_HAT is the covariance between the least squares estimates BETA_0_HAT and BETA_1_HAT</data>
      <data key="d2">69ffba28a61d98d8d18f91c24b74dd4a</data>
    </node>
    <node id="SIGMA_SQUARED_MLE">
      <data key="d0">ESTIMATE</data>
      <data key="d1">SIGMA_SQUARED_MLE (&#963;b^2_MLE) is the maximum likelihood estimate for the error variance, calculated as (1/n)(Y - X BETA_HAT(Y))^T
Sigma squared MLE (&#963;b^2_MLE) is the maximum likelihood estimator of the error variance, calculated as (1/n)(y - X &#946;b(y))^T(y - X &#946;b(y))</data>
      <data key="d2">09caa54ca1372d152e47051be4d44ede,69ffba28a61d98d8d18f91c24b74dd4a</data>
    </node>
    <node id="BETA_HAT0">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">Beta hat 0 (b&#946;0) is the estimator of the parameter Beta0, calculated using the maximum likelihood estimation method</data>
      <data key="d2">09caa54ca1372d152e47051be4d44ede</data>
    </node>
    <node id="Z_BAR">
      <data key="d0">MEAN</data>
      <data key="d1">Z_bar is the sample mean of the observed values z1, ..., zn</data>
      <data key="d2">6648f0d6deed51fb4fb25e6992a71ddf</data>
    </node>
    <node id="SIGMA_HAT_SQUARED_BIAS">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">&#963;b^2 is a biased estimator of the variance, calculated as (1/n) * &#931;(zi - z_bar)^2</data>
      <data key="d2">6648f0d6deed51fb4fb25e6992a71ddf</data>
    </node>
    <node id="S_HAT_SQUARED">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">s^2(Y) is the unbiased estimator for the error variance, calculated as (1/(n-p)) * (Y - X&#946;b)^T(Y - X&#946;b)</data>
      <data key="d2">6648f0d6deed51fb4fb25e6992a71ddf</data>
    </node>
    <node id="THEOREM_6_4">
      <data key="d0">THEOREM</data>
      <data key="d1">Theorem 6.4 states that s^2(Y) is an unbiased estimator for &#963;^2 in normal linear models
Theorem 6.4 states that s^2 is an unbiased estimator for &#963;^2</data>
      <data key="d2">6648f0d6deed51fb4fb25e6992a71ddf,9923e77ac6b3de95cb5026bc5e7fe8c0</data>
    </node>
    <node id="S2">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">S squared (s^2) is the unbiased estimator for the error variance (&#963;^2) in the linear regression model
Unbiased estimate of sigma squared (s^2) is calculated as the residual sum of squares divided by (n - p), where n is the number of observations and p is the number of parameters
s^2 is the estimated variance of the error term in the regression model.&gt;
S2 is the unbiased estimator for the error variance in a statistical model</data>
      <data key="d2">9923e77ac6b3de95cb5026bc5e7fe8c0,9e2ebbb113c00fa43f0af3c0696baf95,aac5b4f040b9c773bd1aa696dec469f6,fc5b725f3c662c5471af20efdcc2dbff</data>
    </node>
    <node id="EXERCISE_18">
      <data key="d0">EXERCISE</data>
      <data key="d1">Exercise 18 is a problem that involves determining the design matrix X and the estimator &#946;b for a given linear model</data>
      <data key="d2">fc5b725f3c662c5471af20efdcc2dbff</data>
    </node>
    <node id="E_Y3_GIVEN_X3">
      <data key="d0">EXPECTED_VALUE</data>
      <data key="d1">Expected value of Y3 given X3=x3, used in the calculation involving Beta1 and Beta2</data>
      <data key="d2">45f31b040576e9f3b4def6d0466cc016</data>
    </node>
    <node id="SIGMA_HAT_SQUARED_MLE">
      <data key="d0">MLE_ESTIMATE</data>
      <data key="d1">MLE estimate for &#963;^2, given by (1/n)(y - X&#946;b(y))^T(y - X&#946;b(y)), but the estimator is biased
Sigma hat squared (&#963;b^2) MLE is the maximum likelihood estimate for sigma squared, calculated as (1/n)(y - X&#946;b(y))^T(y - X&#946;b(y)), but it is a biased estimator</data>
      <data key="d2">2673d078d29f2af78fab9b6eacd15e37,45f31b040576e9f3b4def6d0466cc016</data>
    </node>
    <node id="S_SQUARED">
      <data key="d0">UNBIASED_ESTIMATE</data>
      <data key="d1">Unbiased estimate for &#963;^2, given by (1/(n-p))(y - X&#946;b(y))^T(y - X&#946;b(y))
S squared (s^2) is the unbiased estimate for sigma squared, calculated as (1/(n-p))(y - X&#946;b(y))^T(y - X&#946;b(y)
S^2 is the unbiased estimate of the error variance &#963;^2 based on the model fitted to the full dataset
s^2 is an unbiased estimate of the error variance &#963;^2 in a regression model
S squared (s^2) is the estimator of the variance of the error term in a linear regression model</data>
      <data key="d2">0443ab5e20a4f6b2f243c989ef6c723a,09391efd3b8c510205098b548bc8dc74,0ac60299320c55d642b3e38440c25f90,2673d078d29f2af78fab9b6eacd15e37,45f31b040576e9f3b4def6d0466cc016</data>
    </node>
    <node id="H">
      <data key="d0">HAT_MATRIX</data>
      <data key="d1">H, also known as the hat matrix, is a linear map that takes the observed values y to the fitted values yb. It is called the hat matrix because it "puts the hat on y".
Matrix H, also known as the hat matrix, is a square matrix used in regression analysis to project the response vector onto the space of the predictors. It is symmetric and idempotent, with the property that H^2 = H.
H is the hat matrix, which is idempotent and plays a special role in the theory of linear models, particularly in relation to the leverage of data points
H is the hat matrix in a linear model, used to calculate the leverage of data points
H is the hat matrix, a function of the design matrix X, which is idempotent and symmetric, and is used to compute fitted values and residuals
H is the hat matrix, used in the calculation of predicted values Yc and residuals Eb
H is the hat matrix used in the calculation of the fitted values and the residual vector Eb
H is the hat matrix, a matrix used in regression analysis to project the response vector onto the space of the predictors
H is the hat matrix in the linear model, defined as X(XTX)^-1XT, and is symmetric, idempotent, and of rank p
H, the hat matrix, is defined as X(XTX)^-1XT and is symmetric, idempotent, and of rank p
H is the hat matrix used in the calculation of the fitted values in linear regression, and its properties can be derived
H is the hat matrix used to transform the observed response values into fitted values.</data>
      <data key="d2">0b650eb2f1dcd603b64fec3c4b5cd24b,1da117a2f92b2db00290d2a0bfc06beb,2685edb9e8031c8ea725c43a40af22a8,46629f2efc6c82e81265a131b4bab2ee,5a0d392715f06d5e873f45ae06aa729a,679722cf8ce5ce5aee4e379528470efe,6ee02b38ae842fd5eac9a11c4fd6659f,74d190f10bf6e6936242ca3cdfc4a09f,7d074208b1259e7d84f9f870d3828bb6,bd98ac7b4b5df4f63e7ecc8f4a821f57,e593096f3805c2686423cb91ea276fe6,f470791d2d3fedede166f9bb11598c9c</data>
    </node>
    <node id="Y_HAT">
      <data key="d0">FITTED_VALUES</data>
      <data key="d1">Y hat (yb) are the fitted values obtained by applying the hat matrix H to the observed values Y.</data>
      <data key="d2">f470791d2d3fedede166f9bb11598c9c</data>
    </node>
    <node id="EPSILON_HAT">
      <data key="d0">RESIDUALS</data>
      <data key="d1">Residuals (b&#1013;) are the estimates of the errors of a statistical model, calculated as the difference between the observed values Y and the fitted values Y hat (yb).</data>
      <data key="d2">f470791d2d3fedede166f9bb11598c9c</data>
    </node>
    <node id="LEMMA_7_1">
      <data key="d0">LEMMA</data>
      <data key="d1">Lemma 7.1 describes the properties of the hat matrix H, including its symmetry, idempotence, and the properties of (In - H).</data>
      <data key="d2">f470791d2d3fedede166f9bb11598c9c</data>
    </node>
    <node id="IP">
      <data key="d0">MATRIX</data>
      <data key="d1">Matrix Ip is the p x p identity matrix, where p is the number of predictors.
Ip is the p x p identity matrix, whose trace is equal to p</data>
      <data key="d2">46629f2efc6c82e81265a131b4bab2ee,bd98ac7b4b5df4f63e7ecc8f4a821f57</data>
    </node>
    <node id="HII">
      <data key="d0">LEVERAGE</data>
      <data key="d1">hii is the leverage of the ith data point, which is the ith diagonal element of the hat matrix H
hii is the ith diagonal element of the hat matrix H, representing the leverage of the ith data point
hii is the ith diagonal element of the hat matrix H, representing the leverage value of the ith observation
hii is the ith diagonal element of the hat matrix H, also known as the ith leverage
hii is the leverage value for the ith observation, a measure of how far an independent variable value is from the mean
hii is the ith leverage value, a measure of how far an independent variable value of the ith observation is from the mean of that variable
Hii is the leverage of the ith data point, representing the weight that the observed value yi has when computing the fitted value ybi.
hii is the leverage value for the ith observation, a measure of how far an independent variable value is from the mean
hii is the leverage value for the ith observation in the regression model
Hii is the leverage value for the ith observation, a measure of how far an independent variable value of the observation is from the average</data>
      <data key="d2">0443ab5e20a4f6b2f243c989ef6c723a,0b650eb2f1dcd603b64fec3c4b5cd24b,1da117a2f92b2db00290d2a0bfc06beb,2685edb9e8031c8ea725c43a40af22a8,5a0d392715f06d5e873f45ae06aa729a,679722cf8ce5ce5aee4e379528470efe,6ee02b38ae842fd5eac9a11c4fd6659f,90b7e0427699cc1bb461e37939935138,bd98ac7b4b5df4f63e7ecc8f4a821f57,c47968226557bc2eb5aec5bb7994fd0e</data>
    </node>
    <node id="H2">
      <data key="d0">MATRIX</data>
      <data key="d1">H2 is the square of the hat matrix, which is idempotent and symmetric, and its diagonal elements are related to the leverage values in regression analysis</data>
      <data key="d2">679722cf8ce5ce5aee4e379528470efe</data>
    </node>
    <node id="HIK">
      <data key="d0">MATRIX_ELEMENT</data>
      <data key="d1">hik is the element in the ith row and kth column of the hat matrix H, representing the influence of the kth observation on the fitted value of the ith observation</data>
      <data key="d2">679722cf8ce5ce5aee4e379528470efe</data>
    </node>
    <node id="YC">
      <data key="d0">FITTED_VALUES</data>
      <data key="d1">Yc is the random vector of fitted values, computed as HY, where H is the hat matrix and Y is the vector of response random variables
Yc is the vector of predicted values obtained by multiplying the hat matrix H by the vector Y
Yc is the vector of fitted values in the linear model, calculated as HY
Yc is the random vector of fitted values, calculated as HY</data>
      <data key="d2">1da117a2f92b2db00290d2a0bfc06beb,679722cf8ce5ce5aee4e379528470efe,74d190f10bf6e6936242ca3cdfc4a09f,7d074208b1259e7d84f9f870d3828bb6</data>
    </node>
    <node id="HX">
      <data key="d0">MATRIX</data>
      <data key="d1">HX is the result of the matrix operation X(X'X)^-1X', which simplifies to X</data>
      <data key="d2">1da117a2f92b2db00290d2a0bfc06beb</data>
    </node>
    <node id="VAR">
      <data key="d0">VARIANCE</data>
      <data key="d1">Var is the variance operator, used to calculate the variance of a random variable
Var is the variance function used to calculate the variance of a vector</data>
      <data key="d2">1da117a2f92b2db00290d2a0bfc06beb,74d190f10bf6e6936242ca3cdfc4a09f</data>
    </node>
    <node id="YB_I">
      <data key="d0">VECTOR</data>
      <data key="d1">Yb_i is the ith predicted value in the vector Yc
Yb(i) is the vector of fitted values calculated from the dataset with the ith observation removed.&gt;
Yb(i) is the fitted value of the response variable calculated from the dataset with the ith observation removed
yb(i) is the fitted value using the dataset with the ith observation removed</data>
      <data key="d2">0443ab5e20a4f6b2f243c989ef6c723a,09391efd3b8c510205098b548bc8dc74,1da117a2f92b2db00290d2a0bfc06beb,9e2ebbb113c00fa43f0af3c0696baf95</data>
    </node>
    <node id="EB">
      <data key="d0">VECTOR</data>
      <data key="d1">Eb is the residual vector obtained by subtracting the predicted values Yc from the observed values Y
Eb is the residual vector obtained by subtracting the fitted values from the observed values, defined as (In - H)Y
Eb is the vector of residuals, given by (In - H)Y
EB is the vector of residuals in the linear model, calculated as (In - H)Y
Eb is the random vector of residuals, calculated as (In - H)Y</data>
      <data key="d2">1da117a2f92b2db00290d2a0bfc06beb,2685edb9e8031c8ea725c43a40af22a8,5a0d392715f06d5e873f45ae06aa729a,74d190f10bf6e6936242ca3cdfc4a09f,7d074208b1259e7d84f9f870d3828bb6</data>
    </node>
    <node id="Y_HAT_I">
      <data key="d0">FITTED_VALUE</data>
      <data key="d1">y_hat_i is the fitted value for the ith observation, obtained from the linear regression model
y_hat_i is the fitted value for the ith observation in the regression model</data>
      <data key="d2">2685edb9e8031c8ea725c43a40af22a8,5a0d392715f06d5e873f45ae06aa729a</data>
    </node>
    <node id="EI">
      <data key="d0">RESIDUAL</data>
      <data key="d1">Ei is the ith residual in a regression model, with an expectation of zero</data>
      <data key="d2">2685edb9e8031c8ea725c43a40af22a8</data>
    </node>
    <node id="VAR_EI">
      <data key="d0">VARIANCE</data>
      <data key="d1">Var(Ei) is the variance of the ith residual, given by &#963;^2(1 - hii)</data>
      <data key="d2">2685edb9e8031c8ea725c43a40af22a8</data>
    </node>
    <node id="&#931;_SQUARED">
      <data key="d0">VARIANCE</data>
      <data key="d1">&#963;^2 is the variance of the error term in the regression model</data>
      <data key="d2">2685edb9e8031c8ea725c43a40af22a8</data>
    </node>
    <node id="COV_EB_Y">
      <data key="d0">COVARIANCE_MATRIX</data>
      <data key="d1">Cov(Eb, Y) is the covariance matrix of the vector of residuals Eb and the vector of response variables Y</data>
      <data key="d2">2685edb9e8031c8ea725c43a40af22a8</data>
    </node>
    <node id="COV">
      <data key="d0">COVARIANCE</data>
      <data key="d1">Cov is the covariance function used to calculate the covariance between vectors
Cov is the covariance operator used to calculate the covariance between vectors</data>
      <data key="d2">74d190f10bf6e6936242ca3cdfc4a09f,7d074208b1259e7d84f9f870d3828bb6</data>
    </node>
    <node id="0N_X_N">
      <data key="d0">MATRIX</data>
      <data key="d1">0n&#215;n is the n x n matrix whose entries are all equal to zero</data>
      <data key="d2">74d190f10bf6e6936242ca3cdfc4a09f</data>
    </node>
    <node id="0N&#215;N">
      <data key="d0">ZERO_MATRIX</data>
      <data key="d1">0n&#215;n is the n x n zero matrix</data>
      <data key="d2">7d074208b1259e7d84f9f870d3828bb6</data>
    </node>
    <node id="REGRESSION_OUTLIERS">
      <data key="d0">DATA_POINTS</data>
      <data key="d1">Regression outliers are data points with a large positive or negative residual, indicating they do not fit well with the model</data>
      <data key="d2">e593096f3805c2686423cb91ea276fe6</data>
    </node>
    <node id="COOKS_DISTANCE">
      <data key="d0">METRIC</data>
      <data key="d1">Cook's distance is a measure of influence that can be used to identify influential data points in a regression model
Cook's distance is a statistical measure used to identify influential observations in a regression analysis
Cook's distance is a measure of influence that quantifies how much the fitted values change when a particular observation is removed from the dataset. It takes into account both the response values and the input variates.&gt;
Cook's distance is a measure of how much the fitted values of all regression model predictions would change if an observation were to be excluded
Cook's distance (Di) is a measure of influence defined as (yb(i) - yb)^T(yb(i) - yb) / (ps2), where yb(i) is the predicted value with the ith observation removed
Cook's distance (Di) is a measure of influence of the ith observation, calculated as (yb(i) - yb)^T(yb(i) - yb) / (ps^2)
Cook's distance is a measure of the influence of a data point, combining information on leverage and standardized residuals</data>
      <data key="d2">09391efd3b8c510205098b548bc8dc74,323899f01972255cd3278bccee20d5d8,428db872e71a17a2cf7868b03a52def0,629ce6550294d332948e19171a4acd2d,7e05f1b457a496c8b3630e7044fc5981,9e2ebbb113c00fa43f0af3c0696baf95,e593096f3805c2686423cb91ea276fe6</data>
    </node>
    <node id="X_I">
      <data key="d0">VARIABLE</data>
      <data key="d1">X_i is the ith observation of the explanatory variable in the dataset</data>
      <data key="d2">bd05fe6a05f9a13d33c4f1b5a771ada5</data>
    </node>
    <node id="LEVERAGE">
      <data key="d0">STATISTIC</data>
      <data key="d1">Leverage is a measure of how far an observation is from the mean of the explanatory variable, indicating its influence on the fitted model
Leverage is a statistical concept that measures the distance of a data point from the center of the data
Leverage (hii) is a metric that measures the influence of the ith unit of observation in the regression analysis
Leverage is a measure of how far an observation is from the center of the predictor space
Leverage is a measure of how far an independent variable value of a data point is from the mean of that variable</data>
      <data key="d2">09391efd3b8c510205098b548bc8dc74,428db872e71a17a2cf7868b03a52def0,629ce6550294d332948e19171a4acd2d,7e05f1b457a496c8b3630e7044fc5981,bd05fe6a05f9a13d33c4f1b5a771ada5</data>
    </node>
    <node id="INFLUENCE_INDEX_PLOT">
      <data key="d0">FUNCTION</data>
      <data key="d1">InfluenceIndexPlot is a function from the car package used to plot the leverages (hat-values) for a given model</data>
      <data key="d2">bd05fe6a05f9a13d33c4f1b5a771ada5</data>
    </node>
    <node id="CAR_PACKAGE">
      <data key="d0">SOFTWARE</data>
      <data key="d1">car is a package in R that provides functions for regression analysis
The car package is an R package used for statistical analysis, including functions for regression diagnostics and leverage plots.</data>
      <data key="d2">bd05fe6a05f9a13d33c4f1b5a771ada5,f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </node>
    <node id="MASS_PACKAGE">
      <data key="d0">SOFTWARE</data>
      <data key="d1">MASS is a package in R that provides a variety of statistical and graphical techniques
The MASS package is an R package that provides a variety of statistical and graphical techniques, including linear and generalized linear models, nonlinear regression models, classification, and clustering.</data>
      <data key="d2">bd05fe6a05f9a13d33c4f1b5a771ada5,f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </node>
    <node id="FIGURE_8_1">
      <data key="d0">FIGURE</data>
      <data key="d1">Figure 8.1 is an index plot of the leverages for the mammals dataset regression model</data>
      <data key="d2">bd05fe6a05f9a13d33c4f1b5a771ada5</data>
    </node>
    <node id="REGRESSION">
      <data key="d0">STATISTICAL_METHOD</data>
      <data key="d1">Regression is a statistical method used for modeling the relationship between a dependent variable and one or more independent variables. In this context, it refers to the regression of the logarithm of average brain weight on the logarithm of average body weight.
</data>
      <data key="d2">428db872e71a17a2cf7868b03a52def0,f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </node>
    <node id="LOGARITHM">
      <data key="d0">MATHEMATICAL_FUNCTION</data>
      <data key="d1">Logarithm is a mathematical function that is used to transform data, often to make it more suitable for analysis. In this context, it is used to transform the average brain weight and average body weight in the regression model.</data>
      <data key="d2">f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </node>
    <node id="INDEX_PLOT">
      <data key="d0">GRAPHICAL_REPRESENTATION</data>
      <data key="d1">An index plot is a graphical representation that displays the values of a variable against their index or row number. In this context, it is used to show the leverages for the regression model.
Index plot is a type of plot that displays the absolute standardised residuals against the observation index</data>
      <data key="d2">428db872e71a17a2cf7868b03a52def0,f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </node>
    <node id="RULE_OF_THUMB_THRESHOLD">
      <data key="d0">THRESHOLD</data>
      <data key="d1">The rule of thumb threshold is a commonly used threshold for identifying influential observations in regression analysis. It is typically set at 2 times the average leverage value.</data>
      <data key="d2">f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </node>
    <node id="EXERCISE_21">
      <data key="d0">EXERCISE</data>
      <data key="d1">Exercise 21 is a problem that asks the reader to show a specific formula for calculating leverages in simple linear regression. It provides a hint to parametrize the model in a certain way to simplify the matrix calculations.</data>
      <data key="d2">f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </node>
    <node id="RI">
      <data key="d0">STANDARDISED_RESIDUAL</data>
      <data key="d1">Ri is the standardised residual for the ith observation, derived by dividing the raw residual by an estimate of its standard deviation
RI is the ith standardised residual calculated as &#1013;bi divided by s(1 &#8722; hii)^1/2
ri is the standardised residual for the ith observation</data>
      <data key="d2">90b7e0427699cc1bb461e37939935138,98d6982108f2d42fe0437bff8c666e17,c47968226557bc2eb5aec5bb7994fd0e</data>
    </node>
    <node id="EBI">
      <data key="d0">RAW_RESIDUAL</data>
      <data key="d1">Eb_i is the raw residual for the ith observation, the difference between the observed and predicted values</data>
      <data key="d2">90b7e0427699cc1bb461e37939935138</data>
    </node>
    <node id="EPSILON_BI">
      <data key="d0">ERROR_TERM</data>
      <data key="d1">&#1013;bi is the ith error term in the regression model
Epsilon bi (&#1013;bi) is the residual for the ith observation in the regression model</data>
      <data key="d2">0443ab5e20a4f6b2f243c989ef6c723a,c47968226557bc2eb5aec5bb7994fd0e</data>
    </node>
    <node id="DATASET_SIZE">
      <data key="d0">SIZE</data>
      <data key="d1">The dataset size influences the threshold for identifying outliers based on the standardised residuals
Dataset size refers to the number of observations in the dataset being analyzed</data>
      <data key="d2">428db872e71a17a2cf7868b03a52def0,c47968226557bc2eb5aec5bb7994fd0e</data>
    </node>
    <node id="THRESHOLD">
      <data key="d0">CRITERION</data>
      <data key="d1">The threshold for identifying outliers is set to 2 for small to moderately sized datasets and 3 for large datasets</data>
      <data key="d2">c47968226557bc2eb5aec5bb7994fd0e</data>
    </node>
    <node id="HUMAN_OBSERVATION">
      <data key="d0">OBSERVATION</data>
      <data key="d1">Human observation in the mammals dataset has a standardised residual larger than 2
The observation for human is a data point in the mammals dataset that is flagged as potentially influential in the "Residuals vs Leverage" plot.&gt;
The observation for Human has the largest Cook's distance, indicating high influence in the mammals dataset</data>
      <data key="d2">323899f01972255cd3278bccee20d5d8,9e2ebbb113c00fa43f0af3c0696baf95,c47968226557bc2eb5aec5bb7994fd0e</data>
    </node>
    <node id="WATER_OPOSSUM_OBSERVATION">
      <data key="d0">OBSERVATION</data>
      <data key="d1">Water opposum observation in the mammals dataset has a standardised residual larger than 2
The observation for water opossum is a data point in the mammals dataset that is flagged as potentially influential in the "Residuals vs Leverage" plot.&gt;</data>
      <data key="d2">9e2ebbb113c00fa43f0af3c0696baf95,c47968226557bc2eb5aec5bb7994fd0e</data>
    </node>
    <node id="RHESUS_MONKEY_OBSERVATION">
      <data key="d0">OBSERVATION</data>
      <data key="d1">Rhesus monkey observation in the mammals dataset has a standardised residual larger than 2</data>
      <data key="d2">c47968226557bc2eb5aec5bb7994fd0e</data>
    </node>
    <node id="RHESUS_MONKEY">
      <data key="d0">ANIMAL</data>
      <data key="d1">Rhesus monkey is a species of animal that may be included in the mammals dataset for analysis</data>
      <data key="d2">428db872e71a17a2cf7868b03a52def0</data>
    </node>
    <node id="MODEL_FIT">
      <data key="d0">STATISTICAL_MODEL</data>
      <data key="d1">Model fit is the measure of how well a statistical model fits the data</data>
      <data key="d2">428db872e71a17a2cf7868b03a52def0</data>
    </node>
    <node id="LOG_AVERAGE_BRAIN_WEIGHT">
      <data key="d0">VARIABLE</data>
      <data key="d1">Log average brain weight is a variable used in the regression analysis, representing the logarithm of the average brain weight of mammals
Logarithm of average brain weight is the dependent variable in the regression analysis</data>
      <data key="d2">323899f01972255cd3278bccee20d5d8,428db872e71a17a2cf7868b03a52def0</data>
    </node>
    <node id="LOG_AVERAGE_BODY_WEIGHT">
      <data key="d0">VARIABLE</data>
      <data key="d1">Log average body weight is a variable used in the regression analysis, representing the logarithm of the average body weight of mammals
Logarithm of average body weight is the independent variable in the regression analysis</data>
      <data key="d2">323899f01972255cd3278bccee20d5d8,428db872e71a17a2cf7868b03a52def0</data>
    </node>
    <node id="INFLUENTIAL_OBSERVATION">
      <data key="d0">DATA_POINT</data>
      <data key="d1">An influential observation is a data point whose removal causes a large change to the fitted model</data>
      <data key="d2">428db872e71a17a2cf7868b03a52def0</data>
    </node>
    <node id="RESIDUALS_VS_LEVERAGE_PLOT">
      <data key="d0">PLOT_TYPE</data>
      <data key="d1">Residuals vs leverage plot is a diagnostic plot used to identify influential observations in a regression analysis
The "Residuals vs Leverage" plot is a graphical tool used in regression analysis to identify influential data points. It shows the residuals plotted against the leverage values of each observation.&gt;</data>
      <data key="d2">428db872e71a17a2cf7868b03a52def0,9e2ebbb113c00fa43f0af3c0696baf95</data>
    </node>
    <node id="WATER_OPOSSUM">
      <data key="d0">ANIMAL</data>
      <data key="d1">Water opossum is a species of animal that is flagged as an influential observation in the mammals dataset</data>
      <data key="d2">428db872e71a17a2cf7868b03a52def0</data>
    </node>
    <node id="MUSK_SHREW">
      <data key="d0">ANIMAL</data>
      <data key="d1">Musk shrew is a species of animal that is flagged as an influential observation in the mammals dataset</data>
      <data key="d2">428db872e71a17a2cf7868b03a52def0</data>
    </node>
    <node id="MUSK_SHREW_OBSERVATION">
      <data key="d0">DATA_POINT</data>
      <data key="d1">The observation for musk shrew is a data point in the mammals dataset that is flagged as potentially influential in the "Residuals vs Leverage" plot.&gt;</data>
      <data key="d2">9e2ebbb113c00fa43f0af3c0696baf95</data>
    </node>
    <node id="BETA_HAT_I">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">Beta hat (&#946;b(i)) is the vector of parameter estimates calculated from the dataset with the ith observation removed.&gt;
Beta hat (&#946;b(i)) is the least squares estimator of the parameter Beta calculated from the dataset with the ith observation removed</data>
      <data key="d2">0443ab5e20a4f6b2f243c989ef6c723a,9e2ebbb113c00fa43f0af3c0696baf95</data>
    </node>
    <node id="DI">
      <data key="d0">DIAGNOSTIC</data>
      <data key="d1">Di is a diagnostic measure used to identify influential data points in a regression analysis, defined as (yb(i) - yb)^T(yb(i) - yb)/ps^2 or (&#946;b(i) - &#946;b)TXTX(&#946;b(i) - &#946;b)/ps^2
Di is the Cook's distance for the ith data point, a measure of the influence of the data point on the fitted model
Di is the Cook's distance for the ith observation, a measure of influence in regression analysis</data>
      <data key="d2">0443ab5e20a4f6b2f243c989ef6c723a,323899f01972255cd3278bccee20d5d8,98d6982108f2d42fe0437bff8c666e17</data>
    </node>
    <node id="TXTX">
      <data key="d0">MATRIX</data>
      <data key="d1">TXTX is the matrix product of the transpose of X (XT) and X, used in the calculation of the Cook's distance</data>
      <data key="d2">0443ab5e20a4f6b2f243c989ef6c723a</data>
    </node>
    <node id="PS_SQUARED">
      <data key="d0">VARIANCE</data>
      <data key="d1">Ps^2 is the estimated variance used in the calculation of the Cook's distance</data>
      <data key="d2">0443ab5e20a4f6b2f243c989ef6c723a</data>
    </node>
    <node id="R_SQUARED_I">
      <data key="d0">RESIDUAL</data>
      <data key="d1">Ri^2 is the squared standardised residual for the ith observation</data>
      <data key="d2">0443ab5e20a4f6b2f243c989ef6c723a</data>
    </node>
    <node id="BI">
      <data key="d0">SUBSCRIPT</data>
      <data key="d1">bi is a subscript used in the calculation of the squared error term</data>
      <data key="d2">98d6982108f2d42fe0437bff8c666e17</data>
    </node>
    <node id="PS2">
      <data key="d0">VARIABLE</data>
      <data key="d1">ps2 is a variable used in the calculation of the squared error term</data>
      <data key="d2">98d6982108f2d42fe0437bff8c666e17</data>
    </node>
    <node id="HI">
      <data key="d0">SUBSCRIPT</data>
      <data key="d1">hi is a subscript used in the calculation of the leverage and influence terms</data>
      <data key="d2">98d6982108f2d42fe0437bff8c666e17</data>
    </node>
    <node id="F_DISTRIBUTION">
      <data key="d0">DISTRIBUTION</data>
      <data key="d1">F-distribution is the distribution used to determine if a data point is influential based on its Cook's distance
Fp,n-p(0.5) is the F-distribution with p and n-p degrees of freedom, used as a threshold for Cook's distance</data>
      <data key="d2">09391efd3b8c510205098b548bc8dc74,98d6982108f2d42fe0437bff8c666e17</data>
    </node>
    <node id="FIGURE_8_4">
      <data key="d0">FIGURE</data>
      <data key="d1">Figure 8.4 is an index plot of the Cook's distances for the regression of logarithm of average brain weight on logarithm of average body weight for the mammals
Figure 8.4 is an index plot of the Cook's distances for the regression of logarithm of average brain weight on logarithm of average body weight for the mammals dataset</data>
      <data key="d2">323899f01972255cd3278bccee20d5d8,98d6982108f2d42fe0437bff8c666e17</data>
    </node>
    <node id="FP_N_P">
      <data key="d0">CRITICAL_VALUE</data>
      <data key="d1">Fp,n-p(0.5) is the critical value from the F distribution used to flag influential observations</data>
      <data key="d2">323899f01972255cd3278bccee20d5d8</data>
    </node>
    <node id="STATISTICS">
      <data key="d0">DISCIPLINE</data>
      <data key="d1">Statistics is the field of study that deals with the collection, analysis, interpretation, presentation, and organization of data</data>
      <data key="d2">83bb91cf725e5116ca2f5748fddccfae</data>
    </node>
    <node id="DATA_ENTRY_ERROR">
      <data key="d0">ERROR</data>
      <data key="d1">A data entry error is a mistake made during the input of data, which can result in an influential data point</data>
      <data key="d2">83bb91cf725e5116ca2f5748fddccfae</data>
    </node>
    <node id="ANOTHER_POPULATION">
      <data key="d0">POPULATION</data>
      <data key="d1">Another population refers to a group of observations that are not part of the primary population of interest, and may be treated as outliers</data>
      <data key="d2">83bb91cf725e5116ca2f5748fddccfae</data>
    </node>
    <node id="COMPLETE_DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The complete dataset is the full set of observations used in the analysis, including all data points</data>
      <data key="d2">83bb91cf725e5116ca2f5748fddccfae</data>
    </node>
    <node id="ELEPHANT_SPECIES">
      <data key="d0">SPECIES</data>
      <data key="d1">Elephant species are a type of mammal that can be highly influential in the mammals dataset when using original variables</data>
      <data key="d2">83bb91cf725e5116ca2f5748fddccfae</data>
    </node>
    <node id="ROBUST_REGRESSION">
      <data key="d0">METHOD</data>
      <data key="d1">Robust regression is a statistical method that provides a systematic approach to down-weighting influential points when fitting a model
Robust regression is a method for dealing with influential points in data, providing a systematic approach to down-weighting these points when fitting a model
Robust regression is an alternative approach to handle influential data points, not discussed in the module
Robust regression is an alternative approach to regression analysis that is not discussed in the module, designed to handle outliers and leverage points more effectively</data>
      <data key="d2">09391efd3b8c510205098b548bc8dc74,629ce6550294d332948e19171a4acd2d,7e05f1b457a496c8b3630e7044fc5981,83bb91cf725e5116ca2f5748fddccfae</data>
    </node>
    <node id="YBI">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">Ybi is the estimated value of the response variable for a given observation, calculated using the fitted model</data>
      <data key="d2">83bb91cf725e5116ca2f5748fddccfae</data>
    </node>
    <node id="STANDARDISED_RESIDUAL">
      <data key="d0">METRIC</data>
      <data key="d1">The ith standardised or internally studentised residual (ri) is a metric defined as &#1013;bi / s(1 - hii)^1/2, where s^2 is an unbiased estimate of the error variance &#963;^2
A standardised residual is a residual that has been scaled by the standard deviation of the residuals</data>
      <data key="d2">09391efd3b8c510205098b548bc8dc74,7e05f1b457a496c8b3630e7044fc5981</data>
    </node>
    <node id="INFLUENTIAL_DATA_POINT">
      <data key="d0">DATA_POINT</data>
      <data key="d1">An influential data point is an observation that has a significant impact on the regression model
An influential data point is an observation that has a significant impact on the regression line, potentially altering the slope or intercept</data>
      <data key="d2">09391efd3b8c510205098b548bc8dc74,629ce6550294d332948e19171a4acd2d</data>
    </node>
    <node id="REGRESSION_OUTLIER">
      <data key="d0">DATA_POINT</data>
      <data key="d1">A regression outlier is an observation that has a large residual
A regression outlier is an observation that has a large residual, meaning it is far from the regression line in the vertical direction</data>
      <data key="d2">09391efd3b8c510205098b548bc8dc74,629ce6550294d332948e19171a4acd2d</data>
    </node>
    <node id="HIGH_LEVERAGE_DATA_POINT">
      <data key="d0">DATA_POINT</data>
      <data key="d1">A high leverage data point is an observation that has extreme values in the predictor variables, potentially having a large influence on the regression line</data>
      <data key="d2">629ce6550294d332948e19171a4acd2d</data>
    </node>
    <node id="PLOTS">
      <data key="d0">VISUALIZATION</data>
      <data key="d1">Various plots, such as scatter plots, residual plots, and influence plots, can be used to illustrate leverage, standardized residuals, and Cook's distance</data>
      <data key="d2">629ce6550294d332948e19171a4acd2d</data>
    </node>
    <node id="RULES_OF_THUMB">
      <data key="d0">GUIDELINES</data>
      <data key="d1">Rules of thumb are guidelines for interpreting the values of leverage, standardized residuals, and Cook's distance to identify influential data points</data>
      <data key="d2">629ce6550294d332948e19171a4acd2d</data>
    </node>
    <node id="HANDLING_INFLUENTIAL_DATA_POINTS">
      <data key="d0">DATA_HANDLING</data>
      <data key="d1">Options on how to handle influential data points include removing them, transforming the data, or using robust regression methods</data>
      <data key="d2">629ce6550294d332948e19171a4acd2d</data>
    </node>
    <node id="GENERALIZED_LINEAR_MODELS_BOOK">
      <data key="d0">REFERENCE_MATERIAL</data>
      <data key="d1">Generalized linear models with examples in R (2018) by Dunn and Smyth is a reference book that covers related material on robust regression and influential data points</data>
      <data key="d2">629ce6550294d332948e19171a4acd2d</data>
    </node>
    <node id="DATA_ANALYSIS_AND_GRAPHICS_BOOK">
      <data key="d0">REFERENCE_MATERIAL</data>
      <data key="d1">Data analysis and graphics using R: an example-based approach (2010) by Maindonald and Braun is a reference book that covers related material on robust regression and influential data points</data>
      <data key="d2">629ce6550294d332948e19171a4acd2d</data>
    </node>
    <node id="CATEGORICAL_PREDICTOR_VARIABLES">
      <data key="d0">PREDICTOR_VARIABLE</data>
      <data key="d1">Categorical predictor variables, also known as factors, are qualitative explanatory variables that can take on a limited number of discrete values or levels</data>
      <data key="d2">629ce6550294d332948e19171a4acd2d</data>
    </node>
    <node id="GENDER">
      <data key="d0">CATEGORICAL_VARIABLE</data>
      <data key="d1">Gender is an example of a categorical predictor variable that can take on values such as male, female, or other
Gender is an example of a qualitative explanatory variable that can be used as a categorical predictor in statistical models</data>
      <data key="d2">39aef0392258a09378ce45d8b03a268a,629ce6550294d332948e19171a4acd2d</data>
    </node>
    <node id="DEGREE_COURSE">
      <data key="d0">CATEGORICAL_VARIABLE</data>
      <data key="d1">Degree course is an example of a categorical predictor variable that can take on values such as Data Science, MathStat, and MORSE
Degree course is an example of a qualitative explanatory variable that can be used as a categorical predictor in statistical models, such as Data Science, MathStat, and MORSE</data>
      <data key="d2">39aef0392258a09378ce45d8b03a268a,629ce6550294d332948e19171a4acd2d</data>
    </node>
    <node id="LEVELS">
      <data key="d0">CATEGORICAL_VARIABLE_ATTRIBUTE</data>
      <data key="d1">Levels are the values that a categorical predictor variable can take, such as Data Science, MathStat, and MORSE for the degree course variable</data>
      <data key="d2">629ce6550294d332948e19171a4acd2d</data>
    </node>
    <node id="QUANTITATIVE_PREDICTOR">
      <data key="d0">VARIABLE</data>
      <data key="d1">Quantitative predictor variables are numerical variables used in statistical models to predict outcomes</data>
      <data key="d2">39aef0392258a09378ce45d8b03a268a</data>
    </node>
    <node id="QUALITATIVE_PREDICTOR">
      <data key="d0">VARIABLE</data>
      <data key="d1">Qualitative predictor variables, also known as categorical predictor variables or factors, are non-numerical variables used in statistical models to predict outcomes</data>
      <data key="d2">39aef0392258a09378ce45d8b03a268a</data>
    </node>
    <node id="RETAIL_DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The Retail dataset is a collection of data that includes information about sales volumes and other variables related to retail stores
The Retail dataset contains information about sales volumes and brands of stores</data>
      <data key="d2">39aef0392258a09378ce45d8b03a268a,ab898d123f48e380384aa01e035a83ca</data>
    </node>
    <node id="AVERAGE_RESPONSE">
      <data key="d0">STATISTICAL_MEASURE</data>
      <data key="d1">The average response is a statistical measure that can be modeled to be dependent on the value that a categorical predictor takes</data>
      <data key="d2">39aef0392258a09378ce45d8b03a268a</data>
    </node>
    <node id="COMPARATIVE_BOXPLOTS">
      <data key="d0">VISUALIZATION</data>
      <data key="d1">Comparative boxplots are a type of visualization used to illustrate the relationship between a categorical variable and a quantitative variable
Comparative boxplots are used to illustrate the relationship between a categorical variable and a quantitative variable, such as sales volumes and brands</data>
      <data key="d2">39aef0392258a09378ce45d8b03a268a,ab898d123f48e380384aa01e035a83ca</data>
    </node>
    <node id="BOXPLOT_COMMAND">
      <data key="d0">FUNCTION</data>
      <data key="d1">The boxplot command is a function used to produce comparative boxplots of a quantitative variable grouped by a categorical predictor variable</data>
      <data key="d2">39aef0392258a09378ce45d8b03a268a</data>
    </node>
    <node id="SALES_VOLUMES">
      <data key="d0">QUANTITATIVE_VARIABLE</data>
      <data key="d1">Sales volumes are the quantitative data points representing the sales of stores from different brands</data>
      <data key="d2">ab898d123f48e380384aa01e035a83ca</data>
    </node>
    <node id="BRAND_C">
      <data key="d0">CATEGORICAL_VARIABLE</data>
      <data key="d1">Brand C is one of the brands in the Retail dataset, with stores that tend to have higher sales volumes than the other brands
Brand C is one of the brands considered in the analysis, with an average sales volume of 126,680 units, substantially higher than the other two brands.
Brand C is one of the brands of retail stores whose sales data is being analyzed. Observations for Brand C tend to lie above the fitted regression line, suggesting that Brand C's sales volume is influenced by factors other than price.&gt;
Brand C is one of the three store brands considered in the model
Brand C is one of the categories of store brands in the regression model
Brand C is one of the brands that stores can belong to, represented by the indicator variable xjC which is 1 if store j is of Brand C and 0 otherwise
Brand C is one of the three brands in the study&gt;
Brand C is one of the groups defined by the brand variable, representing stores of a specific brand
Brand C is one of the brands in the retail example, and its sales volumes are compared to Brand A
Brand C is one of the brands of stores in the dataset
Brand C is another brand being analyzed in the sales data, distinct from Brand A and Brand B
Brand C is one of the categories in the categorical predictor, representing a type of store whose sales volume is compared to Brand A
Brand C is one of the levels in the categorical predictor used in the linear model for the Retail data
Brand C is one of the brands of stores considered in the model
Brand C is one of the brands considered in the model, and its sales volume is predicted by the model
Brand C is one of the categories of the brand variable in the model and is used as the reference category in the second parameterisation
Brand C is a specific brand category used as the reference category in the model equations
Brand C is one of the brands in the retail data, whose observations tend to lie above the fitted line in the initial regression model
Brand C is one of the store brands being analyzed in the regression model
Brand C is another brand in the dataset, with its own regression line
Brand C is one of the brands considered in the model, with its own coefficient for the intercept and interaction with price
Brand C is a type of store with a specific sales model where sales are estimated as 162.879 - 0.231 * pricei if the store is of Brand C
Brand C is a brand of stores being analyzed in the model, with a less steep gradient for the fitted regression line compared to Brand A and Brand B</data>
      <data key="d2">06199787dd7f75f7338dd24d4f3dc26e,096afa471635bc59c3bfa9af4d04d625,0cb40986e6c2bb439e1ffcaae2df96ac,1820d10ee0f23f34b3ea88ba475bc52d,1b523d1edabe381403fc470a9b8d47fa,1d141ab04db553f78a313e430e54abb5,228bdca7843406def245d755e8df49f6,3dd24a54028976ba54304ec7169bb74b,48971100deb5bb374a41c1f2b7b2a86a,7037e0369bfdaad5a730cabb2b44831c,7a605c3b689bec7ab2c46df9c123e3f3,825b600cbab3535ce67e9f561ddcb84b,8326c645426789920a99ed373725fa0e,86ece4718d27d1a6c6a1f448cc850e2b,906eb7d6b49fa360e7e5b65c56cd4d76,9854704301b8df256ca1013b8d53dfac,a1fc936df848a0fbc791e4bcc9b527b6,ab898d123f48e380384aa01e035a83ca,ac15b639b0849006471dfe102376c2c0,adbc52b340a69a8633c919c4fd2cd3f6,baa0dc3d4ec0e51c0a321e5579caf8aa,c103c6d096d52868eda26d991194b5f2,e079b7c92d5c0b009ff02040eb652bc6</data>
    </node>
    <node id="BRAND_A">
      <data key="d0">CATEGORICAL_VARIABLE</data>
      <data key="d1">Brand A is one of the brands in the Retail dataset, with stores that have a sample mean sales volume of 109,679 units
Brand A is one of the brands considered in the analysis, with an average sales volume of 109,679 units.
Brand A is one of the brands of retail stores whose sales data is being analyzed. Observations for Brand A tend to lie below the fitted regression line, suggesting that Brand A's sales volume is influenced by factors other than price.&gt;
Brand A is one of the three store brands considered in the model
Brand A is one of the categories of store brands in the regression model
Brand A is one of the brands that stores can belong to, represented by the indicator variable xjA which is calculated as 1 - xjB - xjC
Brand A is one of the three brands in the study&gt;
Brand A is one of the groups defined by the brand variable, representing stores of a specific brand
Brand A is one of the brands in the retail example, and the CEO is looking after the stores of this brand
Brand A is one of the brands of stores in the dataset
Brand A is a brand that is being compared against in the context of sales and marketing
Brand A is the baseline or reference category in the regression model, against which the sales volumes of Brand B and Brand C stores are compared
Brand A is the baseline or reference category in the categorical predictor used in the linear model for the Retail data
Brand A is one of the brands of stores considered in the model
Brand A is one of the categories of the brand variable in the model
Brand A is one of the brands in the retail data, whose observations also tend to lie below the fitted line in the initial regression model
Brand A is one of the store brands being analyzed in the regression model
Brand A is one of the brands considered in the model, used as a reference for comparison
Brand A is a type of store with a specific sales model where sales are estimated as 210.379 - 0.657 * pricei if the store is of Brand A
Brand A is one of the brands of stores being analyzed in the model, with a steeper gradient for the fitted regression line than Brand C</data>
      <data key="d2">06199787dd7f75f7338dd24d4f3dc26e,0cb40986e6c2bb439e1ffcaae2df96ac,1820d10ee0f23f34b3ea88ba475bc52d,1b523d1edabe381403fc470a9b8d47fa,1d141ab04db553f78a313e430e54abb5,228bdca7843406def245d755e8df49f6,3dd24a54028976ba54304ec7169bb74b,48971100deb5bb374a41c1f2b7b2a86a,7037e0369bfdaad5a730cabb2b44831c,7a605c3b689bec7ab2c46df9c123e3f3,8326c645426789920a99ed373725fa0e,906eb7d6b49fa360e7e5b65c56cd4d76,9854704301b8df256ca1013b8d53dfac,a1fc936df848a0fbc791e4bcc9b527b6,ab898d123f48e380384aa01e035a83ca,ac15b639b0849006471dfe102376c2c0,adbc52b340a69a8633c919c4fd2cd3f6,baa0dc3d4ec0e51c0a321e5579caf8aa,c103c6d096d52868eda26d991194b5f2,e079b7c92d5c0b009ff02040eb652bc6</data>
    </node>
    <node id="BRAND_B">
      <data key="d0">CATEGORICAL_VARIABLE</data>
      <data key="d1">Brand B is one of the brands in the Retail dataset, with stores that have a sample mean sales volume of 105,728 units
Brand B is one of the brands considered in the analysis, with an average sales volume of 105,728 units.
Brand B is one of the brands of retail stores whose sales data is being analyzed. Observations for Brand B also tend to lie below the fitted regression line, suggesting that Brand B's sales volume is influenced by factors other than price.&gt;
Brand B is one of the three store brands considered in the model
Brand B is one of the categories of store brands in the regression model
Brand B is one of the brands that stores can belong to, represented by the indicator variable xjB which is 1 if store j is of Brand B and 0 otherwise
Brand B is one of the three brands in the study&gt;
Brand B is one of the groups defined by the brand variable, representing stores of a specific brand
Brand B is one of the brands in the retail example, and its sales volumes are compared to Brand A
Brand B is one of the brands of stores in the dataset
Brand B is one of the brands being analyzed in the sales data, distinct from Brand A
Brand B is one of the categories in the categorical predictor, representing a type of store whose sales volume is compared to Brand A
Brand B is one of the levels in the categorical predictor used in the linear model for the Retail data
Brand B is one of the brands of stores considered in the model
Brand B is one of the categories of the brand variable in the model
Brand B is one of the brands in the retail data, whose observations tend to lie below the fitted line in the initial regression model
Brand B is one of the store brands being analyzed in the regression model
Brand B is one of the brands in the dataset, with its own regression line
Brand B is one of the brands considered in the model, with its own coefficient for the intercept and interaction with price
Brand B is a type of store with a specific sales model where sales are estimated as 225.252 - 0.803 * pricei if the store is of Brand B
Brand B is another brand of stores being analyzed in the model, also with a steeper gradient for the fitted regression line than Brand C</data>
      <data key="d2">06199787dd7f75f7338dd24d4f3dc26e,0cb40986e6c2bb439e1ffcaae2df96ac,1820d10ee0f23f34b3ea88ba475bc52d,1b523d1edabe381403fc470a9b8d47fa,1d141ab04db553f78a313e430e54abb5,228bdca7843406def245d755e8df49f6,3dd24a54028976ba54304ec7169bb74b,48971100deb5bb374a41c1f2b7b2a86a,7037e0369bfdaad5a730cabb2b44831c,7a605c3b689bec7ab2c46df9c123e3f3,825b600cbab3535ce67e9f561ddcb84b,8326c645426789920a99ed373725fa0e,906eb7d6b49fa360e7e5b65c56cd4d76,9854704301b8df256ca1013b8d53dfac,a1fc936df848a0fbc791e4bcc9b527b6,ab898d123f48e380384aa01e035a83ca,ac15b639b0849006471dfe102376c2c0,adbc52b340a69a8633c919c4fd2cd3f6,baa0dc3d4ec0e51c0a321e5579caf8aa,c103c6d096d52868eda26d991194b5f2,e079b7c92d5c0b009ff02040eb652bc6</data>
    </node>
    <node id="REGRESSION_MODELS">
      <data key="d0">STATISTICAL_MODEL</data>
      <data key="d1">Regression models are used to model the mean of a quantitative variable, such as sales volumes, based on a categorical predictor variable, such as brand
Regression models are statistical models used to predict the mean of a dependent variable based on one or more independent variables.</data>
      <data key="d2">ab898d123f48e380384aa01e035a83ca,e079b7c92d5c0b009ff02040eb652bc6</data>
    </node>
    <node id="MEDIAN">
      <data key="d0">STATISTICAL_MEASURE</data>
      <data key="d1">The median is a statistical measure shown as a horizontal line in data visualization.</data>
      <data key="d2">e079b7c92d5c0b009ff02040eb652bc6</data>
    </node>
    <node id="SALES_VOLUME">
      <data key="d0">DEPENDENT_VARIABLE</data>
      <data key="d1">Sales volume is the dependent variable in the regression model, representing the total units sold.
Sales volume is the dependent variable in the linear regression model, which is being predicted based on price and brand.&gt;
Sales volume is the dependent variable in the linear regression model, representing the quantity of units sold
Sales volume is a variable representing the sales volume of stores
Sales volume is the quantity of sales for a particular brand, which the model predicts for Brand C
Sales volume is the dependent variable in the model, which is influenced by price and brand
Sales volume is the response variable in the regression model, representing the quantity of products sold.</data>
      <data key="d2">06199787dd7f75f7338dd24d4f3dc26e,096afa471635bc59c3bfa9af4d04d625,7a605c3b689bec7ab2c46df9c123e3f3,b0ca3e6c22c4cf884d03b1f6f82be5df,b6870535f3975c49d45e62fbe475f198,baa0dc3d4ec0e51c0a321e5579caf8aa,e079b7c92d5c0b009ff02040eb652bc6</data>
    </node>
    <node id="STATISTICAL_MODEL">
      <data key="d0">MODEL_TYPE</data>
      <data key="d1">A statistical model is a mathematical representation of the relationships between variables, used here to predict sales volume.</data>
      <data key="d2">e079b7c92d5c0b009ff02040eb652bc6</data>
    </node>
    <node id="FIGURE_9.2">
      <data key="d0">DATA_VISUALIZATION</data>
      <data key="d1">Figure 9.2 is a scatterplot of sales against price, with the fitted regression line and color-coded data points according to brand.</data>
      <data key="d2">e079b7c92d5c0b009ff02040eb652bc6</data>
    </node>
    <node id="DATAPOINTS">
      <data key="d0">DATA_POINTS</data>
      <data key="d1">Datapoints are individual pieces of data plotted on the scatterplot, with different plotting symbols and color-coding according to brand.</data>
      <data key="d2">e079b7c92d5c0b009ff02040eb652bc6</data>
    </node>
    <node id="MU_A">
      <data key="d0">PARAMETER</data>
      <data key="d1">&#181;A is the intercept parameter for Brand A in the linear regression model, representing the expected sales volume when price is zero for Brand A.&gt;
Mu_A (&#181;A) is a parameter in the linear regression model, representing the effect of predictor A
&#181;A is the intercept parameter for Brand A in the regression model&gt;
&#181;A is the parameter in the linear model for stores of Brand A, representing the expected sales volume for Brand A</data>
      <data key="d2">1b523d1edabe381403fc470a9b8d47fa,48971100deb5bb374a41c1f2b7b2a86a,7a605c3b689bec7ab2c46df9c123e3f3,aeddef300427d211c74c6008b5b6b328</data>
    </node>
    <node id="MU_B">
      <data key="d0">PARAMETER</data>
      <data key="d1">&#181;B is the intercept parameter for Brand B in the linear regression model, representing the expected sales volume when price is zero for Brand B.&gt;
Mu_B (&#181;B) is a parameter in the linear regression model, representing the effect of predictor B
&#181;B is the intercept parameter for Brand B in the regression model&gt;
&#181;B is the parameter in the linear model for stores of Brand B, representing the expected sales volume for Brand B
Mu hat (&#181;b) is the intercept coefficient for Brand A in the model</data>
      <data key="d2">1b523d1edabe381403fc470a9b8d47fa,48971100deb5bb374a41c1f2b7b2a86a,7a605c3b689bec7ab2c46df9c123e3f3,adbc52b340a69a8633c919c4fd2cd3f6,aeddef300427d211c74c6008b5b6b328</data>
    </node>
    <node id="MU_C">
      <data key="d0">PARAMETER</data>
      <data key="d1">&#181;C is the intercept parameter for Brand C in the linear regression model, representing the expected sales volume when price is zero for Brand C.&gt;
Mu_C (&#181;C) is a parameter in the linear regression model, representing the effect of predictor C
&#181;C is the intercept parameter for Brand C in the regression model&gt;
&#181;C is the parameter in the linear model for stores of Brand C, representing the expected sales volume for Brand C</data>
      <data key="d2">1b523d1edabe381403fc470a9b8d47fa,48971100deb5bb374a41c1f2b7b2a86a,7a605c3b689bec7ab2c46df9c123e3f3,aeddef300427d211c74c6008b5b6b328</data>
    </node>
    <node id="BRAND_MODEL1">
      <data key="d0">MODEL</data>
      <data key="d1">Brand Model 1 is the parallel lines model implemented in R using the lm function, with sales as the dependent variable and brand and price as independent variables
Brand.model1 is the linear model implemented in R, which includes the brand and price variables</data>
      <data key="d2">8326c645426789920a99ed373725fa0e,ee295ebc4c2d6a2a5c738796fcc2ab71</data>
    </node>
    <node id="MUA">
      <data key="d0">PARAMETER</data>
      <data key="d1">MuA is a parameter in the model, representing the intercept for Brand A
muA is a parameter in the model, representing the effect of Brand A on sales
muA is the intercept parameter for Brand A in the parallel lines model</data>
      <data key="d2">228bdca7843406def245d755e8df49f6,925e17c26fb7d979f52538f4632333e7,ee295ebc4c2d6a2a5c738796fcc2ab71</data>
    </node>
    <node id="MUB">
      <data key="d0">PARAMETER</data>
      <data key="d1">MuB is a parameter in the model, representing the intercept for Brand B
muB is a parameter in the model, representing the effect of Brand B on sales
muB is the intercept parameter for Brand B in the parallel lines model
Mu hat (&#181;b) is the estimated intercept parameter in the regression model</data>
      <data key="d2">228bdca7843406def245d755e8df49f6,825b600cbab3535ce67e9f561ddcb84b,925e17c26fb7d979f52538f4632333e7,ee295ebc4c2d6a2a5c738796fcc2ab71</data>
    </node>
    <node id="MUC">
      <data key="d0">PARAMETER</data>
      <data key="d1">MuC is a parameter in the model, representing the intercept for Brand C
muC is a parameter in the model, representing the effect of Brand C on sales
muC is the intercept parameter for Brand C in the parallel lines model</data>
      <data key="d2">228bdca7843406def245d755e8df49f6,925e17c26fb7d979f52538f4632333e7,ee295ebc4c2d6a2a5c738796fcc2ab71</data>
    </node>
    <node id="FIGURE_9_3">
      <data key="d0">FIGURE</data>
      <data key="d1">Figure 9.3 is a scatterplot of sales against price, coded according to brand, showing the three brand-specific lines of best fit from the parallel lines model
Figure 9.3 is a scatterplot showing the relationship between sales and price, with points coded by brand and fitted regression lines for each brand</data>
      <data key="d2">b2c33cb151a8e7724ebfb7b2d88bc45f,ee295ebc4c2d6a2a5c738796fcc2ab71</data>
    </node>
    <node id="FIGURE_9_2">
      <data key="d0">SCATTERPLOT</data>
      <data key="d1">Figure 9.2 is a scatterplot that revealed a systematic pattern of sales and price, with most Brand A and B data points below the regression line and Brand C above</data>
      <data key="d2">b2c33cb151a8e7724ebfb7b2d88bc45f</data>
    </node>
    <node id="PARALLEL_LINES_MODEL">
      <data key="d0">REGRESSION_MODEL</data>
      <data key="d1">The parallel lines model is a regression model that fits parallel lines to the data for each brand, with the same slope but different intercepts
The parallel lines model is a statistical model used to analyze data with multiple groups or categories, assuming that the regression lines for each group are parallel
The parallel lines model is a regression model that includes indicator variables for Brand B and Brand C, and price as predictors
The parallel lines model is a regression model that assumes the regression lines for different brands are parallel
The parallel lines model is a regression model where the effect of an increase in price on the expected sales volume is the same for each brand, and the difference in expected sales volume for stores of different brands is the same for every fixed value of price
Parallel lines models are a type of linear model that assumes the regression lines for different categories of a factor variable are parallel. This means that the slopes of the regression lines are the same across categories.</data>
      <data key="d2">0cb40986e6c2bb439e1ffcaae2df96ac,1820d10ee0f23f34b3ea88ba475bc52d,77e76692753fdf53493182b09018e6bc,86ece4718d27d1a6c6a1f448cc850e2b,ac15b639b0849006471dfe102376c2c0,b2c33cb151a8e7724ebfb7b2d88bc45f</data>
    </node>
    <node id="MU_HAT_A">
      <data key="d0">INTERCEPT</data>
      <data key="d1">Mu hat A (&#181;&#710;A) is the estimated intercept for Brand A in the parallel lines model
Mu hat (&#181;&#710;A) is the estimated intercept for Brand A in the regression model</data>
      <data key="d2">7037e0369bfdaad5a730cabb2b44831c,b2c33cb151a8e7724ebfb7b2d88bc45f</data>
    </node>
    <node id="MU_HAT_B">
      <data key="d0">INTERCEPT</data>
      <data key="d1">Mu hat B (&#181;&#710;B) is the estimated intercept for Brand B in the parallel lines model
Mu hat (&#181;&#710;B) is the estimated intercept for Brand B in the regression model</data>
      <data key="d2">7037e0369bfdaad5a730cabb2b44831c,b2c33cb151a8e7724ebfb7b2d88bc45f</data>
    </node>
    <node id="MU_HAT_C">
      <data key="d0">INTERCEPT</data>
      <data key="d1">Mu hat C (&#181;&#710;C) is the estimated intercept for Brand C in the parallel lines model
Mu hat (&#181;&#710;C) is the estimated intercept for Brand C in the regression model</data>
      <data key="d2">7037e0369bfdaad5a730cabb2b44831c,b2c33cb151a8e7724ebfb7b2d88bc45f</data>
    </node>
    <node id="STORE_BRAND">
      <data key="d0">VARIABLE</data>
      <data key="d1">Store brand is a categorical variable in the model, indicating the brand of the store</data>
      <data key="d2">248924760a2bfbc82501fd6b11cfa0aa</data>
    </node>
    <node id="XJA">
      <data key="d0">VARIABLE</data>
      <data key="d1">XjA is an indicator variable for store brand A, taking the value 1 if store j is of brand A, and 0 otherwise</data>
      <data key="d2">248924760a2bfbc82501fd6b11cfa0aa</data>
    </node>
    <node id="XJB">
      <data key="d0">VARIABLE</data>
      <data key="d1">XjB is an indicator variable for store brand B, taking the value 1 if store j is of brand B, and 0 otherwise
xjB is an indicator variable that equals 1 if store j is of Brand B and 0 otherwise
XjB is the indicator variable for Brand B, taking the value 1 if the jth observation is of Brand B, and 0 otherwise</data>
      <data key="d2">248924760a2bfbc82501fd6b11cfa0aa,ac15b639b0849006471dfe102376c2c0,c103c6d096d52868eda26d991194b5f2</data>
    </node>
    <node id="XJC">
      <data key="d0">VARIABLE</data>
      <data key="d1">XjC is an indicator variable for store brand C, taking the value 1 if store j is of brand C, and 0 otherwise

XjC is the indicator variable for Brand C, taking the value 1 if the jth observation is of Brand C, and 0 otherwise</data>
      <data key="d2">248924760a2bfbc82501fd6b11cfa0aa,ac15b639b0849006471dfe102376c2c0,c103c6d096d52868eda26d991194b5f2</data>
    </node>
    <node id="SALESJ">
      <data key="d0">SALES</data>
      <data key="d1">Salesj represents the sales at store j, which is modeled as a function of brand and price</data>
      <data key="d2">228bdca7843406def245d755e8df49f6</data>
    </node>
    <node id="PRICEJ">
      <data key="d0">PRICE</data>
      <data key="d1">Pricej is the price at store j, which is a variable in the model for Salesj
pricej is the vector of prices for the jth store
Pricej is the price of the jth observation in the retail data</data>
      <data key="d2">228bdca7843406def245d755e8df49f6,925e17c26fb7d979f52538f4632333e7,ac15b639b0849006471dfe102376c2c0</data>
    </node>
    <node id="BRANDA">
      <data key="d0">DUMMY_VARIABLE</data>
      <data key="d1">BrandA is a dummy variable representing the presence (1) or absence (0) of brand A in the dataset
brandA is one of the categories of the Brand variable
BrandA is one of the brands analyzed in the regression model, with a coefficient of 109.922</data>
      <data key="d2">06d5666e6bfdda828b48adba883b4a61,93da9813e10a119798de6982977f1239,e800735d6b2a244875f5e0d292de1527</data>
    </node>
    <node id="BRANDB">
      <data key="d0">DUMMY_VARIABLE</data>
      <data key="d1">BrandB is a dummy variable representing the presence (1) or absence (0) of brand B in the dataset
brandB is one of the categories of the Brand variable
BrandB is one of the brands analyzed in the regression model, with a coefficient of 103.617</data>
      <data key="d2">06d5666e6bfdda828b48adba883b4a61,93da9813e10a119798de6982977f1239,e800735d6b2a244875f5e0d292de1527</data>
    </node>
    <node id="BRANDC">
      <data key="d0">DUMMY_VARIABLE</data>
      <data key="d1">BrandC is a dummy variable representing the presence (1) or absence (0) of brand C in the dataset
brandC is one of the categories of the Brand variable
BrandC is one of the brands analyzed in the regression model, with a coefficient of 128.549</data>
      <data key="d2">06d5666e6bfdda828b48adba883b4a61,93da9813e10a119798de6982977f1239,e800735d6b2a244875f5e0d292de1527</data>
    </node>
    <node id="BRAND.MODEL1">
      <data key="d0">REGRESSION_MODEL</data>
      <data key="d1">Brand.model1 is the regression model being analyzed, which includes the brand and price variables</data>
      <data key="d2">e800735d6b2a244875f5e0d292de1527</data>
    </node>
    <node id="C_PRICE">
      <data key="d0">DERIVED_VARIABLE</data>
      <data key="d1">c_price is a derived variable representing the deviation of the price from the sample mean of price
c_pricej is the centered price predictor, calculated as the difference between the original pricej and the sample mean price (152.76)&gt;
c_price is a variable in the regression model, representing the price difference from a baseline price of 152.76</data>
      <data key="d2">06d5666e6bfdda828b48adba883b4a61,1b523d1edabe381403fc470a9b8d47fa,93da9813e10a119798de6982977f1239</data>
    </node>
    <node id="BRAND_MODEL2">
      <data key="d0">MODEL</data>
      <data key="d1">Brand.model2 is a statistical model used to analyze sales data for different brands, including brandA, brandB, and brandC, with c_price as a variable</data>
      <data key="d2">93da9813e10a119798de6982977f1239</data>
    </node>
    <node id="DIAMONDS_EXAMPLE">
      <data key="d0">CASE_STUDY</data>
      <data key="d1">The diamonds example is a case study used to illustrate the concept of reparameterisation and its impact on the interpretability of parameters</data>
      <data key="d2">9854704301b8df256ca1013b8d53dfac</data>
    </node>
    <node id="BRAND_VARIABLE">
      <data key="d0">FACTOR</data>
      <data key="d1">The brand variable is a factor variable that defines groups within the data, in this case, the stores of various brands</data>
      <data key="d2">9854704301b8df256ca1013b8d53dfac</data>
    </node>
    <node id="AVERAGE_PRICE">
      <data key="d0">VALUE</data>
      <data key="d1">The average price is the mean price within the observed sample, used as a reference point for interpreting the estimated coefficients</data>
      <data key="d2">9854704301b8df256ca1013b8d53dfac</data>
    </node>
    <node id="CEO">
      <data key="d0">ROLE</data>
      <data key="d1">The CEO is the chief executive officer, responsible for overseeing the stores of a specific brand</data>
      <data key="d2">9854704301b8df256ca1013b8d53dfac</data>
    </node>
    <node id="RETAIL_EXAMPLE">
      <data key="d0">CASE_STUDY</data>
      <data key="d1">The retail example is a case study used to illustrate the application of regression analysis in a retail context</data>
      <data key="d2">9854704301b8df256ca1013b8d53dfac</data>
    </node>
    <node id="FACTOR_VARIABLE">
      <data key="d0">VARIABLE</data>
      <data key="d1">A factor variable defines groups within the data, such as the stores of various brands</data>
      <data key="d2">906eb7d6b49fa360e7e5b65c56cd4d76</data>
    </node>
    <node id="ALPHA_B">
      <data key="d0">PARAMETER</data>
      <data key="d1">Alpha B (&#945;B) is a parameter in the reparameterised model, representing the difference in sales volume between Brand B and Brand A
Alpha B (&#945;B) is a parameter in the model, representing the difference in intercept between the regression line for Brand B and that for Brand A
Alpha_B (&#945;B) is the parameter estimate for Brand B in the linear regression model, indicating the expected difference in sales volume compared to Brand A for a fixed product price
Alpha B (&#945;B) is a parameter in the re-parameterised model representing the difference in sales volume between Brand B and Brand A stores
Alpha B (&#945;B) is the additional intercept parameter for Brand B in the model
Alpha B (&#945;B) is a parameter in the parallel lines model, representing the effect of Brand B on sales
Alpha B (&#945;B) is a parameter in the regression model, representing the effect of Brand B on sales
Alpha B (&#945;B) is the parameter that represents the difference in intercept for brand B compared to brand A</data>
      <data key="d2">06199787dd7f75f7338dd24d4f3dc26e,0cb40986e6c2bb439e1ffcaae2df96ac,1d141ab04db553f78a313e430e54abb5,906eb7d6b49fa360e7e5b65c56cd4d76,a1fc936df848a0fbc791e4bcc9b527b6,ac15b639b0849006471dfe102376c2c0,b6870535f3975c49d45e62fbe475f198,baa0dc3d4ec0e51c0a321e5579caf8aa</data>
    </node>
    <node id="ALPHA_C">
      <data key="d0">PARAMETER</data>
      <data key="d1">Alpha C (&#945;C) is a parameter in the reparameterised model, representing the difference in sales volume between Brand C and Brand A
Alpha C (&#945;C) is a parameter in the model, representing the difference in intercept between the regression line for Brand C and that for Brand A
Alpha_C (&#945;C) is the parameter estimate for Brand C in the linear regression model, indicating the expected difference in sales volume compared to Brand A for a fixed product price
Alpha C (&#945;C) is a parameter in the re-parameterised model representing the difference in sales volume between Brand C and Brand A stores
Alpha C (&#945;C) is the additional intercept parameter for Brand C in the model
Alpha C (&#945;C) is a parameter in the parallel lines model, representing the effect of Brand C on sales
Alpha C (&#945;C) is a parameter in the regression model, representing the effect of Brand C on sales
Alpha C (&#945;C) is the parameter that represents the difference in intercept for brand C compared to brand A
Alpha C (&#945;C) is the parameter for brand C in the regression model</data>
      <data key="d2">06199787dd7f75f7338dd24d4f3dc26e,0cb40986e6c2bb439e1ffcaae2df96ac,1d141ab04db553f78a313e430e54abb5,825b600cbab3535ce67e9f561ddcb84b,906eb7d6b49fa360e7e5b65c56cd4d76,a1fc936df848a0fbc791e4bcc9b527b6,ac15b639b0849006471dfe102376c2c0,b6870535f3975c49d45e62fbe475f198,baa0dc3d4ec0e51c0a321e5579caf8aa</data>
    </node>
    <node id="X_B">
      <data key="d0">VARIABLE</data>
      <data key="d1">X_B (xjB) is an indicator variable, equal to 1 if store j is of Brand B, and 0 otherwise</data>
      <data key="d2">1d141ab04db553f78a313e430e54abb5</data>
    </node>
    <node id="X_C">
      <data key="d0">VARIABLE</data>
      <data key="d1">X_C (xjC) is an indicator variable, equal to 1 if store j is of Brand C, and 0 otherwise</data>
      <data key="d2">1d141ab04db553f78a313e430e54abb5</data>
    </node>
    <node id="DESIGN_MATRIX_X">
      <data key="d0">MATRIX</data>
      <data key="d1">The design matrix X has 96 rows and 4 columns, representing the values of the intercept, indicator variables for Brand B and C, and price for each store</data>
      <data key="d2">c103c6d096d52868eda26d991194b5f2</data>
    </node>
    <node id="BRAND_MODEL3">
      <data key="d0">MODEL</data>
      <data key="d1">Brand_model3 is a linear model fitted using the lm() function in R, with sales as the dependent variable and brand and price as independent variables</data>
      <data key="d2">6a6f85d0a6e46196ab3a901fcc82a720</data>
    </node>
    <node id="MU_HAT">
      <data key="d0">PARAMETER</data>
      <data key="d1">Mu_hat (192.246) is the estimated intercept parameter in the linear model</data>
      <data key="d2">6a6f85d0a6e46196ab3a901fcc82a720</data>
    </node>
    <node id="ALPHA_HAT_B">
      <data key="d0">PARAMETER</data>
      <data key="d1">Alpha_hat_B (-6.305) is the estimated parameter for brand B in the linear model</data>
      <data key="d2">6a6f85d0a6e46196ab3a901fcc82a720</data>
    </node>
    <node id="ALPHA_HAT_C">
      <data key="d0">PARAMETER</data>
      <data key="d1">Alpha_hat_C (18.627) is the estimated parameter for brand C in the linear model</data>
      <data key="d2">6a6f85d0a6e46196ab3a901fcc82a720</data>
    </node>
    <node id="PRODUCT_PRICE">
      <data key="d0">INDEPENDENT_VARIABLE</data>
      <data key="d1">Product price is an independent variable in the linear regression model, assumed to be fixed in the context of comparing sales volumes</data>
      <data key="d2">baa0dc3d4ec0e51c0a321e5579caf8aa</data>
    </node>
    <node id="TREATMENT_CODING">
      <data key="d0">PARAMETERISATION</data>
      <data key="d1">Treatment coding is a type of parameterisation used in the regression model, where the levels of the categorical predictor are compared to a baseline or reference category</data>
      <data key="d2">baa0dc3d4ec0e51c0a321e5579caf8aa</data>
    </node>
    <node id="SAMPLE_MEANS">
      <data key="d0">STATISTIC</data>
      <data key="d1">The sample means of sales volume for stores of Brand A, Brand B, and Brand C are statistics calculated from the observed data
Sample means are the average sales volume for stores of each brand</data>
      <data key="d2">06199787dd7f75f7338dd24d4f3dc26e,48971100deb5bb374a41c1f2b7b2a86a</data>
    </node>
    <node id="MODEL_FITTED_IN_H">
      <data key="d0">MODEL</data>
      <data key="d1">The model fitted in h. is used to predict the sales volume for Brand C stores</data>
      <data key="d2">096afa471635bc59c3bfa9af4d04d625</data>
    </node>
    <node id="MODEL_FITTED_IN_C">
      <data key="d0">MODEL</data>
      <data key="d1">The model fitted in c. also predicts the sales volume for Brand C stores, which is compared to the prediction from the model fitted in h.</data>
      <data key="d2">096afa471635bc59c3bfa9af4d04d625</data>
    </node>
    <node id="EXERCISE_22A">
      <data key="d0">EXERCISE</data>
      <data key="d1">Exercise 22a refers to a previous exercise that introduced the model being considered in Exercise 23</data>
      <data key="d2">096afa471635bc59c3bfa9af4d04d625</data>
    </node>
    <node id="SA">
      <data key="d0">SET</data>
      <data key="d1">SA is the set containing the indices of the observations that are of Brand A
SA is the set containing the indices of the observations that are of Brand A</data>
      <data key="d2">096afa471635bc59c3bfa9af4d04d625,925e17c26fb7d979f52538f4632333e7</data>
    </node>
    <node id="SB">
      <data key="d0">SET</data>
      <data key="d1">SB is the set containing the indices of the observations that are of Brand B
SB is the set containing the indices of the observations that are of Brand B</data>
      <data key="d2">096afa471635bc59c3bfa9af4d04d625,925e17c26fb7d979f52538f4632333e7</data>
    </node>
    <node id="SC">
      <data key="d0">SET</data>
      <data key="d1">SC is the set containing the indices of the observations that are of Brand C
SC is the set containing the indices of the observations that are of Brand C</data>
      <data key="d2">096afa471635bc59c3bfa9af4d04d625,925e17c26fb7d979f52538f4632333e7</data>
    </node>
    <node id="NA">
      <data key="d0">NUMBER</data>
      <data key="d1">nA is the number of observations that are of Brand A
nA is the number of observations that are of Brand A</data>
      <data key="d2">096afa471635bc59c3bfa9af4d04d625,925e17c26fb7d979f52538f4632333e7</data>
    </node>
    <node id="NB">
      <data key="d0">NUMBER</data>
      <data key="d1">nB is the number of observations that are of Brand B
nB is the number of observations that are of Brand B</data>
      <data key="d2">096afa471635bc59c3bfa9af4d04d625,925e17c26fb7d979f52538f4632333e7</data>
    </node>
    <node id="NC">
      <data key="d0">NUMBER</data>
      <data key="d1">nC is the number of observations that are of Brand C
nC is the number of observations that are of Brand C</data>
      <data key="d2">096afa471635bc59c3bfa9af4d04d625,925e17c26fb7d979f52538f4632333e7</data>
    </node>
    <node id="SALESI">
      <data key="d0">VECTOR</data>
      <data key="d1">salesi is the vector of sales for the ith observation</data>
      <data key="d2">925e17c26fb7d979f52538f4632333e7</data>
    </node>
    <node id="ALPHAB">
      <data key="d0">PARAMETER</data>
      <data key="d1">alphaB is the difference in intercept for Brand B compared to Brand A in the parallel lines model</data>
      <data key="d2">925e17c26fb7d979f52538f4632333e7</data>
    </node>
    <node id="ALPHAC">
      <data key="d0">PARAMETER</data>
      <data key="d1">alphaC is the difference in intercept for Brand C compared to Brand A in the parallel lines model</data>
      <data key="d2">925e17c26fb7d979f52538f4632333e7</data>
    </node>
    <node id="ROUNDING_ERRORS">
      <data key="d0">ERRORS</data>
      <data key="d1">Rounding errors are small discrepancies that can occur due to the rounding of numbers during calculations</data>
      <data key="d2">86ece4718d27d1a6c6a1f448cc850e2b</data>
    </node>
    <node id="REFERENCE_CATEGORY">
      <data key="d0">CATEGORY</data>
      <data key="d1">The reference category is a specific category chosen as the baseline for comparison in the model
The reference category is the level of a categorical variable that is not included as an indicator variable in the model. It serves as the baseline level against which the other categories are compared.</data>
      <data key="d2">77e76692753fdf53493182b09018e6bc,86ece4718d27d1a6c6a1f448cc850e2b</data>
    </node>
    <node id="RELEVEL">
      <data key="d0">COMMAND</data>
      <data key="d1">Relevel is an R command used to change the reference category of a factor variable</data>
      <data key="d2">86ece4718d27d1a6c6a1f448cc850e2b</data>
    </node>
    <node id="BRAND_MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">Brand model is the model fitted using the lm() function in R, with sales as the response variable and price and brand as predictor variables</data>
      <data key="d2">86ece4718d27d1a6c6a1f448cc850e2b</data>
    </node>
    <node id="INTERACTION">
      <data key="d0">MODEL_FEATURE</data>
      <data key="d1">Interaction refers to the effect of one predictor variable on the response variable that depends on the level of another predictor variable
Interaction is a concept in regression analysis where the effect of one explanatory variable on the response depends on the value of another explanatory variable
Interaction is a type of effect in regression analysis where the effect of one predictor on the response variable depends on the value of another predictor.
Interaction in a linear model occurs when the effect of one explanatory variable on the response variable depends on the value of another explanatory variable. It is represented by the inclusion of product terms in the model equations.
An interaction in a statistical model occurs when the effect of one predictor variable on the response variable depends on the level of another predictor variable. It is introduced into a model to allow for the relationship between the response and the quantitative predictor to vary across levels of the categorical predictor.</data>
      <data key="d2">0cb40986e6c2bb439e1ffcaae2df96ac,77e76692753fdf53493182b09018e6bc,86ece4718d27d1a6c6a1f448cc850e2b,b0ca3e6c22c4cf884d03b1f6f82be5df,d7f3a28534ffe830fe6f4cef8c41a9b4</data>
    </node>
    <node id="FITTED_LINE">
      <data key="d0">REGRESSION_LINE</data>
      <data key="d1">The fitted line is the regression line obtained from the regression model, used to predict sales based on price and brand</data>
      <data key="d2">ac15b639b0849006471dfe102376c2c0</data>
    </node>
    <node id="FIGURE_9_4">
      <data key="d0">FIGURE</data>
      <data key="d1">Figure 9.4 is a graphical representation showing separate scatterplots for each brand with the corresponding fitted regression line from the parallel lines model
Figure 9.4 is a graphical representation showing three scatterplots of sales against price, one for each store brand, with the corresponding regression lines from the parallel lines model</data>
      <data key="d2">0cb40986e6c2bb439e1ffcaae2df96ac,ac15b639b0849006471dfe102376c2c0</data>
    </node>
    <node id="GAMMA_A">
      <data key="d0">PARAMETER</data>
      <data key="d1">Gamma A (&#947;A) is a parameter in the regression model, representing the interaction effect between Brand A and price on sales</data>
      <data key="d2">0cb40986e6c2bb439e1ffcaae2df96ac</data>
    </node>
    <node id="GAMMA_B">
      <data key="d0">PARAMETER</data>
      <data key="d1">Gamma B (&#947;B) is a parameter in the regression model, representing the interaction effect between Brand B and price on sales
Gamma B (&#947;B) is the parameter that represents the difference in slope for brand B compared to brand A</data>
      <data key="d2">0cb40986e6c2bb439e1ffcaae2df96ac,b6870535f3975c49d45e62fbe475f198</data>
    </node>
    <node id="INDICATOR_VARIABLES">
      <data key="d0">VARIABLE</data>
      <data key="d1">Indicator variables (xjB and xjC) are binary variables used in the regression model to represent the brand of the store
Indicator variables, or dummy variables, are used to encode categorical predictor variables in a linear model. If a categorical predictor variable has d levels, d-1 indicator variables are used to encode the factor, with the reference category being the level not included in the model.</data>
      <data key="d2">0cb40986e6c2bb439e1ffcaae2df96ac,77e76692753fdf53493182b09018e6bc</data>
    </node>
    <node id="STORE">
      <data key="d0">ENTITY</data>
      <data key="d1">A store is a place where sales occur, and its brand affects the sales volume</data>
      <data key="d2">b6870535f3975c49d45e62fbe475f198</data>
    </node>
    <node id="GAMMA_C">
      <data key="d0">PARAMETER</data>
      <data key="d1">Gamma C (&#947;C) is the parameter that represents the difference in slope for brand C compared to brand A
Gamma C (&#947;C) is the parameter describing the difference in slope between the regression line for Brand C and Brand A</data>
      <data key="d2">825b600cbab3535ce67e9f561ddcb84b,b6870535f3975c49d45e62fbe475f198</data>
    </node>
    <node id="STORE_J">
      <data key="d0">STORE</data>
      <data key="d1">Store j is a specific store in the dataset, which can be of brand B or C</data>
      <data key="d2">825b600cbab3535ce67e9f561ddcb84b</data>
    </node>
    <node id="PRICE_J">
      <data key="d0">PREDICTOR</data>
      <data key="d1">Price j is the price of the product in store j</data>
      <data key="d2">825b600cbab3535ce67e9f561ddcb84b</data>
    </node>
    <node id="BRAND_MODEL4">
      <data key="d0">MODEL</data>
      <data key="d1">brand.model4 is the linear model object created by fitting the regression model in R</data>
      <data key="d2">825b600cbab3535ce67e9f561ddcb84b</data>
    </node>
    <node id="ROUND_FUNCTION">
      <data key="d0">FUNCTION</data>
      <data key="d1">round() is the function in R used to round numbers to a specified number of decimal places</data>
      <data key="d2">825b600cbab3535ce67e9f561ddcb84b</data>
    </node>
    <node id="BBETA">
      <data key="d0">ESTIMATED_PARAMETER</data>
      <data key="d1">Beta hat (b&#946;) is the estimated coefficient for the price predictor in the regression model</data>
      <data key="d2">825b600cbab3535ce67e9f561ddcb84b</data>
    </node>
    <node id="ALPHAB_B">
      <data key="d0">ESTIMATED_PARAMETER</data>
      <data key="d1">Alpha hat for brand B (&#945;bB) is the estimated parameter for brand B in the regression model</data>
      <data key="d2">825b600cbab3535ce67e9f561ddcb84b</data>
    </node>
    <node id="ALPHAB_C">
      <data key="d0">ESTIMATED_PARAMETER</data>
      <data key="d1">Alpha hat for brand C (&#945;bC) is the estimated parameter for brand C in the regression model</data>
      <data key="d2">825b600cbab3535ce67e9f561ddcb84b</data>
    </node>
    <node id="ALPHA_B_B">
      <data key="d0">COEFFICIENT</data>
      <data key="d1">Alpha hat for Brand B (&#945;bB) is the coefficient for Brand B, representing the difference in intercept compared to Brand A</data>
      <data key="d2">adbc52b340a69a8633c919c4fd2cd3f6</data>
    </node>
    <node id="ALPHA_B_C">
      <data key="d0">COEFFICIENT</data>
      <data key="d1">Alpha hat for Brand C (&#945;bC) is the coefficient for Brand C, representing the difference in intercept compared to Brand A</data>
      <data key="d2">adbc52b340a69a8633c919c4fd2cd3f6</data>
    </node>
    <node id="GAMMA_B_B">
      <data key="d0">COEFFICIENT</data>
      <data key="d1">Gamma hat for Brand B (&#947;bB) is the coefficient for the interaction between Brand B and price, representing the difference in price effect compared to Brand A</data>
      <data key="d2">adbc52b340a69a8633c919c4fd2cd3f6</data>
    </node>
    <node id="GAMMA_B_C">
      <data key="d0">COEFFICIENT</data>
      <data key="d1">Gamma hat for Brand C (&#947;bC) is the coefficient for the interaction between Brand C and price, representing the difference in price effect compared to Brand A</data>
      <data key="d2">adbc52b340a69a8633c919c4fd2cd3f6</data>
    </node>
    <node id="FIGURE_9_5">
      <data key="d0">FIGURE</data>
      <data key="d1">Figure 9.5 is a scatterplot of sales against price with coding according to brand, showing the three lines of best fit, one for each brand</data>
      <data key="d2">3dd24a54028976ba54304ec7169bb74b</data>
    </node>
    <node id="INTERACTION_MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">The interaction model is a regression model where the slopes of the regression lines for different brands are allowed to differ, meaning the effect of an increase in price on the expected sales volume differs between brands, and the difference in expected sales volume for stores of different brands depends on the price being charged for the product</data>
      <data key="d2">1820d10ee0f23f34b3ea88ba475bc52d</data>
    </node>
    <node id="FACTOR">
      <data key="d0">CATEGORICAL_VARIABLE</data>
      <data key="d1">Factor is a categorical predictor variable in regression models, often represented by indicator variables or dummy variables.</data>
      <data key="d2">b0ca3e6c22c4cf884d03b1f6f82be5df</data>
    </node>
    <node id="INDICATOR_VARIABLE">
      <data key="d0">VARIABLE_TYPE</data>
      <data key="d1">Indicator variables, also known as dummy variables, are used to encode categorical predictor variables in regression models.</data>
      <data key="d2">b0ca3e6c22c4cf884d03b1f6f82be5df</data>
    </node>
    <node id="DUMMY_VARIABLE">
      <data key="d0">VARIABLE_TYPE</data>
      <data key="d1">Dummy variables are a type of indicator variable used to represent categorical predictors in regression models.</data>
      <data key="d2">b0ca3e6c22c4cf884d03b1f6f82be5df</data>
    </node>
    <node id="EXERCISE_26">
      <data key="d0">EXERCISE</data>
      <data key="d1">Exercise 26 asks for the design matrix for the model defined in equation (9.6).</data>
      <data key="d2">b0ca3e6c22c4cf884d03b1f6f82be5df</data>
    </node>
    <node id="CHAPTER_9">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Chapter 9 of a book or module introduces categorical predictor variables, also known as factors, in linear models.</data>
      <data key="d2">b0ca3e6c22c4cf884d03b1f6f82be5df</data>
    </node>
    <node id="CATEGORICAL_PREDICTORS">
      <data key="d0">VARIABLE_TYPE</data>
      <data key="d1">Categorical predictor variables, also known as factors, are variables in a linear model that have discrete categories or levels. They are accommodated within the linear model framework using indicator variables, also called dummy variables.
Categorical predictors are variables that can take on one of a limited, and usually fixed, number of possible values, such as gender, race, or country of origin. They are incorporated into a linear model to analyze their effect on the response variable.</data>
      <data key="d2">77e76692753fdf53493182b09018e6bc,d7f3a28534ffe830fe6f4cef8c41a9b4</data>
    </node>
    <node id="QUANTITATIVE_VARIABLES">
      <data key="d0">VARIABLE_TYPE</data>
      <data key="d1">Quantitative variables are numerical variables that can take on any value within a range. They are used as predictors in linear models.</data>
      <data key="d2">77e76692753fdf53493182b09018e6bc</data>
    </node>
    <node id="PRODUCT_TERMS">
      <data key="d0">MODEL_COMPONENT</data>
      <data key="d1">Product terms are introduced into linear model equations to allow for interaction between explanatory variables. They represent the effect of one explanatory variable on the response variable depending on the value of another explanatory variable.</data>
      <data key="d2">77e76692753fdf53493182b09018e6bc</data>
    </node>
    <node id="PARALLEL_LINES_REGRESSION_MODEL">
      <data key="d0">MODEL</data>
      <data key="d1">A parallel lines regression model is a type of linear model that assumes the regression lines for different levels of a categorical predictor are parallel. This model is used when the effect of the quantitative predictor is the same across all levels of the categorical predictor.</data>
      <data key="d2">d7f3a28534ffe830fe6f4cef8c41a9b4</data>
    </node>
    <node id="T_STATISTIC">
      <data key="d0">STATISTICAL_MEASURE</data>
      <data key="d1">The T-statistic is a statistical measure used in hypothesis testing to determine whether the estimated value of a parameter is significantly different from a hypothesized value. It is calculated by dividing the estimated parameter by its standard error.</data>
      <data key="d2">d7f3a28534ffe830fe6f4cef8c41a9b4</data>
    </node>
    <node id="MAXIMUM_LIKELIHOOD_ESTIMATOR">
      <data key="d0">ESTIMATOR</data>
      <data key="d1">The maximum likelihood estimator (MLE) is a method of estimating the parameters of a statistical model, given observations. It is based on the likelihood function, which is the probability of the observed data given the parameters of the model.</data>
      <data key="d2">d7f3a28534ffe830fe6f4cef8c41a9b4</data>
    </node>
    <node id="U">
      <data key="d0">TRANSFORMED_VECTOR</data>
      <data key="d1">U is the transformed vector AZ, resulting from the multiplication of matrix A and vector Z
U is a random variable defined as AZ, where A is a matrix and Z is a vector of independent standard normal random variables</data>
      <data key="d2">0ac60299320c55d642b3e38440c25f90,aac5b4f040b9c773bd1aa696dec469f6</data>
    </node>
    <node id="V">
      <data key="d0">TRANSFORMED_VECTOR</data>
      <data key="d1">V is the transformed vector BZ, resulting from the multiplication of matrix B and vector Z
V is a random variable defined as BZ, where B is a matrix and Z is a vector of independent standard normal random variables</data>
      <data key="d2">0ac60299320c55d642b3e38440c25f90,aac5b4f040b9c773bd1aa696dec469f6</data>
    </node>
    <node id="CHI_SQUARED_DISTRIBUTION">
      <data key="d0">DISTRIBUTION</data>
      <data key="d1">The chi-squared distribution is a continuous probability distribution that arises in the context of the sum of squares of independent standard normal random variables</data>
      <data key="d2">aac5b4f040b9c773bd1aa696dec469f6</data>
    </node>
    <node id="CHI_SQUARED">
      <data key="d0">DISTRIBUTION</data>
      <data key="d1">The chi-squared distribution with n degrees of freedom is a probability distribution used in hypothesis testing and goodness of fit tests</data>
      <data key="d2">0ac60299320c55d642b3e38440c25f90</data>
    </node>
    <node id="COV_U_V">
      <data key="d0">COVARIANCE</data>
      <data key="d1">The covariance between U and V is zero, indicating that U and V are uncorrelated</data>
      <data key="d2">0ac60299320c55d642b3e38440c25f90</data>
    </node>
    <edge source="ST231" target="SIMPLE LINEAR REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">ST231 lecture notes cover simple linear regression, which is a fundamental concept in the field of statistics</data>
      <data key="d6">54206a4a813f5be515f41653e9422eeb</data>
    </edge>
    <edge source="ST231" target="TERMINOLOGY AND NOTATION">
      <data key="d4">1.0</data>
      <data key="d5">ST231 lecture notes include terminology and notation used in the field of statistics</data>
      <data key="d6">54206a4a813f5be515f41653e9422eeb</data>
    </edge>
    <edge source="ST231" target="MULTIPLE REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">ST231 lecture notes cover multiple regression, which is an extension of simple linear regression</data>
      <data key="d6">54206a4a813f5be515f41653e9422eeb</data>
    </edge>
    <edge source="ST231" target="LINEAR MODELS">
      <data key="d4">1.0</data>
      <data key="d5">ST231 lecture notes discuss the class of linear models, which includes simple and multiple regression</data>
      <data key="d6">54206a4a813f5be515f41653e9422eeb</data>
    </edge>
    <edge source="ST231" target="ANSCOMBE'S QUARTET">
      <data key="d4">1.0</data>
      <data key="d5">ST231 lecture notes include Anscombe's Quartet, which is a set of datasets used to illustrate the importance of graphing data</data>
      <data key="d6">54206a4a813f5be515f41653e9422eeb</data>
    </edge>
    <edge source="ST231" target="POLYNOMIAL REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">ST231 lecture notes cover polynomial regression, which is a form of regression analysis that models the relationship between variables as a polynomial</data>
      <data key="d6">54206a4a813f5be515f41653e9422eeb</data>
    </edge>
    <edge source="LINEARITY" target="ANSCOMBES_QUARTET">
      <data key="d4">1.0</data>
      <data key="d5">Anscombe's Quartet is an example that demonstrates the importance of linearity in statistical models and the need for graphical analysis to understand the data</data>
      <data key="d6">35bac6a2c3eb466ca9fc7b31bf2cc42c</data>
    </edge>
    <edge source="LINEARITY" target="POLYNOMIAL_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Polynomial regression is an extension of linear regression that allows for the modelling of nonlinear relationships, which are still considered under the broader concept of linearity in statistical models</data>
      <data key="d6">35bac6a2c3eb466ca9fc7b31bf2cc42c</data>
    </edge>
    <edge source="LINEARITY" target="LOG_TRANSFORMED_PREDICTOR">
      <data key="d4">1.0</data>
      <data key="d5">A linear model with a log-transformed predictor is a specific case of linear models where the predictor is transformed to meet the linearity assumption</data>
      <data key="d6">35bac6a2c3eb466ca9fc7b31bf2cc42c</data>
    </edge>
    <edge source="LINEARITY" target="STRATEGY_FOR_STATISTICAL_MODELLING">
      <data key="d4">1.0</data>
      <data key="d5">A strategy for statistical modelling includes considerations for ensuring linearity in the relationship between variables</data>
      <data key="d6">35bac6a2c3eb466ca9fc7b31bf2cc42c</data>
    </edge>
    <edge source="LINEARITY" target="GOOD_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">A good model should meet the assumption of linearity, which is a fundamental aspect of statistical models</data>
      <data key="d6">35bac6a2c3eb466ca9fc7b31bf2cc42c</data>
    </edge>
    <edge source="LINEARITY" target="SUMMARY_OF_CHAPTER_2">
      <data key="d4">1.0</data>
      <data key="d5">The summary of Chapter 2 includes a recap of the concept of linearity and its importance in statistical models</data>
      <data key="d6">35bac6a2c3eb466ca9fc7b31bf2cc42c</data>
    </edge>
    <edge source="LINEARITY" target="RESIDUAL_ANALYSIS">
      <data key="d4">1.0</data>
      <data key="d5">Residual analysis is used to check the assumption of linearity in statistical models by examining the residuals</data>
      <data key="d6">35bac6a2c3eb466ca9fc7b31bf2cc42c</data>
    </edge>
    <edge source="LINEARITY" target="GRAPHICAL_EXPLORATION">
      <data key="d4">1.0</data>
      <data key="d5">Graphical exploration is used to assess the adequacy of the linear model's systematic component</data>
      <data key="d6">6616e10c85e86291147e72776854b8a2</data>
    </edge>
    <edge source="LINEARITY" target="LEAST_SQUARES_ESTIMATION">
      <data key="d4">1.0</data>
      <data key="d5">Least squares estimation can be used to fit models even when the systematic component is not strictly linear</data>
      <data key="d6">6616e10c85e86291147e72776854b8a2</data>
    </edge>
    <edge source="LINEARITY" target="SIMPLE_LINEAR_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Linearity is a property of the relationship between the response and the explanatory variable in the simple linear regression model</data>
      <data key="d6">25fce1af816975003128126b5cfea73b</data>
    </edge>
    <edge source="LINEARITY" target="Y">
      <data key="d4">1.0</data>
      <data key="d5">The linearity assumption applies to the relationship between the response variable Y and the explanatory variables X</data>
      <data key="d6">3cbe71f7649e84cd67cb3fa0d3e632cf</data>
    </edge>
    <edge source="LINEARITY" target="RESIDUAL_PLOTS">
      <data key="d4">1.0</data>
      <data key="d5">Residual plots can be used to check for violations of the linearity assumption in a statistical model</data>
      <data key="d6">7cd6069e88e81548a237fa937adfecc6</data>
    </edge>
    <edge source="LINEARITY" target="NON_LINEAR_TRANSFORMATIONS">
      <data key="d4">1.0</data>
      <data key="d5">Non-linear transformations can help meet the assumption of linearity</data>
      <data key="d6">c03eb12d07d48f9e94260f08dae10cdf</data>
    </edge>
    <edge source="POLYNOMIAL_REGRESSION" target="SIMPLE_LINEAR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Polynomial regression is an extension of simple linear models, allowing for more complex relationships between variables</data>
      <data key="d6">b8ec334f8c87bf1d9cb6043fa1a64214</data>
    </edge>
    <edge source="POLYNOMIAL_REGRESSION" target="LINEAR_MODELS">
      <data key="d4">2.0</data>
      <data key="d5">Linear models are extended to polynomial regression when the relationship between the response and the explanatory variables is not linear but can be described by a polynomial function
Polynomial regression is a specific type of linear model that includes polynomials of the explanatory variables to model non-linear relationships</data>
      <data key="d6">0328e428a30c44572676dd571dd1e9bd,87ba4f416a28aabc3b396908f5913b54</data>
    </edge>
    <edge source="POLYNOMIAL_REGRESSION" target="QUADRATIC_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Quadratic regression is a specific case of polynomial regression where the model includes a squared term of the independent variable</data>
      <data key="d6">87ba4f416a28aabc3b396908f5913b54</data>
    </edge>
    <edge source="POLYNOMIAL_REGRESSION" target="PLR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">plr.model is an instance of polynomial regression, specifically a quadratic regression model</data>
      <data key="d6">084dadebfca8bcb6377c205c45bee295</data>
    </edge>
    <edge source="POLYNOMIAL_REGRESSION" target="BETA1">
      <data key="d4">1.0</data>
      <data key="d5">Beta1 is a parameter in the polynomial regression model</data>
      <data key="d6">11452a08471d93959558de2ece9a69af</data>
    </edge>
    <edge source="POLYNOMIAL_REGRESSION" target="BETA2">
      <data key="d4">1.0</data>
      <data key="d5">Beta2 is a parameter in the polynomial regression model</data>
      <data key="d6">11452a08471d93959558de2ece9a69af</data>
    </edge>
    <edge source="POLYNOMIAL_REGRESSION" target="LINEAR_MODEL">
      <data key="d4">2.0</data>
      <data key="d5">Polynomial regression is considered a type of linear model because it is linear in the parameters, even though the relationship between the response variable and the predictor variable is non-linear.
A polynomial regression model is a type of linear model that includes polynomials of the explanatory variables</data>
      <data key="d6">188219b9e5b6b6368360840921877de9,b9af17718641389ba07f53be13f31f8c</data>
    </edge>
    <edge source="LOG_TRANSFORMED_PREDICTOR" target="LINEAR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The log-transformed predictor is used in the linear model</data>
      <data key="d6">656dce234514b9db38b5b5616557c1e9</data>
    </edge>
    <edge source="GOOD_MODEL" target="MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The criteria for a good model apply to the model</data>
      <data key="d6">bb31f1c77bbba73300f735a100086a67</data>
    </edge>
    <edge source="RESIDUAL_ANALYSIS" target="LINEAR_MODELS">
      <data key="d4">1.0</data>
      <data key="d5">Residual analysis is a critical step in assessing the adequacy of model assumptions in linear models</data>
      <data key="d6">0328e428a30c44572676dd571dd1e9bd</data>
    </edge>
    <edge source="RESIDUAL_ANALYSIS" target="RESIDUAL_PLOTS">
      <data key="d4">1.0</data>
      <data key="d5">Residual plots are a tool used in residual analysis to visually inspect the residuals for patterns that might indicate violations of model assumptions</data>
      <data key="d6">0328e428a30c44572676dd571dd1e9bd</data>
    </edge>
    <edge source="RESIDUAL_ANALYSIS" target="Q_Q_PLOTS">
      <data key="d4">1.0</data>
      <data key="d5">Q-Q plots are used in residual analysis to compare the distribution of the residuals to a theoretical distribution, helping to assess the normality of the residuals</data>
      <data key="d6">0328e428a30c44572676dd571dd1e9bd</data>
    </edge>
    <edge source="RESIDUAL_ANALYSIS" target="NULL_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">Residual analysis is used to create a null plot, which helps in assessing whether the model assumptions are satisfied</data>
      <data key="d6">aa13c33a7e61206e6021e2736002ca9a</data>
    </edge>
    <edge source="RESIDUAL_ANALYSIS" target="Q_Q_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">Q-Q plots are used in residual analysis to check the normality assumption of the errors in a linear model. Deviations from the straight line indicate departures from normality.</data>
      <data key="d6">3bfc9b92571973e54c8095302acc1aaa</data>
    </edge>
    <edge source="RESIDUAL_ANALYSIS" target="LINEAR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Residual analysis is applied to linear models to check the assumptions of linearity, homoscedasticity, independence, and normality of errors. It helps to evaluate the validity of the model.</data>
      <data key="d6">3bfc9b92571973e54c8095302acc1aaa</data>
    </edge>
    <edge source="CHAPTER 2" target="RESIDUAL ANALYSIS">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 2 is summarized before the discussion of residual analysis</data>
      <data key="d6">752d1285c8b1e15a2e175515f77ddd5a</data>
    </edge>
    <edge source="RESIDUAL ANALYSIS" target="DEFINITIONS">
      <data key="d4">1.0</data>
      <data key="d5">Residual analysis includes definitions provided in Subsection 3.1</data>
      <data key="d6">752d1285c8b1e15a2e175515f77ddd5a</data>
    </edge>
    <edge source="RESIDUAL ANALYSIS" target="MODEL ASSUMPTIONS">
      <data key="d4">1.0</data>
      <data key="d5">Residual analysis includes a discussion of model assumptions in Subsection 3.2</data>
      <data key="d6">752d1285c8b1e15a2e175515f77ddd5a</data>
    </edge>
    <edge source="RESIDUAL ANALYSIS" target="RESIDUAL PLOTS">
      <data key="d4">1.0</data>
      <data key="d5">Residual analysis includes an explanation of residual plots in Subsection 3.3</data>
      <data key="d6">752d1285c8b1e15a2e175515f77ddd5a</data>
    </edge>
    <edge source="RESIDUAL ANALYSIS" target="ASSESSING NORMALITY">
      <data key="d4">1.0</data>
      <data key="d5">Residual analysis includes methods for assessing normality in Subsection 3.4</data>
      <data key="d6">752d1285c8b1e15a2e175515f77ddd5a</data>
    </edge>
    <edge source="RESIDUAL ANALYSIS" target="SUMMARY OF CHAPTER 3">
      <data key="d4">1.0</data>
      <data key="d5">Residual analysis is followed by a summary of Chapter 3 in Subsection 3.5</data>
      <data key="d6">752d1285c8b1e15a2e175515f77ddd5a</data>
    </edge>
    <edge source="NON-LINEAR TRANSFORMATIONS" target="THE LOG-TRANSFORMATION">
      <data key="d4">1.0</data>
      <data key="d5">Non-linear transformations include the log-transformation discussed in Subsection 4.1</data>
      <data key="d6">752d1285c8b1e15a2e175515f77ddd5a</data>
    </edge>
    <edge source="CHAPTER_3" target="NON_LINEAR_TRANSFORMATIONS">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 3 is likely discussed before Chapter 4, which covers non-linear transformations, indicating a possible progression in the document's structure</data>
      <data key="d6">9846990771550ccdb865e49ecb96e2a3</data>
    </edge>
    <edge source="NON_LINEAR_TRANSFORMATIONS" target="LOG_TRANSFORMATION">
      <data key="d4">1.0</data>
      <data key="d5">Non-linear transformations include the log-transformation, which is a specific method for changing the scale of data</data>
      <data key="d6">9846990771550ccdb865e49ecb96e2a3</data>
    </edge>
    <edge source="NON_LINEAR_TRANSFORMATIONS" target="MAMMALS_DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Non-linear transformations are likely applied to the mammals dataset as an example of their use in data analysis</data>
      <data key="d6">9846990771550ccdb865e49ecb96e2a3</data>
    </edge>
    <edge source="NON_LINEAR_TRANSFORMATIONS" target="TREES_DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Non-linear transformations are likely applied to the trees dataset as an example of their use in data analysis</data>
      <data key="d6">9846990771550ccdb865e49ecb96e2a3</data>
    </edge>
    <edge source="NON_LINEAR_TRANSFORMATIONS" target="CHAPTER_4">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 4 discusses non-linear transformations, including specific examples and datasets</data>
      <data key="d6">9846990771550ccdb865e49ecb96e2a3</data>
    </edge>
    <edge source="NON_LINEAR_TRANSFORMATIONS" target="REMEDIAL_ACTIONS">
      <data key="d4">1.0</data>
      <data key="d5">Non-linear transformations are one of the remedial actions that can be taken to address violations of the modelling assumptions</data>
      <data key="d6">e361ac139c268d5c3f3623f920e68af2</data>
    </edge>
    <edge source="NON_LINEAR_TRANSFORMATIONS" target="MODEL_ASSUMPTIONS">
      <data key="d4">1.0</data>
      <data key="d5">Non-linear transformations can be used to address violations of the model assumptions</data>
      <data key="d6">c03eb12d07d48f9e94260f08dae10cdf</data>
    </edge>
    <edge source="NON_LINEAR_TRANSFORMATIONS" target="HETEROSCEDASTICITY">
      <data key="d4">2.0</data>
      <data key="d5">Non-linear transformations can address heteroscedasticity
Non-linear transformations can address heteroscedasticity in regression models</data>
      <data key="d6">c03eb12d07d48f9e94260f08dae10cdf,d71b402ab9edbb4347e09c7af3257cf5</data>
    </edge>
    <edge source="NON_LINEAR_TRANSFORMATIONS" target="UNUSUAL_OBSERVATIONS">
      <data key="d4">2.0</data>
      <data key="d5">Non-linear transformations can reduce the influence of unusual observations
Non-linear transformations can reduce the influence of unusual observations in regression models</data>
      <data key="d6">c03eb12d07d48f9e94260f08dae10cdf,d71b402ab9edbb4347e09c7af3257cf5</data>
    </edge>
    <edge source="NON_LINEAR_TRANSFORMATIONS" target="LOG_TRANSFORM">
      <data key="d4">1.0</data>
      <data key="d5">The log-transform is a type of non-linear transformation</data>
      <data key="d6">c03eb12d07d48f9e94260f08dae10cdf</data>
    </edge>
    <edge source="NON_LINEAR_TRANSFORMATIONS" target="DUNN_AND_SMYTH_BOOK">
      <data key="d4">1.0</data>
      <data key="d5">The book by Dunn and Smyth discusses the use of non-linear transformations in regression models</data>
      <data key="d6">d71b402ab9edbb4347e09c7af3257cf5</data>
    </edge>
    <edge source="NON_LINEAR_TRANSFORMATIONS" target="LINEAR_MODELS">
      <data key="d4">2.0</data>
      <data key="d5">Non-linear transformations are used to adjust linear models to meet model assumptions
Non-linear transformations are used in linear models to address violations of model assumptions, such as non-linearity and heteroscedasticity, and to reduce the influence of unusual observations</data>
      <data key="d6">07951ffe6787af44aa60c90c69e62f83,d71b402ab9edbb4347e09c7af3257cf5</data>
    </edge>
    <edge source="NON_LINEAR_TRANSFORMATIONS" target="LOG_TRANSFORMED_VARIABLES">
      <data key="d4">1.0</data>
      <data key="d5">Non-linear transformations often involve log-transformed variables to address model assumptions</data>
      <data key="d6">d71b402ab9edbb4347e09c7af3257cf5</data>
    </edge>
    <edge source="LOG_TRANSFORMATION" target="VARIANCE">
      <data key="d4">1.0</data>
      <data key="d5">Log-transforming the response may stabilise the variance, making it more consistent across different levels of the mean</data>
      <data key="d6">66f7fae9d896ff2b3fd40186cc833503</data>
    </edge>
    <edge source="LOG_TRANSFORMATION" target="RIGHT_SKEWED_DISTRIBUTION">
      <data key="d4">1.0</data>
      <data key="d5">Log-transforming the variable tends to make the distribution more symmetrical, especially when the variable has a right skewed distribution</data>
      <data key="d6">66f7fae9d896ff2b3fd40186cc833503</data>
    </edge>
    <edge source="LOG_TRANSFORMATION" target="POSITIVE_RESPONSE_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">Applying a log-transformation to a positive response variable ensures that predictions from the model will always be positive</data>
      <data key="d6">66f7fae9d896ff2b3fd40186cc833503</data>
    </edge>
    <edge source="LOG_TRANSFORMATION" target="HETEROSCEDASTICITY">
      <data key="d4">1.0</data>
      <data key="d5">Log transformation is a specific type of transformation that can be used to address heteroscedasticity in linear models</data>
      <data key="d6">07951ffe6787af44aa60c90c69e62f83</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="CHAPTER_4">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 4 likely uses the mammals dataset as an example to illustrate the application of non-linear transformations</data>
      <data key="d6">9846990771550ccdb865e49ecb96e2a3</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="BODY_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">The mammals dataset contains the average body weight in kg for 62 species of land mammal</data>
      <data key="d6">66f7fae9d896ff2b3fd40186cc833503</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="BRAIN_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">The mammals dataset contains the average brain weight in g for 62 species of land mammal</data>
      <data key="d6">66f7fae9d896ff2b3fd40186cc833503</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="SCATTERPLOT">
      <data key="d4">2.0</data>
      <data key="d5">A scatterplot of BRAIN against BODY is created from the mammals dataset
The scatterplot is a graphical representation of the relationship between variables in the mammals dataset</data>
      <data key="d6">66f7fae9d896ff2b3fd40186cc833503,f9d6c3504b8f8b5c25550076e45f8270</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="AFRICAN_ELEPHANT">
      <data key="d4">2.0</data>
      <data key="d5">The African elephant is one of the species in the mammals dataset with an unusually high average body weight and average brain weight
The African elephant is a species included in the mammals dataset, with unusually high body and brain weights</data>
      <data key="d6">66f7fae9d896ff2b3fd40186cc833503,f9d6c3504b8f8b5c25550076e45f8270</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="ASIAN_ELEPHANT">
      <data key="d4">2.0</data>
      <data key="d5">The Asian elephant is one of the species in the mammals dataset with an unusually high average body weight and average brain weight
The Asian elephant is a species included in the mammals dataset, with unusually high body and brain weights</data>
      <data key="d6">66f7fae9d896ff2b3fd40186cc833503,f9d6c3504b8f8b5c25550076e45f8270</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="HUMAN">
      <data key="d4">2.0</data>
      <data key="d5">The human is one of the species in the mammals dataset with an average body weight that stands out
The human is a species included in the mammals dataset, with an average body weight but unusually high brain weight</data>
      <data key="d6">66f7fae9d896ff2b3fd40186cc833503,f9d6c3504b8f8b5c25550076e45f8270</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="FIGURE_4_1">
      <data key="d4">1.0</data>
      <data key="d5">Figure 4.1 is a visual representation of the mammals dataset, specifically showing the scatterplot of brain weight against body weight</data>
      <data key="d6">f9d6c3504b8f8b5c25550076e45f8270</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="LOG_TRANSFORM">
      <data key="d4">1.0</data>
      <data key="d5">Log transformation is applied to the body weight variable in the mammals dataset to reduce skewness and the influence of unusual observations</data>
      <data key="d6">f9d6c3504b8f8b5c25550076e45f8270</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="FIGURE_4_2">
      <data key="d4">1.0</data>
      <data key="d5">Figure 4.2 is a visual representation of the mammals dataset, specifically showing the histograms of body weight and log(body weight)</data>
      <data key="d6">f9d6c3504b8f8b5c25550076e45f8270</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="LOG_BRAIN_WEIGHT">
      <data key="d4">2.0</data>
      <data key="d5">Log brain weight is a variable in the mammals dataset used in regression analysis
Logarithm of average brain weight is a variable in the mammals dataset</data>
      <data key="d6">bd05fe6a05f9a13d33c4f1b5a771ada5,c47968226557bc2eb5aec5bb7994fd0e</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="LOG_BODY_WEIGHT">
      <data key="d4">2.0</data>
      <data key="d5">Log body weight is a variable in the mammals dataset used in regression analysis
Logarithm of average body weight is a variable in the mammals dataset</data>
      <data key="d6">bd05fe6a05f9a13d33c4f1b5a771ada5,c47968226557bc2eb5aec5bb7994fd0e</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">The mammals dataset is used to fit a regression model of the logarithm of average brain weight on the logarithm of average body weight.</data>
      <data key="d6">f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="MASS_PACKAGE">
      <data key="d4">1.0</data>
      <data key="d5">The mammals dataset is part of the MASS package, which provides the data for the regression analysis.</data>
      <data key="d6">f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="HUMAN_OBSERVATION">
      <data key="d4">1.0</data>
      <data key="d5">Human observation is part of the mammals dataset</data>
      <data key="d6">c47968226557bc2eb5aec5bb7994fd0e</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="WATER_OPOSSUM_OBSERVATION">
      <data key="d4">1.0</data>
      <data key="d5">Water opposum observation is part of the mammals dataset</data>
      <data key="d6">c47968226557bc2eb5aec5bb7994fd0e</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="RHESUS_MONKEY_OBSERVATION">
      <data key="d4">1.0</data>
      <data key="d5">Rhesus monkey observation is part of the mammals dataset</data>
      <data key="d6">c47968226557bc2eb5aec5bb7994fd0e</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="RESIDUALS_VS_LEVERAGE_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">The residuals vs leverage plot is applied to the mammals dataset to identify influential data points</data>
      <data key="d6">9e2ebbb113c00fa43f0af3c0696baf95</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="ELEPHANT_SPECIES">
      <data key="d4">1.0</data>
      <data key="d5">The mammals dataset includes elephant species, which can be highly influential</data>
      <data key="d6">83bb91cf725e5116ca2f5748fddccfae</data>
    </edge>
    <edge source="MAMMALS_DATASET" target="LOG_TRANSFORMED_VARIABLES">
      <data key="d4">1.0</data>
      <data key="d5">Log-transformed variables can be used in the mammals dataset to reduce the influence of elephant species</data>
      <data key="d6">83bb91cf725e5116ca2f5748fddccfae</data>
    </edge>
    <edge source="TREES_DATASET" target="CHAPTER_4">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 4 likely uses the trees dataset as an example to illustrate the application of non-linear transformations</data>
      <data key="d6">9846990771550ccdb865e49ecb96e2a3</data>
    </edge>
    <edge source="TREES_DATASET" target="HEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">Height is a variable in the trees dataset used for predicting the volume of timber</data>
      <data key="d6">efeeb664622c1ee594e6a08a8322ffe3</data>
    </edge>
    <edge source="TREES_DATASET" target="GIRTH">
      <data key="d4">1.0</data>
      <data key="d5">Girth is a variable in the trees dataset used for predicting the volume of timber</data>
      <data key="d6">efeeb664622c1ee594e6a08a8322ffe3</data>
    </edge>
    <edge source="TREES_DATASET" target="VOLUME">
      <data key="d4">1.0</data>
      <data key="d5">Volume is the dependent variable in the trees dataset, to be predicted from height and girth</data>
      <data key="d6">efeeb664622c1ee594e6a08a8322ffe3</data>
    </edge>
    <edge source="TREES_DATASET" target="LOGTREES">
      <data key="d4">1.0</data>
      <data key="d5">The trees dataset is transformed into the logTrees data frame by applying a logarithmic transformation to the variables</data>
      <data key="d6">a60af43e42c72a41fa90da06beb29d1b</data>
    </edge>
    <edge source="TREES_DATASET" target="LOG_VOLUME">
      <data key="d4">1.0</data>
      <data key="d5">The trees dataset contains the dependent variable log-volume</data>
      <data key="d6">d71b402ab9edbb4347e09c7af3257cf5</data>
    </edge>
    <edge source="TREES_DATASET" target="LOG_DIAMETER">
      <data key="d4">1.0</data>
      <data key="d5">The trees dataset contains the independent variable log-diameter</data>
      <data key="d6">d71b402ab9edbb4347e09c7af3257cf5</data>
    </edge>
    <edge source="TREES_DATASET" target="LOG_HEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">The trees dataset contains the independent variable log-height</data>
      <data key="d6">d71b402ab9edbb4347e09c7af3257cf5</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATION" target="CHAPTER_5">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 5 discusses least squares estimation, which is a method for estimating model parameters</data>
      <data key="d6">9846990771550ccdb865e49ecb96e2a3</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATION" target="LEAST_SQUARES_ESTIMATE">
      <data key="d4">1.0</data>
      <data key="d5">Least squares estimation involves calculating the least squares estimate, which is a specific method for estimating model parameters</data>
      <data key="d6">9846990771550ccdb865e49ecb96e2a3</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATION" target="SIMPLE_LINEAR_REGRESSION">
      <data key="d4">2.0</data>
      <data key="d5">Least squares estimation is used in simple linear regression, which is a statistical method for modeling the relationship between variables
Least squares estimation is used in simple linear regression to find the line of best fit that minimizes the sum of the squares of the residuals</data>
      <data key="d6">9846990771550ccdb865e49ecb96e2a3,cf6e59c3746d399dc8baf5064f78ac57</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATION" target="DERIVATION_OF_LSE">
      <data key="d4">1.0</data>
      <data key="d5">The least squares estimate is derived through a process that involves calculus and linear algebra, which is explained in the derivation of the LSE</data>
      <data key="d6">cf6e59c3746d399dc8baf5064f78ac57</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATION" target="REGRESSION_PLANE">
      <data key="d4">2.0</data>
      <data key="d5">The regression plane is determined by least squares estimation, which minimizes the sum of squared residuals
Least squares estimation is used to find the regression plane by minimizing the sum of squared distances along the z-axis</data>
      <data key="d6">8a9b984c146f59b2af83d1c2f373d376,b1690cb1a67892245c0665e5099e322d</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATION" target="DESIGN_MATRIX">
      <data key="d4">3.0</data>
      <data key="d5">The design matrix is used in least squares estimation to fit models
Least squares estimation uses the design matrix to estimate the parameter vector in a linear model
The design matrix (X) is used in conjunction with the least squares estimation algorithm to estimate the parameter vector (&#946;) in the linear model.</data>
      <data key="d6">6616e10c85e86291147e72776854b8a2,9f335f1ecb85a1427df926df8bb1e89f,b9af17718641389ba07f53be13f31f8c</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATION" target="PARAMETER_VECTOR">
      <data key="d4">4.0</data>
      <data key="d5">The parameter vector is used in least squares estimation to fit models
Least squares estimation estimates the parameter vector based on the design matrix and the observed data
The parameter vector (&#946;) is estimated using the least squares estimation algorithm, which minimizes the sum of the squared differences between the observed values and the values predicted by the model.
Least squares estimation is used to estimate the parameter vector in linear models by minimizing the sum of the squares of the residuals</data>
      <data key="d6">07951ffe6787af44aa60c90c69e62f83,6616e10c85e86291147e72776854b8a2,9f335f1ecb85a1427df926df8bb1e89f,b9af17718641389ba07f53be13f31f8c</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATION" target="SYSTEMATIC_COMPONENT">
      <data key="d4">1.0</data>
      <data key="d5">Least squares estimation fits models where the systematic component is linear in the parameters</data>
      <data key="d6">9f335f1ecb85a1427df926df8bb1e89f</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATION" target="LINEAR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Least squares estimation is used to fit linear models</data>
      <data key="d6">9f335f1ecb85a1427df926df8bb1e89f</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATION" target="QUADRATIC_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Least squares estimation is used in quadratic regression to determine the parameters that minimize the sum of squared distances between the observations and the parabola</data>
      <data key="d6">87ba4f416a28aabc3b396908f5913b54</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATION" target="PARAMETERS">
      <data key="d4">1.0</data>
      <data key="d5">Least squares estimation is a method for determining the values of parameters (such as &#946;0, &#946;1, and &#946;2) in a statistical model that best fit the data</data>
      <data key="d6">87ba4f416a28aabc3b396908f5913b54</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATION" target="MODEL_REPARAMETERISATIONS">
      <data key="d4">1.0</data>
      <data key="d5">Least squares estimation provides the mathematical framework for model reparameterisations in linear models</data>
      <data key="d6">07951ffe6787af44aa60c90c69e62f83</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATE" target="EXERCISE_22A">
      <data key="d4">1.0</data>
      <data key="d5">Exercise 22a introduced the model for which the least squares estimate is given</data>
      <data key="d6">096afa471635bc59c3bfa9af4d04d625</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATE" target="MU">
      <data key="d4">1.0</data>
      <data key="d5">The least squares estimate is for the parameter &#181; = (&#181;A, &#181;B, &#181;C)</data>
      <data key="d6">096afa471635bc59c3bfa9af4d04d625</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATE" target="SA">
      <data key="d4">1.0</data>
      <data key="d5">SA is used in the calculation of the least squares estimate for &#181;A</data>
      <data key="d6">096afa471635bc59c3bfa9af4d04d625</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATE" target="SB">
      <data key="d4">1.0</data>
      <data key="d5">SB is used in the calculation of the least squares estimate for &#181;B</data>
      <data key="d6">096afa471635bc59c3bfa9af4d04d625</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATE" target="SC">
      <data key="d4">1.0</data>
      <data key="d5">SC is used in the calculation of the least squares estimate for &#181;C</data>
      <data key="d6">096afa471635bc59c3bfa9af4d04d625</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATE" target="NA">
      <data key="d4">1.0</data>
      <data key="d5">nA is used in the calculation of the least squares estimate for &#181;A</data>
      <data key="d6">096afa471635bc59c3bfa9af4d04d625</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATE" target="NB">
      <data key="d4">1.0</data>
      <data key="d5">nB is used in the calculation of the least squares estimate for &#181;B</data>
      <data key="d6">096afa471635bc59c3bfa9af4d04d625</data>
    </edge>
    <edge source="LEAST_SQUARES_ESTIMATE" target="NC">
      <data key="d4">1.0</data>
      <data key="d5">nC is used in the calculation of the least squares estimate for &#181;C</data>
      <data key="d6">096afa471635bc59c3bfa9af4d04d625</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="DERIVATION_OF_LSE">
      <data key="d4">1.0</data>
      <data key="d5">The derivation of the least squares estimate is relevant to simple linear regression, as it is used to find the parameters of the model</data>
      <data key="d6">cf6e59c3746d399dc8baf5064f78ac57</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="SUMMARY_OF_CHAPTER_5">
      <data key="d4">1.0</data>
      <data key="d5">Simple linear regression is a topic covered in the summary of Chapter 5, which provides an overview of the key points related to least squares estimation</data>
      <data key="d6">cf6e59c3746d399dc8baf5064f78ac57</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="ST117">
      <data key="d4">2.0</data>
      <data key="d5">ST117 introduced the simple linear regression model, which is the simplest form of a linear model
ST117 introduced the concept of simple linear regression as part of its curriculum</data>
      <data key="d6">28eee75e95bbbaf143368c3289585670,7b32c106246576bb451a5a3985914351</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="ST121">
      <data key="d4">2.0</data>
      <data key="d5">ST121 also introduced the simple linear regression model, which is the simplest form of a linear model
ST121 also introduced the concept of simple linear regression as part of its curriculum</data>
      <data key="d6">28eee75e95bbbaf143368c3289585670,7b32c106246576bb451a5a3985914351</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="LINEAR_ALGEBRA">
      <data key="d4">1.0</data>
      <data key="d5">Simple linear regression models can be understood and analyzed using tools from linear algebra</data>
      <data key="d6">7b32c106246576bb451a5a3985914351</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="LINEAR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">A simple linear regression is a specific type of linear model</data>
      <data key="d6">28eee75e95bbbaf143368c3289585670</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="R">
      <data key="d4">2.0</data>
      <data key="d5">R provides functions to fit simple linear regression models
R is used to fit the simple linear regression model</data>
      <data key="d6">25fce1af816975003128126b5cfea73b,28eee75e95bbbaf143368c3289585670</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="DIAMOND_DATA">
      <data key="d4">1.0</data>
      <data key="d5">The diamond data can be analyzed using simple linear regression to understand the relationship between the price and weight of diamonds</data>
      <data key="d6">28eee75e95bbbaf143368c3289585670</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="OUTCOME_VARIABLE_Y">
      <data key="d4">1.0</data>
      <data key="d5">Simple linear regression involves the outcome variable Y, which is the response variable in the model</data>
      <data key="d6">e47d573a10e64a657e58218df64d8920</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="EXPLANATORY_VARIABLE_X">
      <data key="d4">1.0</data>
      <data key="d5">Simple linear regression involves the explanatory variable X, which is used to explain the variation in Y</data>
      <data key="d6">e47d573a10e64a657e58218df64d8920</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="STATISTICAL_INDEPENDENCE">
      <data key="d4">1.0</data>
      <data key="d5">Statistical independence is a concept that might be relevant when considering the assumptions of simple linear regression, particularly in the context of the independence of errors.</data>
      <data key="d6">4683e58cf41e5f5d415a63ddb2fe0cac</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="OBSERVATIONS">
      <data key="d4">1.0</data>
      <data key="d5">Simple linear regression uses a set of paired observations (x1, y1), (x2, y2), ..., (xn, yn) to model the relationship between the explanatory and response variables.</data>
      <data key="d6">4683e58cf41e5f5d415a63ddb2fe0cac</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="SOLITAIRE_RING_EXAMPLE">
      <data key="d4">1.0</data>
      <data key="d5">The Solitaire ring example illustrates the application of simple linear regression, where the price of the ring (yj) is the response variable and the weight of the diamond (xj) is the explanatory variable.</data>
      <data key="d6">4683e58cf41e5f5d415a63ddb2fe0cac</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="R2">
      <data key="d4">1.0</data>
      <data key="d5">R2 is a measure used in simple linear regression to assess the goodness of fit of the model</data>
      <data key="d6">8a9b984c146f59b2af83d1c2f373d376</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="REGRESSION_PLANE">
      <data key="d4">1.0</data>
      <data key="d5">Simple linear regression is extended to a regression plane in R3 for multiple regression analysis</data>
      <data key="d6">8a9b984c146f59b2af83d1c2f373d376</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="EPSILON">
      <data key="d4">2.0</data>
      <data key="d5">The error term (&#1013;) is part of the simple linear regression model, representing the unexplained variation in Y
&#1013;j is the error term in the simple linear regression model, which represents the deviation of the observed Y values from their expected values.</data>
      <data key="d6">512d9ffebe309a6f944ebce1ae2ff2a3,74a5a0e8ae0f846240c782cc1a30f82f</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="BETA_0">
      <data key="d4">2.0</data>
      <data key="d5">The intercept (&#946;0) is part of the simple linear regression model, representing the expected value of Y when all predictor variables are zero
Beta_0 (&#946;0) is the intercept parameter in the simple linear regression model, which determines the value of Y when X is zero.</data>
      <data key="d6">512d9ffebe309a6f944ebce1ae2ff2a3,74a5a0e8ae0f846240c782cc1a30f82f</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="BETA_1">
      <data key="d4">2.0</data>
      <data key="d5">The coefficient (&#946;1) is not directly applicable in the simple linear regression model, as it is specific to the relationship between X1 and Y in the presence of X2
Beta_1 (&#946;1) is the slope parameter in the simple linear regression model, which determines the change in Y for a one-unit change in X.</data>
      <data key="d6">512d9ffebe309a6f944ebce1ae2ff2a3,74a5a0e8ae0f846240c782cc1a30f82f</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="X1">
      <data key="d4">1.0</data>
      <data key="d5">X1 (price) is the predictor variable in the simple linear regression model</data>
      <data key="d6">512d9ffebe309a6f944ebce1ae2ff2a3</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="Y">
      <data key="d4">2.0</data>
      <data key="d5">Y (sales volume) is the dependent variable in the simple linear regression model
In simple linear regression, Y is the dependent variable whose values are predicted based on the values of the independent variable X.</data>
      <data key="d6">512d9ffebe309a6f944ebce1ae2ff2a3,74a5a0e8ae0f846240c782cc1a30f82f</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="PRICE">
      <data key="d4">1.0</data>
      <data key="d5">The simple linear regression model uses price as the only predictor variable to estimate the relationship between price and sales. The relationship strength is moderate, as the model only considers one variable.</data>
      <data key="d6">426434b67f6a287852ab66b82ca873cf</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="MULTIPLE_LINEAR_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">The simple linear regression model is a simplified version of the multiple linear regression model, which includes only price as a predictor variable. The relationship strength is moderate, as the multiple linear regression model provides a more comprehensive analysis by including additional variables.</data>
      <data key="d6">426434b67f6a287852ab66b82ca873cf</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="INTERCEPT">
      <data key="d4">1.0</data>
      <data key="d5">The intercept is a parameter in the simple linear regression model, but its interpretation is limited due to the dataset's range of price values. The relationship strength is low, as the intercept's relevance is restricted in this context.</data>
      <data key="d6">426434b67f6a287852ab66b82ca873cf</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="X">
      <data key="d4">1.0</data>
      <data key="d5">In simple linear regression, X is the independent variable whose values are used to predict the values of the dependent variable Y.</data>
      <data key="d6">74a5a0e8ae0f846240c782cc1a30f82f</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="SIGMA_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">&#963;^2 is the variance of the error term &#1013;j in the simple linear regression model, which determines the spread of the observed Y values around their expected values.</data>
      <data key="d6">74a5a0e8ae0f846240c782cc1a30f82f</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="HEIGHTS">
      <data key="d4">1.0</data>
      <data key="d5">Heights are the response variable in the simple linear regression model</data>
      <data key="d6">25fce1af816975003128126b5cfea73b</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="LOG2_DIAMETERS">
      <data key="d4">1.0</data>
      <data key="d5">Log2-diameters are the explanatory variable in the simple linear regression model</data>
      <data key="d6">25fce1af816975003128126b5cfea73b</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="NULL_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">Simple linear regression models can produce null plots when the model assumptions are met</data>
      <data key="d6">aa13c33a7e61206e6021e2736002ca9a</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="TRANSFORM">
      <data key="d4">1.0</data>
      <data key="d5">A simple linear regression model can be improved by applying a transform to the explanatory variable</data>
      <data key="d6">15c7b5750483a382ce59751008e86751</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Simple linear regression is an example where the quantities used in the derivation of the least squares estimator are illustrated</data>
      <data key="d6">a4a817bb79d6ae8812c808ca41d47f43</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="LEVERAGES">
      <data key="d4">1.0</data>
      <data key="d5">The formula for calculating leverages in simple linear regression is provided in Exercise 21, which is relevant to understanding the influence of data points in regression analysis.</data>
      <data key="d6">f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="SALES_VOLUME">
      <data key="d4">1.0</data>
      <data key="d5">Simple linear regression is used to model the relationship between sales volume and price.</data>
      <data key="d6">e079b7c92d5c0b009ff02040eb652bc6</data>
    </edge>
    <edge source="SIMPLE_LINEAR_REGRESSION" target="BRAND">
      <data key="d4">1.0</data>
      <data key="d5">The Brand variable is not included in the simple linear regression model, which only considers the price variable</data>
      <data key="d6">86ece4718d27d1a6c6a1f448cc850e2b</data>
    </edge>
    <edge source="CHAPTER_5" target="SUMMARY_OF_CHAPTER_5">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 5 is summarized in the Summary of Chapter 5</data>
      <data key="d6">9133320d451c1c1eddf1438064663b17</data>
    </edge>
    <edge source="INVERTIBLE_LINEAR_TRANSFORMATIONS" target="SUMMARY_OF_CHAPTER_5">
      <data key="d4">1.0</data>
      <data key="d5">Invertible linear transformations are discussed in the summary of Chapter 5, which includes various examples and applications of least squares estimation</data>
      <data key="d6">cf6e59c3746d399dc8baf5064f78ac57</data>
    </edge>
    <edge source="INVERTIBLE_LINEAR_TRANSFORMATIONS" target="BETA">
      <data key="d4">1.0</data>
      <data key="d5">Invertible linear transformations can change the interpretation of the parameter vector Beta</data>
      <data key="d6">255685e281cc5a9edf073c700f425a6b</data>
    </edge>
    <edge source="MAXIMUM_LIKELIHOOD_ESTIMATION" target="LIKELIHOOD_FUNCTION_OF_NORMAL_LINEAR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The likelihood function of a normal linear model is used in maximum likelihood estimation to find the parameters that maximize the likelihood of the observed data</data>
      <data key="d6">cf6e59c3746d399dc8baf5064f78ac57</data>
    </edge>
    <edge source="CHAPTER_6" target="LIKELIHOOD_FUNCTION">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 6 discusses the likelihood function of a normal linear model</data>
      <data key="d6">9133320d451c1c1eddf1438064663b17</data>
    </edge>
    <edge source="CHAPTER_6" target="MLE_PARAMETER_VECTOR">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 6 discusses the MLE for the parameter vector</data>
      <data key="d6">9133320d451c1c1eddf1438064663b17</data>
    </edge>
    <edge source="CHAPTER_6" target="SAMPLING_DISTRIBUTION_LEAST_SQUARES">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 6 discusses the sampling distribution of the least squares estimator</data>
      <data key="d6">9133320d451c1c1eddf1438064663b17</data>
    </edge>
    <edge source="CHAPTER_6" target="UNBIASED_ESTIMATOR_ERROR_VARIANCE">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 6 discusses the unbiased estimator for the error variance</data>
      <data key="d6">9133320d451c1c1eddf1438064663b17</data>
    </edge>
    <edge source="CHAPTER_6" target="SUMMARY_OF_CHAPTER_6">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 6 is summarized in the Summary of Chapter 6</data>
      <data key="d6">9133320d451c1c1eddf1438064663b17</data>
    </edge>
    <edge source="LIKELIHOOD_FUNCTION" target="MLE">
      <data key="d4">1.0</data>
      <data key="d5">The likelihood function is maximized to derive the MLE for the parameter vector &#946;</data>
      <data key="d6">d738df7d83784c8a41b3948271c537b6</data>
    </edge>
    <edge source="LIKELIHOOD_FUNCTION" target="MULTIVARIATE_NORMAL_DISTRIBUTION">
      <data key="d4">1.0</data>
      <data key="d5">The multivariate normal distribution is used to derive the likelihood function in the context of the normal linear model</data>
      <data key="d6">f483798b15ef305e7826fd7142379e03</data>
    </edge>
    <edge source="LIKELIHOOD_FUNCTION" target="Y">
      <data key="d4">1.0</data>
      <data key="d5">Y is the vector of observed values that the likelihood function is calculated for</data>
      <data key="d6">f483798b15ef305e7826fd7142379e03</data>
    </edge>
    <edge source="LIKELIHOOD_FUNCTION" target="BETA">
      <data key="d4">1.0</data>
      <data key="d5">Beta (&#946;) is a parameter in the normal linear model that the likelihood function is a function of</data>
      <data key="d6">f483798b15ef305e7826fd7142379e03</data>
    </edge>
    <edge source="LIKELIHOOD_FUNCTION" target="SIGMA_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">Sigma squared (&#963;^2) is a parameter in the normal linear model that the likelihood function is a function of</data>
      <data key="d6">f483798b15ef305e7826fd7142379e03</data>
    </edge>
    <edge source="LIKELIHOOD_FUNCTION" target="IN">
      <data key="d4">1.0</data>
      <data key="d5">In is part of the covariance matrix of the normal linear model that the likelihood function is derived from</data>
      <data key="d6">f483798b15ef305e7826fd7142379e03</data>
    </edge>
    <edge source="CHAPTER_7" target="HAT_MATRIX_PROPERTIES">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 7 discusses the properties of the hat matrix</data>
      <data key="d6">9133320d451c1c1eddf1438064663b17</data>
    </edge>
    <edge source="CHAPTER_7" target="RESIDUALS_FITTED_VALUES_PROPERTIES">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 7 discusses the properties of the residuals and of the fitted values</data>
      <data key="d6">9133320d451c1c1eddf1438064663b17</data>
    </edge>
    <edge source="HAT_MATRIX" target="PROPERTIES_HAT_MATRIX">
      <data key="d4">1.0</data>
      <data key="d5">The hat matrix has specific properties that are important for understanding its role in regression analysis</data>
      <data key="d6">1d52aaeb960f9787b6229e57738f8e47</data>
    </edge>
    <edge source="HAT_MATRIX" target="RESIDUALS">
      <data key="d4">2.0</data>
      <data key="d5">The hat matrix is used to calculate the residuals in a regression model
The hat matrix (H) is used in the calculation of residuals (b&#1013;) as (In - H)y</data>
      <data key="d6">1d52aaeb960f9787b6229e57738f8e47,3fb977ccba63e267d2e7dd4de6479ce1</data>
    </edge>
    <edge source="HAT_MATRIX" target="FITTED_VALUES">
      <data key="d4">2.0</data>
      <data key="d5">The hat matrix is used to calculate the fitted values in a regression model
The hat matrix (H) is used to calculate the fitted values (yb) in a linear model</data>
      <data key="d6">1d52aaeb960f9787b6229e57738f8e47,3fb977ccba63e267d2e7dd4de6479ce1</data>
    </edge>
    <edge source="HAT_MATRIX" target="SUMMARY_CHAPTER_7">
      <data key="d4">1.0</data>
      <data key="d5">The hat matrix is a key concept discussed in the summary of Chapter 7</data>
      <data key="d6">1d52aaeb960f9787b6229e57738f8e47</data>
    </edge>
    <edge source="HAT_MATRIX" target="BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">The hat matrix is used in the calculation of the least squares estimator Beta hat (&#946;b)</data>
      <data key="d6">9923e77ac6b3de95cb5026bc5e7fe8c0</data>
    </edge>
    <edge source="HAT_MATRIX" target="LINEAR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The hat matrix (H) is a key component in the linear model, used to project observed values to fitted values</data>
      <data key="d6">3fb977ccba63e267d2e7dd4de6479ce1</data>
    </edge>
    <edge source="HAT_MATRIX" target="YB">
      <data key="d4">1.0</data>
      <data key="d5">The hat matrix (H) is used to transform the observed response values (Y) into fitted values (Yb)</data>
      <data key="d6">6ee02b38ae842fd5eac9a11c4fd6659f</data>
    </edge>
    <edge source="HAT_MATRIX" target="LEVERAGE">
      <data key="d4">2.0</data>
      <data key="d5">Hat matrix is used to calculate the leverages (hat-values) of data points
The hat matrix is used to calculate the leverage (hii) of each observation</data>
      <data key="d6">7e05f1b457a496c8b3630e7044fc5981,bd05fe6a05f9a13d33c4f1b5a771ada5</data>
    </edge>
    <edge source="HAT_MATRIX" target="LEVERAGES">
      <data key="d4">1.0</data>
      <data key="d5">Leverages are derived from the hat matrix, which is used in regression analysis to understand the influence of each data point on the fitted regression model.</data>
      <data key="d6">f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </edge>
    <edge source="HAT_MATRIX" target="ROBUST_REGRESSION">
      <data key="d4">2.0</data>
      <data key="d5">Robust regression can be seen as an alternative to using the hat matrix for dealing with influential points
Robust regression involves the use of the hat matrix to identify influential points in the data</data>
      <data key="d6">7e05f1b457a496c8b3630e7044fc5981,83bb91cf725e5116ca2f5748fddccfae</data>
    </edge>
    <edge source="HAT_MATRIX" target="YBI">
      <data key="d4">1.0</data>
      <data key="d5">The hat matrix is used in the calculation of ybi, the estimated value of the response variable</data>
      <data key="d6">83bb91cf725e5116ca2f5748fddccfae</data>
    </edge>
    <edge source="HAT_MATRIX" target="COOKS_DISTANCE">
      <data key="d4">1.0</data>
      <data key="d5">The hat matrix is indirectly related to Cook's distance as it is used to calculate the leverage (hii) which is part of the formula for Cook's distance</data>
      <data key="d6">7e05f1b457a496c8b3630e7044fc5981</data>
    </edge>
    <edge source="RESIDUALS" target="FITTED_VALUES">
      <data key="d4">2.0</data>
      <data key="d5">Residuals are calculated as the difference between the observed values and the fitted values
Residuals are calculated as the difference between the observed values and the fitted values, used to assess the fit of the model</data>
      <data key="d6">1d52aaeb960f9787b6229e57738f8e47,60cc94e681863c9fcc6f9be1e500f840</data>
    </edge>
    <edge source="RESIDUALS" target="LINE_OF_BEST_FIT">
      <data key="d4">1.0</data>
      <data key="d5">Residuals are calculated based on the difference between observed and predicted sales values from the line of best fit</data>
      <data key="d6">f16299fc00a7a69bdf983dce826b4918</data>
    </edge>
    <edge source="RESIDUALS" target="REGRESSION_PLANE">
      <data key="d4">1.0</data>
      <data key="d5">Residuals are the signed distances along the z-axis between the datapoints and the regression plane</data>
      <data key="d6">8a9b984c146f59b2af83d1c2f373d376</data>
    </edge>
    <edge source="RESIDUALS" target="YJ">
      <data key="d4">2.0</data>
      <data key="d5">Residuals are calculated as the difference between the observed response values Yj and their fitted values
Residuals are calculated as the difference between the observed values Yj and the fitted values</data>
      <data key="d6">5cc49d301d9cd1f8e20b92ab9d8346b0,d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </edge>
    <edge source="RESIDUALS" target="PARAMETER_ESTIMATES">
      <data key="d4">1.0</data>
      <data key="d5">Residuals are minimized by choosing appropriate parameter estimates, aiming to reduce the model's error</data>
      <data key="d6">22093a562f5f05dc9891b45ab9bcbea8</data>
    </edge>
    <edge source="RESIDUALS" target="RESIDUAL_SUM_OF_SQUARES">
      <data key="d4">1.0</data>
      <data key="d5">Residuals contribute to the calculation of the residual sum of squares, which is a measure of the model's overall error</data>
      <data key="d6">22093a562f5f05dc9891b45ab9bcbea8</data>
    </edge>
    <edge source="RESIDUALS" target="EPSILON">
      <data key="d4">1.0</data>
      <data key="d5">Residuals are used as estimates of the errors &#1013;1, ..., &#1013;n in the regression model</data>
      <data key="d6">0da640a09a395a50b6e16e047fa8d0d6</data>
    </edge>
    <edge source="RESIDUALS" target="RESIDUAL_PLOTS">
      <data key="d4">3.0</data>
      <data key="d5">Residual plots are used to check for violations of model assumptions using the residuals as estimates of the errors
Residual plots are used to visualize the residuals and assess the fit of a statistical model
Residual plots are used to visualize the residuals in order to assess the fit of the regression model</data>
      <data key="d6">0da640a09a395a50b6e16e047fa8d0d6,7cd6069e88e81548a237fa937adfecc6,a60af43e42c72a41fa90da06beb29d1b</data>
    </edge>
    <edge source="RESIDUALS" target="ERRORS">
      <data key="d4">2.0</data>
      <data key="d5">Residuals are estimates of the errors in a statistical model
Residuals are the differences between the observed values and the values predicted by the model, which are essentially the errors</data>
      <data key="d6">7cd6069e88e81548a237fa937adfecc6,e361ac139c268d5c3f3623f920e68af2</data>
    </edge>
    <edge source="RESIDUALS" target="SMOOTHED_RESIDUAL_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">The smoothed residual plot is a graphical representation of the residuals from the regression model</data>
      <data key="d6">674b8d5bb1f830d0fb944942514d1a16</data>
    </edge>
    <edge source="RESIDUALS" target="SMOOTHING_CURVE">
      <data key="d4">1.0</data>
      <data key="d5">The smoothing curve is a non-parametric estimate of the mean of the residuals</data>
      <data key="d6">674b8d5bb1f830d0fb944942514d1a16</data>
    </edge>
    <edge source="RESIDUALS" target="VARIANCE_ASSUMPTION">
      <data key="d4">1.0</data>
      <data key="d5">The constant variance assumption is based on the residuals</data>
      <data key="d6">312309b45c59e1c84695ac3c7e202742</data>
    </edge>
    <edge source="RESIDUALS" target="ROUNDING">
      <data key="d4">1.0</data>
      <data key="d5">Rounding can affect the residuals</data>
      <data key="d6">312309b45c59e1c84695ac3c7e202742</data>
    </edge>
    <edge source="RESIDUALS" target="HOMOSCEDASTICITY">
      <data key="d4">1.0</data>
      <data key="d5">Homoscedasticity is a property of the residuals, indicating that the variance is the same for all values of the independent variable</data>
      <data key="d6">60cc94e681863c9fcc6f9be1e500f840</data>
    </edge>
    <edge source="RESIDUALS" target="MULTIPLE_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Residuals are used to assess the fit of the multiple regression model</data>
      <data key="d6">60cc94e681863c9fcc6f9be1e500f840</data>
    </edge>
    <edge source="RESIDUALS" target="Y_HAT_J">
      <data key="d4">1.0</data>
      <data key="d5">Residuals are calculated as the difference between the observed values Yj and the fitted values Y_hat_j</data>
      <data key="d6">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </edge>
    <edge source="RESIDUALS" target="RESIDSS">
      <data key="d4">1.0</data>
      <data key="d5">ResidSS is calculated using the residuals</data>
      <data key="d6">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </edge>
    <edge source="RESIDUALS" target="IN">
      <data key="d4">1.0</data>
      <data key="d5">The identity matrix (In) is used in the calculation of residuals (b&#1013;) as (In - H)y</data>
      <data key="d6">3fb977ccba63e267d2e7dd4de6479ce1</data>
    </edge>
    <edge source="RESIDUALS" target="Y">
      <data key="d4">1.0</data>
      <data key="d5">Residuals are calculated by subtracting the fitted values from the observed response vector Y</data>
      <data key="d6">0b650eb2f1dcd603b64fec3c4b5cd24b</data>
    </edge>
    <edge source="RESIDUALS" target="BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">The least squares estimator Beta hat (&#946;b) is used to calculate the fitted values, which in turn are used to calculate the residuals</data>
      <data key="d6">0b650eb2f1dcd603b64fec3c4b5cd24b</data>
    </edge>
    <edge source="RESIDUALS" target="UNUSUAL_OBSERVATIONS">
      <data key="d4">1.0</data>
      <data key="d5">The magnitude of the residuals helps determine the influence of data points on the fitted model</data>
      <data key="d6">e593096f3805c2686423cb91ea276fe6</data>
    </edge>
    <edge source="FITTED_VALUES" target="BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Fitted values are calculated using the estimated parameters Beta hat</data>
      <data key="d6">01d5ee79489582b4135fc96f676b24a0</data>
    </edge>
    <edge source="FITTED_VALUES" target="SIMPLE_REGRESSION_LINE">
      <data key="d4">1.0</data>
      <data key="d5">The simple regression line is used to calculate the fitted values by substituting the explanatory variable values into the model equation</data>
      <data key="d6">22093a562f5f05dc9891b45ab9bcbea8</data>
    </edge>
    <edge source="FITTED_VALUES" target="NULL_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">Fitted values are plotted against residuals in a null plot to check for patterns that might indicate violations of model assumptions</data>
      <data key="d6">aa13c33a7e61206e6021e2736002ca9a</data>
    </edge>
    <edge source="FITTED_VALUES" target="SMOOTHED_RESIDUAL_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">The smoothed residual plot uses the fitted values from the regression model</data>
      <data key="d6">674b8d5bb1f830d0fb944942514d1a16</data>
    </edge>
    <edge source="FITTED_VALUES" target="SMOOTHING_CURVE">
      <data key="d4">1.0</data>
      <data key="d5">The smoothing curve is a function of the fitted values</data>
      <data key="d6">674b8d5bb1f830d0fb944942514d1a16</data>
    </edge>
    <edge source="FITTED_VALUES" target="RESPONSE_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">Fitted values are the values predicted by the model for the response variable</data>
      <data key="d6">e361ac139c268d5c3f3623f920e68af2</data>
    </edge>
    <edge source="FITTED_VALUES" target="RESIDUAL_PLOTS">
      <data key="d4">1.0</data>
      <data key="d5">Residual plots include a plot of residuals versus fitted values to check for patterns that might indicate a poor fit</data>
      <data key="d6">a60af43e42c72a41fa90da06beb29d1b</data>
    </edge>
    <edge source="FITTED_VALUES" target="Y">
      <data key="d4">1.0</data>
      <data key="d5">Fitted values are the predicted values of Y based on the linear model</data>
      <data key="d6">0b650eb2f1dcd603b64fec3c4b5cd24b</data>
    </edge>
    <edge source="FITTED_VALUES" target="H">
      <data key="d4">1.0</data>
      <data key="d5">H is used in the calculation of the fitted values (yb) in the regression model</data>
      <data key="d6">e593096f3805c2686423cb91ea276fe6</data>
    </edge>
    <edge source="FITTED_VALUES" target="UNUSUAL_OBSERVATIONS">
      <data key="d4">1.0</data>
      <data key="d5">The fitted values, along with the residuals, determine the influence of data points on the fitted model</data>
      <data key="d6">e593096f3805c2686423cb91ea276fe6</data>
    </edge>
    <edge source="UNUSUAL_OBSERVATIONS" target="LEVERAGES">
      <data key="d4">2.0</data>
      <data key="d5">Leverages are a type of unusual observation in regression analysis
Leverages, along with the magnitude of the residuals, determine how influential a data point is</data>
      <data key="d6">1d52aaeb960f9787b6229e57738f8e47,e593096f3805c2686423cb91ea276fe6</data>
    </edge>
    <edge source="UNUSUAL_OBSERVATIONS" target="OUTLIERS">
      <data key="d4">1.0</data>
      <data key="d5">Outliers are a type of unusual observation in regression analysis</data>
      <data key="d6">1d52aaeb960f9787b6229e57738f8e47</data>
    </edge>
    <edge source="UNUSUAL_OBSERVATIONS" target="INFLUENCE">
      <data key="d4">1.0</data>
      <data key="d5">Influence is a type of unusual observation in regression analysis</data>
      <data key="d6">1d52aaeb960f9787b6229e57738f8e47</data>
    </edge>
    <edge source="UNUSUAL_OBSERVATIONS" target="TRANSFORMATIONS">
      <data key="d4">1.0</data>
      <data key="d5">Transformations can reduce the influence of unusual observations in linear models</data>
      <data key="d6">07951ffe6787af44aa60c90c69e62f83</data>
    </edge>
    <edge source="UNUSUAL_OBSERVATIONS" target="IN">
      <data key="d4">1.0</data>
      <data key="d5">In is used in the calculation of the influence of data points on the fitted model</data>
      <data key="d6">e593096f3805c2686423cb91ea276fe6</data>
    </edge>
    <edge source="UNUSUAL_OBSERVATIONS" target="REGRESSION_OUTLIERS">
      <data key="d4">1.0</data>
      <data key="d5">Regression outliers are a type of unusual observations that have a large positive or negative residual</data>
      <data key="d6">e593096f3805c2686423cb91ea276fe6</data>
    </edge>
    <edge source="UNUSUAL_OBSERVATIONS" target="COOKS_DISTANCE">
      <data key="d4">1.0</data>
      <data key="d5">Cook's distance is used to identify influential data points, which are a type of unusual observations</data>
      <data key="d6">e593096f3805c2686423cb91ea276fe6</data>
    </edge>
    <edge source="LEVERAGES" target="HII">
      <data key="d4">1.0</data>
      <data key="d5">The concept of leverages is represented by the leverage (hii) of the data points</data>
      <data key="d6">6ee02b38ae842fd5eac9a11c4fd6659f</data>
    </edge>
    <edge source="LEVERAGES" target="CAR_PACKAGE">
      <data key="d4">1.0</data>
      <data key="d5">The car package provides functions to calculate and plot leverages for a given model, as demonstrated with the mammals dataset.</data>
      <data key="d6">f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </edge>
    <edge source="LEVERAGES" target="INDEX_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">An index plot is used to display the leverages for the regression model, as shown in Figure 8.1.</data>
      <data key="d6">f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </edge>
    <edge source="LEVERAGES" target="RULE_OF_THUMB_THRESHOLD">
      <data key="d4">1.0</data>
      <data key="d5">The rule of thumb threshold is used to identify data points with high leverage in the regression model.</data>
      <data key="d6">f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </edge>
    <edge source="OUTLIERS" target="REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Outliers in the context of regression analysis refer to response values that do not fit the current model, potentially indicating unusual observations.</data>
      <data key="d6">f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </edge>
    <edge source="OUTLIERS" target="DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Outliers are present in the dataset and are expected in a reasonably sized dataset</data>
      <data key="d6">428db872e71a17a2cf7868b03a52def0</data>
    </edge>
    <edge source="INFLUENCE" target="INFLUENTIAL_DATA_POINTS">
      <data key="d4">1.0</data>
      <data key="d5">Influential data points are those that have a high degree of influence on the regression model</data>
      <data key="d6">1d52aaeb960f9787b6229e57738f8e47</data>
    </edge>
    <edge source="INFLUENCE" target="CHAPTER 8">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 8 discusses the concept of influence in statistical models, including how to identify and handle influential data points</data>
      <data key="d6">617760dc9b9682075b10899cc8473dd5</data>
    </edge>
    <edge source="INFLUENCE" target="INFLUENTIAL_OBSERVATION">
      <data key="d4">1.0</data>
      <data key="d5">Influence is related to the concept of an influential observation</data>
      <data key="d6">428db872e71a17a2cf7868b03a52def0</data>
    </edge>
    <edge source="INFLUENTIAL_DATA_POINTS" target="HUMAN_OBSERVATION">
      <data key="d4">1.0</data>
      <data key="d5">The Human observation is an example of an influential data point that requires careful consideration</data>
      <data key="d6">323899f01972255cd3278bccee20d5d8</data>
    </edge>
    <edge source="INFLUENTIAL_DATA_POINTS" target="FITTED_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Influential data points can significantly impact the fitted model, potentially skewing the results</data>
      <data key="d6">83bb91cf725e5116ca2f5748fddccfae</data>
    </edge>
    <edge source="CHAPTER 8" target="SUMMARY OF CHAPTER 8">
      <data key="d4">1.0</data>
      <data key="d5">The summary of Chapter 8 provides a recap of the key concepts and findings related to influence in statistical models</data>
      <data key="d6">617760dc9b9682075b10899cc8473dd5</data>
    </edge>
    <edge source="CHAPTER 9" target="CATEGORICAL PREDICTOR VARIABLES">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 9 focuses on the use and analysis of categorical predictor variables in statistical models</data>
      <data key="d6">617760dc9b9682075b10899cc8473dd5</data>
    </edge>
    <edge source="CHAPTER 9" target="RETAIL DATA">
      <data key="d4">1.0</data>
      <data key="d5">Retail data is used as an example in Chapter 9 to demonstrate the inclusion of brand as a predictor variable in statistical models</data>
      <data key="d6">617760dc9b9682075b10899cc8473dd5</data>
    </edge>
    <edge source="CHAPTER 9" target="BRAND">
      <data key="d4">1.0</data>
      <data key="d5">Brand is discussed in Chapter 9 as a categorical predictor variable, particularly in the context of retail data</data>
      <data key="d6">617760dc9b9682075b10899cc8473dd5</data>
    </edge>
    <edge source="CHAPTER 9" target="ALTERNATIVE PARAMETERISATIONS">
      <data key="d4">1.0</data>
      <data key="d5">Alternative parameterisations are discussed in Chapter 9 as methods for representing categorical predictor variables in statistical models</data>
      <data key="d6">617760dc9b9682075b10899cc8473dd5</data>
    </edge>
    <edge source="CHAPTER 9" target="MODEL WITH INTERACTION">
      <data key="d4">1.0</data>
      <data key="d5">A model with an interaction is discussed in Chapter 9 as a type of statistical model that includes interaction terms between predictor variables</data>
      <data key="d6">617760dc9b9682075b10899cc8473dd5</data>
    </edge>
    <edge source="CHAPTER 9" target="SUMMARY OF CHAPTER 9">
      <data key="d4">1.0</data>
      <data key="d5">The summary of Chapter 9 provides a recap of the key concepts and findings related to categorical predictor variables in statistical models</data>
      <data key="d6">617760dc9b9682075b10899cc8473dd5</data>
    </edge>
    <edge source="BRAND" target="MULTIPLE_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Brand is a categorical variable that may be included in multiple regression as a factor influencing the response variable sales</data>
      <data key="d6">336546bc73cbe1828a0cc1a45faf8f5a</data>
    </edge>
    <edge source="BRAND" target="RETAIL_DATASET">
      <data key="d4">1.0</data>
      <data key="d5">The Retail dataset includes the categorical predictor variable brand</data>
      <data key="d6">39aef0392258a09378ce45d8b03a268a</data>
    </edge>
    <edge source="BRAND" target="AVERAGE_RESPONSE">
      <data key="d4">1.0</data>
      <data key="d5">The average response can be modeled to be dependent on the value that the categorical predictor brand takes</data>
      <data key="d6">39aef0392258a09378ce45d8b03a268a</data>
    </edge>
    <edge source="BRAND" target="BRAND_MODEL1">
      <data key="d4">1.0</data>
      <data key="d5">Brand is a predictor variable in the model Brand.model1</data>
      <data key="d6">ee295ebc4c2d6a2a5c738796fcc2ab71</data>
    </edge>
    <edge source="BRAND" target="SALES">
      <data key="d4">3.0</data>
      <data key="d5">Sales are categorized by brand, with different intercepts for each brand in the regression model
Sales is the dependent variable in the model equations, which is influenced by the Brand variable
The sales of the product are influenced by the brand, as represented by the Brand variable in the model</data>
      <data key="d6">06d5666e6bfdda828b48adba883b4a61,86ece4718d27d1a6c6a1f448cc850e2b,b2c33cb151a8e7724ebfb7b2d88bc45f</data>
    </edge>
    <edge source="BRAND" target="FIGURE_9_3">
      <data key="d4">1.0</data>
      <data key="d5">Figure 9.3 codes points by brand, showing the relationship between sales and price for each brand</data>
      <data key="d6">b2c33cb151a8e7724ebfb7b2d88bc45f</data>
    </edge>
    <edge source="BRAND" target="FIGURE_9_2">
      <data key="d4">1.0</data>
      <data key="d5">Figure 9.2 reveals the systematic pattern of sales and price for each brand</data>
      <data key="d6">b2c33cb151a8e7724ebfb7b2d88bc45f</data>
    </edge>
    <edge source="BRAND" target="X">
      <data key="d4">1.0</data>
      <data key="d5">X contains the brand information as dummy variables for brandA, brandB, and brandC</data>
      <data key="d6">e800735d6b2a244875f5e0d292de1527</data>
    </edge>
    <edge source="BRAND" target="BRANDA">
      <data key="d4">1.0</data>
      <data key="d5">BrandA is one of the categories of the Brand variable</data>
      <data key="d6">06d5666e6bfdda828b48adba883b4a61</data>
    </edge>
    <edge source="BRAND" target="BRANDB">
      <data key="d4">1.0</data>
      <data key="d5">BrandB is one of the categories of the Brand variable</data>
      <data key="d6">06d5666e6bfdda828b48adba883b4a61</data>
    </edge>
    <edge source="BRAND" target="BRANDC">
      <data key="d4">1.0</data>
      <data key="d5">BrandC is one of the categories of the Brand variable</data>
      <data key="d6">06d5666e6bfdda828b48adba883b4a61</data>
    </edge>
    <edge source="BRAND" target="PRICE">
      <data key="d4">1.0</data>
      <data key="d5">Price is a variable that is associated with the Brand variable in the model equations</data>
      <data key="d6">06d5666e6bfdda828b48adba883b4a61</data>
    </edge>
    <edge source="BRAND" target="C_PRICE">
      <data key="d4">1.0</data>
      <data key="d5">c_price is derived from the Price variable and is associated with the Brand variable in the model equations</data>
      <data key="d6">06d5666e6bfdda828b48adba883b4a61</data>
    </edge>
    <edge source="BRAND" target="MU">
      <data key="d4">1.0</data>
      <data key="d5">Mu is a parameter in the model equations that is specific to each category of the Brand variable</data>
      <data key="d6">06d5666e6bfdda828b48adba883b4a61</data>
    </edge>
    <edge source="BRAND" target="BETA">
      <data key="d4">1.0</data>
      <data key="d5">Beta is a parameter in the model equations that represents the effect of the price deviation on sales, which is associated with the Brand variable</data>
      <data key="d6">06d5666e6bfdda828b48adba883b4a61</data>
    </edge>
    <edge source="BRAND" target="EPSILON">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon is the error term in the model equations, which is associated with the Brand variable</data>
      <data key="d6">06d5666e6bfdda828b48adba883b4a61</data>
    </edge>
    <edge source="BRAND" target="BRAND_C">
      <data key="d4">1.0</data>
      <data key="d5">Brand C is a specific category within the Brand variable, used as the reference category in the model equations</data>
      <data key="d6">86ece4718d27d1a6c6a1f448cc850e2b</data>
    </edge>
    <edge source="BRAND" target="DESIGN_MATRIX">
      <data key="d4">1.0</data>
      <data key="d5">Brand is a category variable included in the design matrix, with dummy variables representing the different brands</data>
      <data key="d6">86ece4718d27d1a6c6a1f448cc850e2b</data>
    </edge>
    <edge source="BRAND" target="PARAMETER_ESTIMATES">
      <data key="d4">1.0</data>
      <data key="d5">The parameter estimates for the Brand variable correspond to the differences in sales between the different brands and the reference category</data>
      <data key="d6">86ece4718d27d1a6c6a1f448cc850e2b</data>
    </edge>
    <edge source="BRAND" target="PARAMETERISATION">
      <data key="d4">1.0</data>
      <data key="d5">The parameterisation of the model depends on the choice of reference category for the Brand variable</data>
      <data key="d6">86ece4718d27d1a6c6a1f448cc850e2b</data>
    </edge>
    <edge source="BRAND" target="RETAIL_DATA">
      <data key="d4">1.0</data>
      <data key="d5">Brand is a variable in the Retail data, used as a predictor in the model</data>
      <data key="d6">86ece4718d27d1a6c6a1f448cc850e2b</data>
    </edge>
    <edge source="BRAND" target="ROUNDING_ERRORS">
      <data key="d4">1.0</data>
      <data key="d5">Rounding errors can affect the accuracy of the parameter estimates for the Brand variable</data>
      <data key="d6">86ece4718d27d1a6c6a1f448cc850e2b</data>
    </edge>
    <edge source="BRAND" target="REFERENCE_CATEGORY">
      <data key="d4">1.0</data>
      <data key="d5">The reference category for the Brand variable is chosen using the relevel command</data>
      <data key="d6">86ece4718d27d1a6c6a1f448cc850e2b</data>
    </edge>
    <edge source="BRAND" target="RELEVEL">
      <data key="d4">1.0</data>
      <data key="d5">The relevel command is used to change the reference category of the Brand variable</data>
      <data key="d6">86ece4718d27d1a6c6a1f448cc850e2b</data>
    </edge>
    <edge source="BRAND" target="BRAND_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The Brand variable is included as a predictor in the brand.model fitted using the lm() function</data>
      <data key="d6">86ece4718d27d1a6c6a1f448cc850e2b</data>
    </edge>
    <edge source="BRAND" target="INTERACTION">
      <data key="d4">2.0</data>
      <data key="d5">The Brand variable can interact with other predictor variables, such as price, to influence the sales of the product
Brand interacts with price to affect sales volume, showing that the effect of price on sales volume varies by brand</data>
      <data key="d6">86ece4718d27d1a6c6a1f448cc850e2b,b0ca3e6c22c4cf884d03b1f6f82be5df</data>
    </edge>
    <edge source="BRAND" target="SALES_VOLUME">
      <data key="d4">1.0</data>
      <data key="d5">Brand affects sales volume, as seen in the regression model</data>
      <data key="d6">b6870535f3975c49d45e62fbe475f198</data>
    </edge>
    <edge source="PARAMETERISATIONS" target="THE_T_STATISTIC">
      <data key="d4">1.0</data>
      <data key="d5">Parameterisations may be related to the T-statistic as different parameterisations can affect the calculation or interpretation of the T-statistic</data>
      <data key="d6">ef68dd0317c62e3cdde00395f7a21bd7</data>
    </edge>
    <edge source="MODEL_WITH_INTERACTION" target="THE_T_STATISTIC">
      <data key="d4">1.0</data>
      <data key="d5">A model with an interaction may be related to the T-statistic as interaction terms can influence the T-statistic in hypothesis testing</data>
      <data key="d6">ef68dd0317c62e3cdde00395f7a21bd7</data>
    </edge>
    <edge source="SUMMARY_OF_CHAPTER_9" target="THE_T_STATISTIC">
      <data key="d4">1.0</data>
      <data key="d5">Summary of Chapter 9 may be related to the T-statistic as it could provide context or background information relevant to the T-statistic</data>
      <data key="d6">ef68dd0317c62e3cdde00395f7a21bd7</data>
    </edge>
    <edge source="SUMMARY_OF_CHAPTER_9" target="CHAPTER_9">
      <data key="d4">1.0</data>
      <data key="d5">The summary of Chapter 9 provides an overview of the content covered in the chapter, including the introduction of categorical predictors</data>
      <data key="d6">b0ca3e6c22c4cf884d03b1f6f82be5df</data>
    </edge>
    <edge source="THE_T_STATISTIC" target="USEFUL_RESULTS_FOR_MULTIVARIATE_NORMAL">
      <data key="d4">1.0</data>
      <data key="d5">Useful results for the multivariate normal distribution are directly related to the T-statistic as the T-statistic is often derived from the multivariate normal distribution</data>
      <data key="d6">ef68dd0317c62e3cdde00395f7a21bd7</data>
    </edge>
    <edge source="THE_T_STATISTIC" target="DISTRIBUTIONAL_PROPERTIES_OF_BETA_HAT_AND_S_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">Distributional properties of &#946;b and s^2 are directly related to the T-statistic as the T-statistic is calculated using these properties</data>
      <data key="d6">ef68dd0317c62e3cdde00395f7a21bd7</data>
    </edge>
    <edge source="THE_T_STATISTIC" target="SIMPLE_EXAMPLE_IN_R">
      <data key="d4">1.0</data>
      <data key="d5">A simple example in R is related to the T-statistic as it demonstrates how to calculate or use the T-statistic in practice</data>
      <data key="d6">ef68dd0317c62e3cdde00395f7a21bd7</data>
    </edge>
    <edge source="THE_T_STATISTIC" target="SUMMARY_OF_CHAPTER_10">
      <data key="d4">1.0</data>
      <data key="d5">Summary of Chapter 10 may be related to the T-statistic as it could summarize the key points about the T-statistic discussed in the chapter</data>
      <data key="d6">ef68dd0317c62e3cdde00395f7a21bd7</data>
    </edge>
    <edge source="CHAPTER_10" target="CHAPTER_11">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 10 is followed by Chapter 11 in the document, suggesting a sequential relationship</data>
      <data key="d6">0ba6a4dc0ac5f8b86cc2a22fd51b9517</data>
    </edge>
    <edge source="CHAPTER_11" target="CHAPTER_12">
      <data key="d4">2.0</data>
      <data key="d5">Chapter 11 is followed by Chapter 12 in the document, suggesting a sequential relationship
Chapter 11 is likely a prerequisite or foundational to Chapter 12, as it precedes it in the text and may provide necessary background or concepts</data>
      <data key="d6">0ba6a4dc0ac5f8b86cc2a22fd51b9517,f087dce67c830cc3152c8d9cbb76cdb8</data>
    </edge>
    <edge source="CHAPTER_12" target="CHAPTER_13">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 12 is followed by Chapter 13, suggesting a progression in topics from t-tests for normal linear models to the F-test and ANOVA, which may build upon or complement each other</data>
      <data key="d6">f087dce67c830cc3152c8d9cbb76cdb8</data>
    </edge>
    <edge source="CHAPTER_12" target="T_TEST">
      <data key="d4">1.0</data>
      <data key="d5">The t-test is a central topic of Chapter 12, which discusses its application in normal linear models, including hypothesis testing and limitations</data>
      <data key="d6">f087dce67c830cc3152c8d9cbb76cdb8</data>
    </edge>
    <edge source="CHAPTER_13" target="F_TEST">
      <data key="d4">1.0</data>
      <data key="d5">The F-test is a topic covered in Chapter 13, likely in the context of ANOVA and its application in comparing variances between groups</data>
      <data key="d6">f087dce67c830cc3152c8d9cbb76cdb8</data>
    </edge>
    <edge source="CHAPTER_13" target="ANOVA">
      <data key="d4">1.0</data>
      <data key="d5">ANOVA is a key focus of Chapter 13, which explores its use in statistical analysis, particularly in comparing means across multiple groups</data>
      <data key="d6">f087dce67c830cc3152c8d9cbb76cdb8</data>
    </edge>
    <edge source="T_TEST" target="R">
      <data key="d4">1.0</data>
      <data key="d5">R is used in the simple example of the t-test in Chapter 12, demonstrating its application in statistical testing</data>
      <data key="d6">f087dce67c830cc3152c8d9cbb76cdb8</data>
    </edge>
    <edge source="T_TEST" target="F_TEST">
      <data key="d4">1.0</data>
      <data key="d5">The t-test is a simpler version of the F-test, used when comparing two groups. The F-test is more general and can be used to compare multiple groups.</data>
      <data key="d6">59ad428bf172e7866861ea44cbe198e2</data>
    </edge>
    <edge source="F_TEST" target="ANOVA">
      <data key="d4">1.0</data>
      <data key="d5">The F-test is a key component of ANOVA, used to compare multiple group means and determine if there are significant differences among them.</data>
      <data key="d6">59ad428bf172e7866861ea44cbe198e2</data>
    </edge>
    <edge source="F_TEST" target="NESTED_LINEAR_MODELS">
      <data key="d4">1.0</data>
      <data key="d5">Nested linear models are used in the context of the F-test to compare models and determine if a more complex model significantly improves the fit over a simpler model.</data>
      <data key="d6">59ad428bf172e7866861ea44cbe198e2</data>
    </edge>
    <edge source="F_TEST" target="EXISTENCE_OF_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">The F-test is used to test for the existence of regression, determining if there is a significant relationship between the dependent variable and the independent variables.</data>
      <data key="d6">59ad428bf172e7866861ea44cbe198e2</data>
    </edge>
    <edge source="F_TEST" target="DISTRIBUTION_OF_F_STATISTIC">
      <data key="d4">1.0</data>
      <data key="d5">The distribution of the F-statistic is used in the F-test to determine the significance of the test results, comparing the observed F-statistic to the critical value from the F-distribution.</data>
      <data key="d6">59ad428bf172e7866861ea44cbe198e2</data>
    </edge>
    <edge source="ANOVA" target="TOTAL_SUM_OF_SQUARES">
      <data key="d4">1.0</data>
      <data key="d5">The total sum of squares is decomposed in ANOVA to determine the explained and unexplained variability, which is used to calculate the F-statistic.</data>
      <data key="d6">59ad428bf172e7866861ea44cbe198e2</data>
    </edge>
    <edge source="ANOVA" target="ANOVA_TABLE">
      <data key="d4">1.0</data>
      <data key="d5">The ANOVA table is a result of the ANOVA process, summarizing the sources of variation, degrees of freedom, sums of squares, mean squares, and F-statistics.</data>
      <data key="d6">59ad428bf172e7866861ea44cbe198e2</data>
    </edge>
    <edge source="ANOVA" target="ILLUSTRATION_IN_R">
      <data key="d4">1.0</data>
      <data key="d5">Illustration in R provides practical examples of how ANOVA and the F-test are applied using the R programming language.</data>
      <data key="d6">59ad428bf172e7866861ea44cbe198e2</data>
    </edge>
    <edge source="R" target="NORMAL_LINEAR_MODELS">
      <data key="d4">1.0</data>
      <data key="d5">R is used to fit normal linear models, with well-established functions for this purpose</data>
      <data key="d6">7b32c106246576bb451a5a3985914351</data>
    </edge>
    <edge source="R" target="LM_FUNCTION">
      <data key="d4">3.0</data>
      <data key="d5">R provides the lm() function for fitting linear models
R provides the lm() function for fitting linear models
R uses the lm() function to fit linear models</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b,b99ecc2f79f56198a8c2adbdff95d576,f18bacb0a2fbfea44dd6326224184216</data>
    </edge>
    <edge source="R" target="SUMMARY_FUNCTION">
      <data key="d4">1.0</data>
      <data key="d5">R provides the summary() function for summarizing fitted models</data>
      <data key="d6">b99ecc2f79f56198a8c2adbdff95d576</data>
    </edge>
    <edge source="R" target="USINGR_PACKAGE">
      <data key="d4">1.0</data>
      <data key="d5">R can load the UsingR package to access additional datasets</data>
      <data key="d6">b99ecc2f79f56198a8c2adbdff95d576</data>
    </edge>
    <edge source="R" target="I_FUNCTION">
      <data key="d4">1.0</data>
      <data key="d5">R provides the I() function to inhibit the conversion of an expression into an operator</data>
      <data key="d6">f18bacb0a2fbfea44dd6326224184216</data>
    </edge>
    <edge source="R" target="COEF_FUNCTION">
      <data key="d4">1.0</data>
      <data key="d5">R provides the coef() function to extract model coefficients</data>
      <data key="d6">f18bacb0a2fbfea44dd6326224184216</data>
    </edge>
    <edge source="R" target="LM">
      <data key="d4">1.0</data>
      <data key="d5">R is the software used to run the lm() function</data>
      <data key="d6">c48bd062d5f6cc20c5df5758d6285562</data>
    </edge>
    <edge source="R" target="MLR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">R is the software used to create the mlr.model</data>
      <data key="d6">c48bd062d5f6cc20c5df5758d6285562</data>
    </edge>
    <edge source="R" target="X">
      <data key="d4">2.0</data>
      <data key="d5">R uses the design matrix X to fit the linear regression model
R uses the design matrix X in the model.matrix output for brand.model1</data>
      <data key="d6">119bc73ddf8eebadfb8eae272fa323a7,e800735d6b2a244875f5e0d292de1527</data>
    </edge>
    <edge source="R" target="BETA">
      <data key="d4">1.0</data>
      <data key="d5">R estimates the parameter vector Beta when fitting the linear regression model</data>
      <data key="d6">119bc73ddf8eebadfb8eae272fa323a7</data>
    </edge>
    <edge source="R" target="EPSILON">
      <data key="d4">1.0</data>
      <data key="d5">R assumes that the error terms Epsilon are independently and identically distributed with mean zero and constant variance</data>
      <data key="d6">119bc73ddf8eebadfb8eae272fa323a7</data>
    </edge>
    <edge source="R" target="PLR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">R is the software environment used to fit the quadratic regression model plr.model</data>
      <data key="d6">084dadebfca8bcb6377c205c45bee295</data>
    </edge>
    <edge source="R" target="BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">R is used to calculate the estimates Beta hat</data>
      <data key="d6">01d5ee79489582b4135fc96f676b24a0</data>
    </edge>
    <edge source="R" target="YB">
      <data key="d4">1.0</data>
      <data key="d5">In R, the command fitted(model) returns the fitted values YB of a model</data>
      <data key="d6">5cc49d301d9cd1f8e20b92ab9d8346b0</data>
    </edge>
    <edge source="R" target="RESIDUALS_COMMAND">
      <data key="d4">1.0</data>
      <data key="d5">R provides the command residuals(model) to obtain the residuals from a fitted model</data>
      <data key="d6">e6f79ceb0df54119a4dc71b2162ac50b</data>
    </edge>
    <edge source="R" target="SIMULATED_DATA">
      <data key="d4">1.0</data>
      <data key="d5">R is used to generate and analyze simulated data</data>
      <data key="d6">312309b45c59e1c84695ac3c7e202742</data>
    </edge>
    <edge source="R" target="NORMAL_Q_Q_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">In R, the normal Q-Q plot for the standardised residuals of the fitted model can be produced using the plot function with the argument which = 2.</data>
      <data key="d6">eafa2cc6cc64d8bca1c080bdd2ad7654</data>
    </edge>
    <edge source="R" target="BRAND_MODEL1">
      <data key="d4">1.0</data>
      <data key="d5">R is the software used to implement the model Brand.model1</data>
      <data key="d6">ee295ebc4c2d6a2a5c738796fcc2ab71</data>
    </edge>
    <edge source="R" target="BRAND.MODEL1">
      <data key="d4">1.0</data>
      <data key="d5">R is used to verify the design matrix and generate the model.matrix output for brand.model1</data>
      <data key="d6">e800735d6b2a244875f5e0d292de1527</data>
    </edge>
    <edge source="R" target="BRAND_MODEL3">
      <data key="d4">1.0</data>
      <data key="d5">R is the software environment used to fit the linear model Brand_model3</data>
      <data key="d6">6a6f85d0a6e46196ab3a901fcc82a720</data>
    </edge>
    <edge source="R" target="DESIGN_MATRIX">
      <data key="d4">2.0</data>
      <data key="d5">R uses the design matrix to fit the linear model for the Retail data
R uses the design matrix to fit the model</data>
      <data key="d6">06199787dd7f75f7338dd24d4f3dc26e,48971100deb5bb374a41c1f2b7b2a86a</data>
    </edge>
    <edge source="R" target="SAMPLE_MEANS">
      <data key="d4">2.0</data>
      <data key="d5">Parameter estimates from R can be compared with the sample means of sales volume for stores of Brand A, Brand B, and Brand C
R compares the parameter estimates with the sample means of sales volume for stores of each brand</data>
      <data key="d6">06199787dd7f75f7338dd24d4f3dc26e,48971100deb5bb374a41c1f2b7b2a86a</data>
    </edge>
    <edge source="R" target="PARAMETER_ESTIMATES">
      <data key="d4">1.0</data>
      <data key="d5">R calculates the parameter estimates based on the model and data</data>
      <data key="d6">06199787dd7f75f7338dd24d4f3dc26e</data>
    </edge>
    <edge source="R" target="RETAIL_DATA">
      <data key="d4">1.0</data>
      <data key="d5">R is used to fit the model to the Retail data</data>
      <data key="d6">a1fc936df848a0fbc791e4bcc9b527b6</data>
    </edge>
    <edge source="R" target="CATEGORICAL_PREDICTORS">
      <data key="d4">1.0</data>
      <data key="d5">R can be used to incorporate categorical predictors into a linear model. This involves using functions in R to create dummy variables and fit the linear model.</data>
      <data key="d6">d7f3a28534ffe830fe6f4cef8c41a9b4</data>
    </edge>
    <edge source="ANOVA_TABLE" target="F_STATISTIC_DISTRIBUTION">
      <data key="d4">1.0</data>
      <data key="d5">The ANOVA table is used to calculate the F-statistic, which follows a specific distribution under the null hypothesis</data>
      <data key="d6">638b52a0671088c9aa208790411ab898</data>
    </edge>
    <edge source="ANOVA_TABLE" target="ILLUSTRATION_IN_R">
      <data key="d4">1.0</data>
      <data key="d5">Illustration in R can be used to demonstrate the creation and interpretation of an ANOVA table</data>
      <data key="d6">638b52a0671088c9aa208790411ab898</data>
    </edge>
    <edge source="ANOVA_TABLE" target="SUMMARY_OF_CHAPTER_13">
      <data key="d4">1.0</data>
      <data key="d5">The summary of Chapter 13 likely includes a discussion of the ANOVA table and its role in regression analysis</data>
      <data key="d6">638b52a0671088c9aa208790411ab898</data>
    </edge>
    <edge source="ANOVA_TABLE" target="TEST_FOR_NON-LINEARITY">
      <data key="d4">1.0</data>
      <data key="d5">A test for non-linearity can be performed using the residuals from an ANOVA table, to check if the relationship between variables is linear</data>
      <data key="d6">638b52a0671088c9aa208790411ab898</data>
    </edge>
    <edge source="F_STATISTIC_DISTRIBUTION" target="SEQUENTIAL_ANOVA">
      <data key="d4">1.0</data>
      <data key="d5">The distribution of the F-statistic is used in sequential ANOVA to test the significance of each factor added to the model</data>
      <data key="d6">638b52a0671088c9aa208790411ab898</data>
    </edge>
    <edge source="SEQUENTIAL_ANOVA" target="FACTORS">
      <data key="d4">1.0</data>
      <data key="d5">Sequential ANOVA involves the sequential addition of factors to the model, assessing their individual contributions</data>
      <data key="d6">638b52a0671088c9aa208790411ab898</data>
    </edge>
    <edge source="FACTORS" target="CHAPTER 14">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 14 includes a section on factors, which are elements considered in the context of the chapter</data>
      <data key="d6">322cf1f37d33953af834b695b7f08b72</data>
    </edge>
    <edge source="CHAPTER 14" target="TEST FOR NON-LINEARITY">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 14 includes a test for non-linearity, which is a procedure to assess the linearity of a model or data</data>
      <data key="d6">322cf1f37d33953af834b695b7f08b72</data>
    </edge>
    <edge source="CHAPTER 14" target="SUMMARY OF CHAPTER 14">
      <data key="d4">1.0</data>
      <data key="d5">The summary of Chapter 14 provides an overview of the topics covered in the chapter, which includes factors and the test for non-linearity</data>
      <data key="d6">322cf1f37d33953af834b695b7f08b72</data>
    </edge>
    <edge source="CHAPTER 15" target="BIAS AND VARIANCE">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 15 discusses bias and variance, concepts related to model performance and error</data>
      <data key="d6">322cf1f37d33953af834b695b7f08b72</data>
    </edge>
    <edge source="CHAPTER 15" target="THE MODEL HIERARCHY">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 15 includes a section on the model hierarchy, which is a structure or classification of models</data>
      <data key="d6">322cf1f37d33953af834b695b7f08b72</data>
    </edge>
    <edge source="CHAPTER 15" target="MODEL SELECTION STATISTICS">
      <data key="d4">2.0</data>
      <data key="d5">Chapter 15 covers model selection statistics, which are metrics or criteria used to choose among different models
Chapter 15 discusses model selection statistics as a method for comparing and selecting models</data>
      <data key="d6">322cf1f37d33953af834b695b7f08b72,ad35c05a2497a4e16a014d64483842a8</data>
    </edge>
    <edge source="CHAPTER 15" target="VARIABLE SELECTION">
      <data key="d4">2.0</data>
      <data key="d5">Chapter 15 discusses variable selection, a process for choosing the most relevant variables for a model
Chapter 15 covers variable selection as a process for identifying the most relevant variables in a model</data>
      <data key="d6">322cf1f37d33953af834b695b7f08b72,ad35c05a2497a4e16a014d64483842a8</data>
    </edge>
    <edge source="CHAPTER 15" target="MULTICOLLINEARITY">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 15 addresses multicollinearity as a potential issue in multiple regression models</data>
      <data key="d6">ad35c05a2497a4e16a014d64483842a8</data>
    </edge>
    <edge source="CHAPTER 15" target="SUMMARY OF CHAPTER 15">
      <data key="d4">1.0</data>
      <data key="d5">The summary of Chapter 15 provides an overview of the topics covered in the chapter</data>
      <data key="d6">ad35c05a2497a4e16a014d64483842a8</data>
    </edge>
    <edge source="CHAPTER 16" target="GENERAL LINEAR MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 16 discusses the General Linear Model as a broad statistical model</data>
      <data key="d6">ad35c05a2497a4e16a014d64483842a8</data>
    </edge>
    <edge source="CHAPTER 16" target="GENERALISED LEAST SQUARES ESTIMATOR">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 16 covers the generalised least squares estimator as a method for estimating parameters in the presence of non-independent errors</data>
      <data key="d6">ad35c05a2497a4e16a014d64483842a8</data>
    </edge>
    <edge source="CHAPTER 16" target="WEIGHTED REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 16 addresses weighted regression as a technique for regression analysis with weighted data points</data>
      <data key="d6">ad35c05a2497a4e16a014d64483842a8</data>
    </edge>
    <edge source="CHAPTER 16" target="SERIALLY CORRELATED ERRORS">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 16 discusses serially correlated errors as a potential issue in regression models</data>
      <data key="d6">ad35c05a2497a4e16a014d64483842a8</data>
    </edge>
    <edge source="GLM" target="BINARY_RESPONSE_DATA">
      <data key="d4">1.0</data>
      <data key="d5">GLMs can be used for modeling binary response data, providing a framework for analyzing data with binary outcomes</data>
      <data key="d6">54768ad5bc5877b6bf042aac07fb64d9</data>
    </edge>
    <edge source="GLM" target="HYPOTHESIS_TESTING">
      <data key="d4">1.0</data>
      <data key="d5">Hypothesis testing is used in the context of GLMs to test the significance of model parameters and the overall fit of the model</data>
      <data key="d6">54768ad5bc5877b6bf042aac07fb64d9</data>
    </edge>
    <edge source="GLM" target="SUMMARY_OF_CHAPTER_17">
      <data key="d4">1.0</data>
      <data key="d5">Chapter 17's summary includes a review of the concepts related to GLMs, providing a comprehensive overview of the topic</data>
      <data key="d6">54768ad5bc5877b6bf042aac07fb64d9</data>
    </edge>
    <edge source="GLM" target="APPENDIX_A">
      <data key="d4">1.0</data>
      <data key="d5">Linear algebra and multivariable calculus, covered in Appendix A, provide the mathematical foundation for understanding GLMs</data>
      <data key="d6">54768ad5bc5877b6bf042aac07fb64d9</data>
    </edge>
    <edge source="GLM" target="APPENDIX_B">
      <data key="d4">1.0</data>
      <data key="d5">Generalized expectation, discussed in Appendix B, is a theoretical concept that underpins the formulation of GLMs</data>
      <data key="d6">54768ad5bc5877b6bf042aac07fb64d9</data>
    </edge>
    <edge source="GLM" target="APPENDIX_C">
      <data key="d4">1.0</data>
      <data key="d5">The distribution of s^2, explained in Appendix C, is relevant to the estimation of variance components in GLMs</data>
      <data key="d6">54768ad5bc5877b6bf042aac07fb64d9</data>
    </edge>
    <edge source="GLM" target="APPENDIX_D">
      <data key="d4">1.0</data>
      <data key="d5">M-estimators and robust regression, covered in Appendix D, are alternative methods to GLMs for estimating model parameters in the presence of outliers</data>
      <data key="d6">54768ad5bc5877b6bf042aac07fb64d9</data>
    </edge>
    <edge source="APPENDIX_B" target="APPENDIX_C">
      <data key="d4">1.0</data>
      <data key="d5">Appendix B and Appendix C are both sections in a document, covering different statistical concepts</data>
      <data key="d6">acead09befa8eb465dd2e8c2d93a43c5</data>
    </edge>
    <edge source="APPENDIX_C" target="APPENDIX_D">
      <data key="d4">1.0</data>
      <data key="d5">Appendix C and Appendix D are both sections in a document, covering different statistical concepts</data>
      <data key="d6">acead09befa8eb465dd2e8c2d93a43c5</data>
    </edge>
    <edge source="APPENDIX_D" target="APPENDIX_E">
      <data key="d4">1.0</data>
      <data key="d5">Appendix D and Appendix E are both sections in a document, covering different statistical concepts</data>
      <data key="d6">acead09befa8eb465dd2e8c2d93a43c5</data>
    </edge>
    <edge source="APPENDIX_E" target="APPENDIX_F">
      <data key="d4">1.0</data>
      <data key="d5">Appendix E and Appendix F are both sections in a document, covering different statistical concepts</data>
      <data key="d6">acead09befa8eb465dd2e8c2d93a43c5</data>
    </edge>
    <edge source="APPENDIX_F" target="APPENDIX_G">
      <data key="d4">1.0</data>
      <data key="d5">Appendix F and Appendix G are both sections in a document, covering different statistical concepts</data>
      <data key="d6">acead09befa8eb465dd2e8c2d93a43c5</data>
    </edge>
    <edge source="APPENDIX_G" target="APPENDIX_H">
      <data key="d4">1.0</data>
      <data key="d5">Appendix G and Appendix H are both sections in a document, covering different statistical concepts</data>
      <data key="d6">acead09befa8eb465dd2e8c2d93a43c5</data>
    </edge>
    <edge source="PDF_VERSION" target="RIGHTS">
      <data key="d4">1.0</data>
      <data key="d5">The PDF version of the lecture notes is subject to the rights reserved, meaning it should not be distributed or uploaded to the internet</data>
      <data key="d6">d1cc8e172b83ff69b921cef864fc09f5</data>
    </edge>
    <edge source="RIGHTS" target="TYPO_REPORTING">
      <data key="d4">1.0</data>
      <data key="d5">The procedure for reporting typos is an exception to the rights reserved, allowing for feedback on the lecture notes</data>
      <data key="d6">d1cc8e172b83ff69b921cef864fc09f5</data>
    </edge>
    <edge source="TYPO_REPORTING" target="DIVERSITY_NOTE">
      <data key="d4">1.0</data>
      <data key="d5">The diversity note is related to the typo reporting procedure as it encourages the inclusion of more diverse sources in future versions of the lecture notes</data>
      <data key="d6">d1cc8e172b83ff69b921cef864fc09f5</data>
    </edge>
    <edge source="DIVERSITY_NOTE" target="NORMAL_LINEAR_MODELS">
      <data key="d4">1.0</data>
      <data key="d5">The concept of normal linear models is indirectly related to the diversity note as it pertains to the content of the lecture notes that could be augmented with more diverse sources</data>
      <data key="d6">d1cc8e172b83ff69b921cef864fc09f5</data>
    </edge>
    <edge source="NORMAL_LINEAR_MODELS" target="LECTURE_NOTES">
      <data key="d4">1.0</data>
      <data key="d5">The lecture notes discuss normal linear models, which are statistical models used to describe relationships between variables</data>
      <data key="d6">7b32c106246576bb451a5a3985914351</data>
    </edge>
    <edge source="NORMAL_LINEAR_MODELS" target="EXPLANATORY_VARIABLES">
      <data key="d4">1.0</data>
      <data key="d5">Normal linear models use explanatory variables to explain the variation in the outcome variable</data>
      <data key="d6">7b32c106246576bb451a5a3985914351</data>
    </edge>
    <edge source="NORMAL_LINEAR_MODELS" target="OUTCOME_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">Normal linear models predict or explain the outcome variable using one or more explanatory variables</data>
      <data key="d6">7b32c106246576bb451a5a3985914351</data>
    </edge>
    <edge source="NORMAL_LINEAR_MODELS" target="LINEAR_ALGEBRA">
      <data key="d4">1.0</data>
      <data key="d5">Normal linear models are analyzed using tools from linear algebra, which is common for machine learning algorithms</data>
      <data key="d6">7b32c106246576bb451a5a3985914351</data>
    </edge>
    <edge source="EXPLANATORY_VARIABLES" target="OBSERVATIONAL_STUDIES">
      <data key="d4">1.0</data>
      <data key="d5">In observational studies, explanatory variables are considered non-random and the model is developed conditional on their values</data>
      <data key="d6">22478e53f29f16e3eab9d167fea52b22</data>
    </edge>
    <edge source="EXPLANATORY_VARIABLES" target="RESPONSE_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">Explanatory variables are used to explain or predict the response variable in statistical models</data>
      <data key="d6">22478e53f29f16e3eab9d167fea52b22</data>
    </edge>
    <edge source="EXPLANATORY_VARIABLES" target="MULTIPLE_LINEAR_REGRESSION">
      <data key="d4">2.0</data>
      <data key="d5">Explanatory variables, including price and local advertising, are used in the multiple linear regression model to explain variations in sales. The relationship strength is high, as the model considers multiple variables to provide a more accurate prediction of sales.
Explanatory variables are used in multiple linear regression to predict the response variable</data>
      <data key="d6">2ced3e26eaed2dfcd8e4caf49737cab4,426434b67f6a287852ab66b82ca873cf</data>
    </edge>
    <edge source="EXPLANATORY_VARIABLES" target="DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Explanatory variables are part of the dataset</data>
      <data key="d6">2ced3e26eaed2dfcd8e4caf49737cab4</data>
    </edge>
    <edge source="EXPLANATORY_VARIABLES" target="YN">
      <data key="d4">1.0</data>
      <data key="d5">The means of the response variables Y1, ..., Yn depend on the values taken by the explanatory variables</data>
      <data key="d6">0da640a09a395a50b6e16e047fa8d0d6</data>
    </edge>
    <edge source="EXPLANATORY_VARIABLES" target="TREES_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Explanatory variables, such as log-diameter and log-height, are used in the trees.model to predict the dependent variable</data>
      <data key="d6">a60af43e42c72a41fa90da06beb29d1b</data>
    </edge>
    <edge source="LINEAR_ALGEBRA" target="VECTORS">
      <data key="d4">1.0</data>
      <data key="d5">In linear algebra, vectors are denoted by small letters, which can sometimes lead to notational issues when dealing with both random variables and their realizations</data>
      <data key="d6">22478e53f29f16e3eab9d167fea52b22</data>
    </edge>
    <edge source="LINEAR_ALGEBRA" target="MATRICES">
      <data key="d4">1.0</data>
      <data key="d5">In linear algebra, matrices are denoted by capital letters, which can sometimes lead to notational issues when dealing with both random variables and their realizations</data>
      <data key="d6">22478e53f29f16e3eab9d167fea52b22</data>
    </edge>
    <edge source="LINEAR_ALGEBRA" target="MULTIPLE_LINEAR_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Linear algebra provides the mathematical tools needed for multiple linear regression</data>
      <data key="d6">2ced3e26eaed2dfcd8e4caf49737cab4</data>
    </edge>
    <edge source="LINEAR_MODEL" target="MULTIPLE_LINEAR_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Multiple linear regression is a specific type of linear model</data>
      <data key="d6">28eee75e95bbbaf143368c3289585670</data>
    </edge>
    <edge source="LINEAR_MODEL" target="RESPONSE_VARIABLE_Y">
      <data key="d4">1.0</data>
      <data key="d5">Response variable Y is a key component of a linear model, representing the variable of interest</data>
      <data key="d6">7594eee7e77beb023d1cd64aec64920d</data>
    </edge>
    <edge source="LINEAR_MODEL" target="EXPLANATORY_VARIABLES_X">
      <data key="d4">1.0</data>
      <data key="d5">Explanatory variables X are used in a linear model to explain or predict the response variable</data>
      <data key="d6">7594eee7e77beb023d1cd64aec64920d</data>
    </edge>
    <edge source="LINEAR_MODEL" target="CONDITIONAL_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">A linear model can be considered a conditional model, developed based on the values taken by the explanatory variables</data>
      <data key="d6">7594eee7e77beb023d1cd64aec64920d</data>
    </edge>
    <edge source="LINEAR_MODEL" target="X">
      <data key="d4">1.0</data>
      <data key="d5">The relationship between the response variable and the explanatory variable X is part of a linear model, where "linear" refers to linearity in the parameters</data>
      <data key="d6">c9a01b92d11585f6549f62e8bd78d652</data>
    </edge>
    <edge source="LINEAR_MODEL" target="WEISBERG_S_2014">
      <data key="d4">1.0</data>
      <data key="d5">The linear model is described in Weisberg, S. (2014)</data>
      <data key="d6">656dce234514b9db38b5b5616557c1e9</data>
    </edge>
    <edge source="LINEAR_MODEL" target="BETA_0">
      <data key="d4">2.0</data>
      <data key="d5">Beta_0 is a parameter in the linear model
Beta_0 is a parameter in the linear model</data>
      <data key="d6">656dce234514b9db38b5b5616557c1e9,9611ea31ff53888971694cdefe806f64</data>
    </edge>
    <edge source="LINEAR_MODEL" target="BETA_1">
      <data key="d4">2.0</data>
      <data key="d5">Beta_1 is a parameter in the linear model
Beta_1 is a parameter in the linear model</data>
      <data key="d6">656dce234514b9db38b5b5616557c1e9,9611ea31ff53888971694cdefe806f64</data>
    </edge>
    <edge source="LINEAR_MODEL" target="EPSILON_J">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon_j is the error term in the linear model</data>
      <data key="d6">656dce234514b9db38b5b5616557c1e9</data>
    </edge>
    <edge source="LINEAR_MODEL" target="PARAMETER_VECTOR_BETA">
      <data key="d4">1.0</data>
      <data key="d5">A linear model can be defined using the parameter vector &#946;, which contains the coefficients that determine the relationship between variables in the model</data>
      <data key="d6">ae1e66f5b64284090abc285c1d4389f5</data>
    </edge>
    <edge source="LINEAR_MODEL" target="TRANSFORMED_EXPLANATORY_VARIABLES">
      <data key="d4">1.0</data>
      <data key="d5">Linear models can use transformed explanatory variables, such as logarithms, to capture non-linear relationships</data>
      <data key="d6">188219b9e5b6b6368360840921877de9</data>
    </edge>
    <edge source="LINEAR_MODEL" target="ERRORS">
      <data key="d4">1.0</data>
      <data key="d5">The linear model assumes that the errors are independent, have constant variance, and follow a normal distribution. These assumptions are checked using residual analysis.</data>
      <data key="d6">3bfc9b92571973e54c8095302acc1aaa</data>
    </edge>
    <edge source="LINEAR_MODEL" target="BETA_2">
      <data key="d4">1.0</data>
      <data key="d5">Beta_2 is a parameter in the linear model</data>
      <data key="d6">9611ea31ff53888971694cdefe806f64</data>
    </edge>
    <edge source="LINEAR_MODEL" target="EPSILON">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon is the error term in the linear model</data>
      <data key="d6">9611ea31ff53888971694cdefe806f64</data>
    </edge>
    <edge source="LINEAR_MODEL" target="SIGMA_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">Sigma squared (&#963;^2) is an important parameter in the linear model, for which an unbiased estimate can be computed</data>
      <data key="d6">3fb977ccba63e267d2e7dd4de6479ce1</data>
    </edge>
    <edge source="LINEAR_MODEL" target="CATEGORICAL_PREDICTORS">
      <data key="d4">1.0</data>
      <data key="d5">Categorical predictors can be incorporated into a linear model to analyze their effect on the response variable. This involves creating dummy variables for each level of the categorical predictor and including them in the model as explanatory variables.</data>
      <data key="d6">d7f3a28534ffe830fe6f4cef8c41a9b4</data>
    </edge>
    <edge source="LINEAR_MODEL" target="T_STATISTIC">
      <data key="d4">1.0</data>
      <data key="d5">The T-statistic is used in a linear model to test hypotheses about the parameters of the model. It is calculated by dividing the estimated parameter by its standard error, and its distribution under the null hypothesis is used to determine the significance of the parameter.</data>
      <data key="d6">d7f3a28534ffe830fe6f4cef8c41a9b4</data>
    </edge>
    <edge source="MULTIPLE_LINEAR_REGRESSION" target="EPSILON">
      <data key="d4">1.0</data>
      <data key="d5">The error term (&#1013;) is part of the multiple linear regression model, representing the unexplained variation in Y</data>
      <data key="d6">512d9ffebe309a6f944ebce1ae2ff2a3</data>
    </edge>
    <edge source="MULTIPLE_LINEAR_REGRESSION" target="BETA_0">
      <data key="d4">1.0</data>
      <data key="d5">The intercept (&#946;0) is part of the multiple linear regression model, representing the expected value of Y when all predictor variables are zero</data>
      <data key="d6">512d9ffebe309a6f944ebce1ae2ff2a3</data>
    </edge>
    <edge source="MULTIPLE_LINEAR_REGRESSION" target="BETA_1">
      <data key="d4">1.0</data>
      <data key="d5">The coefficient (&#946;1) is part of the multiple linear regression model, representing the change in Y for a one unit increase in X1, given a fixed value of X2</data>
      <data key="d6">512d9ffebe309a6f944ebce1ae2ff2a3</data>
    </edge>
    <edge source="MULTIPLE_LINEAR_REGRESSION" target="BETA_2">
      <data key="d4">1.0</data>
      <data key="d5">The coefficient (&#946;2) is part of the multiple linear regression model, representing the change in Y for a one unit increase in X2, assuming X1 is held constant</data>
      <data key="d6">512d9ffebe309a6f944ebce1ae2ff2a3</data>
    </edge>
    <edge source="MULTIPLE_LINEAR_REGRESSION" target="X1">
      <data key="d4">1.0</data>
      <data key="d5">X1 (price) is one of the predictor variables in the multiple linear regression model</data>
      <data key="d6">512d9ffebe309a6f944ebce1ae2ff2a3</data>
    </edge>
    <edge source="MULTIPLE_LINEAR_REGRESSION" target="X2">
      <data key="d4">1.0</data>
      <data key="d5">X2 (advert) is one of the predictor variables in the multiple linear regression model</data>
      <data key="d6">512d9ffebe309a6f944ebce1ae2ff2a3</data>
    </edge>
    <edge source="MULTIPLE_LINEAR_REGRESSION" target="Y">
      <data key="d4">1.0</data>
      <data key="d5">Y (sales volume) is the dependent variable in the multiple linear regression model</data>
      <data key="d6">512d9ffebe309a6f944ebce1ae2ff2a3</data>
    </edge>
    <edge source="MULTIPLE_LINEAR_REGRESSION" target="ADVERTISING_BUDGET">
      <data key="d4">1.0</data>
      <data key="d5">The multiple linear regression model includes the local advertising budget as a predictor variable, adjusting for its influence on sales. The relationship strength is high, as the model considers the effect of advertising on sales in addition to price.</data>
      <data key="d6">426434b67f6a287852ab66b82ca873cf</data>
    </edge>
    <edge source="MULTIPLE_LINEAR_REGRESSION" target="PRICE">
      <data key="d4">1.0</data>
      <data key="d5">The multiple linear regression model includes price as one of the predictor variables, adjusting for the influence of local advertising on sales. The relationship strength is high, as the model provides a more accurate estimate of the effect of price on sales when controlling for other variables.</data>
      <data key="d6">426434b67f6a287852ab66b82ca873cf</data>
    </edge>
    <edge source="MULTIPLE_LINEAR_REGRESSION" target="PARTIAL_REGRESSION_COEFFICIENTS">
      <data key="d4">1.0</data>
      <data key="d5">Partial regression coefficients are parameters in the multiple linear regression model that represent the expected change in sales for a unit change in an explanatory variable, adjusting for the effects of other variables. The relationship strength is high, as these coefficients are central to the model's predictive power.</data>
      <data key="d6">426434b67f6a287852ab66b82ca873cf</data>
    </edge>
    <edge source="DIAMOND_DATA" target="SINGAPORE_DOLLARS">
      <data key="d4">1.0</data>
      <data key="d5">The price of the diamonds in the diamond data is measured in Singapore Dollars</data>
      <data key="d6">28eee75e95bbbaf143368c3289585670</data>
    </edge>
    <edge source="DIAMOND_DATA" target="CARAT">
      <data key="d4">1.0</data>
      <data key="d5">The weight of the diamonds in the diamond data is measured in carats</data>
      <data key="d6">28eee75e95bbbaf143368c3289585670</data>
    </edge>
    <edge source="DIAMOND_DATA" target="SCATTERPLOT">
      <data key="d4">1.0</data>
      <data key="d5">A scatterplot can be used to visualize the relationship between the price and weight of diamonds in the diamond data</data>
      <data key="d6">28eee75e95bbbaf143368c3289585670</data>
    </edge>
    <edge source="DIAMOND_DATA" target="MODEL_1_1">
      <data key="d4">1.0</data>
      <data key="d5">Diamond data is used to fit model (1.1), which describes the relationship between diamond price and carat weight</data>
      <data key="d6">e47d573a10e64a657e58218df64d8920</data>
    </edge>
    <edge source="DIAMOND_DATA" target="MODEL_1_2">
      <data key="d4">1.0</data>
      <data key="d5">Diamond data is also relevant to model (1.2), which is a reparameterisation of model (1.1)</data>
      <data key="d6">e47d573a10e64a657e58218df64d8920</data>
    </edge>
    <edge source="DIAMOND_DATA" target="REGRESSION_THROUGH_ORIGIN">
      <data key="d4">1.0</data>
      <data key="d5">Diamond data is used to fit a regression through the origin model, as part of Exercise 3</data>
      <data key="d6">e47d573a10e64a657e58218df64d8920</data>
    </edge>
    <edge source="SINGAPORE_DOLLARS" target="RING_PRICE">
      <data key="d4">1.0</data>
      <data key="d5">Singapore Dollars (S$) is the currency used to measure the dependent variable, ring price, in the linear regression model.</data>
      <data key="d6">3e7eef51f3109d60697f3299b541b726</data>
    </edge>
    <edge source="SINGAPORE_DOLLARS" target="SLOPE">
      <data key="d4">1.0</data>
      <data key="d5">The slope in the linear regression model is measured in Singapore Dollars (S$) per carat of diamond weight. This relationship indicates the currency unit used for the price of Solitaire rings.</data>
      <data key="d6">f0e0c5b2deaaf9fc2bc8b63d9ab989b1</data>
    </edge>
    <edge source="CARAT" target="DIAMOND_DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Carat is a variable in the diamond dataset</data>
      <data key="d6">b99ecc2f79f56198a8c2adbdff95d576</data>
    </edge>
    <edge source="CARAT" target="SLR_DIAMOND">
      <data key="d4">1.0</data>
      <data key="d5">Carat is the predictor variable in the SLR.diamond model</data>
      <data key="d6">b99ecc2f79f56198a8c2adbdff95d576</data>
    </edge>
    <edge source="CARAT" target="SLR.DIAMOND">
      <data key="d4">1.0</data>
      <data key="d5">The carat variable is the predictor variable in the SLR.diamond model</data>
      <data key="d6">2b01334fb633566ba368a764ad579fce</data>
    </edge>
    <edge source="CARAT" target="SLOPE">
      <data key="d4">1.0</data>
      <data key="d5">Slope is related to Carat as the slope is the coefficient associated with the explanatory variable carat</data>
      <data key="d6">9fc9b618723695c0c593043162a4084b</data>
    </edge>
    <edge source="CARAT" target="SLOPE_COEFFICIENT">
      <data key="d4">1.0</data>
      <data key="d5">The slope coefficient is associated with the unit of weight for diamonds, indicating the change in price for every additional 0.1 carat</data>
      <data key="d6">e1ad57124a08c0e123deda212ea03c32</data>
    </edge>
    <edge source="CARAT" target="DIAMOND">
      <data key="d4">2.0</data>
      <data key="d5">Diamond weight is measured in carats, with the price of a Solitaire ring being affected by the weight of the diamond
carat is a variable in the diamond dataset used as a predictor in the linear model</data>
      <data key="d6">35e06960dba699ce0d56fc1e98bdbe96,e1ad57124a08c0e123deda212ea03c32</data>
    </edge>
    <edge source="CARAT" target="MEAN">
      <data key="d4">1.0</data>
      <data key="d5">mean(carat) is used to center the carat variable in the linear model</data>
      <data key="d6">35e06960dba699ce0d56fc1e98bdbe96</data>
    </edge>
    <edge source="SCATTERPLOT" target="DIAMOND_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">A scatterplot visually illustrates the relationship between diamond weight and ring price, showing how the price of a ring depends on the weight of its diamond.</data>
      <data key="d6">3e7eef51f3109d60697f3299b541b726</data>
    </edge>
    <edge source="SCATTERPLOT" target="RING_PRICE">
      <data key="d4">1.0</data>
      <data key="d5">A scatterplot visually illustrates the relationship between diamond weight and ring price, showing how the price of a ring depends on the weight of its diamond.</data>
      <data key="d6">3e7eef51f3109d60697f3299b541b726</data>
    </edge>
    <edge source="SCATTERPLOT" target="LINE_OF_BEST_FIT">
      <data key="d4">3.0</data>
      <data key="d5">The line of best fit is added to the scatterplot to illustrate the linearity of the relationship between the price of a ring and the weight of its diamond.
The line of best fit is shown in the scatterplot
A line of best fit can be added to a scatterplot to represent the relationship between variables, often calculated using methods like least squares</data>
      <data key="d6">2e5e1bdaa9fcc7b3391d277fd6bb247a,3e7eef51f3109d60697f3299b541b726,ae1e66f5b64284090abc285c1d4389f5</data>
    </edge>
    <edge source="SCATTERPLOT" target="FIGURE_1_3">
      <data key="d4">1.0</data>
      <data key="d5">Figure 1.3 shows two scatterplots that depict the relationship between diamond weight and ring price</data>
      <data key="d6">c5b269ff5c94db7ebd2cb9f7be16f171</data>
    </edge>
    <edge source="SCATTERPLOT" target="RESIDUAL">
      <data key="d4">1.0</data>
      <data key="d5">The residuals are illustrated by the red lines in the scatterplot</data>
      <data key="d6">2e5e1bdaa9fcc7b3391d277fd6bb247a</data>
    </edge>
    <edge source="SCATTERPLOT" target="ANSCOMBE_QUARTET">
      <data key="d4">1.0</data>
      <data key="d5">Anscombe's Quartet shows that datasets with the same summary statistics can have very different scatterplots</data>
      <data key="d6">9f335f1ecb85a1427df926df8bb1e89f</data>
    </edge>
    <edge source="SCATTERPLOT" target="X">
      <data key="d4">2.0</data>
      <data key="d5">X is one of the variables plotted in the scatterplot
Scatterplot shows the relationship between X and Y</data>
      <data key="d6">11452a08471d93959558de2ece9a69af,2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="SCATTERPLOT" target="Y">
      <data key="d4">2.0</data>
      <data key="d5">Y is one of the variables plotted in the scatterplot
Scatterplot shows the relationship between X and Y</data>
      <data key="d6">11452a08471d93959558de2ece9a69af,2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="SCATTERPLOT" target="DATASET_1">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 1 is visualized using a scatterplot that shows the relationship between x-values and y-values</data>
      <data key="d6">84ffe1b8496dc660c47248c9f7b5bdea</data>
    </edge>
    <edge source="SCATTERPLOT" target="DATASET_2">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 2 is visualized using a scatterplot that reveals a poor fit for a simple linear regression model</data>
      <data key="d6">84ffe1b8496dc660c47248c9f7b5bdea</data>
    </edge>
    <edge source="SCATTERPLOT" target="DATASET_3">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 3 is visualized using a scatterplot that highlights an outlier affecting the fitted line</data>
      <data key="d6">84ffe1b8496dc660c47248c9f7b5bdea</data>
    </edge>
    <edge source="SCATTERPLOT" target="DATASET_4">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 4 is visualized using a scatterplot that shows the dependence of the slope on a single unusual data point</data>
      <data key="d6">84ffe1b8496dc660c47248c9f7b5bdea</data>
    </edge>
    <edge source="SCATTERPLOT" target="PARABOLA">
      <data key="d4">1.0</data>
      <data key="d5">Parabola is the curve of best fit shown in the scatterplot</data>
      <data key="d6">11452a08471d93959558de2ece9a69af</data>
    </edge>
    <edge source="SCATTERPLOT" target="QUADRATIC_CURVE">
      <data key="d4">1.0</data>
      <data key="d5">Scatterplot shows the quadratic curve of best fit</data>
      <data key="d6">11452a08471d93959558de2ece9a69af</data>
    </edge>
    <edge source="SCATTERPLOT" target="WESTERN_RED_CEDAR_DATA">
      <data key="d4">1.0</data>
      <data key="d5">A scatterplot can be created using the Western red cedar data to visualize the relationship between variables such as height and diameter</data>
      <data key="d6">ae1e66f5b64284090abc285c1d4389f5</data>
    </edge>
    <edge source="SCATTERPLOT" target="LOGARITHMIC_CURVE_OF_BEST_FIT">
      <data key="d4">1.0</data>
      <data key="d5">A logarithmic curve of best fit can be added to a scatterplot to represent the relationship between a log-transformed variable and another variable</data>
      <data key="d6">ae1e66f5b64284090abc285c1d4389f5</data>
    </edge>
    <edge source="SCATTERPLOT" target="NULL_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">A scatterplot is often paired with a null plot to visually assess the fit of a model</data>
      <data key="d6">aa13c33a7e61206e6021e2736002ca9a</data>
    </edge>
    <edge source="SCATTERPLOT" target="REGRESSION_LINE">
      <data key="d4">5.0</data>
      <data key="d5">The regression line is added to the scatterplot to illustrate the relationship between the explanatory variable and the response variable
A regression line is fitted to the data in a scatterplot to predict the response variable based on the explanatory variable
The regression line is fitted to the data points in the scatterplot
The regression line is displayed in the scatterplot
Scatterplot is used to visualize the fitted regression line and assess the relationship between the explanatory and response variables</data>
      <data key="d6">312309b45c59e1c84695ac3c7e202742,674b8d5bb1f830d0fb944942514d1a16,82cfcd5865cffe55e965a50745656e60,b9ec8a6c7960cc6196ec94fd976f05b0,ef24ca5edd06893b737e6a1c8a9825f6</data>
    </edge>
    <edge source="SCATTERPLOT" target="WELL_FITTING_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">A well-fitting model is illustrated by a scatterplot where the observations are scattered relatively evenly on either side of the regression line</data>
      <data key="d6">674b8d5bb1f830d0fb944942514d1a16</data>
    </edge>
    <edge source="SCATTERPLOT" target="RESPONSE_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">A scatterplot displays the relationship between the response variable and the explanatory variable</data>
      <data key="d6">b9ec8a6c7960cc6196ec94fd976f05b0</data>
    </edge>
    <edge source="SCATTERPLOT" target="EXPLANATORY_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">A scatterplot displays the relationship between the response variable and the explanatory variable</data>
      <data key="d6">b9ec8a6c7960cc6196ec94fd976f05b0</data>
    </edge>
    <edge source="SCATTERPLOT" target="RESIDUAL_PLOT">
      <data key="d4">4.0</data>
      <data key="d5">A residual plot is derived from a scatterplot and is used to check the assumptions of a regression model
The scatterplot and residual plot are used together to analyze the relationship and patterns in the data
The residual plot is created from the scatterplot
A scatterplot is often used in conjunction with a residual plot to assess the fit of a model and the relationship between variables</data>
      <data key="d6">15c7b5750483a382ce59751008e86751,312309b45c59e1c84695ac3c7e202742,521acf88540d5897188c9ec65b17e6a6,82cfcd5865cffe55e965a50745656e60</data>
    </edge>
    <edge source="SCATTERPLOT" target="OBSERVATIONS">
      <data key="d4">3.0</data>
      <data key="d5">The observations are plotted in the scatterplot to visualize the relationship between variables
Observations are plotted in a scatterplot to visualize the relationship between the response and explanatory variables
The scatterplot is created from the observations</data>
      <data key="d6">312309b45c59e1c84695ac3c7e202742,82cfcd5865cffe55e965a50745656e60,b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </edge>
    <edge source="SCATTERPLOT" target="NON_MONOTONIC_NON_LINEAR_RELATIONSHIP">
      <data key="d4">1.0</data>
      <data key="d5">The non-monotonic non-linear relationship is visualized in the scatterplot</data>
      <data key="d6">82cfcd5865cffe55e965a50745656e60</data>
    </edge>
    <edge source="SCATTERPLOT" target="FITTED_REGRESSION_LINE">
      <data key="d4">1.0</data>
      <data key="d5">A scatterplot of the data can include a fitted regression line, which is a visual representation of the relationship between the independent and dependent variables as estimated by the linear regression model.</data>
      <data key="d6">23fc620f1238c6a1b5c5e3a08e149c53</data>
    </edge>
    <edge source="SCATTERPLOT" target="SMOOTHING_CURVE">
      <data key="d4">2.0</data>
      <data key="d5">A smoothing curve can be added to a scatterplot to help visualize the overall pattern of the data points. This curve can reveal underlying trends or patterns that might not be apparent from the raw data points alone.
The smoothing curve is fitted to the data in the scatterplot</data>
      <data key="d6">23fc620f1238c6a1b5c5e3a08e149c53,312309b45c59e1c84695ac3c7e202742</data>
    </edge>
    <edge source="SCATTERPLOT" target="DATA">
      <data key="d4">1.0</data>
      <data key="d5">The scatterplot is created from the data</data>
      <data key="d6">312309b45c59e1c84695ac3c7e202742</data>
    </edge>
    <edge source="SCATTERPLOT" target="REPEATED_VALUES">
      <data key="d4">1.0</data>
      <data key="d5">Repeated values of the explanatory variable can affect the appearance and interpretation of a scatterplot</data>
      <data key="d6">521acf88540d5897188c9ec65b17e6a6</data>
    </edge>
    <edge source="SCATTERPLOT" target="RETAIL_DATA">
      <data key="d4">1.0</data>
      <data key="d5">Scatterplot is a graphical representation of the relationship between sales and price for each brand in the retail data</data>
      <data key="d6">ac15b639b0849006471dfe102376c2c0</data>
    </edge>
    <edge source="DIAMOND_RING_PRICING" target="LINEAR_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Linear regression is the statistical method used in the study of diamond ring pricing to analyze the relationship between diamond weight and ring price.</data>
      <data key="d6">3e7eef51f3109d60697f3299b541b726</data>
    </edge>
    <edge source="DIAMOND_RING_PRICING" target="JOURNAL_OF_STATISTICS_EDUCATION">
      <data key="d4">1.0</data>
      <data key="d5">The Journal of Statistics Education published a study on diamond ring pricing using linear regression.</data>
      <data key="d6">3e7eef51f3109d60697f3299b541b726</data>
    </edge>
    <edge source="LINEAR_REGRESSION" target="DATASET_1">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 1 is analyzed using linear regression to understand the relationship between x-values and y-values</data>
      <data key="d6">84ffe1b8496dc660c47248c9f7b5bdea</data>
    </edge>
    <edge source="LINEAR_REGRESSION" target="DATASET_2">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 2 is analyzed using linear regression, but the model is not suitable due to the curved relationship</data>
      <data key="d6">84ffe1b8496dc660c47248c9f7b5bdea</data>
    </edge>
    <edge source="LINEAR_REGRESSION" target="DATASET_3">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 3 is analyzed using linear regression, but an outlier significantly affects the fitted line</data>
      <data key="d6">84ffe1b8496dc660c47248c9f7b5bdea</data>
    </edge>
    <edge source="LINEAR_REGRESSION" target="DATASET_4">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 4 is analyzed using linear regression, but the model's validity is questionable due to the unique x-value</data>
      <data key="d6">84ffe1b8496dc660c47248c9f7b5bdea</data>
    </edge>
    <edge source="DIAMOND_WEIGHT" target="RING_PRICE">
      <data key="d4">1.0</data>
      <data key="d5">Diamond weight is the independent variable that influences the dependent variable, ring price, in the linear regression model.</data>
      <data key="d6">3e7eef51f3109d60697f3299b541b726</data>
    </edge>
    <edge source="DIAMOND_WEIGHT" target="SOLITAIRE_RING">
      <data key="d4">1.0</data>
      <data key="d5">The price of a Solitaire ring is influenced by the weight of its diamond. The relationship is described by a linear regression model where the weight of the diamond is a predictor variable and the price of the ring is the response variable.</data>
      <data key="d6">f0e0c5b2deaaf9fc2bc8b63d9ab989b1</data>
    </edge>
    <edge source="LINE_OF_BEST_FIT" target="WEIGHT">
      <data key="d4">2.0</data>
      <data key="d5">Weight is a variable that is used to define the line of best fit in the linear regression model
The line of best fit is determined by the relationship between Weight and Price, as defined by the equation Price = &#946;0 + &#946;1 weight + &#1013;</data>
      <data key="d6">6f10cac870c690419e5351e8a6aeae9e,d4bbb6beb0dd5c40d2941af71b7c1776</data>
    </edge>
    <edge source="LINE_OF_BEST_FIT" target="PRICE">
      <data key="d4">2.0</data>
      <data key="d5">Price is a variable that is predicted by the line of best fit in the linear regression model
Price is the independent variable that is used to predict sales in the line of best fit</data>
      <data key="d6">d4bbb6beb0dd5c40d2941af71b7c1776,f16299fc00a7a69bdf983dce826b4918</data>
    </edge>
    <edge source="LINE_OF_BEST_FIT" target="BETA_0">
      <data key="d4">4.0</data>
      <data key="d5">Beta_0 is a parameter that defines the intercept of the line of best fit
The line of best fit includes the intercept parameter Beta_0
Beta_0 is the intercept parameter in the line of best fit
Beta_0 is the intercept parameter in the line of best fit</data>
      <data key="d6">6f10cac870c690419e5351e8a6aeae9e,b99ecc2f79f56198a8c2adbdff95d576,d4bbb6beb0dd5c40d2941af71b7c1776,f16299fc00a7a69bdf983dce826b4918</data>
    </edge>
    <edge source="LINE_OF_BEST_FIT" target="BETA_1">
      <data key="d4">4.0</data>
      <data key="d5">Beta_1 is a parameter that defines the slope of the line of best fit
The line of best fit includes the slope parameter Beta_1
Beta_1 is the slope parameter in the line of best fit
Beta_1 is the slope parameter in the line of best fit</data>
      <data key="d6">6f10cac870c690419e5351e8a6aeae9e,b99ecc2f79f56198a8c2adbdff95d576,d4bbb6beb0dd5c40d2941af71b7c1776,f16299fc00a7a69bdf983dce826b4918</data>
    </edge>
    <edge source="LINE_OF_BEST_FIT" target="WEIGHT_DEVIATIONS">
      <data key="d4">1.0</data>
      <data key="d5">The line of best fit is a model that represents the relationship between the weight deviations from the mean and the price of Solitaire rings</data>
      <data key="d6">c5b269ff5c94db7ebd2cb9f7be16f171</data>
    </edge>
    <edge source="LINE_OF_BEST_FIT" target="SALES">
      <data key="d4">1.0</data>
      <data key="d5">Sales is the dependent variable that is modeled by the line of best fit</data>
      <data key="d6">f16299fc00a7a69bdf983dce826b4918</data>
    </edge>
    <edge source="LINE_OF_BEST_FIT" target="EPSILON">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon represents the error term in the line of best fit</data>
      <data key="d6">f16299fc00a7a69bdf983dce826b4918</data>
    </edge>
    <edge source="LINE_OF_BEST_FIT" target="RESIDUAL">
      <data key="d4">1.0</data>
      <data key="d5">The residuals are used to find the line of best fit by minimising the sum of squared residuals</data>
      <data key="d6">2e5e1bdaa9fcc7b3391d277fd6bb247a</data>
    </edge>
    <edge source="WEIGHT" target="PRICE">
      <data key="d4">3.0</data>
      <data key="d5">Weight is a variable that is used to predict the price of a Solitaire ring
Weight is a predictor variable that influences the Price of a Solitaire ring in the simple linear regression model
The weight of a diamond influences its price, as predicted by a model</data>
      <data key="d6">6f10cac870c690419e5351e8a6aeae9e,d4bbb6beb0dd5c40d2941af71b7c1776,f18bacb0a2fbfea44dd6326224184216</data>
    </edge>
    <edge source="WEIGHT" target="DETERMINISTIC_PART">
      <data key="d4">1.0</data>
      <data key="d5">Weight is a variable that contributes to the deterministic part of the relationship between price and weight</data>
      <data key="d6">d4bbb6beb0dd5c40d2941af71b7c1776</data>
    </edge>
    <edge source="WEIGHT" target="RANDOM_ERROR">
      <data key="d4">1.0</data>
      <data key="d5">Weight is a variable that, along with the random error, contributes to the scatter of observations around the line of best fit</data>
      <data key="d6">d4bbb6beb0dd5c40d2941af71b7c1776</data>
    </edge>
    <edge source="WEIGHT" target="DIAMOND">
      <data key="d4">2.0</data>
      <data key="d5">The weight of a diamond is a key attribute that affects its price
Weight is a characteristic of diamonds that is being analyzed in relation to price</data>
      <data key="d6">c5b269ff5c94db7ebd2cb9f7be16f171,f18bacb0a2fbfea44dd6326224184216</data>
    </edge>
    <edge source="WEIGHT" target="AVG_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">Avg_weight is the average of the weight of diamonds in the dataset, used in the model equation</data>
      <data key="d6">f18bacb0a2fbfea44dd6326224184216</data>
    </edge>
    <edge source="WEIGHT" target="INTERCEPT">
      <data key="d4">1.0</data>
      <data key="d5">Weight is used to calculate the intercept, which represents the predicted price of a Solitaire ring with a diamond of average weight</data>
      <data key="d6">f8a3c7ad2423fe8e91b33ca812ddfeff</data>
    </edge>
    <edge source="WEIGHT" target="AVERAGE_DIAMOND_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">The average diamond weight is a reference point for analyzing the weight of diamonds</data>
      <data key="d6">c5b269ff5c94db7ebd2cb9f7be16f171</data>
    </edge>
    <edge source="WEIGHT" target="REGRESSION_LINE">
      <data key="d4">1.0</data>
      <data key="d5">The regression line is a model that represents the relationship between the weight of diamonds and the price of Solitaire rings</data>
      <data key="d6">c5b269ff5c94db7ebd2cb9f7be16f171</data>
    </edge>
    <edge source="PRICE" target="DETERMINISTIC_PART">
      <data key="d4">1.0</data>
      <data key="d5">Price is a variable that is influenced by the deterministic part of the relationship between price and weight</data>
      <data key="d6">d4bbb6beb0dd5c40d2941af71b7c1776</data>
    </edge>
    <edge source="PRICE" target="RANDOM_ERROR">
      <data key="d4">1.0</data>
      <data key="d5">Price is a variable that, along with the random error, contributes to the scatter of observations around the line of best fit</data>
      <data key="d6">d4bbb6beb0dd5c40d2941af71b7c1776</data>
    </edge>
    <edge source="PRICE" target="BETA_0">
      <data key="d4">1.0</data>
      <data key="d5">Beta_0 is the intercept parameter that determines the value of Price when Weight is zero</data>
      <data key="d6">6f10cac870c690419e5351e8a6aeae9e</data>
    </edge>
    <edge source="PRICE" target="BETA_1">
      <data key="d4">3.0</data>
      <data key="d5">Beta_1 is the slope parameter that determines the change in Price for a unit change in Weight
Beta_1 is the coefficient for the price variable, indicating the effect of price on sales volume
The explanatory variable Price is associated with the coefficient Beta_1 in the linear regression model</data>
      <data key="d6">250ee5d766c64e7975bcc427b4bf9074,6f10cac870c690419e5351e8a6aeae9e,a828fd17fc38e902484872c88a6b242c</data>
    </edge>
    <edge source="PRICE" target="EPSILON">
      <data key="d4">1.0</data>
      <data key="d5">&#1013; is the random error term that represents the deviation of the observed Price from the systematic component</data>
      <data key="d6">6f10cac870c690419e5351e8a6aeae9e</data>
    </edge>
    <edge source="PRICE" target="DIAMOND_DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Price is a variable in the diamond dataset</data>
      <data key="d6">b99ecc2f79f56198a8c2adbdff95d576</data>
    </edge>
    <edge source="PRICE" target="SLR_DIAMOND">
      <data key="d4">1.0</data>
      <data key="d5">Price is the response variable in the SLR.diamond model</data>
      <data key="d6">b99ecc2f79f56198a8c2adbdff95d576</data>
    </edge>
    <edge source="PRICE" target="SLR.DIAMOND">
      <data key="d4">1.0</data>
      <data key="d5">The price variable is the response variable in the SLR.diamond model</data>
      <data key="d6">2b01334fb633566ba368a764ad579fce</data>
    </edge>
    <edge source="PRICE" target="SLOPE_COEFFICIENT">
      <data key="d4">1.0</data>
      <data key="d5">The slope coefficient affects the price of a Solitaire ring, with an increase of 0.1 carat leading to a S$ 372 increase in price</data>
      <data key="d6">e1ad57124a08c0e123deda212ea03c32</data>
    </edge>
    <edge source="PRICE" target="INTERCEPT">
      <data key="d4">3.0</data>
      <data key="d5">The intercept is related to the price of a Solitaire ring when the diamond weight is zero, which is considered nonsensical
Intercept is the estimated price of a Solitaire ring with a diamond of average weight, which is approximately S$ 500
The interpretation of the intercept in a regression model requires extrapolation when price values are considerably larger than zero</data>
      <data key="d6">2ced3e26eaed2dfcd8e4caf49737cab4,e1ad57124a08c0e123deda212ea03c32,f8a3c7ad2423fe8e91b33ca812ddfeff</data>
    </edge>
    <edge source="PRICE" target="SOLITAIRE_RING">
      <data key="d4">2.0</data>
      <data key="d5">The price of a Solitaire ring is determined by factors such as the weight of the diamond
Price is the cost of Solitaire rings, which is being analyzed in relation to the weight of diamonds</data>
      <data key="d6">c5b269ff5c94db7ebd2cb9f7be16f171,e1ad57124a08c0e123deda212ea03c32</data>
    </edge>
    <edge source="PRICE" target="S_372">
      <data key="d4">1.0</data>
      <data key="d5">S$ 372,- is the predicted increase in price for a diamond ring with a diamond that is 0.1 carat heavier</data>
      <data key="d6">f18bacb0a2fbfea44dd6326224184216</data>
    </edge>
    <edge source="PRICE" target="REGRESSION_LINE">
      <data key="d4">1.0</data>
      <data key="d5">The regression line is a model that represents the relationship between the weight of diamonds and the price of Solitaire rings</data>
      <data key="d6">c5b269ff5c94db7ebd2cb9f7be16f171</data>
    </edge>
    <edge source="PRICE" target="SIMPLE_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Price is the explanatory variable in simple regression, which is analyzed in relation to the response variable sales</data>
      <data key="d6">336546bc73cbe1828a0cc1a45faf8f5a</data>
    </edge>
    <edge source="PRICE" target="MULTIPLE_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Price is one of the explanatory variables in multiple regression, which is analyzed in relation to the response variable sales</data>
      <data key="d6">336546bc73cbe1828a0cc1a45faf8f5a</data>
    </edge>
    <edge source="PRICE" target="SLR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The price variable is used as the predictor variable in the simple linear regression model</data>
      <data key="d6">2e5e1bdaa9fcc7b3391d277fd6bb247a</data>
    </edge>
    <edge source="PRICE" target="SALES">
      <data key="d4">7.0</data>
      <data key="d5">The sales volume is affected by the price of the product, as indicated by the negative coefficient in the model
Price has an effect on sales volume, with the effect being the same for all three store brands
Sales is the dependent variable that is regressed against price, the independent variable
The sales variable is influenced by the price variable in the regression model
Price influences sales volumes, and is accounted for in the analysis
Price affects sales at the jth store through the Beta coefficient
Price is the independent variable that affects the sales volume in the regression model</data>
      <data key="d6">1820d10ee0f23f34b3ea88ba475bc52d,250ee5d766c64e7975bcc427b4bf9074,7037e0369bfdaad5a730cabb2b44831c,8326c645426789920a99ed373725fa0e,906eb7d6b49fa360e7e5b65c56cd4d76,a1fc936df848a0fbc791e4bcc9b527b6,b2c33cb151a8e7724ebfb7b2d88bc45f</data>
    </edge>
    <edge source="PRICE" target="DATAPPOINTS">
      <data key="d4">1.0</data>
      <data key="d5">Price is one of the coordinates (x-axis) of the datapoints in the 3D graphical representation</data>
      <data key="d6">8a9b984c146f59b2af83d1c2f373d376</data>
    </edge>
    <edge source="PRICE" target="REGRESSION_PLANE">
      <data key="d4">1.0</data>
      <data key="d5">Price is one of the explanatory variables in the regression analysis, and the regression plane describes the relationship between price and sales</data>
      <data key="d6">b1690cb1a67892245c0665e5099e322d</data>
    </edge>
    <edge source="PRICE" target="OBSERVED_DATA">
      <data key="d4">1.0</data>
      <data key="d5">Price is one of the explanatory variables in the observed data</data>
      <data key="d6">c48bd062d5f6cc20c5df5758d6285562</data>
    </edge>
    <edge source="PRICE" target="DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Price is a variable in the dataset</data>
      <data key="d6">2ced3e26eaed2dfcd8e4caf49737cab4</data>
    </edge>
    <edge source="PRICE" target="SALES_VOLUME">
      <data key="d4">3.0</data>
      <data key="d5">Price is used as an independent variable in the regression model to predict sales volume.
Price is a predictor variable in the linear regression model used to predict sales volume.
Price affects sales volume, as seen in the regression model</data>
      <data key="d6">7a605c3b689bec7ab2c46df9c123e3f3,b6870535f3975c49d45e62fbe475f198,e079b7c92d5c0b009ff02040eb652bc6</data>
    </edge>
    <edge source="PRICE" target="BRAND_MODEL1">
      <data key="d4">1.0</data>
      <data key="d5">Price is a predictor variable in the model Brand.model1</data>
      <data key="d6">ee295ebc4c2d6a2a5c738796fcc2ab71</data>
    </edge>
    <edge source="PRICE" target="BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Price is an independent variable whose effect on sales is quantified by the estimated coefficient for Beta (&#946;)</data>
      <data key="d6">248924760a2bfbc82501fd6b11cfa0aa</data>
    </edge>
    <edge source="PRICE" target="X">
      <data key="d4">1.0</data>
      <data key="d5">X includes the price variable as a numerical predictor in the regression model</data>
      <data key="d6">e800735d6b2a244875f5e0d292de1527</data>
    </edge>
    <edge source="PRICE" target="C_PRICE">
      <data key="d4">1.0</data>
      <data key="d5">price is the original variable that c_pricej is derived from by subtracting the sample mean</data>
      <data key="d6">1b523d1edabe381403fc470a9b8d47fa</data>
    </edge>
    <edge source="PRICE" target="BRAND_MODEL2">
      <data key="d4">1.0</data>
      <data key="d5">Price is an independent variable in Brand.model2, affecting sales</data>
      <data key="d6">93da9813e10a119798de6982977f1239</data>
    </edge>
    <edge source="PRICE" target="AVERAGE_PRICE">
      <data key="d4">1.0</data>
      <data key="d5">The average price is a specific value of the price variable used as a reference point for interpreting the brand variable coefficients</data>
      <data key="d6">9854704301b8df256ca1013b8d53dfac</data>
    </edge>
    <edge source="PRICE" target="BETA">
      <data key="d4">1.0</data>
      <data key="d5">Beta (&#946;) is the coefficient of the price variable (pricej) in the model</data>
      <data key="d6">1d141ab04db553f78a313e430e54abb5</data>
    </edge>
    <edge source="PRICE" target="DESIGN_MATRIX_X">
      <data key="d4">1.0</data>
      <data key="d5">Price is an independent variable in the linear regression model, included in the design matrix X</data>
      <data key="d6">c103c6d096d52868eda26d991194b5f2</data>
    </edge>
    <edge source="PRICE" target="RETAIL_DATA">
      <data key="d4">1.0</data>
      <data key="d5">Price is a variable in the retail data used as a predictor in the regression models</data>
      <data key="d6">ac15b639b0849006471dfe102376c2c0</data>
    </edge>
    <edge source="PRICE" target="PARALLEL_LINES_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Price is an explanatory variable in the parallel lines model</data>
      <data key="d6">0cb40986e6c2bb439e1ffcaae2df96ac</data>
    </edge>
    <edge source="PRICE" target="BRAND_A">
      <data key="d4">1.0</data>
      <data key="d5">Brand A stores' sales are affected by price changes, as indicated by the sales model 210.379 - 0.657 * pricei</data>
      <data key="d6">3dd24a54028976ba54304ec7169bb74b</data>
    </edge>
    <edge source="PRICE" target="BRAND_B">
      <data key="d4">1.0</data>
      <data key="d5">Brand B stores' sales are affected by price changes, as indicated by the sales model 225.252 - 0.803 * pricei</data>
      <data key="d6">3dd24a54028976ba54304ec7169bb74b</data>
    </edge>
    <edge source="PRICE" target="BRAND_C">
      <data key="d4">1.0</data>
      <data key="d5">Brand C stores' sales are affected by price changes, as indicated by the sales model 162.879 - 0.231 * pricei</data>
      <data key="d6">3dd24a54028976ba54304ec7169bb74b</data>
    </edge>
    <edge source="PRICE" target="INTERACTION">
      <data key="d4">1.0</data>
      <data key="d5">The effect of price on sales volume can change depending on the brand, indicating an interaction between price and brand</data>
      <data key="d6">b0ca3e6c22c4cf884d03b1f6f82be5df</data>
    </edge>
    <edge source="BETA_0" target="DETERMINISTIC_PART">
      <data key="d4">1.0</data>
      <data key="d5">Beta_0 is a parameter that contributes to the deterministic part of the relationship between price and weight</data>
      <data key="d6">d4bbb6beb0dd5c40d2941af71b7c1776</data>
    </edge>
    <edge source="BETA_0" target="SALES">
      <data key="d4">1.0</data>
      <data key="d5">Beta_0 is the intercept term in the model, contributing to the baseline sales volume</data>
      <data key="d6">250ee5d766c64e7975bcc427b4bf9074</data>
    </edge>
    <edge source="BETA_0" target="INTERCEPT">
      <data key="d4">1.0</data>
      <data key="d5">The intercept (&#946;0) is the same as the parameter Beta_0 in the linear regression model</data>
      <data key="d6">a828fd17fc38e902484872c88a6b242c</data>
    </edge>
    <edge source="BETA_0" target="Y">
      <data key="d4">3.0</data>
      <data key="d5">Beta_0 (&#946;0) is the expected value of Y when all explanatory variables are zero
Beta_0 is part of the systematic component that determines the mean of Y
BETA_0 is the intercept parameter in the quadratic regression model that contributes to the calculation of Y</data>
      <data key="d6">2d5cdecc342ddacd2c090f1838430cee,9a27580975988e83f6e3a0d9010893b5,a828fd17fc38e902484872c88a6b242c</data>
    </edge>
    <edge source="BETA_0" target="YJ">
      <data key="d4">2.0</data>
      <data key="d5">&#946;0 is the intercept term in the regression equation for Yj
Yj is calculated using Beta_0 as the intercept in the linear regression model</data>
      <data key="d6">75dc4d8cb195a1f969d9e9496631086b,7ad4ccec4c7bb3702aed71c17dc6b96f</data>
    </edge>
    <edge source="BETA_0" target="YN">
      <data key="d4">1.0</data>
      <data key="d5">Yn is related to BETA_0 as part of the linear regression model for the nth observation</data>
      <data key="d6">8f1d95acff56e1633dceb775fa713174</data>
    </edge>
    <edge source="BETA_0" target="LINEAR_PREDICTOR">
      <data key="d4">2.0</data>
      <data key="d5">Beta_0 (&#946;0) is the intercept parameter in the linear predictor
Beta_0 is part of the linear predictor, contributing to the intercept of the mean function of the response</data>
      <data key="d6">67e4c1866b0c6e162e6e3317949e8da9,6a47154bf457c25f22c3cf9f649c5db0</data>
    </edge>
    <edge source="BETA_0" target="QUADRATIC_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Beta_0 (&#946;0) is one of the parameters in the quadratic regression model. It is estimated using least squares estimation</data>
      <data key="d6">e5131a1158e58f1b7b44b21ced7b6f60</data>
    </edge>
    <edge source="BETA_0" target="YI">
      <data key="d4">2.0</data>
      <data key="d5">The intercept parameter Beta_0 (&#946;0) is part of the model that determines the expected value of the log-transformed response variable Yi when all explanatory variables are zero.
Beta_0 is the intercept in the regression model, contributing to the prediction of Yi</data>
      <data key="d6">0fbc9037ca9a440e79e9ac05664b9b3d,90b7e0427699cc1bb461e37939935138</data>
    </edge>
    <edge source="BETA_0" target="YB">
      <data key="d4">2.0</data>
      <data key="d5">&#946;0 is a component in the calculation of YB, the back-transformed prediction for Y
Beta_0 is part of the formula used to calculate the predicted response YB</data>
      <data key="d6">21e429490eeefe7d9c245058fd48ca68,995fb26a0261f824952fa7b2fac3382e</data>
    </edge>
    <edge source="BETA_0" target="LOG_BRAIN_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">Beta_0 is the intercept of the line of best fit when log(brain weight) is regressed against log(body weight)</data>
      <data key="d6">e2422d8b80004aab4ea74d5209587861</data>
    </edge>
    <edge source="BETA_0" target="BRAIN_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">Beta_0 is part of the model used to predict brain weight</data>
      <data key="d6">efeeb664622c1ee594e6a08a8322ffe3</data>
    </edge>
    <edge source="BETA_0" target="S">
      <data key="d4">3.0</data>
      <data key="d5">Beta_0 (&#946;0) is part of the calculation of the sum of squared differences function S(&#946;) in the simple linear regression model
Beta_0 is a parameter in the function S(&#946;) used to find the least squares estimates
Beta_0 is a parameter in the function S(&#946;) that is minimized to find the least squares estimates</data>
      <data key="d6">10ac76f99674a01ca0f4a55586dea07e,416494d940a9f505da9853caca26fe63,50a56c34050fb7f7709300a51399b150</data>
    </edge>
    <edge source="BETA_0" target="S_BETA">
      <data key="d4">1.0</data>
      <data key="d5">Beta_0 is a parameter in the linear regression model that contributes to the calculation of S(&#946;)</data>
      <data key="d6">8f7a05b6d231105a6194eebdb2df372e</data>
    </edge>
    <edge source="BETA_0" target="BETA_HAT_0">
      <data key="d4">1.0</data>
      <data key="d5">Beta_0 is the true parameter that Beta_hat_0 estimates in the original model</data>
      <data key="d6">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </edge>
    <edge source="BETA_0" target="BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Beta_0 is the intercept parameter that Beta hat (&#946;b) estimates in the simple linear regression model</data>
      <data key="d6">d14413709de2897231aaa83be3aa346f</data>
    </edge>
    <edge source="BETA_0" target="BETA_0_HAT">
      <data key="d4">1.0</data>
      <data key="d5">BETA_0 (&#946;0) is the true parameter that BETA_0_HAT (b&#946;0) estimates</data>
      <data key="d6">69ffba28a61d98d8d18f91c24b74dd4a</data>
    </edge>
    <edge source="BETA_1" target="DETERMINISTIC_PART">
      <data key="d4">1.0</data>
      <data key="d5">Beta_1 is a parameter that contributes to the deterministic part of the relationship between price and weight</data>
      <data key="d6">d4bbb6beb0dd5c40d2941af71b7c1776</data>
    </edge>
    <edge source="BETA_1" target="Y">
      <data key="d4">3.0</data>
      <data key="d5">Beta_1 (&#946;1) indicates the average change in Y for a one unit increase in X1, given a fixed value of X2
Beta_1 is part of the systematic component that determines the mean of Y
BETA_1 is the coefficient of the linear term in the quadratic regression model that contributes to the calculation of Y</data>
      <data key="d6">2d5cdecc342ddacd2c090f1838430cee,9a27580975988e83f6e3a0d9010893b5,a828fd17fc38e902484872c88a6b242c</data>
    </edge>
    <edge source="BETA_1" target="X1">
      <data key="d4">1.0</data>
      <data key="d5">X1 is the explanatory variable associated with the coefficient Beta_1 in the linear regression model</data>
      <data key="d6">a828fd17fc38e902484872c88a6b242c</data>
    </edge>
    <edge source="BETA_1" target="YN">
      <data key="d4">1.0</data>
      <data key="d5">Yn is related to BETA_1 as part of the linear regression model for the nth observation</data>
      <data key="d6">8f1d95acff56e1633dceb775fa713174</data>
    </edge>
    <edge source="BETA_1" target="LINEAR_PREDICTOR">
      <data key="d4">2.0</data>
      <data key="d5">Beta_1 (&#946;1) is the coefficient of X1 in the linear predictor
Beta_1 is part of the linear predictor, contributing to the slope of the mean function of the response</data>
      <data key="d6">67e4c1866b0c6e162e6e3317949e8da9,6a47154bf457c25f22c3cf9f649c5db0</data>
    </edge>
    <edge source="BETA_1" target="YJ">
      <data key="d4">1.0</data>
      <data key="d5">Yj is calculated using Beta_1 as the coefficient of the first explanatory variable</data>
      <data key="d6">7ad4ccec4c7bb3702aed71c17dc6b96f</data>
    </edge>
    <edge source="BETA_1" target="QUADRATIC_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Beta_1 (&#946;1) is one of the parameters in the quadratic regression model. It is estimated using least squares estimation</data>
      <data key="d6">e5131a1158e58f1b7b44b21ced7b6f60</data>
    </edge>
    <edge source="BETA_1" target="YI">
      <data key="d4">2.0</data>
      <data key="d5">The parameter Beta_1 (&#946;1) is associated with the explanatory variable X1 and influences the change in the log-transformed response variable Yi per unit change in X1.
Beta_1 is the slope parameter in the regression model, influencing the prediction of Yi</data>
      <data key="d6">0fbc9037ca9a440e79e9ac05664b9b3d,90b7e0427699cc1bb461e37939935138</data>
    </edge>
    <edge source="BETA_1" target="YB">
      <data key="d4">2.0</data>
      <data key="d5">&#946;1 is a component in the calculation of YB, the back-transformed prediction for Y, and its effect is observed when X1 changes
Beta_1 is the coefficient that determines the effect of X1 on the predicted response YB</data>
      <data key="d6">21e429490eeefe7d9c245058fd48ca68,995fb26a0261f824952fa7b2fac3382e</data>
    </edge>
    <edge source="BETA_1" target="LOG_BRAIN_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">Beta_1 is the slope of the line of best fit when log(brain weight) is regressed against log(body weight)</data>
      <data key="d6">e2422d8b80004aab4ea74d5209587861</data>
    </edge>
    <edge source="BETA_1" target="BRAIN_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">Beta_1 is part of the model used to predict brain weight, with a value of 0.75</data>
      <data key="d6">efeeb664622c1ee594e6a08a8322ffe3</data>
    </edge>
    <edge source="BETA_1" target="S">
      <data key="d4">3.0</data>
      <data key="d5">Beta_1 (&#946;1) is part of the calculation of the sum of squared differences function S(&#946;) in the simple linear regression model
Beta_1 is a parameter in the function S(&#946;) used to find the least squares estimates
Beta_1 is a parameter in the function S(&#946;) that is minimized to find the least squares estimates</data>
      <data key="d6">10ac76f99674a01ca0f4a55586dea07e,416494d940a9f505da9853caca26fe63,50a56c34050fb7f7709300a51399b150</data>
    </edge>
    <edge source="BETA_1" target="S_BETA">
      <data key="d4">1.0</data>
      <data key="d5">Beta_1 is a parameter in the linear regression model that contributes to the calculation of S(&#946;)</data>
      <data key="d6">8f7a05b6d231105a6194eebdb2df372e</data>
    </edge>
    <edge source="BETA_1" target="BETA_HAT_1">
      <data key="d4">1.0</data>
      <data key="d5">Beta_1 is the true parameter that Beta_hat_1 estimates in the original model</data>
      <data key="d6">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </edge>
    <edge source="BETA_1" target="BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Beta_1 is the coefficient of the predictor that Beta hat (&#946;b) estimates in the simple linear regression model</data>
      <data key="d6">d14413709de2897231aaa83be3aa346f</data>
    </edge>
    <edge source="BETA_1" target="BETA_1_HAT">
      <data key="d4">1.0</data>
      <data key="d5">BETA_1 (&#946;1) is the true parameter that BETA_1_HAT (b&#946;1) estimates</data>
      <data key="d6">69ffba28a61d98d8d18f91c24b74dd4a</data>
    </edge>
    <edge source="EPSILON" target="RANDOM_ERROR">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon is the random error term that contributes to the scatter of observations around the line of best fit</data>
      <data key="d6">d4bbb6beb0dd5c40d2941af71b7c1776</data>
    </edge>
    <edge source="EPSILON" target="SIGMA_SQUARED">
      <data key="d4">7.0</data>
      <data key="d5">&#963;^2 is the variance of the error term &#1013;, indicating the spread of the error around the line of best fit
Sigma squared (&#963;^2) is part of the variance-covariance matrix of the distribution of Epsilon
The variance of the error term &#1013; is &#963;^2
EPSILON is related to SIGMA_SQUARED as part of its variance in the linear regression model
Sigma squared is the variance of the error term Epsilon
EPSILON is assumed to follow a normal distribution with variance &#963;^2
Sigma squared (&#963;^2) is the variance of the error term EPSILON in the quadratic regression model</data>
      <data key="d6">2d5cdecc342ddacd2c090f1838430cee,6f10cac870c690419e5351e8a6aeae9e,75dc4d8cb195a1f969d9e9496631086b,7ad4ccec4c7bb3702aed71c17dc6b96f,7fc5b8303ab530821bf2140ba6a8a889,8f1d95acff56e1633dceb775fa713174,dd7e7d54883ca0f687568a738b95d4d0</data>
    </edge>
    <edge source="EPSILON" target="MODEL_EQUATION">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon is the error term in the model equation (1.2)</data>
      <data key="d6">f18bacb0a2fbfea44dd6326224184216</data>
    </edge>
    <edge source="EPSILON" target="SALES">
      <data key="d4">6.0</data>
      <data key="d5">Epsilon represents the unexplained variation in sales, not accounted for by the systematic component of the model
Epsilon represents the random variation in sales that is not explained by the model
&#1013;j is the error term for Salesj at the jth store
Epsilon represents the error term in the sales volume model
&#1013;j is the error term in the linear model, representing the deviation of the observed sales from the expected sales
Epsilon represents the random error in the sales at the jth store</data>
      <data key="d6">1b523d1edabe381403fc470a9b8d47fa,250ee5d766c64e7975bcc427b4bf9074,48971100deb5bb374a41c1f2b7b2a86a,8326c645426789920a99ed373725fa0e,906eb7d6b49fa360e7e5b65c56cd4d76,a1fc936df848a0fbc791e4bcc9b527b6</data>
    </edge>
    <edge source="EPSILON" target="Y">
      <data key="d4">14.0</data>
      <data key="d5">Y is the response variable in the linear regression model, which includes the error term &#1013;
The distribution of Yj around its mean is governed by the distribution of &#1013;j, with the variance of Yj equal to the variance of &#1013;j
Y is the dependent variable in the linear model Y = X&#946; + &#1013;
Y is related to EPSILON as part of the linear regression model
Y includes the error vector Epsilon
&#1013; is the error term in the linear model, which affects the distribution of the response vector Y
EPSILON is the error term in the quadratic regression model that contributes to the calculation of Y
Y is the response variable that includes the additive errors epsilon (&#1013;)
Epsilon (&#1013;j) is the error term that represents the unexplained variation in Y around the straight line model
Epsilon (&#1013;j) is the error term in the linear regression model, contributing to the observed values Y
Vector epsilon is the error term in the model, contributing to the variability of Y around the expected value
EPSILON (&#1013;) is the error term that, when added to the linear combination of BETA_0 and BETA_1 with X, gives the observed values Y
Y is influenced by the error term &#1013; in the linear model
Epsilon (&#1013;) is the error term that represents the difference between the observed sales values (Y) and the predicted values</data>
      <data key="d6">248924760a2bfbc82501fd6b11cfa0aa,2d5cdecc342ddacd2c090f1838430cee,3cbe71f7649e84cd67cb3fa0d3e632cf,69ffba28a61d98d8d18f91c24b74dd4a,6c66e9414880964ee899ceb0f16d22e9,7ad4ccec4c7bb3702aed71c17dc6b96f,7d074208b1259e7d84f9f870d3828bb6,82932abd152e0b84a1c26a2daa4c08df,8f1d95acff56e1633dceb775fa713174,9a27580975988e83f6e3a0d9010893b5,a828fd17fc38e902484872c88a6b242c,dd7e7d54883ca0f687568a738b95d4d0,e41cc40f061f487b1ea0f256d4a963e4,f2300d613896880cbb7c255a4d858315</data>
    </edge>
    <edge source="EPSILON" target="X">
      <data key="d4">7.0</data>
      <data key="d5">X is part of the linear model Y = X&#946; + &#1013;
Matrix X is used in the calculation of the error term &#1013; in the regression model
X is used in conjunction with Epsilon to calculate Y in the linear regression model
The design matrix X is used in the model equation along with the error term epsilon (&#1013;)
X, along with Beta and Epsilon, forms the linear regression model equation
X is the matrix of explanatory variables that, along with the errors epsilon (&#1013;), determines the response variable Y
The design matrix X, along with the parameters, is used to model the error term Epsilon (&#1013;) in the linear regression model</data>
      <data key="d6">119bc73ddf8eebadfb8eae272fa323a7,3cbe71f7649e84cd67cb3fa0d3e632cf,75dc4d8cb195a1f969d9e9496631086b,7ad4ccec4c7bb3702aed71c17dc6b96f,aeddef300427d211c74c6008b5b6b328,dd7e7d54883ca0f687568a738b95d4d0,e4f14e6785c6d7b7469e695aaeb170d0</data>
    </edge>
    <edge source="EPSILON" target="BETA">
      <data key="d4">5.0</data>
      <data key="d5">Beta and Epsilon are components of the linear model Y = X&#946; + &#1013;
Beta and Epsilon are used together to calculate Y in the linear regression model
Beta and Epsilon are components of the linear regression model equation, where Beta represents the coefficients and Epsilon represents the error terms
The parameters Beta and the errors Epsilon are components of a linear model
Beta and epsilon (&#1013;) together determine the response variable Y in the linear model</data>
      <data key="d6">01d5ee79489582b4135fc96f676b24a0,119bc73ddf8eebadfb8eae272fa323a7,3cbe71f7649e84cd67cb3fa0d3e632cf,7ad4ccec4c7bb3702aed71c17dc6b96f,dd7e7d54883ca0f687568a738b95d4d0</data>
    </edge>
    <edge source="EPSILON" target="NN">
      <data key="d4">4.0</data>
      <data key="d5">Epsilon is assumed to follow the multivariate normal distribution Nn
Vector &#1013; follows the multivariate normal distribution Nn
EPSILON is related to Nn as it follows a multivariate normal distribution
Nn is the distribution of the error term &#1013;</data>
      <data key="d6">75dc4d8cb195a1f969d9e9496631086b,8f1d95acff56e1633dceb775fa713174,dd7e7d54883ca0f687568a738b95d4d0,e41cc40f061f487b1ea0f256d4a963e4</data>
    </edge>
    <edge source="EPSILON" target="IN">
      <data key="d4">4.0</data>
      <data key="d5">In is part of the variance-covariance matrix of the distribution of Epsilon
The variance-covariance matrix of the error term &#1013; is &#963;^2In
EPSILON is related to In as part of its covariance matrix in the linear regression model
EPSILON is assumed to have a covariance matrix of &#963;^2In</data>
      <data key="d6">75dc4d8cb195a1f969d9e9496631086b,7ad4ccec4c7bb3702aed71c17dc6b96f,8f1d95acff56e1633dceb775fa713174,dd7e7d54883ca0f687568a738b95d4d0</data>
    </edge>
    <edge source="EPSILON" target="EPSILONJ">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon is the column vector containing all Epsilonj values</data>
      <data key="d6">b5d0a103e1f34a00aef67fedd0e8c693</data>
    </edge>
    <edge source="EPSILON" target="VARIANCE_FUNCTION">
      <data key="d4">1.0</data>
      <data key="d5">&#1013;'s variance contributes to the constant variance function of the response Y</data>
      <data key="d6">67e4c1866b0c6e162e6e3317949e8da9</data>
    </edge>
    <edge source="EPSILON" target="YJ">
      <data key="d4">2.0</data>
      <data key="d5">Epsilon is the error term added to the linear combination of Beta and xj to form Yj
Yj includes the error term Epsilon (&#1013;j) for the jth unit of observation</data>
      <data key="d6">6c1684ed2a4840576c6b0f4d1a3a482f,7fc5b8303ab530821bf2140ba6a8a889</data>
    </edge>
    <edge source="EPSILON" target="N">
      <data key="d4">3.0</data>
      <data key="d5">The dimension n is the length of the error term vector epsilon (&#1013;)
The error term Epsilon (&#1013;j) is assumed to follow the normal distribution N(0, &#963;^2)
N is the distribution of the error term EPSILON in the quadratic regression model</data>
      <data key="d6">2d5cdecc342ddacd2c090f1838430cee,6c1684ed2a4840576c6b0f4d1a3a482f,e4f14e6785c6d7b7469e695aaeb170d0</data>
    </edge>
    <edge source="EPSILON" target="YI">
      <data key="d4">1.0</data>
      <data key="d5">Yi includes the error term Epsilon (&#1013;i) for the ith unit of observation in the quadratic regression model</data>
      <data key="d6">6c1684ed2a4840576c6b0f4d1a3a482f</data>
    </edge>
    <edge source="EPSILON" target="DESIGN_MATRIX">
      <data key="d4">1.0</data>
      <data key="d5">The design matrix X, along with the vector of parameters Beta, is used to predict the response vector Y in the linear model. The difference between the predicted values and the actual observed values is captured by the vector of random errors Epsilon.</data>
      <data key="d6">e7494d6cfc3e38a4d2f3f6b21ef6445d</data>
    </edge>
    <edge source="EPSILON" target="INDEPENDENCE">
      <data key="d4">2.0</data>
      <data key="d5">The independence assumption applies to the errors epsilon (&#1013;)
The errors &#1013;1, ..., &#1013;n are assumed to be independent, which is a requirement for the independence assumption</data>
      <data key="d6">0da640a09a395a50b6e16e047fa8d0d6,3cbe71f7649e84cd67cb3fa0d3e632cf</data>
    </edge>
    <edge source="EPSILON" target="HOMOSCEDASTICITY">
      <data key="d4">2.0</data>
      <data key="d5">The homoscedasticity assumption applies to the errors epsilon (&#1013;)
The errors &#1013;1, ..., &#1013;n are assumed to have constant variance, which is a requirement for homoscedasticity</data>
      <data key="d6">0da640a09a395a50b6e16e047fa8d0d6,3cbe71f7649e84cd67cb3fa0d3e632cf</data>
    </edge>
    <edge source="EPSILON" target="NORMALITY">
      <data key="d4">2.0</data>
      <data key="d5">The normality assumption applies to the errors epsilon (&#1013;)
The errors &#1013;1, ..., &#1013;n are assumed to have a normal distribution, which is a requirement for the normality assumption</data>
      <data key="d6">0da640a09a395a50b6e16e047fa8d0d6,3cbe71f7649e84cd67cb3fa0d3e632cf</data>
    </edge>
    <edge source="EPSILON" target="YN">
      <data key="d4">1.0</data>
      <data key="d5">The response variables Y1, ..., Yn are influenced by the errors &#1013;1, ..., &#1013;n in the regression model</data>
      <data key="d6">0da640a09a395a50b6e16e047fa8d0d6</data>
    </edge>
    <edge source="EPSILON" target="HETEROSCEDASTICITY">
      <data key="d4">1.0</data>
      <data key="d5">Heteroscedasticity is a violation of the assumption that the errors &#1013;1, ..., &#1013;n have constant variance</data>
      <data key="d6">0da640a09a395a50b6e16e047fa8d0d6</data>
    </edge>
    <edge source="EPSILON" target="IDENTICALLY_DISTRIBUTED">
      <data key="d4">1.0</data>
      <data key="d5">The errors &#1013;1, ..., &#1013;n are assumed to be identically distributed, although this is not true for the response variables</data>
      <data key="d6">0da640a09a395a50b6e16e047fa8d0d6</data>
    </edge>
    <edge source="EPSILON" target="LOG_BRAIN_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">epsilon (&#1013;) represents the error term in the linear regression model when log(brain weight) is regressed against log(body weight)</data>
      <data key="d6">e2422d8b80004aab4ea74d5209587861</data>
    </edge>
    <edge source="EPSILON" target="S">
      <data key="d4">1.0</data>
      <data key="d5">&#1013;j is the error term for the jth observation, which is part of the simple linear regression model used in the calculation of S(&#946;)</data>
      <data key="d6">50a56c34050fb7f7709300a51399b150</data>
    </edge>
    <edge source="EPSILON" target="ALPHA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon (&#1013;) is the error term in the linear regression model that Alpha hat (&#945;b) accounts for</data>
      <data key="d6">f5716ce115458c0652124734ca344806</data>
    </edge>
    <edge source="EPSILON" target="ALPHA">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon_j is the error term in the model parameterised by Alpha</data>
      <data key="d6">5609007c6229060ffc85d8056a7fefde</data>
    </edge>
    <edge source="EPSILON" target="BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon (&#1013;) is the error term in the linear model, which affects the distribution of Beta hat (&#946;b)</data>
      <data key="d6">b70a75a6412b2e5c44af50734844f4be</data>
    </edge>
    <edge source="EPSILON" target="DI">
      <data key="d4">1.0</data>
      <data key="d5">epsilon (&#1013;) is part of the error term that contributes to the calculation of the Cook's distance Di</data>
      <data key="d6">98d6982108f2d42fe0437bff8c666e17</data>
    </edge>
    <edge source="EPSILON" target="BRAND_A">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon (&#1013;j) is the error term for the jth store when it is of Brand A</data>
      <data key="d6">1d141ab04db553f78a313e430e54abb5</data>
    </edge>
    <edge source="EPSILON" target="BRAND_B">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon (&#1013;j) is the error term for the jth store when it is of Brand B</data>
      <data key="d6">1d141ab04db553f78a313e430e54abb5</data>
    </edge>
    <edge source="EPSILON" target="BRAND_C">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon (&#1013;j) is the error term for the jth store when it is of Brand C</data>
      <data key="d6">1d141ab04db553f78a313e430e54abb5</data>
    </edge>
    <edge source="EPSILON" target="SALES_VOLUME">
      <data key="d4">2.0</data>
      <data key="d5">Epsilon represents the deviation of the observed sales volume from the expected sales volume for each store
Epsilon is the error term in the regression model, accounting for unexplained variation in sales volume</data>
      <data key="d6">06199787dd7f75f7338dd24d4f3dc26e,b6870535f3975c49d45e62fbe475f198</data>
    </edge>
    <edge source="EPSILON" target="RETAIL_DATA">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon is the error term in the regression models, representing the unexplained variation in sales in the retail data</data>
      <data key="d6">ac15b639b0849006471dfe102376c2c0</data>
    </edge>
    <edge source="EPSILON" target="PARALLEL_LINES_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon is the error term in the parallel lines model</data>
      <data key="d6">0cb40986e6c2bb439e1ffcaae2df96ac</data>
    </edge>
    <edge source="RANDOM_ERROR" target="MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The model includes a random error component that represents the variability not explained by the systematic component</data>
      <data key="d6">bb31f1c77bbba73300f735a100086a67</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="Y">
      <data key="d4">4.0</data>
      <data key="d5">The variance of Y is equal to &#963;^2, which is the variance of the error term &#1013;
Sigma squared (&#963;^2) is part of the covariance matrix of the vector Y
Y has a variance of &#963;^2 due to the error term
The variance of the response vector Y is determined by &#963;^2</data>
      <data key="d6">7ad4ccec4c7bb3702aed71c17dc6b96f,9005147593b2f27b9e2a5eede3601bdc,9a27580975988e83f6e3a0d9010893b5,e41cc40f061f487b1ea0f256d4a963e4</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="N">
      <data key="d4">2.0</data>
      <data key="d5">Sigma squared (&#963;^2) is the variance of the distribution N
Sigma squared (&#963;^2) is the variance parameter in the normal distribution N</data>
      <data key="d6">87b717ba065d6d7c7431af284137eb12,b5d0a103e1f34a00aef67fedd0e8c693</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="VARIANCE_FUNCTION">
      <data key="d4">1.0</data>
      <data key="d5">&#963;^2 is the constant variance of the response Y given the values of the explanatory variables</data>
      <data key="d6">67e4c1866b0c6e162e6e3317949e8da9</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="X">
      <data key="d4">1.0</data>
      <data key="d5">The design matrix X is used in the covariance matrix of the linear regression model, which includes sigma squared (&#963;^2)</data>
      <data key="d6">e4f14e6785c6d7b7469e695aaeb170d0</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="E">
      <data key="d4">1.0</data>
      <data key="d5">&#963;^2 is the variance of the normal distribution of log(Y), which is used to calculate the expected value of Y</data>
      <data key="d6">34fceaaf7d835828b5ee2327325c37f8</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="MLE">
      <data key="d4">1.0</data>
      <data key="d5">&#963;^2 is the variance of the error term in the linear regression model, for which the MLE is derived</data>
      <data key="d6">d738df7d83784c8a41b3948271c537b6</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="LOG_LIKELIHOOD">
      <data key="d4">2.0</data>
      <data key="d5">The log-likelihood function depends on Sigma squared (&#963;^2), the variance of the error term
Sigma squared (&#963;^2) is a parameter in the log-likelihood function, which is maximised for a given value of &#963;^2 by the vector &#946; that minimises the residual sum of squares function S(&#946;).</data>
      <data key="d6">87b717ba065d6d7c7431af284137eb12,ad799500572246a07f983a3b92c0e61f</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="L">
      <data key="d4">2.0</data>
      <data key="d5">Sigma squared (&#963;^2) is part of the likelihood function L
Sigma squared (&#963;^2) is a parameter in the likelihood function L(&#946;, &#963;^2|y)</data>
      <data key="d6">e7edd8b2874a350779ae20f1ecdf4733,f632f01188d2c6e3091a965580cb4600</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="BETA_HAT">
      <data key="d4">7.0</data>
      <data key="d5">&#963;^2 is a parameter in the model that influences the calculation of &#946;b through the MLE
Sigma squared (&#963;^2) is the variance of the error term, which influences the distribution of Beta hat (&#946;b)
Sigma squared (&#963;^2) is part of the covariance matrix of the distribution of Beta hat (&#946;b)
Sigma squared (&#963;^2) is part of the covariance matrix of the distribution of Beta hat (&#946;b)
Sigma squared (&#963;^2) is part of the covariance matrix of the distribution of Beta hat (&#946;b)
Sigma squared (&#963;^2) is part of the covariance matrix of the distribution of Beta hat (&#946;b)
Sigma squared (&#963;^2) is part of the covariance matrix of the distribution of Beta hat (&#946;b)</data>
      <data key="d6">2de7a36b32bf79c8f32612c8aaa9daa8,3d357cfa3ef0d00f49cf4acaeac1c9d1,45f31b040576e9f3b4def6d0466cc016,542f546c5a131196e4701fb33c9b1dee,9dddcd96af7b557e578b3f5f36efacd7,b70a75a6412b2e5c44af50734844f4be,d14413709de2897231aaa83be3aa346f</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="VARIANCE_BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">SIGMA_SQUARED (&#963;^2) is part of the variance of the least squares estimator BETA_HAT</data>
      <data key="d6">69ffba28a61d98d8d18f91c24b74dd4a</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="SIGMA_SQUARED_MLE">
      <data key="d4">1.0</data>
      <data key="d5">Sigma squared (&#963;^2) is the true error variance that Sigma squared MLE (&#963;b^2_MLE) estimates</data>
      <data key="d6">09caa54ca1372d152e47051be4d44ede</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="Z">
      <data key="d4">1.0</data>
      <data key="d5">Z is used in estimating the variance, which is related to the error variance (&#963;^2)</data>
      <data key="d6">09caa54ca1372d152e47051be4d44ede</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="S_HAT_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">&#963;^2 is the true variance that s^2(Y) estimates in the linear regression model</data>
      <data key="d6">6648f0d6deed51fb4fb25e6992a71ddf</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="S2">
      <data key="d4">2.0</data>
      <data key="d5">S squared (s^2) is an unbiased estimator for the error variance (&#963;^2)
Sigma squared (&#963;^2) is the variance that the unbiased estimate s^2 aims to estimate</data>
      <data key="d6">9923e77ac6b3de95cb5026bc5e7fe8c0,fc5b725f3c662c5471af20efdcc2dbff</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="SIGMA_HAT_SQUARED_MLE">
      <data key="d4">2.0</data>
      <data key="d5">The MLE estimate for &#963;^2 is an estimate of the true variance of the error term
Sigma squared (&#963;^2) is the true variance that Sigma hat squared (&#963;b^2) MLE estimates, but the estimate is biased</data>
      <data key="d6">2673d078d29f2af78fab9b6eacd15e37,45f31b040576e9f3b4def6d0466cc016</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="S_SQUARED">
      <data key="d4">2.0</data>
      <data key="d5">The unbiased estimate s^2 is an unbiased estimate of the true variance of the error term
Sigma squared (&#963;^2) is the true variance that S squared (s^2) estimates, and the estimate is unbiased</data>
      <data key="d6">2673d078d29f2af78fab9b6eacd15e37,45f31b040576e9f3b4def6d0466cc016</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="YC">
      <data key="d4">4.0</data>
      <data key="d5">Sigma squared (&#963;^2) is part of the covariance matrix of the distribution of Yc
Sigma squared (&#963;^2) is part of the variance of Yc
Sigma squared (&#963;^2) is part of the covariance matrix of Yc
&#963;^2 is part of the variance of Yc</data>
      <data key="d6">1da117a2f92b2db00290d2a0bfc06beb,679722cf8ce5ce5aee4e379528470efe,74d190f10bf6e6936242ca3cdfc4a09f,7d074208b1259e7d84f9f870d3828bb6</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="EB">
      <data key="d4">3.0</data>
      <data key="d5">The variance of Eb is influenced by Sigma squared (&#963;^2)
Sigma squared (&#963;^2) is part of the covariance matrix of EB
&#963;^2 is part of the variance of Eb</data>
      <data key="d6">5a0d392715f06d5e873f45ae06aa729a,74d190f10bf6e6936242ca3cdfc4a09f,7d074208b1259e7d84f9f870d3828bb6</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="S">
      <data key="d4">2.0</data>
      <data key="d5">Sigma squared (&#963;^2) is estimated by s^2, the unbiased estimate of the error variance
s is an estimate of &#963;^2, the error variance in the regression model</data>
      <data key="d6">90b7e0427699cc1bb461e37939935138,c47968226557bc2eb5aec5bb7994fd0e</data>
    </edge>
    <edge source="SIGMA_SQUARED" target="DI">
      <data key="d4">1.0</data>
      <data key="d5">Di is indirectly related to Sigma squared (&#963;^2), the true error variance</data>
      <data key="d6">0443ab5e20a4f6b2f243c989ef6c723a</data>
    </edge>
    <edge source="LM_FUNCTION" target="SLR_DIAMOND">
      <data key="d4">1.0</data>
      <data key="d5">lm() is used to fit the SLR.diamond model</data>
      <data key="d6">b99ecc2f79f56198a8c2adbdff95d576</data>
    </edge>
    <edge source="LM_FUNCTION" target="BRAND_MODEL4">
      <data key="d4">1.0</data>
      <data key="d5">brand.model4 is created by the lm() function in R</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="SUMMARY_FUNCTION" target="SLR_DIAMOND">
      <data key="d4">1.0</data>
      <data key="d5">summary() is used to provide a summary of the SLR.diamond model</data>
      <data key="d6">b99ecc2f79f56198a8c2adbdff95d576</data>
    </edge>
    <edge source="USINGR_PACKAGE" target="DIAMOND_DATASET">
      <data key="d4">1.0</data>
      <data key="d5">The UsingR package contains the diamond dataset</data>
      <data key="d6">b99ecc2f79f56198a8c2adbdff95d576</data>
    </edge>
    <edge source="DIAMOND_DATASET" target="SLR_DIAMOND2">
      <data key="d4">1.0</data>
      <data key="d5">The diamond dataset is used to fit the linear model slr_diamond2</data>
      <data key="d6">f18bacb0a2fbfea44dd6326224184216</data>
    </edge>
    <edge source="DIAMOND_DATASET" target="SIMPLE_LINEAR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The diamond dataset is suitable for exploratory analysis and modeling, including the application of simple linear models</data>
      <data key="d6">b8ec334f8c87bf1d9cb6043fa1a64214</data>
    </edge>
    <edge source="USINGR" target="INSTALL.PACKAGES">
      <data key="d4">1.0</data>
      <data key="d5">The UsingR package is installed using the install.packages function</data>
      <data key="d6">2b01334fb633566ba368a764ad579fce</data>
    </edge>
    <edge source="USINGR" target="LIBRARY">
      <data key="d4">1.0</data>
      <data key="d5">The UsingR package is loaded into the R session using the library function</data>
      <data key="d6">2b01334fb633566ba368a764ad579fce</data>
    </edge>
    <edge source="SLR.DIAMOND" target="LM">
      <data key="d4">1.0</data>
      <data key="d5">The SLR.diamond model is created by fitting the price of diamonds as a function of their carat weight using the lm function</data>
      <data key="d6">2b01334fb633566ba368a764ad579fce</data>
    </edge>
    <edge source="SLR.DIAMOND" target="DIAMOND">
      <data key="d4">1.0</data>
      <data key="d5">The diamond dataset is used as the data source for the SLR.diamond model</data>
      <data key="d6">2b01334fb633566ba368a764ad579fce</data>
    </edge>
    <edge source="SLR.DIAMOND" target="SUMMARY">
      <data key="d4">1.0</data>
      <data key="d5">The summary function is used to provide a statistical summary of the SLR.diamond model</data>
      <data key="d6">2b01334fb633566ba368a764ad579fce</data>
    </edge>
    <edge source="LM" target="DIAMOND">
      <data key="d4">1.0</data>
      <data key="d5">lm() is used to fit a linear model to the diamond dataset</data>
      <data key="d6">35e06960dba699ce0d56fc1e98bdbe96</data>
    </edge>
    <edge source="LM" target="I">
      <data key="d4">1.0</data>
      <data key="d5">I() is used in the formula argument of lm() to evaluate the expression before using it as an explanatory variable</data>
      <data key="d6">35e06960dba699ce0d56fc1e98bdbe96</data>
    </edge>
    <edge source="LM" target="MODEL">
      <data key="d4">1.0</data>
      <data key="d5">lm() function is used to create the model</data>
      <data key="d6">c48bd062d5f6cc20c5df5758d6285562</data>
    </edge>
    <edge source="LM" target="PLR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">lm() is the function in R used to fit the quadratic regression model plr.model</data>
      <data key="d6">084dadebfca8bcb6377c205c45bee295</data>
    </edge>
    <edge source="LM" target="TREE_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">lm function is used to create the tree.model</data>
      <data key="d6">25fce1af816975003128126b5cfea73b</data>
    </edge>
    <edge source="DIAMOND" target="SOLITAIRE_RING">
      <data key="d4">3.0</data>
      <data key="d5">A Solitaire ring contains a single diamond as its main stone
A diamond is a component of a Solitaire ring, which is used for comparison in the text
Diamonds are the main component of Solitaire rings</data>
      <data key="d6">c5b269ff5c94db7ebd2cb9f7be16f171,e1ad57124a08c0e123deda212ea03c32,f18bacb0a2fbfea44dd6326224184216</data>
    </edge>
    <edge source="DIAMOND" target="INTERCEPT">
      <data key="d4">1.0</data>
      <data key="d5">Diamond weight is a factor in determining the intercept, which represents the predicted price of a Solitaire ring with a diamond of average weight</data>
      <data key="d6">f8a3c7ad2423fe8e91b33ca812ddfeff</data>
    </edge>
    <edge source="RESIDUAL_STANDARD_ERROR" target="MULTIPLE_R_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">Residual standard error is related to Multiple R-squared as both are measures of model fit, with R-squared indicating the proportion of variance explained by the model</data>
      <data key="d6">9fc9b618723695c0c593043162a4084b</data>
    </edge>
    <edge source="RESIDUAL_STANDARD_ERROR" target="ADJUSTED_R_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">Residual standard error is related to Adjusted R-squared as both are measures of model fit, with Adjusted R-squared adjusting for the number of predictors</data>
      <data key="d6">9fc9b618723695c0c593043162a4084b</data>
    </edge>
    <edge source="RESIDUAL_STANDARD_ERROR" target="F_STATISTIC">
      <data key="d4">1.0</data>
      <data key="d5">Residual standard error is related to F-statistic as both are used to assess the significance of the model</data>
      <data key="d6">9fc9b618723695c0c593043162a4084b</data>
    </edge>
    <edge source="RESIDUAL_STANDARD_ERROR" target="P_VALUE">
      <data key="d4">1.0</data>
      <data key="d5">Residual standard error is related to P-value as both are used to assess the significance of the model</data>
      <data key="d6">9fc9b618723695c0c593043162a4084b</data>
    </edge>
    <edge source="MULTIPLE_R_SQUARED" target="ADJUSTED_R_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">Multiple R-squared is related to Adjusted R-squared as Adjusted R-squared adjusts for the number of predictors in the model</data>
      <data key="d6">9fc9b618723695c0c593043162a4084b</data>
    </edge>
    <edge source="MULTIPLE_R_SQUARED" target="F_STATISTIC">
      <data key="d4">1.0</data>
      <data key="d5">Multiple R-squared is related to F-statistic as both are used to assess the significance of the model</data>
      <data key="d6">9fc9b618723695c0c593043162a4084b</data>
    </edge>
    <edge source="MULTIPLE_R_SQUARED" target="P_VALUE">
      <data key="d4">1.0</data>
      <data key="d5">Multiple R-squared is related to P-value as both are used to assess the significance of the model</data>
      <data key="d6">9fc9b618723695c0c593043162a4084b</data>
    </edge>
    <edge source="ADJUSTED_R_SQUARED" target="F_STATISTIC">
      <data key="d4">1.0</data>
      <data key="d5">Adjusted R-squared is related to F-statistic as both are used to assess the significance of the model</data>
      <data key="d6">9fc9b618723695c0c593043162a4084b</data>
    </edge>
    <edge source="ADJUSTED_R_SQUARED" target="P_VALUE">
      <data key="d4">1.0</data>
      <data key="d5">Adjusted R-squared is related to P-value as both are used to assess the significance of the model</data>
      <data key="d6">9fc9b618723695c0c593043162a4084b</data>
    </edge>
    <edge source="F_STATISTIC" target="P_VALUE">
      <data key="d4">1.0</data>
      <data key="d5">F-statistic is related to P-value as the P-value is calculated based on the F-statistic to determine the significance of the model</data>
      <data key="d6">9fc9b618723695c0c593043162a4084b</data>
    </edge>
    <edge source="ESTIMATE" target="INTERCEPT">
      <data key="d4">1.0</data>
      <data key="d5">Estimate is related to Intercept as the Estimate column lists the intercept of the line of best fit</data>
      <data key="d6">9fc9b618723695c0c593043162a4084b</data>
    </edge>
    <edge source="ESTIMATE" target="SLOPE">
      <data key="d4">1.0</data>
      <data key="d5">Estimate is related to Slope as the Estimate column lists the slope of the line of best fit</data>
      <data key="d6">9fc9b618723695c0c593043162a4084b</data>
    </edge>
    <edge source="INTERCEPT" target="SOLITAIRE_RING_PRICE">
      <data key="d4">1.0</data>
      <data key="d5">Intercept is related to Solitaire Ring Price as it represents the expected average price of a Solitaire ring with a diamond of zero weight</data>
      <data key="d6">9fc9b618723695c0c593043162a4084b</data>
    </edge>
    <edge source="INTERCEPT" target="SOLITAIRE_RING">
      <data key="d4">2.0</data>
      <data key="d5">The intercept in the linear regression model represents the expected price of a Solitaire ring when the diamond weight is zero. This relationship is naive and may not make practical sense in real-world scenarios.
Solitaire ring is the product whose price is estimated by the intercept in the regression model</data>
      <data key="d6">f0e0c5b2deaaf9fc2bc8b63d9ab989b1,f8a3c7ad2423fe8e91b33ca812ddfeff</data>
    </edge>
    <edge source="INTERCEPT" target="NEGATIVE_AVERAGE_PRICE">
      <data key="d4">1.0</data>
      <data key="d5">A negative average price is a nonsensical concept that may arise from the interpretation of the intercept in the model</data>
      <data key="d6">e1ad57124a08c0e123deda212ea03c32</data>
    </edge>
    <edge source="INTERCEPT" target="SLR_DIAMOND2">
      <data key="d4">1.0</data>
      <data key="d5">The intercept parameter is estimated in the slr.diamond2 model</data>
      <data key="d6">35e06960dba699ce0d56fc1e98bdbe96</data>
    </edge>
    <edge source="INTERCEPT" target="AVERAGE_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">Average weight is the specific carat weight (0.204 carats) used in the interpretation of the intercept</data>
      <data key="d6">f8a3c7ad2423fe8e91b33ca812ddfeff</data>
    </edge>
    <edge source="INTERCEPT" target="SAMPLE_MEAN_PRICE">
      <data key="d4">1.0</data>
      <data key="d5">Sample mean price is equal to the estimated intercept, indicating the average price of Solitaire rings in the dataset</data>
      <data key="d6">f8a3c7ad2423fe8e91b33ca812ddfeff</data>
    </edge>
    <edge source="INTERCEPT" target="SLR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The intercept is a parameter in the simple linear regression model</data>
      <data key="d6">2e5e1bdaa9fcc7b3391d277fd6bb247a</data>
    </edge>
    <edge source="INTERCEPT" target="TREE_MODEL">
      <data key="d4">2.0</data>
      <data key="d5">Intercept is a parameter in the tree.model
The intercept is a parameter in Tree.model, representing the expected value of the Height when all predictor variables are zero.</data>
      <data key="d6">25fce1af816975003128126b5cfea73b,c619949b08fc2b7edf3a7635b46dc147</data>
    </edge>
    <edge source="INTERCEPT" target="TREES_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The intercept is one of the parameters estimated by the trees.model</data>
      <data key="d6">a60af43e42c72a41fa90da06beb29d1b</data>
    </edge>
    <edge source="INTERCEPT" target="PARALLEL_LINES_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Intercept is a parameter in the parallel lines model</data>
      <data key="d6">0cb40986e6c2bb439e1ffcaae2df96ac</data>
    </edge>
    <edge source="SLOPE" target="SOLITAIRE_RING_PRICE">
      <data key="d4">1.0</data>
      <data key="d5">Slope is related to Solitaire Ring Price as it indicates the average price increase for every additional carat of weight</data>
      <data key="d6">9fc9b618723695c0c593043162a4084b</data>
    </edge>
    <edge source="SLOPE" target="SOLITAIRE_RING">
      <data key="d4">1.0</data>
      <data key="d5">The slope in the linear regression model represents the change in the price of a Solitaire ring for every additional carat of diamond weight. This relationship is used to estimate the price increase for additional diamond weight.</data>
      <data key="d6">f0e0c5b2deaaf9fc2bc8b63d9ab989b1</data>
    </edge>
    <edge source="SLOPE" target="ROUNDING">
      <data key="d4">1.0</data>
      <data key="d5">The process of rounding the slope coefficient in a regression model involves adjusting the numerical value to a more sensible representation in the given context. This relationship is important for practical interpretation of the model.</data>
      <data key="d6">f0e0c5b2deaaf9fc2bc8b63d9ab989b1</data>
    </edge>
    <edge source="SLOPE" target="SLR_DIAMOND2">
      <data key="d4">1.0</data>
      <data key="d5">The slope parameter is estimated in the slr.diamond2 model</data>
      <data key="d6">35e06960dba699ce0d56fc1e98bdbe96</data>
    </edge>
    <edge source="SOLITAIRE_RING" target="SAMPLE_MEAN_PRICE">
      <data key="d4">1.0</data>
      <data key="d5">The sample mean price of Solitaire rings is a statistical measure that is equal to the estimated intercept of the regression line</data>
      <data key="d6">c5b269ff5c94db7ebd2cb9f7be16f171</data>
    </edge>
    <edge source="ROUNDING" target="REGRESSION_LINE">
      <data key="d4">1.0</data>
      <data key="d5">Rounding can affect the accuracy of the fitted regression line, but the line still provides a good description of the relationship between the explanatory and response variables</data>
      <data key="d6">ef24ca5edd06893b737e6a1c8a9825f6</data>
    </edge>
    <edge source="SLOPE_COEFFICIENT" target="LOG2">
      <data key="d4">1.0</data>
      <data key="d5">The log2 transformation of the predictor variable (Dbh) affects the interpretation of the slope coefficient in Tree.model. A doubling of the diameter of a Western red cedar tree is associated with an increase in its height of around 83 decimeters on average.</data>
      <data key="d6">c619949b08fc2b7edf3a7635b46dc147</data>
    </edge>
    <edge source="SLOPE_COEFFICIENT" target="TREE_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The slope coefficient is a parameter in Tree.model, representing the change in Height for a one-unit increase in the log2-transformed Dbh.</data>
      <data key="d6">c619949b08fc2b7edf3a7635b46dc147</data>
    </edge>
    <edge source="ALPHA_0" target="MODEL_EQUATION">
      <data key="d4">1.0</data>
      <data key="d5">Alpha_0 is the intercept in the model equation (1.2)</data>
      <data key="d6">f18bacb0a2fbfea44dd6326224184216</data>
    </edge>
    <edge source="ALPHA_0" target="Y">
      <data key="d4">1.0</data>
      <data key="d5">Alpha_0 (&#945;0) is the intercept parameter that determines the starting point of the straight line model</data>
      <data key="d6">f2300d613896880cbb7c255a4d858315</data>
    </edge>
    <edge source="ALPHA_0" target="ALPHA_HAT_0">
      <data key="d4">1.0</data>
      <data key="d5">Alpha_0 is the true parameter that Alpha_hat_0 estimates in the reparameterised model</data>
      <data key="d6">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </edge>
    <edge source="ALPHA_1" target="MODEL_EQUATION">
      <data key="d4">1.0</data>
      <data key="d5">Alpha_1 is the coefficient for the predictor variable (weight - avg_weight) in the model equation (1.2)</data>
      <data key="d6">f18bacb0a2fbfea44dd6326224184216</data>
    </edge>
    <edge source="ALPHA_1" target="Y">
      <data key="d4">1.0</data>
      <data key="d5">Alpha_1 (&#945;1) is the slope parameter that determines the rate of change of Y with respect to X in the straight line model</data>
      <data key="d6">f2300d613896880cbb7c255a4d858315</data>
    </edge>
    <edge source="ALPHA_1" target="SXX">
      <data key="d4">1.0</data>
      <data key="d5">Sxx is used in the calculation of Alpha_1 (&#945;1) in the straight line model</data>
      <data key="d6">f2300d613896880cbb7c255a4d858315</data>
    </edge>
    <edge source="ALPHA_1" target="SXY">
      <data key="d4">1.0</data>
      <data key="d5">Sxy is used in the calculation of Alpha_1 (&#945;1) in the straight line model</data>
      <data key="d6">f2300d613896880cbb7c255a4d858315</data>
    </edge>
    <edge source="ALPHA_1" target="X_BAR">
      <data key="d4">1.0</data>
      <data key="d5">Bar X (x&#175;) is used in the calculation of Alpha_1 (&#945;1) in the straight line model</data>
      <data key="d6">f2300d613896880cbb7c255a4d858315</data>
    </edge>
    <edge source="ALPHA_1" target="Y_BAR">
      <data key="d4">1.0</data>
      <data key="d5">Bar Y (y&#175;) is used in the calculation of Alpha_1 (&#945;1) in the straight line model</data>
      <data key="d6">f2300d613896880cbb7c255a4d858315</data>
    </edge>
    <edge source="ALPHA_1" target="ALPHA_HAT_1">
      <data key="d4">1.0</data>
      <data key="d5">Alpha_1 is the true parameter that Alpha_hat_1 estimates in the reparameterised model</data>
      <data key="d6">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </edge>
    <edge source="COEF_FUNCTION" target="BRAND_MODEL4">
      <data key="d4">1.0</data>
      <data key="d5">The coef() function is used to extract coefficients from brand.model4</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="COEF_FUNCTION" target="ROUND_FUNCTION">
      <data key="d4">1.0</data>
      <data key="d5">The round() function is used to round the coefficients extracted by the coef() function</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="SLR_DIAMOND2" target="COEF">
      <data key="d4">1.0</data>
      <data key="d5">coef() is used to extract the coefficients from the slr.diamond2 model</data>
      <data key="d6">35e06960dba699ce0d56fc1e98bdbe96</data>
    </edge>
    <edge source="SLR_DIAMOND2" target="MEAN">
      <data key="d4">1.0</data>
      <data key="d5">mean(carat) is used in the formula of the slr.diamond2 model to center the carat variable</data>
      <data key="d6">35e06960dba699ce0d56fc1e98bdbe96</data>
    </edge>
    <edge source="I" target="N">
      <data key="d4">1.0</data>
      <data key="d5">I ranges from 1 to n, indicating the total number of observations</data>
      <data key="d6">bd05fe6a05f9a13d33c4f1b5a771ada5</data>
    </edge>
    <edge source="COEF" target="MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Model is used as input for the coef() function to extract coefficients</data>
      <data key="d6">c48bd062d5f6cc20c5df5758d6285562</data>
    </edge>
    <edge source="COEF" target="BETA0">
      <data key="d4">1.0</data>
      <data key="d5">coef() function extracts the value of Beta0 (&#946;0)</data>
      <data key="d6">c48bd062d5f6cc20c5df5758d6285562</data>
    </edge>
    <edge source="COEF" target="BETA1">
      <data key="d4">1.0</data>
      <data key="d5">coef() function extracts the value of Beta1 (&#946;1)</data>
      <data key="d6">c48bd062d5f6cc20c5df5758d6285562</data>
    </edge>
    <edge source="COEF" target="BETA2">
      <data key="d4">1.0</data>
      <data key="d5">coef() function extracts the value of Beta2 (&#946;2)</data>
      <data key="d6">c48bd062d5f6cc20c5df5758d6285562</data>
    </edge>
    <edge source="COEF" target="PLR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The coefficients of the quadratic regression model plr.model are extracted using the coef() function</data>
      <data key="d6">084dadebfca8bcb6377c205c45bee295</data>
    </edge>
    <edge source="COEF" target="TREE_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Tree.model is used as input for the coef function to extract the coefficients</data>
      <data key="d6">25fce1af816975003128126b5cfea73b</data>
    </edge>
    <edge source="COEF" target="TREES_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The coef() function is used to extract the coefficients of the trees.model</data>
      <data key="d6">a60af43e42c72a41fa90da06beb29d1b</data>
    </edge>
    <edge source="COEF" target="TREES.MODEL">
      <data key="d4">1.0</data>
      <data key="d5">trees.model is the linear model from which the coefficients are extracted by the coef function</data>
      <data key="d6">9a28a6420fca4405488ca35762f9dc28</data>
    </edge>
    <edge source="COEF" target="BRAND_MODEL3">
      <data key="d4">1.0</data>
      <data key="d5">Brand_model3 is the model from which the coefficients are extracted using the coef() function</data>
      <data key="d6">6a6f85d0a6e46196ab3a901fcc82a720</data>
    </edge>
    <edge source="REGRESSION_LINE" target="ANSCOMBE_QUARTET">
      <data key="d4">1.0</data>
      <data key="d5">Anscombe's Quartet has the same regression line for all four datasets, despite having different scatterplots</data>
      <data key="d6">9f335f1ecb85a1427df926df8bb1e89f</data>
    </edge>
    <edge source="REGRESSION_LINE" target="X">
      <data key="d4">1.0</data>
      <data key="d5">X is one of the variables used to fit the regression line</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="REGRESSION_LINE" target="Y">
      <data key="d4">1.0</data>
      <data key="d5">Y is the variable that is predicted by the regression line</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="REGRESSION_LINE" target="LINEARITY_ASSUMPTION">
      <data key="d4">1.0</data>
      <data key="d5">The linearity assumption is checked by examining the regression line and residual plots to ensure the relationship is linear</data>
      <data key="d6">b9ec8a6c7960cc6196ec94fd976f05b0</data>
    </edge>
    <edge source="REGRESSION_LINE" target="EXPLANATORY_VARIABLE">
      <data key="d4">2.0</data>
      <data key="d5">The explanatory variable is used to predict the response variable in the regression model
Explanatory variable is used in the regression line to explain the variation in the response variable</data>
      <data key="d6">82cfcd5865cffe55e965a50745656e60,ef24ca5edd06893b737e6a1c8a9825f6</data>
    </edge>
    <edge source="REGRESSION_LINE" target="RESPONSE_VARIABLE">
      <data key="d4">2.0</data>
      <data key="d5">The response variable is predicted by the regression line in the model
Response variable is the dependent variable in the regression line, whose variation is explained by the explanatory variable</data>
      <data key="d6">82cfcd5865cffe55e965a50745656e60,ef24ca5edd06893b737e6a1c8a9825f6</data>
    </edge>
    <edge source="REGRESSION_LINE" target="DATA">
      <data key="d4">1.0</data>
      <data key="d5">The regression line is calculated from the data</data>
      <data key="d6">312309b45c59e1c84695ac3c7e202742</data>
    </edge>
    <edge source="REGRESSION_LINE" target="OBSERVATIONS">
      <data key="d4">1.0</data>
      <data key="d5">The regression line is calculated from the observations</data>
      <data key="d6">312309b45c59e1c84695ac3c7e202742</data>
    </edge>
    <edge source="REGRESSION_LINE" target="RESIDUAL_PLOT">
      <data key="d4">2.0</data>
      <data key="d5">The residuals are calculated from the regression line
Residual plot is used to assess the fit of the regression line by examining the residuals</data>
      <data key="d6">312309b45c59e1c84695ac3c7e202742,ef24ca5edd06893b737e6a1c8a9825f6</data>
    </edge>
    <edge source="REGRESSION_LINE" target="PREDICTOR_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">The regression line is calculated from the predictor variable</data>
      <data key="d6">312309b45c59e1c84695ac3c7e202742</data>
    </edge>
    <edge source="REGRESSION_LINE" target="SALES_VOLUME">
      <data key="d4">1.0</data>
      <data key="d5">The regression line is used to visualize the relationship between sales volume and price, and to predict sales volume based on price.</data>
      <data key="d6">7a605c3b689bec7ab2c46df9c123e3f3</data>
    </edge>
    <edge source="REGRESSION_LINE" target="INTERACTION">
      <data key="d4">1.0</data>
      <data key="d5">The non-parallel regression lines for different brands indicate an interaction between brand and price</data>
      <data key="d6">b0ca3e6c22c4cf884d03b1f6f82be5df</data>
    </edge>
    <edge source="REGRESSION_LINES" target="PARAMETERISATION">
      <data key="d4">1.0</data>
      <data key="d5">Regression lines are affected by the choice of parameterisation, which can alter the interpretation of the model</data>
      <data key="d6">9854704301b8df256ca1013b8d53dfac</data>
    </edge>
    <edge source="PARAMETERISATION" target="DIAMONDS_EXAMPLE">
      <data key="d4">1.0</data>
      <data key="d5">Parameterisation is illustrated through the diamonds example, showing how reparameterisation can improve interpretability</data>
      <data key="d6">9854704301b8df256ca1013b8d53dfac</data>
    </edge>
    <edge source="PARAMETERISATION" target="BRAND_C">
      <data key="d4">1.0</data>
      <data key="d5">Changing the reference category of the brand variable to Brand C affects the parameterisation of the model</data>
      <data key="d6">a1fc936df848a0fbc791e4bcc9b527b6</data>
    </edge>
    <edge source="REPARAMETERISATIONS" target="MATERIAL_COVERED">
      <data key="d4">1.0</data>
      <data key="d5">Re-parameterisations are a concept that will be covered in the material of the module, requiring students to develop skills in moving between mathematical descriptions, R implementation, and interpretation in the application context.</data>
      <data key="d6">ccced70c40ef9105ac2f7a9bfd151125</data>
    </edge>
    <edge source="MATERIAL_COVERED" target="SKILLS">
      <data key="d4">1.0</data>
      <data key="d5">The material covered so far exemplifies the skills needed to move confidently between mathematical descriptions, R implementation, and interpretation in the application context.</data>
      <data key="d6">ccced70c40ef9105ac2f7a9bfd151125</data>
    </edge>
    <edge source="SKILLS" target="EXERCISES">
      <data key="d4">1.0</data>
      <data key="d5">The skills required for the module are practiced through the exercises provided, which help students assimilate and practice the material discussed so far.</data>
      <data key="d6">ccced70c40ef9105ac2f7a9bfd151125</data>
    </edge>
    <edge source="EXERCISES" target="EXERCISE_1">
      <data key="d4">1.0</data>
      <data key="d5">Exercise 1 is one of the exercises provided to help students assimilate and practice the material discussed so far.</data>
      <data key="d6">ccced70c40ef9105ac2f7a9bfd151125</data>
    </edge>
    <edge source="EXERCISES" target="EXERCISE_2">
      <data key="d4">1.0</data>
      <data key="d5">Exercise 2 is one of the exercises provided to help students assimilate and practice the material discussed so far.</data>
      <data key="d6">ccced70c40ef9105ac2f7a9bfd151125</data>
    </edge>
    <edge source="EXERCISES" target="EXERCISE_3">
      <data key="d4">1.0</data>
      <data key="d5">Exercise 3 is one of the exercises provided to help students assimilate and practice the material discussed so far, specifically addressing the issue of negative price predictions for Solitaire rings with very small diamonds.</data>
      <data key="d6">ccced70c40ef9105ac2f7a9bfd151125</data>
    </edge>
    <edge source="EXERCISE_3" target="MODEL_1_1">
      <data key="d4">1.0</data>
      <data key="d5">Model (1.1) is compared to a regression through the origin model in Exercise 3 to assess the fit of the models</data>
      <data key="d6">e47d573a10e64a657e58218df64d8920</data>
    </edge>
    <edge source="MODEL_1_1" target="REPARAMETERISATION">
      <data key="d4">1.0</data>
      <data key="d5">Model (1.1) can be reparameterised into model (1.2), leading to the same predictions</data>
      <data key="d6">e47d573a10e64a657e58218df64d8920</data>
    </edge>
    <edge source="REPARAMETERISATION" target="BETA">
      <data key="d4">2.0</data>
      <data key="d5">Reparameterisation can change the interpretation of the parameter Beta in a linear model
Reparameterisation does not change the estimate for Beta, the parameter for price, but improves its interpretability</data>
      <data key="d6">9854704301b8df256ca1013b8d53dfac,9fc2b1e8b2b61b557f88eb9e9c708597</data>
    </edge>
    <edge source="REPARAMETERISATION" target="BRAND_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">Reparameterisation allows for the interpretation of the estimated coefficients for the brand variable without assuming a specific price</data>
      <data key="d6">9854704301b8df256ca1013b8d53dfac</data>
    </edge>
    <edge source="REGRESSION_THROUGH_ORIGIN" target="R_COMMAND">
      <data key="d4">1.0</data>
      <data key="d5">The R command is used to fit the regression through the origin model to the diamond data</data>
      <data key="d6">e47d573a10e64a657e58218df64d8920</data>
    </edge>
    <edge source="Y" target="LINEAR_REGRESSION_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Y is the response variable in the linear regression model, which is the outcome being predicted</data>
      <data key="d6">070499b11a2fc1530fd2751d0920ad31</data>
    </edge>
    <edge source="Y" target="BETA_2">
      <data key="d4">2.0</data>
      <data key="d5">Beta_2 (&#946;2) indicates the average change in Y for a one unit increase in X2, assuming the value of X1 is fixed
BETA_2 is the coefficient of the quadratic term in the quadratic regression model that contributes to the calculation of Y</data>
      <data key="d6">2d5cdecc342ddacd2c090f1838430cee,a828fd17fc38e902484872c88a6b242c</data>
    </edge>
    <edge source="Y" target="X">
      <data key="d4">12.0</data>
      <data key="d5">The mean of Y depends on X through the systematic component &#946;0 + &#946;1xj
Y is the dependent variable in the linear model Y = X&#946; + &#1013;
X is the design matrix that determines the mean of the vector Y
Y is calculated using X as the design matrix in the linear regression model
The design matrix X is used to calculate the response vector Y in the linear regression model
Y is the response vector in the linear model, which is related to the design matrix X through the mean function E(Y) = X&#946;
X and Y are variables in the dataset that are analyzed together in the regression analysis
The response variable Y is influenced by the explanatory variable X in a non-linear fashion, as described by the polynomial regression model
X is the predictor variable vector used in the calculation of Y in the quadratic regression model
Y is the response variable that is related to the explanatory variables X in the linear model
X is the predictor variable that influences the response variable Y in the straight line model
Matrix X and vector Y are related through the model equation, where Y is a function of X and the parameter vector Beta</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0,2d5cdecc342ddacd2c090f1838430cee,3cbe71f7649e84cd67cb3fa0d3e632cf,6c66e9414880964ee899ceb0f16d22e9,7ad4ccec4c7bb3702aed71c17dc6b96f,9005147593b2f27b9e2a5eede3601bdc,9a27580975988e83f6e3a0d9010893b5,c9a01b92d11585f6549f62e8bd78d652,dd7e7d54883ca0f687568a738b95d4d0,e41cc40f061f487b1ea0f256d4a963e4,e4f14e6785c6d7b7469e695aaeb170d0,f2300d613896880cbb7c255a4d858315</data>
    </edge>
    <edge source="Y" target="Y_GIVEN_X">
      <data key="d4">1.0</data>
      <data key="d5">The conditional expectation of Y given X is equal to &#946;0 + &#946;1x, which is the systematic component of the model</data>
      <data key="d6">9a27580975988e83f6e3a0d9010893b5</data>
    </edge>
    <edge source="Y" target="Y_VECTOR">
      <data key="d4">1.0</data>
      <data key="d5">Y is represented as a column vector Y in the matrix formulation of the linear regression model</data>
      <data key="d6">9a27580975988e83f6e3a0d9010893b5</data>
    </edge>
    <edge source="Y" target="X_MATRIX">
      <data key="d4">1.0</data>
      <data key="d5">X is the matrix in the linear regression model that, when multiplied by the parameter vector &#946;, gives the systematic component of Y</data>
      <data key="d6">9a27580975988e83f6e3a0d9010893b5</data>
    </edge>
    <edge source="Y" target="BETA">
      <data key="d4">8.0</data>
      <data key="d5">Beta is the vector of parameters that, when multiplied by X, gives the systematic component of Y
Y is the dependent variable in the linear model Y = X&#946; + &#1013;
Y is related to BETA as part of the linear regression model
Beta is the parameter vector that, when multiplied by X, determines the mean of the vector Y
Y is calculated using Beta as the parameter vector in the linear regression model
Y is the response vector in the linear model, which is related to the parameter vector &#946; through the mean function E(Y) = X&#946;
Y is the response variable that is influenced by the parameters Beta in the linear model
Y is influenced by Beta in the linear model</data>
      <data key="d6">3cbe71f7649e84cd67cb3fa0d3e632cf,7ad4ccec4c7bb3702aed71c17dc6b96f,7d074208b1259e7d84f9f870d3828bb6,8f1d95acff56e1633dceb775fa713174,9005147593b2f27b9e2a5eede3601bdc,9a27580975988e83f6e3a0d9010893b5,dd7e7d54883ca0f687568a738b95d4d0,e41cc40f061f487b1ea0f256d4a963e4</data>
    </edge>
    <edge source="Y" target="EPSILON_VECTOR">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon is the vector of errors that, when added to the systematic component X&#946;, gives the observed values of Y</data>
      <data key="d6">9a27580975988e83f6e3a0d9010893b5</data>
    </edge>
    <edge source="Y" target="YJ">
      <data key="d4">3.0</data>
      <data key="d5">Y is the column vector containing all YJ values
Y is the vector form of the set of equations that includes YjYj is one of the components that make up the vector Y</data>
      <data key="d6">7fc5b8303ab530821bf2140ba6a8a889,b5d0a103e1f34a00aef67fedd0e8c693</data>
    </edge>
    <edge source="Y" target="LINEAR_PREDICTOR">
      <data key="d4">2.0</data>
      <data key="d5">Y is the response variable whose mean is determined by the linear predictor
Y is the response variable that is modeled as a function of the linear predictor</data>
      <data key="d6">67e4c1866b0c6e162e6e3317949e8da9,6a47154bf457c25f22c3cf9f649c5db0</data>
    </edge>
    <edge source="Y" target="VARIANCE_FUNCTION">
      <data key="d4">1.0</data>
      <data key="d5">Y's variance given the values of the explanatory variables is constant and equal to the variance of the error term &#1013;</data>
      <data key="d6">67e4c1866b0c6e162e6e3317949e8da9</data>
    </edge>
    <edge source="Y" target="NN">
      <data key="d4">2.0</data>
      <data key="d5">Y follows a multivariate normal distribution Nn with mean X&#946; and covariance matrix &#963;^2In
Y follows a multivariate normal distribution Nn with mean X&#946; and covariance matrix &#963;^2In</data>
      <data key="d6">67e4c1866b0c6e162e6e3317949e8da9,9005147593b2f27b9e2a5eede3601bdc</data>
    </edge>
    <edge source="Y" target="Y1">
      <data key="d4">1.0</data>
      <data key="d5">Y1 is one of the components of the vector Y</data>
      <data key="d6">9005147593b2f27b9e2a5eede3601bdc</data>
    </edge>
    <edge source="Y" target="YN">
      <data key="d4">1.0</data>
      <data key="d5">Yn is one of the components of the vector Y</data>
      <data key="d6">9005147593b2f27b9e2a5eede3601bdc</data>
    </edge>
    <edge source="Y" target="IN">
      <data key="d4">3.0</data>
      <data key="d5">In is part of the covariance matrix of the vector Y
Y has a covariance matrix of &#963;^2In due to the error term
The covariance matrix of the response vector Y is determined by In</data>
      <data key="d6">7ad4ccec4c7bb3702aed71c17dc6b96f,9005147593b2f27b9e2a5eede3601bdc,e41cc40f061f487b1ea0f256d4a963e4</data>
    </edge>
    <edge source="Y" target="E_Y">
      <data key="d4">2.0</data>
      <data key="d5">E(Y) is the expected value of the response variable Y
E(Y) is the mean function of the response vector Y</data>
      <data key="d6">7fc5b8303ab530821bf2140ba6a8a889,e41cc40f061f487b1ea0f256d4a963e4</data>
    </edge>
    <edge source="Y" target="Y">
      <data key="d4">1.0</data>
      <data key="d5">y are the observed values of the response variable Y</data>
      <data key="d6">7fc5b8303ab530821bf2140ba6a8a889</data>
    </edge>
    <edge source="Y" target="X_BETA">
      <data key="d4">1.0</data>
      <data key="d5">X&#946; is the linear combination of the design matrix X and the parameter vector Beta that contributes to the expected value of Y</data>
      <data key="d6">7fc5b8303ab530821bf2140ba6a8a889</data>
    </edge>
    <edge source="Y" target="N">
      <data key="d4">1.0</data>
      <data key="d5">The dimension n is the length of the vector Y, which is the number of units of observation</data>
      <data key="d6">e4f14e6785c6d7b7469e695aaeb170d0</data>
    </edge>
    <edge source="Y" target="JTH_UNIT_OBSERVATION">
      <data key="d4">1.0</data>
      <data key="d5">The jth unit of observation is associated with the response vector Y</data>
      <data key="d6">e41cc40f061f487b1ea0f256d4a963e4</data>
    </edge>
    <edge source="Y" target="VAR_Y">
      <data key="d4">1.0</data>
      <data key="d5">Var(Y) is the variance-covariance matrix of the response vector Y</data>
      <data key="d6">e41cc40f061f487b1ea0f256d4a963e4</data>
    </edge>
    <edge source="Y" target="PLR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Y is the response variable in the quadratic regression model plr.model</data>
      <data key="d6">084dadebfca8bcb6377c205c45bee295</data>
    </edge>
    <edge source="Y" target="QUADRATIC_CURVE">
      <data key="d4">1.0</data>
      <data key="d5">Quadratic curve represents the relationship between X and Y</data>
      <data key="d6">11452a08471d93959558de2ece9a69af</data>
    </edge>
    <edge source="Y" target="DESIGN_MATRIX">
      <data key="d4">1.0</data>
      <data key="d5">The design matrix X is used in conjunction with the vector of parameters Beta to predict the response vector Y in the linear model. The relationship is given by the equation Y = X Beta + Epsilon.</data>
      <data key="d6">e7494d6cfc3e38a4d2f3f6b21ef6445d</data>
    </edge>
    <edge source="Y" target="LOG_Y">
      <data key="d4">1.0</data>
      <data key="d5">Y is transformed into log(Y) by taking the natural logarithm</data>
      <data key="d6">21e429490eeefe7d9c245058fd48ca68</data>
    </edge>
    <edge source="Y" target="S">
      <data key="d4">6.0</data>
      <data key="d5">Y is the observed value vector used in the calculation of the sum of squared differences function S(&#946;)
Vector y is a key component in the calculation of S(&#946;), representing the observed values
Y is a vector of observed values that is used in the calculation of the function S
Y is a vector of observed values used in the function S(&#946;) to calculate the residuals
Y is a vector of observed values that influences the function S(&#946;) and the least squares estimates
Y is the vector of observed values that the sum of squared differences (S) is calculated with respect to</data>
      <data key="d6">10ac76f99674a01ca0f4a55586dea07e,2167274129d4cfa74a002c4cc39df8a8,255685e281cc5a9edf073c700f425a6b,416494d940a9f505da9853caca26fe63,50a56c34050fb7f7709300a51399b150,eac62cdd5518e1269fed150639331c2c</data>
    </edge>
    <edge source="Y" target="BETA_HAT">
      <data key="d4">21.0</data>
      <data key="d5">Y is the vector of observed values that Beta hat (&#946;b) is calculated from
y is the vector of observed values that Beta hat (&#946;b) is calculated from
Y is the vector of observed values that Beta hat (&#946;b) is calculated from
Y is the vector of observed values that Beta hat (&#946;b) is calculated to fit
Y is the vector of observed values that Beta hat (&#946;b) is calculated from
Y is the vector of observed values that Beta hat (&#946;b) is calculated from
Y is the vector of observed values that Beta hat (b&#946;) is calculated from
Y is the vector of observed values that Beta hat (&#946;b) is calculated from
y is the vector of observed values that Beta hat (&#946;b) is calculated from
Y is the vector of observed values that Beta hat (&#946;b) is calculated from
Y is the vector of observed values that Beta hat (&#946;b) is calculated from
Y is the vector of observed values that &#946;b is calculated from using the MLE
Y is the observed response vector used to calculate the least squares estimate Beta hat (&#946;b)
Y is the vector of observed values that Beta hat (&#946;b) is calculated from
Y is the vector of observed values that Beta hat (&#946;b) is calculated from
Y is the vector of observed values that Beta hat (&#946;b) is calculated from
BETA_HAT (&#946;b) is calculated from the vector of observed values Y
Y is the vector of observed values used to calculate the estimator Beta hat (&#946;b)
Y is the vector of observed values that Beta hat (&#946;b) is calculated from
Y is the vector of observed values that Beta hat (&#946;b) is calculated from
Y is the vector of observed values from which Beta hat (&#946;b) is estimated</data>
      <data key="d6">0ac60299320c55d642b3e38440c25f90,2673d078d29f2af78fab9b6eacd15e37,28cf5ff0c09fa5c0390267bb9aa3ce47,2de7a36b32bf79c8f32612c8aaa9daa8,2f2523c52c6d2869fb19f77b66ce8259,3d357cfa3ef0d00f49cf4acaeac1c9d1,45f31b040576e9f3b4def6d0466cc016,542f546c5a131196e4701fb33c9b1dee,56ff186fc629e1e42f2759fc4b984199,69ffba28a61d98d8d18f91c24b74dd4a,6b55b41598d5264f8dc6b72769748722,7955aae3fd4ca51b9ef8843e13c1f517,82932abd152e0b84a1c26a2daa4c08df,9d300fc83afb3261af61b2ab9721cadc,9dddcd96af7b557e578b3f5f36efacd7,9fc2b1e8b2b61b557f88eb9e9c708597,a4a817bb79d6ae8812c808ca41d47f43,aa195e72eb5285a4bcae9c856af30a87,b70a75a6412b2e5c44af50734844f4be,f9b615b879f72501f338f8983d4cac3d,fc5b725f3c662c5471af20efdcc2dbff</data>
    </edge>
    <edge source="Y" target="S_BETA">
      <data key="d4">1.0</data>
      <data key="d5">Y is a vector used in the expression of S(&#946;)</data>
      <data key="d6">21ec28dfe2b2c18030d541d63e51f45e</data>
    </edge>
    <edge source="Y" target="XTY">
      <data key="d4">1.0</data>
      <data key="d5">Vector Y is multiplied by matrix XT to form vector XTY</data>
      <data key="d6">254a8a17b1be06702934341e3bf41e85</data>
    </edge>
    <edge source="Y" target="ALPHA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Y is the vector of observed values that Alpha hat (&#945;b) is calculated from</data>
      <data key="d6">f5716ce115458c0652124734ca344806</data>
    </edge>
    <edge source="Y" target="GAMMA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Y is the vector of observed values that Gamma hat (&#947;b) is calculated from</data>
      <data key="d6">d94760a5f9f6ea115fcc18024035a627</data>
    </edge>
    <edge source="Y" target="ALPHA">
      <data key="d4">1.0</data>
      <data key="d5">Y_j is the dependent variable in the model parameterised by Alpha</data>
      <data key="d6">5609007c6229060ffc85d8056a7fefde</data>
    </edge>
    <edge source="Y" target="X_ALPHA">
      <data key="d4">1.0</data>
      <data key="d5">Matrix X_alpha and vector Y are related through the reparameterised model equation, where Y is a function of X_alpha and the parameter vector Alpha</data>
      <data key="d6">6c66e9414880964ee899ceb0f16d22e9</data>
    </edge>
    <edge source="Y" target="EPSILON_BJ">
      <data key="d4">1.0</data>
      <data key="d5">Y is the vector of observed values from which the residuals (&#1013;bj) are calculated</data>
      <data key="d6">255685e281cc5a9edf073c700f425a6b</data>
    </edge>
    <edge source="Y" target="L">
      <data key="d4">2.0</data>
      <data key="d5">Y is used in the calculation of the likelihood function L
Y is the observed data used in the likelihood function L(&#946;, &#963;^2|y)</data>
      <data key="d6">e7edd8b2874a350779ae20f1ecdf4733,f632f01188d2c6e3091a965580cb4600</data>
    </edge>
    <edge source="Y" target="SIGMA_SQUARED_MLE">
      <data key="d4">2.0</data>
      <data key="d5">Y is used in the calculation of the maximum likelihood estimate for the error variance SIGMA_SQUARED_MLE
Y is the vector of observed values used in the calculation of Sigma squared MLE (&#963;b^2_MLE)</data>
      <data key="d6">09caa54ca1372d152e47051be4d44ede,69ffba28a61d98d8d18f91c24b74dd4a</data>
    </edge>
    <edge source="Y" target="S_HAT_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">Y is the response vector used in the calculation of the unbiased estimator s^2(Y) for the error variance</data>
      <data key="d6">6648f0d6deed51fb4fb25e6992a71ddf</data>
    </edge>
    <edge source="Y" target="S2">
      <data key="d4">1.0</data>
      <data key="d5">Y is the vector of observed values used in the calculation of the unbiased estimator s^2</data>
      <data key="d6">9923e77ac6b3de95cb5026bc5e7fe8c0</data>
    </edge>
    <edge source="Y" target="YC">
      <data key="d4">3.0</data>
      <data key="d5">Yc is derived from Y by applying the hat matrix H, representing the fitted values
Yc is calculated from Y using the transformation H
Yc is derived from Y by applying the hat matrix H</data>
      <data key="d6">679722cf8ce5ce5aee4e379528470efe,74d190f10bf6e6936242ca3cdfc4a09f,7d074208b1259e7d84f9f870d3828bb6</data>
    </edge>
    <edge source="Y" target="EB">
      <data key="d4">5.0</data>
      <data key="d5">Eb is calculated from Y by applying the transformation (In - H)
The covariance matrix Cov(Eb, Y) is calculated as (In - H)&#963;^2In, showing the relationship between the vector of residuals Eb and the vector of response variables Y
The covariance between EB and Y is not equal to the zero matrixEB is calculated from Y using the transformation (In - H)
EB is derived from Y by applying the matrix (In - H)</data>
      <data key="d6">2685edb9e8031c8ea725c43a40af22a8,5a0d392715f06d5e873f45ae06aa729a,74d190f10bf6e6936242ca3cdfc4a09f,7d074208b1259e7d84f9f870d3828bb6</data>
    </edge>
    <edge source="Y" target="YB">
      <data key="d4">1.0</data>
      <data key="d5">Yb is calculated from the observed response values (Y)</data>
      <data key="d6">6ee02b38ae842fd5eac9a11c4fd6659f</data>
    </edge>
    <edge source="Y" target="SALES">
      <data key="d4">1.0</data>
      <data key="d5">Y is the vector of observed sales values</data>
      <data key="d6">248924760a2bfbc82501fd6b11cfa0aa</data>
    </edge>
    <edge source="Y" target="S_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">Y is the vector of observed values from which S squared (s^2) is estimated</data>
      <data key="d6">0ac60299320c55d642b3e38440c25f90</data>
    </edge>
    <edge source="X" target="LINEAR_REGRESSION_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">X is the explanatory variable in the linear regression model, which is used to explain the variation in Y</data>
      <data key="d6">070499b11a2fc1530fd2751d0920ad31</data>
    </edge>
    <edge source="X" target="BETA">
      <data key="d4">8.0</data>
      <data key="d5">X is the design matrix in the linear model Y = X&#946; + &#1013;
X is related to BETA as part of the linear regression model
X is used in conjunction with Beta to calculate Y in the linear regression model
The design matrix X is multiplied by the parameter vector Beta to calculate the mean function of the response vector Y
X is used to calculate the predicted values in the linear regression model by multiplying it with the parameter vector Beta
Matrix X is used in the calculation of the parameters Beta (&#946;0, &#946;1, ..., &#946;q) using least squares estimation
X is the matrix of explanatory variables that is multiplied by the parameters Beta in the linear model
Beta (&#946;) is one of the parameters that the design matrix X is used to estimate in the linear regression model, specifically for the price predictor</data>
      <data key="d6">119bc73ddf8eebadfb8eae272fa323a7,3cbe71f7649e84cd67cb3fa0d3e632cf,6c1684ed2a4840576c6b0f4d1a3a482f,7ad4ccec4c7bb3702aed71c17dc6b96f,8f1d95acff56e1633dceb775fa713174,aeddef300427d211c74c6008b5b6b328,dd7e7d54883ca0f687568a738b95d4d0,e4f14e6785c6d7b7469e695aaeb170d0</data>
    </edge>
    <edge source="X" target="YJ">
      <data key="d4">2.0</data>
      <data key="d5">X contains the values of the explanatory variables that Yj is dependent on
X is used in the calculation of Yj in the straight line model</data>
      <data key="d6">1303b66694a101878ca530c0b41cf5ef,7fc5b8303ab530821bf2140ba6a8a889</data>
    </edge>
    <edge source="X" target="X_BETA">
      <data key="d4">2.0</data>
      <data key="d5">X is multiplied by Beta to form the product X&#946;
The design matrix X is used to calculate the mean function of the response vector Y, given by X&#946;</data>
      <data key="d6">7fc5b8303ab530821bf2140ba6a8a889,e4f14e6785c6d7b7469e695aaeb170d0</data>
    </edge>
    <edge source="X" target="P">
      <data key="d4">1.0</data>
      <data key="d5">The dimension p is the number of columns in the design matrix X, including the intercept and explanatory variables</data>
      <data key="d6">e4f14e6785c6d7b7469e695aaeb170d0</data>
    </edge>
    <edge source="X" target="NN">
      <data key="d4">1.0</data>
      <data key="d5">The design matrix X is used in the distribution of the response vector Y, which is assumed to be Nn(X&#946;, &#963;^2In)</data>
      <data key="d6">e4f14e6785c6d7b7469e695aaeb170d0</data>
    </edge>
    <edge source="X" target="KTH_EXPLANATORY_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">The kth explanatory variable is a column in the design matrix X</data>
      <data key="d6">e41cc40f061f487b1ea0f256d4a963e4</data>
    </edge>
    <edge source="X" target="PLR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">X is the predictor variable used in the quadratic regression model plr.model</data>
      <data key="d6">084dadebfca8bcb6377c205c45bee295</data>
    </edge>
    <edge source="X" target="QUADRATIC_CURVE">
      <data key="d4">1.0</data>
      <data key="d5">Quadratic curve represents the relationship between X and Y</data>
      <data key="d6">11452a08471d93959558de2ece9a69af</data>
    </edge>
    <edge source="X" target="BETA1">
      <data key="d4">1.0</data>
      <data key="d5">X is the variable whose linear term is represented by Beta1 in the quadratic regression model</data>
      <data key="d6">11452a08471d93959558de2ece9a69af</data>
    </edge>
    <edge source="X" target="BETA2">
      <data key="d4">1.0</data>
      <data key="d5">X is the variable whose quadratic term is represented by Beta2 in the quadratic regression model</data>
      <data key="d6">11452a08471d93959558de2ece9a69af</data>
    </edge>
    <edge source="X" target="EXPECTED_CHANGE">
      <data key="d4">1.0</data>
      <data key="d5">The expected change in the response due to a unit change in the explanatory variable X depends on the current value x of X</data>
      <data key="d6">c9a01b92d11585f6549f62e8bd78d652</data>
    </edge>
    <edge source="X" target="PLOT">
      <data key="d4">1.0</data>
      <data key="d5">A plot is usually helpful when there is only one explanatory variable X, to visualize the relationship between the expected response and X</data>
      <data key="d6">c9a01b92d11585f6549f62e8bd78d652</data>
    </edge>
    <edge source="X" target="QUADRATIC_RELATIONSHIP">
      <data key="d4">1.0</data>
      <data key="d5">The explanatory variable X has a quadratic relationship with the expected response, as described by the systematic component of the fitted model</data>
      <data key="d6">c9a01b92d11585f6549f62e8bd78d652</data>
    </edge>
    <edge source="X" target="SYSTEMATIC_COMPONENT">
      <data key="d4">1.0</data>
      <data key="d5">The systematic component of the fitted model describes the relationship between the response variable and the explanatory variable X</data>
      <data key="d6">c9a01b92d11585f6549f62e8bd78d652</data>
    </edge>
    <edge source="X" target="POLYNOMIAL_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The relationship between the response variable and the explanatory variable X is described by a polynomial model of order 2</data>
      <data key="d6">c9a01b92d11585f6549f62e8bd78d652</data>
    </edge>
    <edge source="X" target="XJ">
      <data key="d4">1.0</data>
      <data key="d5">Matrix X contains the values of the explanatory variable xj for all units of observation</data>
      <data key="d6">6c1684ed2a4840576c6b0f4d1a3a482f</data>
    </edge>
    <edge source="X" target="BETA_HAT">
      <data key="d4">18.0</data>
      <data key="d5">X is the design matrix used to calculate the estimated parameter vector Beta hat (&#946;b)
X is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator
X is the design matrix that influences the calculation of Beta hat (&#946;b) and is assumed to be of full rank
X is the design matrix that, along with Y, is used to calculate Beta hat (&#946;b)
X is the design matrix used in the calculation of Beta hat (&#946;b) and in the function S(&#946;)
X is used in the calculation of Beta hat (b&#946;) through the matrix operations XTX and XTY
x is the vector of predictor variables that Beta hat (&#946;b) is calculated from
X is used in the calculation of Beta hat (&#946;b) as part of the least squares estimate
X is used in the calculation of Beta hat (&#946;b)
X is used in the calculation of the least squares estimate Beta hat (&#946;b)
X is the design matrix used in the calculation of Beta hat (&#946;b)
X is the design matrix used in the calculation of Beta hat (&#946;b) as part of the least squares estimator
X is the design matrix used in the calculation of Beta hat (&#946;b)
X is the design matrix used in the calculation of BETA_HAT (&#946;b)
X is the design matrix used in the calculation of Beta hat (&#946;b)
X is used in the calculation of Beta hat (&#946;b) as part of the least squares and maximum likelihood estimator
Matrix X contains the predictor variables used in the calculation of Beta hat (&#946;b)
X is the design matrix that defines the linear relationship between the independent variables and the estimated coefficient for Beta (&#946;)</data>
      <data key="d6">248924760a2bfbc82501fd6b11cfa0aa,255685e281cc5a9edf073c700f425a6b,2673d078d29f2af78fab9b6eacd15e37,28cf5ff0c09fa5c0390267bb9aa3ce47,2b6d31b6bff4eae3a4809451c4fb9fa6,2de7a36b32bf79c8f32612c8aaa9daa8,2f2523c52c6d2869fb19f77b66ce8259,3d357cfa3ef0d00f49cf4acaeac1c9d1,45f31b040576e9f3b4def6d0466cc016,69ffba28a61d98d8d18f91c24b74dd4a,6b55b41598d5264f8dc6b72769748722,7955aae3fd4ca51b9ef8843e13c1f517,aa195e72eb5285a4bcae9c856af30a87,b70a75a6412b2e5c44af50734844f4be,e7edd8b2874a350779ae20f1ecdf4733,f632f01188d2c6e3091a965580cb4600,f9b615b879f72501f338f8983d4cac3d,fc5b725f3c662c5471af20efdcc2dbff</data>
    </edge>
    <edge source="X" target="YB">
      <data key="d4">3.0</data>
      <data key="d5">X is used to compute the vector of fitted values Yb by multiplying it with Beta hat (&#946;b)
YB is calculated as X&#946;b, where X is the design matrix
X is used in the calculation of the fitted values Yb</data>
      <data key="d6">2b6d31b6bff4eae3a4809451c4fb9fa6,5cc49d301d9cd1f8e20b92ab9d8346b0,82932abd152e0b84a1c26a2daa4c08df</data>
    </edge>
    <edge source="X" target="EPSILON_BJ">
      <data key="d4">2.0</data>
      <data key="d5">Epsilon bj (&#1013;bj) is calculated using X, the design matrix
The design matrix X is used in the calculation of the residuals (&#1013;bj) through the fitted values</data>
      <data key="d6">255685e281cc5a9edf073c700f425a6b,5cc49d301d9cd1f8e20b92ab9d8346b0</data>
    </edge>
    <edge source="X" target="S">
      <data key="d4">6.0</data>
      <data key="d5">X is the predictor variable vector used in the calculation of the sum of squared differences function S(&#946;)
Matrix X is used in the calculation of S(&#946;) as part of the predicted values X&#946;
Matrix X is used in the calculation of the function S, which represents the sum of squared errors
X is a matrix of predictor variables used in the function S(&#946;) to calculate the residuals
X is a vector of predictor variables that influences the function S(&#946;) and the least squares estimates
X is used in the calculation of the sum of squared differences (S) as part of the least squares estimate</data>
      <data key="d6">10ac76f99674a01ca0f4a55586dea07e,2167274129d4cfa74a002c4cc39df8a8,255685e281cc5a9edf073c700f425a6b,416494d940a9f505da9853caca26fe63,50a56c34050fb7f7709300a51399b150,eac62cdd5518e1269fed150639331c2c</data>
    </edge>
    <edge source="X" target="S_BETA">
      <data key="d4">1.0</data>
      <data key="d5">X is a matrix used in the expression of S(&#946;)</data>
      <data key="d6">21ec28dfe2b2c18030d541d63e51f45e</data>
    </edge>
    <edge source="X" target="NORMAL_EQUATIONS">
      <data key="d4">1.0</data>
      <data key="d5">X is the matrix used in the normal equations</data>
      <data key="d6">21ec28dfe2b2c18030d541d63e51f45e</data>
    </edge>
    <edge source="X" target="RANK">
      <data key="d4">1.0</data>
      <data key="d5">The rank of X is equal to p, indicating that X has full column rank</data>
      <data key="d6">9d300fc83afb3261af61b2ab9721cadc</data>
    </edge>
    <edge source="X" target="XT">
      <data key="d4">2.0</data>
      <data key="d5">Matrix X is transposed to form matrix XT
X is used in the calculation of XT, the transpose of X</data>
      <data key="d6">1303b66694a101878ca530c0b41cf5ef,254a8a17b1be06702934341e3bf41e85</data>
    </edge>
    <edge source="X" target="X1">
      <data key="d4">1.0</data>
      <data key="d5">X1 to Xn are the observed values that form the second column of the matrix X</data>
      <data key="d6">56ff186fc629e1e42f2759fc4b984199</data>
    </edge>
    <edge source="X" target="XTX">
      <data key="d4">2.0</data>
      <data key="d5">X is used in the calculation of XTX, which is a key matrix in the least squares estimation
X is used in the calculation of XTX, the matrix product of the transpose of X and X</data>
      <data key="d6">1303b66694a101878ca530c0b41cf5ef,56ff186fc629e1e42f2759fc4b984199</data>
    </edge>
    <edge source="X" target="ALPHA0">
      <data key="d4">1.0</data>
      <data key="d5">X is used in the calculation of Alpha0 in the straight line model</data>
      <data key="d6">1303b66694a101878ca530c0b41cf5ef</data>
    </edge>
    <edge source="X" target="ALPHA1">
      <data key="d4">1.0</data>
      <data key="d5">X is used in the calculation of Alpha1 in the straight line model</data>
      <data key="d6">1303b66694a101878ca530c0b41cf5ef</data>
    </edge>
    <edge source="X" target="X_BAR">
      <data key="d4">1.0</data>
      <data key="d5">X is used in the calculation of X_bar, the mean of the xj values</data>
      <data key="d6">1303b66694a101878ca530c0b41cf5ef</data>
    </edge>
    <edge source="X" target="SXX">
      <data key="d4">1.0</data>
      <data key="d5">X is used in the calculation of Sxx, the variance of the xj values</data>
      <data key="d6">1303b66694a101878ca530c0b41cf5ef</data>
    </edge>
    <edge source="X" target="SXY">
      <data key="d4">1.0</data>
      <data key="d5">X is used in the calculation of Sxy, the covariance between xj and yj values</data>
      <data key="d6">1303b66694a101878ca530c0b41cf5ef</data>
    </edge>
    <edge source="X" target="Y_BAR">
      <data key="d4">1.0</data>
      <data key="d5">X is used in the calculation of Y_bar, the mean of the yj values</data>
      <data key="d6">1303b66694a101878ca530c0b41cf5ef</data>
    </edge>
    <edge source="X" target="XTY">
      <data key="d4">1.0</data>
      <data key="d5">X is used in the calculation of XTY, the matrix product of the transpose of X and Y</data>
      <data key="d6">1303b66694a101878ca530c0b41cf5ef</data>
    </edge>
    <edge source="X" target="ALPHA_HAT">
      <data key="d4">2.0</data>
      <data key="d5">X is used in the calculation of Alpha hat, the least squares estimate for the model parameters
X is the design matrix used in the calculation of Alpha hat (&#945;b) as part of the least squares estimator</data>
      <data key="d6">1303b66694a101878ca530c0b41cf5ef,f5716ce115458c0652124734ca344806</data>
    </edge>
    <edge source="X" target="Z">
      <data key="d4">1.0</data>
      <data key="d5">X is transformed by A^-1 to obtain the design matrix Z in the transformed model</data>
      <data key="d6">d94760a5f9f6ea115fcc18024035a627</data>
    </edge>
    <edge source="X" target="X_ALPHA">
      <data key="d4">1.0</data>
      <data key="d5">Matrix X is transformed to X_alpha using matrix A to obtain the design matrix for the reparameterised model</data>
      <data key="d6">6c66e9414880964ee899ceb0f16d22e9</data>
    </edge>
    <edge source="X" target="SIGMA_SQUARED_MLE">
      <data key="d4">1.0</data>
      <data key="d5">X is the matrix of predictor variables used in the calculation of Sigma squared MLE (&#963;b^2_MLE)</data>
      <data key="d6">09caa54ca1372d152e47051be4d44ede</data>
    </edge>
    <edge source="X" target="S2">
      <data key="d4">1.0</data>
      <data key="d5">X is the matrix of predictor variables used in the calculation of the unbiased estimator s^2</data>
      <data key="d6">9923e77ac6b3de95cb5026bc5e7fe8c0</data>
    </edge>
    <edge source="X" target="H">
      <data key="d4">2.0</data>
      <data key="d5">Matrix H is calculated using matrix X, making it dependent on the design matrix X
H is derived from X by applying the formula X(XTX)^-1XT</data>
      <data key="d6">46629f2efc6c82e81265a131b4bab2ee,7d074208b1259e7d84f9f870d3828bb6</data>
    </edge>
    <edge source="X" target="HX">
      <data key="d4">1.0</data>
      <data key="d5">HX is the result of the matrix operation X(X'X)^-1X', which simplifies to X, indicating that HX = X</data>
      <data key="d6">1da117a2f92b2db00290d2a0bfc06beb</data>
    </edge>
    <edge source="X" target="YC">
      <data key="d4">2.0</data>
      <data key="d5">X is used in the calculation of Yc as X&#946;
Yc is indirectly derived from X through the hat matrix H</data>
      <data key="d6">1da117a2f92b2db00290d2a0bfc06beb,7d074208b1259e7d84f9f870d3828bb6</data>
    </edge>
    <edge source="X" target="EB">
      <data key="d4">2.0</data>
      <data key="d5">Eb is influenced by the design matrix X through the calculation X&#946;
EB is indirectly derived from X through the matrix (In - H)</data>
      <data key="d6">5a0d392715f06d5e873f45ae06aa729a,7d074208b1259e7d84f9f870d3828bb6</data>
    </edge>
    <edge source="X" target="HII">
      <data key="d4">1.0</data>
      <data key="d5">The values of the explanatory variables (X) in the design matrix influence the leverage (hii) of the data points</data>
      <data key="d6">6ee02b38ae842fd5eac9a11c4fd6659f</data>
    </edge>
    <edge source="X" target="SALESJ">
      <data key="d4">1.0</data>
      <data key="d5">X is the design matrix used in the model for Salesj</data>
      <data key="d6">228bdca7843406def245d755e8df49f6</data>
    </edge>
    <edge source="X" target="N">
      <data key="d4">1.0</data>
      <data key="d5">n is the number of rows in the design matrix X</data>
      <data key="d6">228bdca7843406def245d755e8df49f6</data>
    </edge>
    <edge source="X" target="SALES">
      <data key="d4">1.0</data>
      <data key="d5">The Sales vector is modeled as a linear combination of the columns of the design matrix X</data>
      <data key="d6">aeddef300427d211c74c6008b5b6b328</data>
    </edge>
    <edge source="X" target="MU_A">
      <data key="d4">1.0</data>
      <data key="d5">Mu_A (&#181;A) is one of the parameters that the design matrix X is used to estimate in the linear regression model</data>
      <data key="d6">aeddef300427d211c74c6008b5b6b328</data>
    </edge>
    <edge source="X" target="MU_B">
      <data key="d4">1.0</data>
      <data key="d5">Mu_B (&#181;B) is one of the parameters that the design matrix X is used to estimate in the linear regression model</data>
      <data key="d6">aeddef300427d211c74c6008b5b6b328</data>
    </edge>
    <edge source="X" target="MU_C">
      <data key="d4">1.0</data>
      <data key="d5">Mu_C (&#181;C) is one of the parameters that the design matrix X is used to estimate in the linear regression model</data>
      <data key="d6">aeddef300427d211c74c6008b5b6b328</data>
    </edge>
    <edge source="X" target="BRANDA">
      <data key="d4">1.0</data>
      <data key="d5">X includes the dummy variable brandA to represent brand A in the dataset</data>
      <data key="d6">e800735d6b2a244875f5e0d292de1527</data>
    </edge>
    <edge source="X" target="BRANDB">
      <data key="d4">1.0</data>
      <data key="d5">X includes the dummy variable brandB to represent brand B in the dataset</data>
      <data key="d6">e800735d6b2a244875f5e0d292de1527</data>
    </edge>
    <edge source="X" target="BRANDC">
      <data key="d4">1.0</data>
      <data key="d5">X includes the dummy variable brandC to represent brand C in the dataset</data>
      <data key="d6">e800735d6b2a244875f5e0d292de1527</data>
    </edge>
    <edge source="OBSERVATIONS" target="XJ">
      <data key="d4">1.0</data>
      <data key="d5">Xj is the measurement of the explanatory variable X for the jth unit of observation, which is part of the paired observations used in simple linear regression.</data>
      <data key="d6">4683e58cf41e5f5d415a63ddb2fe0cac</data>
    </edge>
    <edge source="OBSERVATIONS" target="YJ">
      <data key="d4">1.0</data>
      <data key="d5">Yj is the measurement of the response variable Y for the jth unit of observation, which is part of the paired observations used in simple linear regression.</data>
      <data key="d6">4683e58cf41e5f5d415a63ddb2fe0cac</data>
    </edge>
    <edge source="OBSERVATIONS" target="DATASET_1">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 1 has a specific number of observations</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="OBSERVATIONS" target="DATASET_2">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 2 has a specific number of observations</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="OBSERVATIONS" target="RESIDUAL_PLOT">
      <data key="d4">3.0</data>
      <data key="d5">The observations are used to calculate the residuals, which are plotted in the residual plot
Observations are used to calculate residuals, which are plotted in a residual plot to assess model fit
The residual plot is created from the observations</data>
      <data key="d6">312309b45c59e1c84695ac3c7e202742,82cfcd5865cffe55e965a50745656e60,b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </edge>
    <edge source="OBSERVATIONS" target="DATA">
      <data key="d4">1.0</data>
      <data key="d5">The data is composed of individual observations</data>
      <data key="d6">312309b45c59e1c84695ac3c7e202742</data>
    </edge>
    <edge source="XJ" target="YJ">
      <data key="d4">3.0</data>
      <data key="d5">xj is one of the explanatory variables that contributes to the value of Yj
Yj is a function of the explanatory variable xj for the jth unit of observation
Xj is the explanatory variable that influences the dependent variable Yj</data>
      <data key="d6">6c1684ed2a4840576c6b0f4d1a3a482f,7fc5b8303ab530821bf2140ba6a8a889,d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </edge>
    <edge source="XJ" target="S_BETA">
      <data key="d4">1.0</data>
      <data key="d5">Xj is used in the calculation of S(&#946;) as part of the sum of squared residuals</data>
      <data key="d6">8f7a05b6d231105a6194eebdb2df372e</data>
    </edge>
    <edge source="XJ" target="BETA_0_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Xj is used in the calculation of Beta_0 hat (b&#946;0) as part of the least squares estimation</data>
      <data key="d6">3fdeeb7593174f5e8a9cff55a7cd92e3</data>
    </edge>
    <edge source="XJ" target="BETA_1_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Xj is used in the calculation of Beta_1 hat (b&#946;1) as part of the least squares estimation</data>
      <data key="d6">3fdeeb7593174f5e8a9cff55a7cd92e3</data>
    </edge>
    <edge source="XJ" target="SXY">
      <data key="d4">2.0</data>
      <data key="d5">Xj is used in the calculation of Sxy, the covariance between X and Y
Xj is used in the calculation of Sxy as part of the covariance between x and y</data>
      <data key="d6">f5716ce115458c0652124734ca344806,f9e7b2eac9f82681301da3d1e2f23328</data>
    </edge>
    <edge source="XJ" target="SXX">
      <data key="d4">1.0</data>
      <data key="d5">Xj is used in the calculation of Sxx, the variance of X</data>
      <data key="d6">f9e7b2eac9f82681301da3d1e2f23328</data>
    </edge>
    <edge source="XJ" target="ALPHA">
      <data key="d4">1.0</data>
      <data key="d5">x_j is the independent variable in the model parameterised by Alpha</data>
      <data key="d6">5609007c6229060ffc85d8056a7fefde</data>
    </edge>
    <edge source="XJ" target="C">
      <data key="d4">1.0</data>
      <data key="d5">C is the constant by which we multiply all observations of the explanatory variable Xj</data>
      <data key="d6">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </edge>
    <edge source="XJ" target="BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Xj is the predictor value that contributes to the calculation of Beta hat (&#946;b) in the simple linear regression model</data>
      <data key="d6">d14413709de2897231aaa83be3aa346f</data>
    </edge>
    <edge source="XJ" target="X_BAR">
      <data key="d4">2.0</data>
      <data key="d5">Xj values are used in the calculation of X_bar, the mean of the x valuesX_bar is the mean of all Xj values, used in the calculation of the variance</data>
      <data key="d6">90b7e0427699cc1bb461e37939935138</data>
    </edge>
    <edge source="YJ" target="X1">
      <data key="d4">1.0</data>
      <data key="d5">Variable X1 is one of the predictors used to explain the response variable Yj</data>
      <data key="d6">75dc4d8cb195a1f969d9e9496631086b</data>
    </edge>
    <edge source="YJ" target="XK">
      <data key="d4">1.0</data>
      <data key="d5">Variable Xk is one of the predictors used to explain the response variable Yj</data>
      <data key="d6">75dc4d8cb195a1f969d9e9496631086b</data>
    </edge>
    <edge source="YJ" target="XJM">
      <data key="d4">2.0</data>
      <data key="d5">Yj is the response variable that is explained by the value of the mth explanatory variable xjm
XJM is one of the explanatory variables used in the calculation of YJ</data>
      <data key="d6">75dc4d8cb195a1f969d9e9496631086b,b5d0a103e1f34a00aef67fedd0e8c693</data>
    </edge>
    <edge source="YJ" target="BETA_M">
      <data key="d4">1.0</data>
      <data key="d5">&#946;m is the coefficient for the mth explanatory variable in the regression equation for Yj</data>
      <data key="d6">75dc4d8cb195a1f969d9e9496631086b</data>
    </edge>
    <edge source="YJ" target="XN">
      <data key="d4">1.0</data>
      <data key="d5">XN is used in the calculation of YJ in the multiple regression model</data>
      <data key="d6">b5d0a103e1f34a00aef67fedd0e8c693</data>
    </edge>
    <edge source="YJ" target="BETA0">
      <data key="d4">2.0</data>
      <data key="d5">Beta0 is the intercept term in the equation for YJ
Yj is modeled as a linear function of Beta0, the intercept parameter</data>
      <data key="d6">87b717ba065d6d7c7431af284137eb12,b5d0a103e1f34a00aef67fedd0e8c693</data>
    </edge>
    <edge source="YJ" target="BETA1">
      <data key="d4">2.0</data>
      <data key="d5">Beta1 is the coefficient of the first explanatory variable in the equation for YJ
Yj is modeled as a linear function of Beta1, one of the slope parameters</data>
      <data key="d6">87b717ba065d6d7c7431af284137eb12,b5d0a103e1f34a00aef67fedd0e8c693</data>
    </edge>
    <edge source="YJ" target="BETAK">
      <data key="d4">2.0</data>
      <data key="d5">Betak is the coefficient of the kth explanatory variable in the equation for YJ
Yj is modeled as a linear function of Beta_k, one of the slope parameters</data>
      <data key="d6">87b717ba065d6d7c7431af284137eb12,b5d0a103e1f34a00aef67fedd0e8c693</data>
    </edge>
    <edge source="YJ" target="EPSILONJ">
      <data key="d4">3.0</data>
      <data key="d5">Epsilonj is the error term for the jth unit of observation in the equation for YJ
Yj is the observed value that includes the error term Epsilon_j
Yj is modeled as a linear function plus an error term Epsilon_j</data>
      <data key="d6">87b717ba065d6d7c7431af284137eb12,b5d0a103e1f34a00aef67fedd0e8c693,d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </edge>
    <edge source="YJ" target="BETA">
      <data key="d4">2.0</data>
      <data key="d5">Beta is the coefficient vector that, when multiplied by the explanatory variables, contributes to the expected value of Yj
Yj is a function of the parameters Beta (&#946;0, &#946;1, ..., &#946;q) in the model equation</data>
      <data key="d6">6c1684ed2a4840576c6b0f4d1a3a482f,7fc5b8303ab530821bf2140ba6a8a889</data>
    </edge>
    <edge source="YJ" target="BETA_2">
      <data key="d4">1.0</data>
      <data key="d5">Yj is calculated using Beta_2 as the coefficient of the second explanatory variable</data>
      <data key="d6">7ad4ccec4c7bb3702aed71c17dc6b96f</data>
    </edge>
    <edge source="YJ" target="BETA_K">
      <data key="d4">1.0</data>
      <data key="d5">Yj is calculated using Beta_k as the coefficient of the kth explanatory variable</data>
      <data key="d6">7ad4ccec4c7bb3702aed71c17dc6b96f</data>
    </edge>
    <edge source="YJ" target="XJ1">
      <data key="d4">2.0</data>
      <data key="d5">Yj is calculated using Xj1 as the value of the first explanatory variable
Yj is modeled as a linear function of Xj1, the first predictor variable</data>
      <data key="d6">7ad4ccec4c7bb3702aed71c17dc6b96f,87b717ba065d6d7c7431af284137eb12</data>
    </edge>
    <edge source="YJ" target="XJ2">
      <data key="d4">2.0</data>
      <data key="d5">Yj is calculated using Xj2 as the value of the second explanatory variable
Yj is modeled as a linear function of Xj2, the second predictor variable</data>
      <data key="d6">7ad4ccec4c7bb3702aed71c17dc6b96f,87b717ba065d6d7c7431af284137eb12</data>
    </edge>
    <edge source="YJ" target="XJK">
      <data key="d4">2.0</data>
      <data key="d5">Yj is calculated using Xjk as the value of the kth explanatory variable
Yj is modeled as a linear function of Xjk, the kth predictor variable</data>
      <data key="d6">7ad4ccec4c7bb3702aed71c17dc6b96f,87b717ba065d6d7c7431af284137eb12</data>
    </edge>
    <edge source="YJ" target="EPSILON_J">
      <data key="d4">1.0</data>
      <data key="d5">Yj includes the error term Epsilon_j</data>
      <data key="d6">7ad4ccec4c7bb3702aed71c17dc6b96f</data>
    </edge>
    <edge source="YJ" target="EPSILON_BJ">
      <data key="d4">2.0</data>
      <data key="d5">Yj is used in the calculation of the jth residual &#1013;bj
Epsilon bj (&#1013;bj) is calculated as the difference between the observed value Yj and the fitted value Ybj, indicating the residual for the jth observation</data>
      <data key="d6">5cc49d301d9cd1f8e20b92ab9d8346b0,e6f79ceb0df54119a4dc71b2162ac50b</data>
    </edge>
    <edge source="YJ" target="YBJ">
      <data key="d4">1.0</data>
      <data key="d5">Yj is the observed value that is compared to the fitted value Ybj to calculate the residual &#1013;bj</data>
      <data key="d6">e6f79ceb0df54119a4dc71b2162ac50b</data>
    </edge>
    <edge source="YJ" target="S_BETA">
      <data key="d4">1.0</data>
      <data key="d5">Yj is used in the calculation of S(&#946;) as part of the sum of squared residuals</data>
      <data key="d6">8f7a05b6d231105a6194eebdb2df372e</data>
    </edge>
    <edge source="YJ" target="BETA_0_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Yj is used in the calculation of Beta_0 hat (b&#946;0) as part of the least squares estimation</data>
      <data key="d6">3fdeeb7593174f5e8a9cff55a7cd92e3</data>
    </edge>
    <edge source="YJ" target="BETA_1_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Yj is used in the calculation of Beta_1 hat (b&#946;1) as part of the least squares estimation</data>
      <data key="d6">3fdeeb7593174f5e8a9cff55a7cd92e3</data>
    </edge>
    <edge source="YJ" target="SXY">
      <data key="d4">2.0</data>
      <data key="d5">Yj is used in the calculation of Sxy, the covariance between X and Y
Yj is used in the calculation of Sxy as part of the covariance between x and y</data>
      <data key="d6">f5716ce115458c0652124734ca344806,f9e7b2eac9f82681301da3d1e2f23328</data>
    </edge>
    <edge source="YJ" target="SXX">
      <data key="d4">1.0</data>
      <data key="d5">Yj is indirectly related to Sxx through its relationship with Xj and Y_bar</data>
      <data key="d6">f9e7b2eac9f82681301da3d1e2f23328</data>
    </edge>
    <edge source="YJ" target="BETA2">
      <data key="d4">1.0</data>
      <data key="d5">Yj is modeled as a linear function of Beta2, one of the slope parameters</data>
      <data key="d6">87b717ba065d6d7c7431af284137eb12</data>
    </edge>
    <edge source="YJ" target="BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Yj is one of the observed values that contribute to the calculation of Beta hat (&#946;b)</data>
      <data key="d6">d14413709de2897231aaa83be3aa346f</data>
    </edge>
    <edge source="VARIABLES" target="DATA">
      <data key="d4">1.0</data>
      <data key="d5">Variables are quantifiable features in the system of interest, and data are the realized values obtained when these variables are measured on specific units of observation.</data>
      <data key="d6">4683e58cf41e5f5d415a63ddb2fe0cac</data>
    </edge>
    <edge source="DATA" target="FEATURES">
      <data key="d4">1.0</data>
      <data key="d5">The data contains the features that are relevant for analysis</data>
      <data key="d6">bb31f1c77bbba73300f735a100086a67</data>
    </edge>
    <edge source="DATA" target="RESIDUAL_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">The residual plot is created from the data</data>
      <data key="d6">312309b45c59e1c84695ac3c7e202742</data>
    </edge>
    <edge source="DATA" target="NORMAL_Q_Q_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">Data are plotted on the normal Q-Q plot, either on the vertical or horizontal axis, to assess their conformity to a normal distribution.</data>
      <data key="d6">eafa2cc6cc64d8bca1c080bdd2ad7654</data>
    </edge>
    <edge source="RANDOM_VARIABLE" target="APPLIED_STATISTICS">
      <data key="d4">1.0</data>
      <data key="d5">The concept of a random variable is important in applied statistics, as it helps to distinguish between the theoretical construct of a variable and the actual values observed in data.</data>
      <data key="d6">4683e58cf41e5f5d415a63ddb2fe0cac</data>
    </edge>
    <edge source="RANDOM_VARIABLE" target="UNITS_OF_OBSERVATION">
      <data key="d4">1.0</data>
      <data key="d5">Units of observation are the basis for defining the outcomes of a random variable in a statistical study</data>
      <data key="d6">7594eee7e77beb023d1cd64aec64920d</data>
    </edge>
    <edge source="RANDOM_VARIABLE" target="REALISATION">
      <data key="d4">1.0</data>
      <data key="d5">Random variable and its realisation are related concepts, where the realisation is the observed value of the random variable</data>
      <data key="d6">7594eee7e77beb023d1cd64aec64920d</data>
    </edge>
    <edge source="APPLIED_STATISTICS" target="THEORY_UNDERNEATH">
      <data key="d4">1.0</data>
      <data key="d5">Applied statistics relies on the theory underneath for its methods and models, although it may use less consistent terminology and notation</data>
      <data key="d6">7594eee7e77beb023d1cd64aec64920d</data>
    </edge>
    <edge source="APPLIED_STATISTICS" target="PRECISION_OF_LANGUAGE_AND_NOTATION">
      <data key="d4">1.0</data>
      <data key="d5">Precision of language and notation is important in applied statistics, especially at the undergraduate level, to maintain clarity and consistency</data>
      <data key="d6">7594eee7e77beb023d1cd64aec64920d</data>
    </edge>
    <edge source="EXPLANATORY_VARIABLES_X" target="DESIGNED_EXPERIMENT">
      <data key="d4">1.0</data>
      <data key="d5">In a designed experiment, the values of the explanatory variables are typically chosen by the experimenter</data>
      <data key="d6">7594eee7e77beb023d1cd64aec64920d</data>
    </edge>
    <edge source="EXPLANATORY_VARIABLES_X" target="OBSERVATIONAL_STUDIES">
      <data key="d4">1.0</data>
      <data key="d5">In observational studies, the values of the explanatory variables are observed along with the response variable</data>
      <data key="d6">7594eee7e77beb023d1cd64aec64920d</data>
    </edge>
    <edge source="EXPLANATORY_VARIABLES_X" target="NONRANDOM_VARIABLES">
      <data key="d4">1.0</data>
      <data key="d5">Explanatory variables X are treated as nonrandom variables in statistical models, meaning their values are considered fixed</data>
      <data key="d6">7594eee7e77beb023d1cd64aec64920d</data>
    </edge>
    <edge source="OBSERVATIONAL_STUDIES" target="DATA_MEASUREMENT">
      <data key="d4">1.0</data>
      <data key="d5">Data in observational studies is measured or observed at the same time as the response variable</data>
      <data key="d6">22478e53f29f16e3eab9d167fea52b22</data>
    </edge>
    <edge source="RESPONSE_VARIABLE" target="EXPLANATORY_VARIABLE">
      <data key="d4">2.0</data>
      <data key="d5">The explanatory variable (x) is used in the model equation to predict the response variable (Y).
The explanatory variable is used to predict or explain the response variable</data>
      <data key="d6">b9af17718641389ba07f53be13f31f8c,b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </edge>
    <edge source="RESPONSE_VARIABLE" target="ERROR_TERM">
      <data key="d4">1.0</data>
      <data key="d5">The response variable (Y) is modeled as a function of the explanatory variable and the parameters of the model, with the error term (&#1013;) representing the difference between the observed values and the values predicted by the model.</data>
      <data key="d6">b9af17718641389ba07f53be13f31f8c</data>
    </edge>
    <edge source="RESPONSE_VARIABLE" target="MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The model aims to predict or explain the response variable</data>
      <data key="d6">bb31f1c77bbba73300f735a100086a67</data>
    </edge>
    <edge source="RESPONSE_VARIABLE" target="PARAMETER_ESTIMATION">
      <data key="d4">1.0</data>
      <data key="d5">The response variable is the target of parameter estimation, which aims to understand its relationship with predictor variables</data>
      <data key="d6">768c516c8b27fb9800427e848f02fc33</data>
    </edge>
    <edge source="RESPONSE_VARIABLE" target="VARIANCE">
      <data key="d4">1.0</data>
      <data key="d5">The variance of the response variable is a measure of its spread or dispersion</data>
      <data key="d6">b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </edge>
    <edge source="RESPONSE_VARIABLE" target="PREDICTOR_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">The response variable is predicted by the predictor variable</data>
      <data key="d6">312309b45c59e1c84695ac3c7e202742</data>
    </edge>
    <edge source="RESPONSE_VARIABLE" target="ERRORS">
      <data key="d4">1.0</data>
      <data key="d5">Errors are the discrepancies between the observed values of the response variable and the values predicted by the model</data>
      <data key="d6">e361ac139c268d5c3f3623f920e68af2</data>
    </edge>
    <edge source="PROBABILITY_THEORY" target="RANDOM_VARIABLES">
      <data key="d4">1.0</data>
      <data key="d5">In probability theory, random variables are denoted by capital letters to distinguish them from their realizations</data>
      <data key="d6">22478e53f29f16e3eab9d167fea52b22</data>
    </edge>
    <edge source="VECTORS" target="SIMPLE_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Vectors are used in simple regression to represent the data points for the response and explanatory variables</data>
      <data key="d6">336546bc73cbe1828a0cc1a45faf8f5a</data>
    </edge>
    <edge source="SIMULATED_DATASET" target="RETAIL_STORES">
      <data key="d4">1.0</data>
      <data key="d5">The simulated dataset consists of data from 96 retail stores</data>
      <data key="d6">22478e53f29f16e3eab9d167fea52b22</data>
    </edge>
    <edge source="RETAIL_STORES" target="PRODUCT_SALES">
      <data key="d4">1.0</data>
      <data key="d5">For each of the 96 retail stores, the data includes information on product sales</data>
      <data key="d6">22478e53f29f16e3eab9d167fea52b22</data>
    </edge>
    <edge source="SIMPLE_REGRESSION" target="MULTIPLE_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Simple regression is a special case of multiple regression, which uses one explanatory variable to predict the response variable</data>
      <data key="d6">22478e53f29f16e3eab9d167fea52b22</data>
    </edge>
    <edge source="SIMPLE_REGRESSION" target="SALES">
      <data key="d4">1.0</data>
      <data key="d5">Sales is the response variable in simple regression, which is analyzed in relation to one explanatory variable</data>
      <data key="d6">336546bc73cbe1828a0cc1a45faf8f5a</data>
    </edge>
    <edge source="MULTIPLE_REGRESSION" target="MATRIX">
      <data key="d4">1.0</data>
      <data key="d5">Matrices are used in multiple regression to organize and manipulate the data, including the response and multiple explanatory variables</data>
      <data key="d6">336546bc73cbe1828a0cc1a45faf8f5a</data>
    </edge>
    <edge source="MULTIPLE_REGRESSION" target="SALES">
      <data key="d4">1.0</data>
      <data key="d5">Sales is the response variable in multiple regression, which is analyzed in relation to multiple explanatory variables</data>
      <data key="d6">336546bc73cbe1828a0cc1a45faf8f5a</data>
    </edge>
    <edge source="MULTIPLE_REGRESSION" target="ADVERT">
      <data key="d4">1.0</data>
      <data key="d5">Advert is one of the explanatory variables in multiple regression, which is analyzed in relation to the response variable sales</data>
      <data key="d6">336546bc73cbe1828a0cc1a45faf8f5a</data>
    </edge>
    <edge source="MULTIPLE_REGRESSION" target="NULL_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">Multiple regression models can also produce null plots when the model assumptions are met</data>
      <data key="d6">aa13c33a7e61206e6021e2736002ca9a</data>
    </edge>
    <edge source="MULTIPLE_REGRESSION" target="TREES_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The trees.model is an example of a multiple regression model that includes more than one explanatory variable</data>
      <data key="d6">a60af43e42c72a41fa90da06beb29d1b</data>
    </edge>
    <edge source="MATRIX" target="BRAND_MODEL3">
      <data key="d4">1.0</data>
      <data key="d5">Matrix is used as input data for the linear model Brand_model3</data>
      <data key="d6">6a6f85d0a6e46196ab3a901fcc82a720</data>
    </edge>
    <edge source="SALES" target="SLR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The sales variable is used as the response variable in the simple linear regression model</data>
      <data key="d6">2e5e1bdaa9fcc7b3391d277fd6bb247a</data>
    </edge>
    <edge source="SALES" target="ADVERT">
      <data key="d4">2.0</data>
      <data key="d5">The amount spent on local advertising for the product (advert) may also have an influence on the sales volume
The sales volume is affected by the amount spent on local advertising, as indicated by the positive coefficient in the model</data>
      <data key="d6">250ee5d766c64e7975bcc427b4bf9074,2e5e1bdaa9fcc7b3391d277fd6bb247a</data>
    </edge>
    <edge source="SALES" target="R_2">
      <data key="d4">1.0</data>
      <data key="d5">R^2 is the space in which the simple linear regression model is represented, with sales as the dependent variable</data>
      <data key="d6">250ee5d766c64e7975bcc427b4bf9074</data>
    </edge>
    <edge source="SALES" target="R_3">
      <data key="d4">1.0</data>
      <data key="d5">R^3 is the space in which the extended linear regression model is represented, with sales as the dependent variable</data>
      <data key="d6">250ee5d766c64e7975bcc427b4bf9074</data>
    </edge>
    <edge source="SALES" target="DATAPPOINTS">
      <data key="d4">1.0</data>
      <data key="d5">Sales is one of the coordinates (z-axis) of the datapoints in the 3D graphical representation</data>
      <data key="d6">8a9b984c146f59b2af83d1c2f373d376</data>
    </edge>
    <edge source="SALES" target="REGRESSION_PLANE">
      <data key="d4">1.0</data>
      <data key="d5">Sales is the response variable in the regression analysis, and the regression plane describes the relationship between sales and the explanatory variables</data>
      <data key="d6">b1690cb1a67892245c0665e5099e322d</data>
    </edge>
    <edge source="SALES" target="OBSERVED_DATA">
      <data key="d4">1.0</data>
      <data key="d5">Sales volume (sales) is the response variable in the observed data</data>
      <data key="d6">c48bd062d5f6cc20c5df5758d6285562</data>
    </edge>
    <edge source="SALES" target="ADVERTISING_BUDGET">
      <data key="d4">1.0</data>
      <data key="d5">An increase in the local advertising budget is associated with an increase in sales. The relationship strength is high, as a &#163;1000 increase in the advertising budget is associated with a 544 unit increase in sales.</data>
      <data key="d6">426434b67f6a287852ab66b82ca873cf</data>
    </edge>
    <edge source="SALES" target="BRAND_A">
      <data key="d4">9.0</data>
      <data key="d5">Brand A's sales are modeled as &#181;B + &#946; pricej + &#1013;j if the jth store is of Brand A
Sales are influenced by whether the store is of Brand A, with a specific intercept (&#181;&#710;A)
Salesj is modeled differently for Brand A stores, with a specific intercept &#181;A
Brand A's sales volumes are the focus of the CEO's interest
Sales (Salesj) is the dependent variable for stores of Brand A
Brand A is being compared against in terms of sales, indicating a relationship between the brand and sales figures
Brand A's category affects the sales at the jth store by using Mu as the intercept
Brand A stores have a sales model where sales are estimated as 210.379 - 0.657 * pricei, indicating the relationship between sales and price for Brand A stores
The sales volume of Brand A stores is influenced by the price of the product, with a steeper gradient for the fitted regression line than Brand C</data>
      <data key="d6">1820d10ee0f23f34b3ea88ba475bc52d,1b523d1edabe381403fc470a9b8d47fa,1d141ab04db553f78a313e430e54abb5,3dd24a54028976ba54304ec7169bb74b,7037e0369bfdaad5a730cabb2b44831c,8326c645426789920a99ed373725fa0e,906eb7d6b49fa360e7e5b65c56cd4d76,a1fc936df848a0fbc791e4bcc9b527b6,c103c6d096d52868eda26d991194b5f2</data>
    </edge>
    <edge source="SALES" target="BRAND_B">
      <data key="d4">8.0</data>
      <data key="d5">Brand B's sales are modeled as &#181;C + &#946; pricej + &#1013;j if the jth store is of Brand B
Sales are influenced by whether the store is of Brand B, with a specific intercept (&#181;&#710;B)
Salesj is modeled differently for Brand B stores, with a specific intercept &#181;B
Brand B's sales volumes are compared to Brand A's
Sales (Salesj) is the dependent variable for stores of Brand B
Brand B's category affects the sales at the jth store by adding Alpha B to the intercept
Brand B stores have a sales model where sales are estimated as 225.252 - 0.803 * pricei, indicating the relationship between sales and price for Brand B stores
The sales volume of Brand B stores is influenced by the price of the product, with a steeper gradient for the fitted regression line than Brand C</data>
      <data key="d6">1820d10ee0f23f34b3ea88ba475bc52d,1b523d1edabe381403fc470a9b8d47fa,1d141ab04db553f78a313e430e54abb5,3dd24a54028976ba54304ec7169bb74b,7037e0369bfdaad5a730cabb2b44831c,8326c645426789920a99ed373725fa0e,906eb7d6b49fa360e7e5b65c56cd4d76,a1fc936df848a0fbc791e4bcc9b527b6</data>
    </edge>
    <edge source="SALES" target="BRAND_C">
      <data key="d4">8.0</data>
      <data key="d5">Brand C's sales are modeled as &#181;C + &#946; pricej + &#1013;j if the jth store is of Brand C
Sales are influenced by whether the store is of Brand C, with a specific intercept (&#181;&#710;C)
Salesj is modeled differently for Brand C stores, with a specific intercept &#181;C
Brand C's sales volumes are compared to Brand A's
Sales (Salesj) is the dependent variable for stores of Brand C
Brand C's category affects the sales at the jth store by adding Alpha C to the intercept
Brand C stores have a sales model where sales are estimated as 162.879 - 0.231 * pricei, indicating the relationship between sales and price for Brand C stores
The sales volume of Brand C stores is influenced by the price of the product, but with a less steep gradient for the fitted regression line compared to Brand A and Brand B</data>
      <data key="d6">1820d10ee0f23f34b3ea88ba475bc52d,1b523d1edabe381403fc470a9b8d47fa,1d141ab04db553f78a313e430e54abb5,3dd24a54028976ba54304ec7169bb74b,7037e0369bfdaad5a730cabb2b44831c,8326c645426789920a99ed373725fa0e,906eb7d6b49fa360e7e5b65c56cd4d76,a1fc936df848a0fbc791e4bcc9b527b6</data>
    </edge>
    <edge source="SALES" target="BETA">
      <data key="d4">4.0</data>
      <data key="d5">Beta represents the effect of price on sales volume
Beta is the parameter associated with c_pricej in the model for Salesj
Beta represents the effect of price on sales volume in the reparameterised model
Beta is the coefficient for the price variable, affecting sales at the jth store</data>
      <data key="d6">1b523d1edabe381403fc470a9b8d47fa,8326c645426789920a99ed373725fa0e,906eb7d6b49fa360e7e5b65c56cd4d76,a1fc936df848a0fbc791e4bcc9b527b6</data>
    </edge>
    <edge source="SALES" target="BRAND_MODEL1">
      <data key="d4">2.0</data>
      <data key="d5">Brand Model 1 is used to estimate sales based on brand and price
Sales is the dependent variable in the model Brand.model1</data>
      <data key="d6">8326c645426789920a99ed373725fa0e,ee295ebc4c2d6a2a5c738796fcc2ab71</data>
    </edge>
    <edge source="SALES" target="FIGURE_9_3">
      <data key="d4">1.0</data>
      <data key="d5">Figure 9.3 shows the scatterplot of sales against price</data>
      <data key="d6">b2c33cb151a8e7724ebfb7b2d88bc45f</data>
    </edge>
    <edge source="SALES" target="FIGURE_9_2">
      <data key="d4">1.0</data>
      <data key="d5">Figure 9.2 shows the scatterplot of sales against price, revealing a systematic pattern</data>
      <data key="d6">b2c33cb151a8e7724ebfb7b2d88bc45f</data>
    </edge>
    <edge source="SALES" target="MU_HAT_A">
      <data key="d4">1.0</data>
      <data key="d5">The sales variable is influenced by the estimated intercept for Brand A (&#181;&#710;A) in the regression model</data>
      <data key="d6">7037e0369bfdaad5a730cabb2b44831c</data>
    </edge>
    <edge source="SALES" target="MU_HAT_B">
      <data key="d4">1.0</data>
      <data key="d5">The sales variable is influenced by the estimated intercept for Brand B (&#181;&#710;B) in the regression model</data>
      <data key="d6">7037e0369bfdaad5a730cabb2b44831c</data>
    </edge>
    <edge source="SALES" target="MU_HAT_C">
      <data key="d4">1.0</data>
      <data key="d5">The sales variable is influenced by the estimated intercept for Brand C (&#181;&#710;C) in the regression model</data>
      <data key="d6">7037e0369bfdaad5a730cabb2b44831c</data>
    </edge>
    <edge source="SALES" target="BETA_HAT">
      <data key="d4">2.0</data>
      <data key="d5">The sales variable is influenced by the estimated coefficient for the price variable (&#946;&#710;) in the regression model
Sales is the dependent variable that is influenced by the estimated coefficient for Beta (&#946;)</data>
      <data key="d6">248924760a2bfbc82501fd6b11cfa0aa,7037e0369bfdaad5a730cabb2b44831c</data>
    </edge>
    <edge source="SALES" target="C_PRICE">
      <data key="d4">1.0</data>
      <data key="d5">c_pricej is used as a predictor in the model equations for Salesj</data>
      <data key="d6">1b523d1edabe381403fc470a9b8d47fa</data>
    </edge>
    <edge source="SALES" target="MU_A">
      <data key="d4">2.0</data>
      <data key="d5">&#181;A is the intercept parameter for Brand A in the model for Salesj
Sales for stores of Brand A are modeled as &#181;A + &#1013;j</data>
      <data key="d6">1b523d1edabe381403fc470a9b8d47fa,48971100deb5bb374a41c1f2b7b2a86a</data>
    </edge>
    <edge source="SALES" target="MU_B">
      <data key="d4">2.0</data>
      <data key="d5">&#181;B is the intercept parameter for Brand B in the model for Salesj
Sales for stores of Brand B are modeled as &#181;B + &#1013;j</data>
      <data key="d6">1b523d1edabe381403fc470a9b8d47fa,48971100deb5bb374a41c1f2b7b2a86a</data>
    </edge>
    <edge source="SALES" target="MU_C">
      <data key="d4">2.0</data>
      <data key="d5">&#181;C is the intercept parameter for Brand C in the model for Salesj
Sales for stores of Brand C are modeled as &#181;C + &#1013;j</data>
      <data key="d6">1b523d1edabe381403fc470a9b8d47fa,48971100deb5bb374a41c1f2b7b2a86a</data>
    </edge>
    <edge source="SALES" target="BRAND_MODEL2">
      <data key="d4">1.0</data>
      <data key="d5">Sales is the dependent variable in Brand.model2, influenced by brand and price</data>
      <data key="d6">93da9813e10a119798de6982977f1239</data>
    </edge>
    <edge source="SALES" target="MU">
      <data key="d4">2.0</data>
      <data key="d5">Mu represents the baseline sales volume in the reparameterised model
Mu is the base intercept for sales at the jth store</data>
      <data key="d6">906eb7d6b49fa360e7e5b65c56cd4d76,a1fc936df848a0fbc791e4bcc9b527b6</data>
    </edge>
    <edge source="SALES" target="ALPHA_B">
      <data key="d4">2.0</data>
      <data key="d5">Alpha B represents the difference in sales volume between Brand B and Brand A
Alpha B is added to Mu to get the intercept for sales at the jth store if it is of Brand B</data>
      <data key="d6">906eb7d6b49fa360e7e5b65c56cd4d76,a1fc936df848a0fbc791e4bcc9b527b6</data>
    </edge>
    <edge source="SALES" target="ALPHA_C">
      <data key="d4">2.0</data>
      <data key="d5">Alpha C represents the difference in sales volume between Brand C and Brand A
Alpha C is added to Mu to get the intercept for sales at the jth store if it is of Brand C</data>
      <data key="d6">906eb7d6b49fa360e7e5b65c56cd4d76,a1fc936df848a0fbc791e4bcc9b527b6</data>
    </edge>
    <edge source="SALES" target="DESIGN_MATRIX_X">
      <data key="d4">1.0</data>
      <data key="d5">Sales is the dependent variable in the linear regression model, which is modeled using the design matrix X</data>
      <data key="d6">c103c6d096d52868eda26d991194b5f2</data>
    </edge>
    <edge source="SALES" target="RETAIL_DATA">
      <data key="d4">1.0</data>
      <data key="d5">Sales is the dependent variable in the regression models, which is predicted based on price and brand</data>
      <data key="d6">ac15b639b0849006471dfe102376c2c0</data>
    </edge>
    <edge source="SALES" target="PARALLEL_LINES_MODEL">
      <data key="d4">2.0</data>
      <data key="d5">Sales is the response variable in the parallel lines model
In the parallel lines model, the effect of price on sales volume is the same for each brand</data>
      <data key="d6">0cb40986e6c2bb439e1ffcaae2df96ac,1820d10ee0f23f34b3ea88ba475bc52d</data>
    </edge>
    <edge source="SALES" target="BRAND_MODEL4">
      <data key="d4">1.0</data>
      <data key="d5">Sales is the response variable in the regression model fitted by brand.model4</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="SALES" target="INTERACTION_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">In the interaction model, the effect of price on sales volume differs between brands</data>
      <data key="d6">1820d10ee0f23f34b3ea88ba475bc52d</data>
    </edge>
    <edge source="ADVERT" target="BETA_2">
      <data key="d4">2.0</data>
      <data key="d5">Beta_2 is the coefficient for the advert variable, indicating the effect of advertising on sales volume
The explanatory variable Advert is associated with the coefficient Beta_2 in the linear regression model</data>
      <data key="d6">250ee5d766c64e7975bcc427b4bf9074,a828fd17fc38e902484872c88a6b242c</data>
    </edge>
    <edge source="ADVERT" target="FIGURE_1_6">
      <data key="d4">1.0</data>
      <data key="d5">Figure 1.6 shows the relationship between the sales volume and the local advertising budget</data>
      <data key="d6">250ee5d766c64e7975bcc427b4bf9074</data>
    </edge>
    <edge source="ADVERT" target="DATAPPOINTS">
      <data key="d4">1.0</data>
      <data key="d5">Advert is one of the coordinates (y-axis) of the datapoints in the 3D graphical representation</data>
      <data key="d6">8a9b984c146f59b2af83d1c2f373d376</data>
    </edge>
    <edge source="ADVERT" target="REGRESSION_PLANE">
      <data key="d4">1.0</data>
      <data key="d5">Advert is one of the explanatory variables in the regression analysis, and the regression plane describes the relationship between advert and sales</data>
      <data key="d6">b1690cb1a67892245c0665e5099e322d</data>
    </edge>
    <edge source="ADVERT" target="OBSERVED_DATA">
      <data key="d4">1.0</data>
      <data key="d5">Advertising budget (advert) is one of the explanatory variables in the observed data</data>
      <data key="d6">c48bd062d5f6cc20c5df5758d6285562</data>
    </edge>
    <edge source="ADVERT" target="STATISTICAL_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Advert was considered as an independent variable in a more complex model but is not discussed in the context of simple linear regression.</data>
      <data key="d6">e079b7c92d5c0b009ff02040eb652bc6</data>
    </edge>
    <edge source="RESIDUAL" target="INFLUENTIAL_DATA_POINT">
      <data key="d4">1.0</data>
      <data key="d5">Residuals (ri) are used to identify influential data points by comparing their absolute values to thresholds</data>
      <data key="d6">09391efd3b8c510205098b548bc8dc74</data>
    </edge>
    <edge source="SLR_MODEL" target="COEFFICIENT">
      <data key="d4">1.0</data>
      <data key="d5">The coefficient is a parameter in the simple linear regression model</data>
      <data key="d6">2e5e1bdaa9fcc7b3391d277fd6bb247a</data>
    </edge>
    <edge source="BETA_2" target="X2">
      <data key="d4">1.0</data>
      <data key="d5">X2 is the explanatory variable associated with the coefficient Beta_2 in the linear regression model</data>
      <data key="d6">a828fd17fc38e902484872c88a6b242c</data>
    </edge>
    <edge source="BETA_2" target="QUADRATIC_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">BETA_2 (&#946;2) is one of the parameters in the quadratic regression model. It is estimated using least squares estimation</data>
      <data key="d6">e5131a1158e58f1b7b44b21ced7b6f60</data>
    </edge>
    <edge source="BETA_2" target="YI">
      <data key="d4">1.0</data>
      <data key="d5">The parameter Beta_2 (&#946;2) is associated with the explanatory variable X2 and affects the change in the log-transformed response variable Yi per unit change in X2.</data>
      <data key="d6">0fbc9037ca9a440e79e9ac05664b9b3d</data>
    </edge>
    <edge source="BETA_2" target="YB">
      <data key="d4">2.0</data>
      <data key="d5">&#946;2 is a component in the calculation of YB, the back-transformed prediction for Y
Beta_2 is the coefficient that determines the effect of X2 on the predicted response YB, but X2 is fixed in this scenario</data>
      <data key="d6">21e429490eeefe7d9c245058fd48ca68,995fb26a0261f824952fa7b2fac3382e</data>
    </edge>
    <edge source="R2" target="OBSERVED_DATA">
      <data key="d4">1.0</data>
      <data key="d5">When there is one explanatory variable, the observed data can be represented as points in R2</data>
      <data key="d6">c48bd062d5f6cc20c5df5758d6285562</data>
    </edge>
    <edge source="R2" target="DI">
      <data key="d4">1.0</data>
      <data key="d5">r2 is part of the variable representing the squared standardised residual for the ith observation that contributes to the Cook's distance Di</data>
      <data key="d6">98d6982108f2d42fe0437bff8c666e17</data>
    </edge>
    <edge source="R3" target="REGRESSION_PLANE">
      <data key="d4">1.0</data>
      <data key="d5">R3 is the space in which the regression plane is visualized in a 3D graphical representation</data>
      <data key="d6">8a9b984c146f59b2af83d1c2f373d376</data>
    </edge>
    <edge source="R3" target="OBSERVED_DATA">
      <data key="d4">1.0</data>
      <data key="d5">When there are two explanatory variables, the observed data can be represented as points in R3</data>
      <data key="d6">c48bd062d5f6cc20c5df5758d6285562</data>
    </edge>
    <edge source="R3" target="PLANE">
      <data key="d4">1.0</data>
      <data key="d5">Points in R3 are summarized using a plane</data>
      <data key="d6">c48bd062d5f6cc20c5df5758d6285562</data>
    </edge>
    <edge source="GRAPHICAL_ILLUSTRATION" target="HTML_VERSION">
      <data key="d4">1.0</data>
      <data key="d5">Graphical illustration is used in the HTML version of the document to provide a visual representation of the data and fitted model</data>
      <data key="d6">8a9b984c146f59b2af83d1c2f373d376</data>
    </edge>
    <edge source="GRAPHICAL_ILLUSTRATION" target="3D_GRAPHICAL_REPRESENTATION">
      <data key="d4">1.0</data>
      <data key="d5">3D graphical representation is a type of graphical illustration that shows the data and fitted model in three dimensions</data>
      <data key="d6">8a9b984c146f59b2af83d1c2f373d376</data>
    </edge>
    <edge source="HTML_VERSION" target="PDF_FORMAT">
      <data key="d4">1.0</data>
      <data key="d5">The HTML version of the document contains interactive graphics, whereas the PDF format shows a static graphic</data>
      <data key="d6">8a9b984c146f59b2af83d1c2f373d376</data>
    </edge>
    <edge source="DATAPPOINTS" target="REGRESSION_PLANE">
      <data key="d4">2.0</data>
      <data key="d5">Datapoints are plotted in the 3D space and their relationship to the regression plane is visualized
Datapoints are used to determine the regression plane by minimizing the sum of squared distances along the z-axis</data>
      <data key="d6">8a9b984c146f59b2af83d1c2f373d376,b1690cb1a67892245c0665e5099e322d</data>
    </edge>
    <edge source="REGRESSION_PLANE" target="PLANE">
      <data key="d4">1.0</data>
      <data key="d5">The plane is the same as the regression plane, used to represent the relationship between sales, price, and advert</data>
      <data key="d6">b1690cb1a67892245c0665e5099e322d</data>
    </edge>
    <edge source="REGRESSION_PLANE" target="PDF_FORMAT">
      <data key="d4">1.0</data>
      <data key="d5">PDF format shows a static graphic of the regression plane, but does not support interactive graphics</data>
      <data key="d6">b1690cb1a67892245c0665e5099e322d</data>
    </edge>
    <edge source="REGRESSION_PLANE" target="Z_AXIS">
      <data key="d4">1.0</data>
      <data key="d5">The z-axis is used in least squares estimation to measure the distance between the observed datapoints and the regression plane</data>
      <data key="d6">b1690cb1a67892245c0665e5099e322d</data>
    </edge>
    <edge source="REGRESSION_PLANE" target="RETAIL_DATA">
      <data key="d4">1.0</data>
      <data key="d5">Retail data is used to determine the regression plane by analyzing the relationship between sales, price, and advert</data>
      <data key="d6">b1690cb1a67892245c0665e5099e322d</data>
    </edge>
    <edge source="PDF_FORMAT" target="STATIC_GRAPHIC">
      <data key="d4">1.0</data>
      <data key="d5">Static graphic is used in the PDF format to represent the regression plane and datapoints</data>
      <data key="d6">8a9b984c146f59b2af83d1c2f373d376</data>
    </edge>
    <edge source="FIGURE_1_7" target="RETAIL_DATA">
      <data key="d4">1.0</data>
      <data key="d5">Figure 1.7 is a graphical representation of the Retail data, including the plane of best fit</data>
      <data key="d6">b1690cb1a67892245c0665e5099e322d</data>
    </edge>
    <edge source="RETAIL_DATA" target="EXERCISE_4">
      <data key="d4">1.0</data>
      <data key="d5">Retail data is used in Exercise 4 to practice reparameterising a multiple regression model</data>
      <data key="d6">2ced3e26eaed2dfcd8e4caf49737cab4</data>
    </edge>
    <edge source="RETAIL_DATA" target="BRAND_C">
      <data key="d4">1.0</data>
      <data key="d5">Brand C is a category in the retail data whose observations are analyzed in the regression models</data>
      <data key="d6">ac15b639b0849006471dfe102376c2c0</data>
    </edge>
    <edge source="RETAIL_DATA" target="BRAND_B">
      <data key="d4">1.0</data>
      <data key="d5">Brand B is a category in the retail data whose observations are analyzed in the regression models</data>
      <data key="d6">ac15b639b0849006471dfe102376c2c0</data>
    </edge>
    <edge source="RETAIL_DATA" target="BRAND_A">
      <data key="d4">1.0</data>
      <data key="d5">Brand A is a category in the retail data whose observations are analyzed in the regression models</data>
      <data key="d6">ac15b639b0849006471dfe102376c2c0</data>
    </edge>
    <edge source="RETAIL_DATA" target="PARALLEL_LINES_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The parallel lines model is applied to the retail data to analyze the relationship between sales, price, and brand</data>
      <data key="d6">ac15b639b0849006471dfe102376c2c0</data>
    </edge>
    <edge source="RETAIL_DATA" target="MU">
      <data key="d4">1.0</data>
      <data key="d5">Mu is a parameter in the regression models that represents the baseline sales level in the retail data</data>
      <data key="d6">ac15b639b0849006471dfe102376c2c0</data>
    </edge>
    <edge source="RETAIL_DATA" target="ALPHA_B">
      <data key="d4">1.0</data>
      <data key="d5">Alpha B is a parameter in the regression models that represents the effect of Brand B on sales in the retail data</data>
      <data key="d6">ac15b639b0849006471dfe102376c2c0</data>
    </edge>
    <edge source="RETAIL_DATA" target="ALPHA_C">
      <data key="d4">1.0</data>
      <data key="d5">Alpha C is a parameter in the regression models that represents the effect of Brand C on sales in the retail data</data>
      <data key="d6">ac15b639b0849006471dfe102376c2c0</data>
    </edge>
    <edge source="RETAIL_DATA" target="BETA">
      <data key="d4">1.0</data>
      <data key="d5">Beta is a parameter in the regression models that represents the effect of price on sales in the retail data</data>
      <data key="d6">ac15b639b0849006471dfe102376c2c0</data>
    </edge>
    <edge source="RETAIL_DATA" target="XJB">
      <data key="d4">1.0</data>
      <data key="d5">XjB is an indicator variable in the regression models that represents whether the jth observation in the retail data is of Brand B</data>
      <data key="d6">ac15b639b0849006471dfe102376c2c0</data>
    </edge>
    <edge source="RETAIL_DATA" target="XJC">
      <data key="d4">1.0</data>
      <data key="d5">XjC is an indicator variable in the regression models that represents whether the jth observation in the retail data is of Brand C</data>
      <data key="d6">ac15b639b0849006471dfe102376c2c0</data>
    </edge>
    <edge source="RETAIL_DATA" target="PRICEJ">
      <data key="d4">1.0</data>
      <data key="d5">Pricej is a variable in the regression models that represents the price of the jth observation in the retail data</data>
      <data key="d6">ac15b639b0849006471dfe102376c2c0</data>
    </edge>
    <edge source="RETAIL_DATA" target="FITTED_LINE">
      <data key="d4">1.0</data>
      <data key="d5">The fitted line is obtained from the regression models and is used to predict sales based on price and brand in the retail data</data>
      <data key="d6">ac15b639b0849006471dfe102376c2c0</data>
    </edge>
    <edge source="RETAIL_DATA" target="FIGURE_9_4">
      <data key="d4">1.0</data>
      <data key="d5">Figure 9.4 is a graphical representation showing separate scatterplots for each brand with the corresponding fitted regression line from the parallel lines model in the retail data</data>
      <data key="d6">ac15b639b0849006471dfe102376c2c0</data>
    </edge>
    <edge source="RETAIL_DATA" target="BRAND_MODEL4">
      <data key="d4">1.0</data>
      <data key="d5">Retail data is used in the regression model fitted by brand.model4</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="EXPLANATORY_VARIABLE" target="OBSERVED_DATA">
      <data key="d4">1.0</data>
      <data key="d5">Explanatory variables are part of the observed data</data>
      <data key="d6">c48bd062d5f6cc20c5df5758d6285562</data>
    </edge>
    <edge source="EXPLANATORY_VARIABLE" target="ERROR_TERM">
      <data key="d4">1.0</data>
      <data key="d5">The values of the explanatory variable (x) for each unit of observation (xj) are used in the model equation, and the difference between the observed values of the response variable and the values predicted by the model is represented by the error term (&#1013;).</data>
      <data key="d6">b9af17718641389ba07f53be13f31f8c</data>
    </edge>
    <edge source="EXPLANATORY_VARIABLE" target="MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The model uses the explanatory variable to predict or explain the response variable</data>
      <data key="d6">bb31f1c77bbba73300f735a100086a67</data>
    </edge>
    <edge source="EXPLANATORY_VARIABLE" target="TRANSFORMATION">
      <data key="d4">2.0</data>
      <data key="d5">A transformation is applied to the explanatory variable to meet the assumptions of a statistical model, such as linearity
Transformation of the explanatory variable is considered if linearity assumption is not met</data>
      <data key="d6">7347b44ffb25a066e43321f4eaf5a806,b9ec8a6c7960cc6196ec94fd976f05b0</data>
    </edge>
    <edge source="EXPLANATORY_VARIABLE" target="VARIANCE">
      <data key="d4">1.0</data>
      <data key="d5">The variance of the response variable may increase with the explanatory variable</data>
      <data key="d6">b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </edge>
    <edge source="EXPLANATORY_VARIABLE" target="STATISTICAL_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Explanatory variables, such as brand, are included in statistical models to predict sales volume.</data>
      <data key="d6">e079b7c92d5c0b009ff02040eb652bc6</data>
    </edge>
    <edge source="MODEL" target="PARAMETERS">
      <data key="d4">1.0</data>
      <data key="d5">The model contains parameters that need to be estimated or optimized</data>
      <data key="d6">bb31f1c77bbba73300f735a100086a67</data>
    </edge>
    <edge source="MODEL" target="STOCHASTIC_NATURE">
      <data key="d4">1.0</data>
      <data key="d5">The model takes into account the stochastic nature of the response</data>
      <data key="d6">bb31f1c77bbba73300f735a100086a67</data>
    </edge>
    <edge source="MODEL" target="SYSTEMATIC_COMPONENT">
      <data key="d4">1.0</data>
      <data key="d5">The model includes a systematic component that follows a specific pattern or rule</data>
      <data key="d6">bb31f1c77bbba73300f735a100086a67</data>
    </edge>
    <edge source="MODEL" target="MODEL_ADEQUACY">
      <data key="d4">1.0</data>
      <data key="d5">Model adequacy is a criterion for evaluating the model</data>
      <data key="d6">bb31f1c77bbba73300f735a100086a67</data>
    </edge>
    <edge source="MODEL" target="GEORGE E. BOX">
      <data key="d4">1.0</data>
      <data key="d5">George E. Box's quote relates to the concept of models being approximations of reality</data>
      <data key="d6">22061b1108c7f9963497b7a320be22b8</data>
    </edge>
    <edge source="MODEL" target="DESCRIPTION">
      <data key="d4">1.0</data>
      <data key="d5">Models can be used for description, summarizing data and reducing dimensionality</data>
      <data key="d6">22061b1108c7f9963497b7a320be22b8</data>
    </edge>
    <edge source="MODEL" target="PREDICTION">
      <data key="d4">1.0</data>
      <data key="d5">Models can be used for prediction, focusing on forecasting and accuracy</data>
      <data key="d6">22061b1108c7f9963497b7a320be22b8</data>
    </edge>
    <edge source="MODEL" target="EXPLANATION">
      <data key="d4">1.0</data>
      <data key="d5">Models can be used for explanation, shedding light on relationships between predictor variables and response</data>
      <data key="d6">22061b1108c7f9963497b7a320be22b8</data>
    </edge>
    <edge source="MODEL" target="PARSIMONY">
      <data key="d4">1.0</data>
      <data key="d5">Parsimony is a criterion for evaluating the adequacy of a model</data>
      <data key="d6">22061b1108c7f9963497b7a320be22b8</data>
    </edge>
    <edge source="MODEL" target="PLAUSIBILITY">
      <data key="d4">1.0</data>
      <data key="d5">Plausibility is a criterion for evaluating the adequacy of a model</data>
      <data key="d6">22061b1108c7f9963497b7a320be22b8</data>
    </edge>
    <edge source="MODEL" target="RESIDUAL_PLOTS">
      <data key="d4">1.0</data>
      <data key="d5">Residual plots are used to assess the fit of a statistical model</data>
      <data key="d6">7cd6069e88e81548a237fa937adfecc6</data>
    </edge>
    <edge source="MODEL" target="R_SOFTWARE">
      <data key="d4">1.0</data>
      <data key="d5">R software is used to fit statistical models and produce residual plots</data>
      <data key="d6">7cd6069e88e81548a237fa937adfecc6</data>
    </edge>
    <edge source="BETA0" target="BETA">
      <data key="d4">1.0</data>
      <data key="d5">Beta is the column vector containing all Beta parameters, including Beta0</data>
      <data key="d6">b5d0a103e1f34a00aef67fedd0e8c693</data>
    </edge>
    <edge source="BETA0" target="YI">
      <data key="d4">2.0</data>
      <data key="d5">Yi is a function of Beta0 (&#946;0) in the second and third models, representing the intercept in the linear relationship
Yi is calculated using Beta0 as the intercept in the exponential model</data>
      <data key="d6">34fceaaf7d835828b5ee2327325c37f8,90ed6030c5a5a0764b7dcd4115b4d4d3</data>
    </edge>
    <edge source="BETA0" target="BETA1">
      <data key="d4">3.0</data>
      <data key="d5">BETA0 and BETA1 are parameters in the linear regression model
Beta1 is used in the calculation of Beta0 as part of the simple linear regression model
Beta0 (b&#946;0) is calculated using Beta1 (b&#946;1) as part of the formula ybar - (Sxy/Sxx)xbar</data>
      <data key="d6">254a8a17b1be06702934341e3bf41e85,5b24b5382abe9d1898810b3e4b9b455a,86c401dda130c2d201c3339526062a24</data>
    </edge>
    <edge source="BETA0" target="VOLUMEI">
      <data key="d4">1.0</data>
      <data key="d5">&#946;0 is the intercept term in the model used to calculate Volumei</data>
      <data key="d6">60cc94e681863c9fcc6f9be1e500f840</data>
    </edge>
    <edge source="BETA0" target="X_BAR">
      <data key="d4">2.0</data>
      <data key="d5">x&#175; is used in the calculation of Beta0 as part of the simple linear regression model
X_bar is used in the calculation of Beta0 in the least squares estimation</data>
      <data key="d6">28cf5ff0c09fa5c0390267bb9aa3ce47,5b24b5382abe9d1898810b3e4b9b455a</data>
    </edge>
    <edge source="BETA0" target="Y_BAR">
      <data key="d4">2.0</data>
      <data key="d5">y&#175; is used in the calculation of Beta0 as part of the simple linear regression model
Y_bar is used in the calculation of Beta0 in the least squares estimation</data>
      <data key="d6">28cf5ff0c09fa5c0390267bb9aa3ce47,5b24b5382abe9d1898810b3e4b9b455a</data>
    </edge>
    <edge source="BETA0" target="BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Beta0 is part of the Beta hat (b&#946;) vector, representing the intercept in the linear regression model</data>
      <data key="d6">28cf5ff0c09fa5c0390267bb9aa3ce47</data>
    </edge>
    <edge source="BETA0" target="SXY">
      <data key="d4">1.0</data>
      <data key="d5">Beta0 (b&#946;0) is calculated using Sxy as part of the formula ybar - (Sxy/Sxx)xbar</data>
      <data key="d6">254a8a17b1be06702934341e3bf41e85</data>
    </edge>
    <edge source="BETA0" target="SXX">
      <data key="d4">1.0</data>
      <data key="d5">Beta0 (b&#946;0) is calculated using Sxx as part of the formula ybar - (Sxy/Sxx)xbar</data>
      <data key="d6">254a8a17b1be06702934341e3bf41e85</data>
    </edge>
    <edge source="BETA0" target="LOG_LIKELIHOOD">
      <data key="d4">1.0</data>
      <data key="d5">The log-likelihood function depends on Beta0, the intercept parameter</data>
      <data key="d6">87b717ba065d6d7c7431af284137eb12</data>
    </edge>
    <edge source="BETA0" target="BETA_HAT0">
      <data key="d4">1.0</data>
      <data key="d5">Beta0 is the true parameter that Beta hat 0 (b&#946;0) estimates in the linear regression model</data>
      <data key="d6">09caa54ca1372d152e47051be4d44ede</data>
    </edge>
    <edge source="BETA1" target="BETA">
      <data key="d4">1.0</data>
      <data key="d5">Beta is the column vector containing all Beta parameters, including Beta1</data>
      <data key="d6">b5d0a103e1f34a00aef67fedd0e8c693</data>
    </edge>
    <edge source="BETA1" target="BETA2">
      <data key="d4">1.0</data>
      <data key="d5">Beta1 and Beta2 are coefficients in the quadratic regression model that together determine the expected change in the response due to a unit change in the explanatory variable</data>
      <data key="d6">11452a08471d93959558de2ece9a69af</data>
    </edge>
    <edge source="BETA1" target="EXPECTED_CHANGE">
      <data key="d4">1.0</data>
      <data key="d5">Beta1 contributes to the linear term of the expected change in the response due to a unit change in the explanatory variable</data>
      <data key="d6">c9a01b92d11585f6549f62e8bd78d652</data>
    </edge>
    <edge source="BETA1" target="YI">
      <data key="d4">2.0</data>
      <data key="d5">Yi is a function of Beta1 (&#946;1) and xi,1 in the first model, representing the linear relationship between the response and explanatory variable
Yi is calculated using Beta1 as the coefficient of xi1 in the exponential model</data>
      <data key="d6">34fceaaf7d835828b5ee2327325c37f8,90ed6030c5a5a0764b7dcd4115b4d4d3</data>
    </edge>
    <edge source="BETA1" target="BRAINI">
      <data key="d4">1.0</data>
      <data key="d5">BRAINi is the response variable in the linear regression model, which is related to the slope coefficient Beta1</data>
      <data key="d6">86c401dda130c2d201c3339526062a24</data>
    </edge>
    <edge source="BETA1" target="BODYI">
      <data key="d4">1.0</data>
      <data key="d5">BODYi is the explanatory variable in the linear regression model, which is related to the slope coefficient Beta1</data>
      <data key="d6">86c401dda130c2d201c3339526062a24</data>
    </edge>
    <edge source="BETA1" target="EPSILONI">
      <data key="d4">1.0</data>
      <data key="d5">EPSILONi is the error term in the linear regression model, which is independent of the slope coefficient Beta1</data>
      <data key="d6">86c401dda130c2d201c3339526062a24</data>
    </edge>
    <edge source="BETA1" target="VOLUMEI">
      <data key="d4">1.0</data>
      <data key="d5">&#946;1 is the coefficient for Diameteri in the model used to calculate Volumei</data>
      <data key="d6">60cc94e681863c9fcc6f9be1e500f840</data>
    </edge>
    <edge source="BETA1" target="SXY">
      <data key="d4">3.0</data>
      <data key="d5">Sxy is used in the calculation of Beta1 as part of the simple linear regression model
Sxy is used in the calculation of Beta1 in the least squares estimation
Beta1 (b&#946;1) is calculated using Sxy as part of the formula Sxy/Sxx</data>
      <data key="d6">254a8a17b1be06702934341e3bf41e85,28cf5ff0c09fa5c0390267bb9aa3ce47,5b24b5382abe9d1898810b3e4b9b455a</data>
    </edge>
    <edge source="BETA1" target="SXX">
      <data key="d4">3.0</data>
      <data key="d5">Sxx is used in the calculation of Beta1 as part of the simple linear regression model
Sxx is used in the calculation of Beta1 in the least squares estimation
Beta1 (b&#946;1) is calculated using Sxx as part of the formula Sxy/Sxx</data>
      <data key="d6">254a8a17b1be06702934341e3bf41e85,28cf5ff0c09fa5c0390267bb9aa3ce47,5b24b5382abe9d1898810b3e4b9b455a</data>
    </edge>
    <edge source="BETA1" target="BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Beta1 is part of the Beta hat (b&#946;) vector, representing the slope in the linear regression model</data>
      <data key="d6">28cf5ff0c09fa5c0390267bb9aa3ce47</data>
    </edge>
    <edge source="BETA1" target="LOG_LIKELIHOOD">
      <data key="d4">1.0</data>
      <data key="d5">The log-likelihood function depends on Beta1, one of the slope parameters</data>
      <data key="d6">87b717ba065d6d7c7431af284137eb12</data>
    </edge>
    <edge source="BETA1" target="BETA_HAT1">
      <data key="d4">1.0</data>
      <data key="d5">Beta1 is the true parameter that Beta hat 1 (b&#946;1) estimates in the linear regression model</data>
      <data key="d6">09caa54ca1372d152e47051be4d44ede</data>
    </edge>
    <edge source="BETA1" target="E_Y3_GIVEN_X3">
      <data key="d4">1.0</data>
      <data key="d5">Beta1 is used in the calculation involving the expected value of Y3 given X3=x3 and Beta2</data>
      <data key="d6">45f31b040576e9f3b4def6d0466cc016</data>
    </edge>
    <edge source="BETA2" target="EXPECTED_CHANGE">
      <data key="d4">1.0</data>
      <data key="d5">Beta2 contributes to the quadratic term of the expected change in the response due to a unit change in the explanatory variable</data>
      <data key="d6">c9a01b92d11585f6549f62e8bd78d652</data>
    </edge>
    <edge source="BETA2" target="YI">
      <data key="d4">2.0</data>
      <data key="d5">Yi is a function of Beta2 (&#946;2) and xi,2 in the logarithmic form in the fifth model, representing the coefficient of the logarithmic explanatory variable
Yi is calculated using Beta2 as the coefficient of xi2 in the exponential model</data>
      <data key="d6">34fceaaf7d835828b5ee2327325c37f8,90ed6030c5a5a0764b7dcd4115b4d4d3</data>
    </edge>
    <edge source="BETA2" target="VOLUMEI">
      <data key="d4">1.0</data>
      <data key="d5">&#946;2 is the coefficient for Heighti in the model used to calculate Volumei</data>
      <data key="d6">60cc94e681863c9fcc6f9be1e500f840</data>
    </edge>
    <edge source="BETA2" target="E_Y3_GIVEN_X3">
      <data key="d4">1.0</data>
      <data key="d5">Beta2 is used in the calculation of the expected value of Y3 given X3=x3</data>
      <data key="d6">45f31b040576e9f3b4def6d0466cc016</data>
    </edge>
    <edge source="MLR_MODEL" target="AVERAGE_EFFECT">
      <data key="d4">1.0</data>
      <data key="d5">Mlr.model is used to determine the average effect of explanatory variables</data>
      <data key="d6">c48bd062d5f6cc20c5df5758d6285562</data>
    </edge>
    <edge source="X1" target="LINEAR_PREDICTOR">
      <data key="d4">1.0</data>
      <data key="d5">X1 is one of the explanatory variables whose value x1 is used in the linear predictor to determine the mean of the response</data>
      <data key="d6">6a47154bf457c25f22c3cf9f649c5db0</data>
    </edge>
    <edge source="X1" target="YI">
      <data key="d4">1.0</data>
      <data key="d5">X1 is one of the explanatory variables in the model that influences the log-transformed response variable Yi.</data>
      <data key="d6">0fbc9037ca9a440e79e9ac05664b9b3d</data>
    </edge>
    <edge source="X1" target="YB">
      <data key="d4">2.0</data>
      <data key="d5">X1 influences YB when it changes by one unit while X2 stays fixed
X1 is the predictor variable that increases by one unit, affecting the predicted response YB</data>
      <data key="d6">21e429490eeefe7d9c245058fd48ca68,995fb26a0261f824952fa7b2fac3382e</data>
    </edge>
    <edge source="X2" target="LINEAR_PREDICTOR">
      <data key="d4">1.0</data>
      <data key="d5">X2 is one of the explanatory variables whose value x2 is used in the linear predictor to determine the mean of the response</data>
      <data key="d6">6a47154bf457c25f22c3cf9f649c5db0</data>
    </edge>
    <edge source="X2" target="YI">
      <data key="d4">1.0</data>
      <data key="d5">X2 is another explanatory variable in the model that affects the log-transformed response variable Yi.</data>
      <data key="d6">0fbc9037ca9a440e79e9ac05664b9b3d</data>
    </edge>
    <edge source="X2" target="YB">
      <data key="d4">2.0</data>
      <data key="d5">X2 is held constant when calculating the change in YB due to a change in X1
X2 is the predictor variable that stays fixed, not affecting the predicted response YB in this scenario</data>
      <data key="d6">21e429490eeefe7d9c245058fd48ca68,995fb26a0261f824952fa7b2fac3382e</data>
    </edge>
    <edge source="DATASET" target="EXERCISE_13">
      <data key="d4">1.0</data>
      <data key="d5">The dataset is used in Exercise 13 to compute parameter estimates, fitted values, residuals, and the deviance of the model</data>
      <data key="d6">5b24b5382abe9d1898810b3e4b9b455a</data>
    </edge>
    <edge source="DATASET" target="RHESUS_MONKEY">
      <data key="d4">1.0</data>
      <data key="d5">Rhesus monkey is included in the mammals dataset for analysis</data>
      <data key="d6">428db872e71a17a2cf7868b03a52def0</data>
    </edge>
    <edge source="EXERCISE_4" target="LINEAR_MODELS">
      <data key="d4">1.0</data>
      <data key="d5">Exercise 4 involves reparameterising a model within the class of linear models</data>
      <data key="d6">2ced3e26eaed2dfcd8e4caf49737cab4</data>
    </edge>
    <edge source="LINEAR_MODELS" target="TRANSFORMED_EXPLANATORY_VARIABLES">
      <data key="d4">1.0</data>
      <data key="d5">Linear models can use transformed explanatory variables to better fit the data or to satisfy model assumptions</data>
      <data key="d6">0328e428a30c44572676dd571dd1e9bd</data>
    </edge>
    <edge source="LINEAR_MODELS" target="MODEL_DEVELOPMENT_STRATEGY">
      <data key="d4">1.0</data>
      <data key="d5">A model development strategy guides the building and refining of linear models, ensuring they are both realistic and as simple as possible</data>
      <data key="d6">0328e428a30c44572676dd571dd1e9bd</data>
    </edge>
    <edge source="LINEAR_MODELS" target="CATEGORICAL_PREDICTORS">
      <data key="d4">1.0</data>
      <data key="d5">Categorical predictors can be incorporated into linear models to analyze their effect on the response variable</data>
      <data key="d6">77e76692753fdf53493182b09018e6bc</data>
    </edge>
    <edge source="LINEAR_MODELS" target="QUANTITATIVE_VARIABLES">
      <data key="d4">1.0</data>
      <data key="d5">Quantitative variables are used as predictors in linear models to describe their relationship with the response variable</data>
      <data key="d6">77e76692753fdf53493182b09018e6bc</data>
    </edge>
    <edge source="LINEAR_MODELS" target="PARALLEL_LINES_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">A parallel lines model is a specific type of linear model that assumes the regression lines for different categories of a factor variable are parallel</data>
      <data key="d6">77e76692753fdf53493182b09018e6bc</data>
    </edge>
    <edge source="BETA" target="BETAK">
      <data key="d4">1.0</data>
      <data key="d5">Beta is the column vector containing all Beta parameters, including Betak</data>
      <data key="d6">b5d0a103e1f34a00aef67fedd0e8c693</data>
    </edge>
    <edge source="BETA" target="YI">
      <data key="d4">1.0</data>
      <data key="d5">Yi is a function of the parameters Beta (&#946;0, &#946;1, &#946;2) in the quadratic regression model equation</data>
      <data key="d6">6c1684ed2a4840576c6b0f4d1a3a482f</data>
    </edge>
    <edge source="BETA" target="DESIGN_MATRIX">
      <data key="d4">1.0</data>
      <data key="d5">The design matrix X is used in conjunction with the vector of parameters Beta to predict the response vector Y in the linear model. The relationship is given by the equation Y = X Beta + Epsilon.</data>
      <data key="d6">e7494d6cfc3e38a4d2f3f6b21ef6445d</data>
    </edge>
    <edge source="BETA" target="BETA_HAT">
      <data key="d4">24.0</data>
      <data key="d5">Beta hat is the estimate of the parameter vector Beta
Beta (&#946;) is the true parameter vector that Beta hat (&#946;b) estimates
Beta is the true parameter that Beta hat (&#946;b) estimates in the linear regression model
Beta is the true parameter that Beta hat (&#946;b) estimates in the linear regression model
Beta is the true parameter that Beta hat (&#946;b) estimates in the linear regression model
Beta is the true parameter that Beta hat (&#946;b) estimates in the linear regression model
Beta is the true parameter that Beta hat (&#946;b) estimates in the linear regression model
Beta is the true parameter that Beta hat (&#946;b) estimates in the linear regression model
Beta is the true parameter that Beta hat (b&#946;) estimates in the linear regression model
Beta is the true parameter that Beta hat (&#946;b) estimates in the linear regression model
Beta is the true parameter that Beta hat (&#946;b) estimates in the linear regression model
Beta is the true parameter vector that Beta hat (&#946;b) estimates in the linear regression model
Beta is the true parameter that Beta hat (&#946;b) estimates in the linear model
Beta hat (&#946;b) is the MLE of the parameter vector Beta
&#946; is the true parameter that &#946;b estimates using the MLE method
Beta is the true parameter that Beta hat (&#946;b) estimates in the linear regression model.
Beta is the true parameter vector that Beta hat (&#946;b) estimates
Beta is the true parameter that Beta hat (&#946;b) estimates in the linear model
Beta is the true parameter that Beta hat (&#946;b) estimates in the linear model
Beta is the true parameter that Beta hat (&#946;b) estimates in the linear regression model
Beta is the true parameter that Beta hat (&#946;b) estimates in the linear regression model
Beta is the true parameter that Beta hat (&#946;b) estimates in the linear regression model
Beta (&#946;) is the true parameter that Beta hat (&#946;b) estimates in the linear regression model
Beta is the true parameter that Beta hat (&#946;) estimates in the linear regression model</data>
      <data key="d6">01d5ee79489582b4135fc96f676b24a0,248924760a2bfbc82501fd6b11cfa0aa,255685e281cc5a9edf073c700f425a6b,2673d078d29f2af78fab9b6eacd15e37,28cf5ff0c09fa5c0390267bb9aa3ce47,2b6d31b6bff4eae3a4809451c4fb9fa6,2de7a36b32bf79c8f32612c8aaa9daa8,3d357cfa3ef0d00f49cf4acaeac1c9d1,542f546c5a131196e4701fb33c9b1dee,6b55b41598d5264f8dc6b72769748722,7955aae3fd4ca51b9ef8843e13c1f517,82932abd152e0b84a1c26a2daa4c08df,9d300fc83afb3261af61b2ab9721cadc,9dddcd96af7b557e578b3f5f36efacd7,9fc2b1e8b2b61b557f88eb9e9c708597,a4a817bb79d6ae8812c808ca41d47f43,aa195e72eb5285a4bcae9c856af30a87,ad799500572246a07f983a3b92c0e61f,b70a75a6412b2e5c44af50734844f4be,d14413709de2897231aaa83be3aa346f,d94760a5f9f6ea115fcc18024035a627,e7edd8b2874a350779ae20f1ecdf4733,f9b615b879f72501f338f8983d4cac3d,fc5b725f3c662c5471af20efdcc2dbff</data>
    </edge>
    <edge source="BETA" target="BETA_BAR">
      <data key="d4">1.0</data>
      <data key="d5">Beta bar is the notation for the estimated parameter vector Beta</data>
      <data key="d6">01d5ee79489582b4135fc96f676b24a0</data>
    </edge>
    <edge source="BETA" target="S">
      <data key="d4">3.0</data>
      <data key="d5">Parameter &#946; is used in the calculation of S(&#946;) as part of the predicted values X&#946;
Beta is a parameter in the linear regression model that is used in the calculation of the function S
Beta is the parameter vector that the sum of squared differences (S) is calculated with respect to</data>
      <data key="d6">2167274129d4cfa74a002c4cc39df8a8,255685e281cc5a9edf073c700f425a6b,eac62cdd5518e1269fed150639331c2c</data>
    </edge>
    <edge source="BETA" target="F_BETA">
      <data key="d4">1.0</data>
      <data key="d5">Beta (&#946;) is the variable in the function f(&#946;) = &#946;T A&#946;</data>
      <data key="d6">21ec28dfe2b2c18030d541d63e51f45e</data>
    </edge>
    <edge source="BETA" target="S_BETA">
      <data key="d4">1.0</data>
      <data key="d5">Beta (&#946;) is the variable in the function S(&#946;)</data>
      <data key="d6">21ec28dfe2b2c18030d541d63e51f45e</data>
    </edge>
    <edge source="BETA" target="ALPHA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Beta is the original parameter vector that Alpha hat (&#945;b) estimates in the reparameterized model</data>
      <data key="d6">f5716ce115458c0652124734ca344806</data>
    </edge>
    <edge source="BETA" target="GAMMA">
      <data key="d4">1.0</data>
      <data key="d5">Beta is transformed by A to obtain Gamma</data>
      <data key="d6">d94760a5f9f6ea115fcc18024035a627</data>
    </edge>
    <edge source="BETA" target="ALPHA">
      <data key="d4">3.0</data>
      <data key="d5">Alpha is related to Beta through the transformation xj - x&#175; in the reparameterised model (1)
Alpha is a linear transformation of Beta using matrix A
Beta and Alpha are related through the reparameterisation of the model, where Alpha is a function of Beta and the transformation matrix A</data>
      <data key="d6">5609007c6229060ffc85d8056a7fefde,6c66e9414880964ee899ceb0f16d22e9,82932abd152e0b84a1c26a2daa4c08df</data>
    </edge>
    <edge source="BETA" target="MLE">
      <data key="d4">2.0</data>
      <data key="d5">Maximum likelihood estimation (MLE) is a method that can be used to estimate the parameter Beta under the assumption of normally distributed errors
MLE is an estimate for the parameter vector &#946; in the linear regression model, derived under the assumption that errors are iid N(0, &#963;^2)</data>
      <data key="d6">9fc2b1e8b2b61b557f88eb9e9c708597,d738df7d83784c8a41b3948271c537b6</data>
    </edge>
    <edge source="BETA" target="LSE">
      <data key="d4">1.0</data>
      <data key="d5">LSE is an estimate for the parameter vector &#946; in the linear regression model</data>
      <data key="d6">d738df7d83784c8a41b3948271c537b6</data>
    </edge>
    <edge source="BETA" target="L">
      <data key="d4">2.0</data>
      <data key="d5">Beta is a parameter in the likelihood function L
Beta (&#946;) is a parameter in the likelihood function L(&#946;, &#963;^2|y)</data>
      <data key="d6">e7edd8b2874a350779ae20f1ecdf4733,f632f01188d2c6e3091a965580cb4600</data>
    </edge>
    <edge source="BETA" target="EB">
      <data key="d4">1.0</data>
      <data key="d5">The expectation of Eb is influenced by the parameter Beta through the calculation X&#946;</data>
      <data key="d6">5a0d392715f06d5e873f45ae06aa729a</data>
    </edge>
    <edge source="BETA" target="SALES_VOLUME">
      <data key="d4">2.0</data>
      <data key="d5">&#946; is the coefficient of the price variable in the linear regression model, and is used to predict the change in sales volume for a unit change in price.
Beta represents the effect of price on sales volume for brand A in the regression model</data>
      <data key="d6">7a605c3b689bec7ab2c46df9c123e3f3,b6870535f3975c49d45e62fbe475f198</data>
    </edge>
    <edge source="BETA" target="BRAND_MODEL1">
      <data key="d4">1.0</data>
      <data key="d5">Beta is a parameter in the model Brand.model1, representing the coefficient of the price variable</data>
      <data key="d6">ee295ebc4c2d6a2a5c738796fcc2ab71</data>
    </edge>
    <edge source="BETA" target="SALESJ">
      <data key="d4">1.0</data>
      <data key="d5">beta is a parameter in the model for Salesj, representing the effect of price</data>
      <data key="d6">228bdca7843406def245d755e8df49f6</data>
    </edge>
    <edge source="BETA" target="BRAND_MODEL2">
      <data key="d4">1.0</data>
      <data key="d5">Beta is the parameter for price in Brand.model2, with a specific estimate</data>
      <data key="d6">93da9813e10a119798de6982977f1239</data>
    </edge>
    <edge source="BETA" target="SALESI">
      <data key="d4">1.0</data>
      <data key="d5">beta is the slope parameter for price in the salesi vector</data>
      <data key="d6">925e17c26fb7d979f52538f4632333e7</data>
    </edge>
    <edge source="BETA" target="PARALLEL_LINES_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Beta is a parameter in the parallel lines model</data>
      <data key="d6">0cb40986e6c2bb439e1ffcaae2df96ac</data>
    </edge>
    <edge source="BETA" target="PRICE_J">
      <data key="d4">1.0</data>
      <data key="d5">Beta (&#946;) is the coefficient for price j in the regression model</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="NN" target="IN">
      <data key="d4">1.0</data>
      <data key="d5">In is part of the covariance matrix of the multivariate normal distribution Nn</data>
      <data key="d6">67e4c1866b0c6e162e6e3317949e8da9</data>
    </edge>
    <edge source="NN" target="BETA_HAT">
      <data key="d4">5.0</data>
      <data key="d5">Nn is the distribution of Y, which is used in the likelihood function L to calculate &#946;b
Nn is the distribution of Y, which influences the distribution of Beta hat (&#946;b)
Nn is the distribution of Y, which influences the distribution of Beta hat (&#946;b)
Nn is the distribution of Y, which influences the distribution of Beta hat (&#946;b)
Nn is the distribution of the error term &#1013;, which influences the distribution of Beta hat (&#946;b)</data>
      <data key="d6">3d357cfa3ef0d00f49cf4acaeac1c9d1,45f31b040576e9f3b4def6d0466cc016,542f546c5a131196e4701fb33c9b1dee,9dddcd96af7b557e578b3f5f36efacd7,b70a75a6412b2e5c44af50734844f4be</data>
    </edge>
    <edge source="IN" target="N">
      <data key="d4">1.0</data>
      <data key="d5">The dimension n is the size of the identity matrix In</data>
      <data key="d6">e4f14e6785c6d7b7469e695aaeb170d0</data>
    </edge>
    <edge source="IN" target="BETA_HAT">
      <data key="d4">6.0</data>
      <data key="d5">In is part of the covariance matrix used in the calculation of Beta hat (&#946;b)
In is part of the covariance matrix of the distribution of Y, which is used in the MLE calculation of &#946;b
In is part of the covariance matrix of the distribution of Beta hat (&#946;b)
In is part of the covariance matrix of the distribution of Y, which influences the distribution of Beta hat (&#946;b)
In is part of the covariance matrix of the distribution of Beta hat (&#946;b)
In is part of the covariance matrix of the distribution of Beta hat (&#946;b)</data>
      <data key="d6">3d357cfa3ef0d00f49cf4acaeac1c9d1,45f31b040576e9f3b4def6d0466cc016,542f546c5a131196e4701fb33c9b1dee,9dddcd96af7b557e578b3f5f36efacd7,b70a75a6412b2e5c44af50734844f4be,e7edd8b2874a350779ae20f1ecdf4733</data>
    </edge>
    <edge source="IN" target="H">
      <data key="d4">3.0</data>
      <data key="d5">Properties of the hat matrix H are linked to the identity matrix In, particularly in the calculation of the residuals and in the properties of (In - H)
Matrix H is used in the calculation of (In - H), which is also a symmetric and idempotent matrix
The trace of In minus the trace of H is equal to n - p</data>
      <data key="d6">46629f2efc6c82e81265a131b4bab2ee,bd98ac7b4b5df4f63e7ecc8f4a821f57,f470791d2d3fedede166f9bb11598c9c</data>
    </edge>
    <edge source="IN" target="YC">
      <data key="d4">2.0</data>
      <data key="d5">In is part of the covariance matrix of the distribution of Yc
In is part of the covariance matrix of Yc</data>
      <data key="d6">679722cf8ce5ce5aee4e379528470efe,74d190f10bf6e6936242ca3cdfc4a09f</data>
    </edge>
    <edge source="IN" target="EB">
      <data key="d4">3.0</data>
      <data key="d5">In is used in the calculation of the residual vector Eb as (In - H)Y
In is used in the calculation of EB as part of the transformation (In - H)
EB is derived from In by applying the matrix (In - H)</data>
      <data key="d6">1da117a2f92b2db00290d2a0bfc06beb,74d190f10bf6e6936242ca3cdfc4a09f,7d074208b1259e7d84f9f870d3828bb6</data>
    </edge>
    <edge source="XK" target="LINEAR_PREDICTOR">
      <data key="d4">1.0</data>
      <data key="d5">Xk is one of the explanatory variables whose value xk is used in the linear predictor to determine the mean of the response</data>
      <data key="d6">6a47154bf457c25f22c3cf9f649c5db0</data>
    </edge>
    <edge source="XN" target="BETA_0_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Xn is used in the calculation of Beta_0 hat (b&#946;0) as part of the least squares estimation</data>
      <data key="d6">3fdeeb7593174f5e8a9cff55a7cd92e3</data>
    </edge>
    <edge source="XN" target="BETA_1_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Xn is used in the calculation of Beta_1 hat (b&#946;1) as part of the least squares estimation</data>
      <data key="d6">3fdeeb7593174f5e8a9cff55a7cd92e3</data>
    </edge>
    <edge source="XN" target="S">
      <data key="d4">1.0</data>
      <data key="d5">Xn is a function used in the function S(&#946;) to sum over the squared residuals</data>
      <data key="d6">10ac76f99674a01ca0f4a55586dea07e</data>
    </edge>
    <edge source="BETAK" target="LOG_LIKELIHOOD">
      <data key="d4">1.0</data>
      <data key="d5">The log-likelihood function depends on Beta_k, one of the slope parameters</data>
      <data key="d6">87b717ba065d6d7c7431af284137eb12</data>
    </edge>
    <edge source="EPSILONJ" target="N">
      <data key="d4">1.0</data>
      <data key="d5">N is the distribution of Epsilonj</data>
      <data key="d6">b5d0a103e1f34a00aef67fedd0e8c693</data>
    </edge>
    <edge source="EPSILONJ" target="EPSILON_BJ">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon j (&#1013;j) is the error term that the residual &#1013;bj estimates, indicating the similarity between the error and the residual</data>
      <data key="d6">e6f79ceb0df54119a4dc71b2162ac50b</data>
    </edge>
    <edge source="EPSILONJ" target="SALESI">
      <data key="d4">1.0</data>
      <data key="d5">epsilonj is the error term for the jth store, affecting salesi</data>
      <data key="d6">925e17c26fb7d979f52538f4632333e7</data>
    </edge>
    <edge source="N" target="ERRORS">
      <data key="d4">2.0</data>
      <data key="d5">Errors are assumed to follow the normal distribution N
Errors are assumed to follow the normal distribution N(0, &#963;^2)</data>
      <data key="d6">25fce1af816975003128126b5cfea73b,d738df7d83784c8a41b3948271c537b6</data>
    </edge>
    <edge source="N" target="NORMAL_DISTRIBUTION">
      <data key="d4">1.0</data>
      <data key="d5">N data points are simulated from the normal distribution</data>
      <data key="d6">ee22e1f5947947f9bd3f7f8922745e48</data>
    </edge>
    <edge source="N" target="T2_DISTRIBUTION">
      <data key="d4">1.0</data>
      <data key="d5">N data points are also simulated from the t2 distribution</data>
      <data key="d6">ee22e1f5947947f9bd3f7f8922745e48</data>
    </edge>
    <edge source="N" target="BETA_HAT_1">
      <data key="d4">1.0</data>
      <data key="d5">Sample size N is used in the calculation of Beta_hat_1 (b&#946;1)</data>
      <data key="d6">8f7a05b6d231105a6194eebdb2df372e</data>
    </edge>
    <edge source="N" target="XTX">
      <data key="d4">1.0</data>
      <data key="d5">N is used in the calculation of the elements of the matrix XTX</data>
      <data key="d6">56ff186fc629e1e42f2759fc4b984199</data>
    </edge>
    <edge source="N" target="L">
      <data key="d4">1.0</data>
      <data key="d5">N is used in the calculation of the likelihood function L</data>
      <data key="d6">e7edd8b2874a350779ae20f1ecdf4733</data>
    </edge>
    <edge source="N" target="SIGMA_HAT_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">N is used in the calculation of the unbiased estimator &#963;b^2 for the variance</data>
      <data key="d6">6648f0d6deed51fb4fb25e6992a71ddf</data>
    </edge>
    <edge source="N" target="S2">
      <data key="d4">2.0</data>
      <data key="d5">The total number of observations (n) is used in the calculation of the unbiased estimator s^2
N is the total number of observations, which is used in the calculation of the unbiased estimate s^2</data>
      <data key="d6">9923e77ac6b3de95cb5026bc5e7fe8c0,fc5b725f3c662c5471af20efdcc2dbff</data>
    </edge>
    <edge source="N" target="HII">
      <data key="d4">1.0</data>
      <data key="d5">The leverage hii is bounded between 0 and 1 for all i from 1 to n</data>
      <data key="d6">0b650eb2f1dcd603b64fec3c4b5cd24b</data>
    </edge>
    <edge source="N" target="DI">
      <data key="d4">1.0</data>
      <data key="d5">Di is calculated using n, the number of observations in the regression model</data>
      <data key="d6">98d6982108f2d42fe0437bff8c666e17</data>
    </edge>
    <edge source="N" target="COOKS_DISTANCE">
      <data key="d4">1.0</data>
      <data key="d5">n is used in the calculation of Cook's distance (Di) and in the F-distribution threshold</data>
      <data key="d6">09391efd3b8c510205098b548bc8dc74</data>
    </edge>
    <edge source="N" target="BRAND_MODEL3">
      <data key="d4">1.0</data>
      <data key="d5">Number of observations (n=96) is used in the fitting of the linear model Brand_model3</data>
      <data key="d6">6a6f85d0a6e46196ab3a901fcc82a720</data>
    </edge>
    <edge source="YN" target="BETA_K">
      <data key="d4">1.0</data>
      <data key="d5">Yn is related to BETA_k as part of the linear regression model for the nth observation</data>
      <data key="d6">8f1d95acff56e1633dceb775fa713174</data>
    </edge>
    <edge source="YN" target="EPSILON_N">
      <data key="d4">1.0</data>
      <data key="d5">Yn is related to EPSILON_n as part of the linear regression model for the nth observation</data>
      <data key="d6">8f1d95acff56e1633dceb775fa713174</data>
    </edge>
    <edge source="YN" target="HOMOSCEDASTICITY">
      <data key="d4">1.0</data>
      <data key="d5">The response variables Y1, ..., Yn are assumed to have constant variance, which is a requirement for homoscedasticity</data>
      <data key="d6">0da640a09a395a50b6e16e047fa8d0d6</data>
    </edge>
    <edge source="YN" target="NORMALITY">
      <data key="d4">1.0</data>
      <data key="d5">The response variables Y1, ..., Yn are assumed to have a normal distribution, which is a requirement for the normality assumption</data>
      <data key="d6">0da640a09a395a50b6e16e047fa8d0d6</data>
    </edge>
    <edge source="YN" target="INDEPENDENCE">
      <data key="d4">1.0</data>
      <data key="d5">The response variables Y1, ..., Yn are assumed to be independent, although they are not identically distributed</data>
      <data key="d6">0da640a09a395a50b6e16e047fa8d0d6</data>
    </edge>
    <edge source="BETA_K" target="LINEAR_PREDICTOR">
      <data key="d4">2.0</data>
      <data key="d5">Beta_k (&#946;k) is the coefficient of Xk in the linear predictor
Beta_k is part of the linear predictor, contributing to the slope of the mean function of the response</data>
      <data key="d6">67e4c1866b0c6e162e6e3317949e8da9,6a47154bf457c25f22c3cf9f649c5db0</data>
    </edge>
    <edge source="LINEAR_PREDICTOR" target="X_1">
      <data key="d4">1.0</data>
      <data key="d5">X_1 is an explanatory variable that, along with its coefficient Beta_1, contributes to the linear predictor</data>
      <data key="d6">67e4c1866b0c6e162e6e3317949e8da9</data>
    </edge>
    <edge source="LINEAR_PREDICTOR" target="X_K">
      <data key="d4">1.0</data>
      <data key="d5">X_k is an explanatory variable that, along with its coefficient Beta_k, contributes to the linear predictor</data>
      <data key="d6">67e4c1866b0c6e162e6e3317949e8da9</data>
    </edge>
    <edge source="E_Y" target="LOG_Y">
      <data key="d4">1.0</data>
      <data key="d5">The expected value of Y can be calculated from log(Y) using the formula exp(&#181; + &#963;^2/2)</data>
      <data key="d6">21e429490eeefe7d9c245058fd48ca68</data>
    </edge>
    <edge source="X_BETA" target="ALPHA">
      <data key="d4">1.0</data>
      <data key="d5">X_beta is the design matrix of the original model parameterisation, which is transformed into X_alpha</data>
      <data key="d6">5609007c6229060ffc85d8056a7fefde</data>
    </edge>
    <edge source="EPSILON_J" target="BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">&#1013;j is the error term that contributes to the calculation of Beta hat (&#946;b) in the simple linear regression model</data>
      <data key="d6">d14413709de2897231aaa83be3aa346f</data>
    </edge>
    <edge source="EPSILON_J" target="STORE_J">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon j (&#1013;j) is the error term associated with store j in the regression model</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="P" target="S_HAT_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">P is used in the calculation of the unbiased estimator s^2(Y) for the error variance</data>
      <data key="d6">6648f0d6deed51fb4fb25e6992a71ddf</data>
    </edge>
    <edge source="P" target="S2">
      <data key="d4">2.0</data>
      <data key="d5">The number of parameters (p) is used in the calculation of the unbiased estimator s^2
P is the number of parameters, which is used in the calculation of the unbiased estimate s^2</data>
      <data key="d6">9923e77ac6b3de95cb5026bc5e7fe8c0,fc5b725f3c662c5471af20efdcc2dbff</data>
    </edge>
    <edge source="P" target="HII">
      <data key="d4">2.0</data>
      <data key="d5">The average leverage hii over all observations is equal to p/n
The sum of all leverages hii divided by the number of observations n equals the number of parameters p divided by n</data>
      <data key="d6">0b650eb2f1dcd603b64fec3c4b5cd24b,bd98ac7b4b5df4f63e7ecc8f4a821f57</data>
    </edge>
    <edge source="P" target="LEVERAGE">
      <data key="d4">1.0</data>
      <data key="d5">Leverage is used to identify influential observations, with a threshold related to p/n</data>
      <data key="d6">bd05fe6a05f9a13d33c4f1b5a771ada5</data>
    </edge>
    <edge source="P" target="COOKS_DISTANCE">
      <data key="d4">2.0</data>
      <data key="d5">Cook's distance uses the number of parameters p in the regression model to calculate the influence of an observation
p is used in the calculation of Cook's distance (Di) and in the F-distribution threshold</data>
      <data key="d6">09391efd3b8c510205098b548bc8dc74,9e2ebbb113c00fa43f0af3c0696baf95</data>
    </edge>
    <edge source="P" target="DI">
      <data key="d4">2.0</data>
      <data key="d5">Di is calculated using P, the number of parameters in the regression model
p is part of the variable representing the number of predictors in the regression model that contributes to the Cook's distance Di</data>
      <data key="d6">0443ab5e20a4f6b2f243c989ef6c723a,98d6982108f2d42fe0437bff8c666e17</data>
    </edge>
    <edge source="RESPONSE_RANDOM_VECTOR" target="MODEL_DESCRIPTION">
      <data key="d4">1.0</data>
      <data key="d5">The response random vector is a key component of the model described in vector/matrix notation</data>
      <data key="d6">6616e10c85e86291147e72776854b8a2</data>
    </edge>
    <edge source="MODEL_DESCRIPTION" target="ESTIMATED_COEFFICIENTS">
      <data key="d4">1.0</data>
      <data key="d5">The model description includes the interpretation of the estimated coefficients of the model</data>
      <data key="d6">6616e10c85e86291147e72776854b8a2</data>
    </edge>
    <edge source="MODEL_DESCRIPTION" target="TEXTBOOK_RECOMMENDATION">
      <data key="d4">1.0</data>
      <data key="d5">The textbook recommendation provides further reading on the topics covered in the model description</data>
      <data key="d6">6616e10c85e86291147e72776854b8a2</data>
    </edge>
    <edge source="GRAPHICAL_EXPLORATION" target="ANSCOMBE_S_QUARTET">
      <data key="d4">1.0</data>
      <data key="d5">Anscombe's Quartet illustrates the importance of graphical exploration in statistical analysis</data>
      <data key="d6">6616e10c85e86291147e72776854b8a2</data>
    </edge>
    <edge source="GRAPHICAL_EXPLORATION" target="ANSCOMBE_QUARTET">
      <data key="d4">1.0</data>
      <data key="d5">Anscombe's Quartet illustrates the importance of graphical exploration in statistical analysis</data>
      <data key="d6">9f335f1ecb85a1427df926df8bb1e89f</data>
    </edge>
    <edge source="DESIGN_MATRIX" target="QUADRATIC_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">The design matrix is used in the matrix notation of the model equations of the quadratic regression model</data>
      <data key="d6">e5131a1158e58f1b7b44b21ced7b6f60</data>
    </edge>
    <edge source="DESIGN_MATRIX" target="PARAMETER_VECTOR">
      <data key="d4">1.0</data>
      <data key="d5">The design matrix (X) is multiplied by the parameter vector (&#946;) to calculate the linear predictor for the given dataset, which is a key component of the linear model.</data>
      <data key="d6">b9af17718641389ba07f53be13f31f8c</data>
    </edge>
    <edge source="DESIGN_MATRIX" target="BRAND_A">
      <data key="d4">2.0</data>
      <data key="d5">Brand A is represented in the design matrix as a column of indicator variables for stores of Brand A
Brand A is represented in the design matrix as a column for stores of Brand A</data>
      <data key="d6">06199787dd7f75f7338dd24d4f3dc26e,48971100deb5bb374a41c1f2b7b2a86a</data>
    </edge>
    <edge source="DESIGN_MATRIX" target="BRAND_B">
      <data key="d4">2.0</data>
      <data key="d5">Brand B is represented in the design matrix as a column of indicator variables for stores of Brand B
Brand B is represented in the design matrix as a column for stores of Brand B</data>
      <data key="d6">06199787dd7f75f7338dd24d4f3dc26e,48971100deb5bb374a41c1f2b7b2a86a</data>
    </edge>
    <edge source="DESIGN_MATRIX" target="BRAND_C">
      <data key="d4">2.0</data>
      <data key="d5">Brand C is represented in the design matrix as a column of indicator variables for stores of Brand C
Brand C is represented in the design matrix as a column for stores of Brand C</data>
      <data key="d6">06199787dd7f75f7338dd24d4f3dc26e,48971100deb5bb374a41c1f2b7b2a86a</data>
    </edge>
    <edge source="DESIGN_MATRIX" target="ALPHA_B">
      <data key="d4">1.0</data>
      <data key="d5">Alpha B is represented in the design matrix for the re-parameterised model</data>
      <data key="d6">06199787dd7f75f7338dd24d4f3dc26e</data>
    </edge>
    <edge source="DESIGN_MATRIX" target="ALPHA_C">
      <data key="d4">1.0</data>
      <data key="d5">Alpha C is represented in the design matrix for the re-parameterised model</data>
      <data key="d6">06199787dd7f75f7338dd24d4f3dc26e</data>
    </edge>
    <edge source="DESIGN_MATRIX" target="MU">
      <data key="d4">1.0</data>
      <data key="d5">Mu is represented in the design matrix as the intercept for Brand A stores</data>
      <data key="d6">06199787dd7f75f7338dd24d4f3dc26e</data>
    </edge>
    <edge source="DESIGN_MATRIX" target="EXERCISE_26">
      <data key="d4">1.0</data>
      <data key="d5">Exercise 26 asks for the design matrix of a specific model, indicating the relevance of design matrices in exercises</data>
      <data key="d6">b0ca3e6c22c4cf884d03b1f6f82be5df</data>
    </edge>
    <edge source="PARAMETER_VECTOR" target="DESIGN_MATRIX_X">
      <data key="d4">1.0</data>
      <data key="d5">The parameter vector is associated with the design matrix X, as it contains the coefficients for the intercept and the independent variables</data>
      <data key="d6">c103c6d096d52868eda26d991194b5f2</data>
    </edge>
    <edge source="ANSCOMBE_QUARTET" target="STATISTICAL_ANALYSIS">
      <data key="d4">1.0</data>
      <data key="d5">Anscombe's Quartet is an example used in statistical analysis to demonstrate the limitations of numerical methods</data>
      <data key="d6">9f335f1ecb85a1427df926df8bb1e89f</data>
    </edge>
    <edge source="ANSCOMBE_QUARTET" target="SUMMARY_STATISTICS">
      <data key="d4">1.0</data>
      <data key="d5">Anscombe's Quartet has the same summary statistics for all four datasets</data>
      <data key="d6">9f335f1ecb85a1427df926df8bb1e89f</data>
    </edge>
    <edge source="ANSCOMBE_QUARTET" target="DATASET_2">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 2 is one of the datasets in Anscombe&#8217;s quartet, which is a set of four datasets that illustrate the importance of graphical data analysis</data>
      <data key="d6">87ba4f416a28aabc3b396908f5913b54</data>
    </edge>
    <edge source="ANSCOMBE" target="AMERICAN_STATISTICIAN">
      <data key="d4">1.0</data>
      <data key="d5">Anscombe is the author of the paper published in The American Statistician</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="ANSCOMBE" target="DOI">
      <data key="d4">1.0</data>
      <data key="d5">Anscombe's paper has a DOI that is used for referencing</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="DATASET_1" target="SAMPLE_MEAN_X">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 1 has a specific sample mean of x</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="DATASET_1" target="SAMPLE_VARIANCE_X">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 1 has a specific sample variance of x</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="DATASET_1" target="SAMPLE_MEAN_Y">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 1 has a specific sample mean of y</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="DATASET_1" target="SAMPLE_VARIANCE_Y">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 1 has a specific sample variance of y</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="DATASET_1" target="CORRELATION_COEFFICIENT">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 1 has a specific correlation coefficient of x and y</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="DATASET_1" target="FITTED_REGRESSION_LINE">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 1 has a specific fitted regression line</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="DATASET_2" target="SAMPLE_MEAN_X">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 2 has a specific sample mean of x</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="DATASET_2" target="SAMPLE_VARIANCE_X">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 2 has a specific sample variance of x</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="DATASET_2" target="SAMPLE_MEAN_Y">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 2 has a specific sample mean of y</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="DATASET_2" target="SAMPLE_VARIANCE_Y">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 2 has a specific sample variance of y</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="DATASET_2" target="CORRELATION_COEFFICIENT">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 2 has a specific correlation coefficient of x and y</data>
      <data key="d6">2a5997c641e47fc6c32ebf81101c54e0</data>
    </edge>
    <edge source="DATASET_2" target="SIMPLE_LINEAR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 2 suggests that a simple linear model is not adequate due to the curved relationship visible in the data</data>
      <data key="d6">84ffe1b8496dc660c47248c9f7b5bdea</data>
    </edge>
    <edge source="DATASET_2" target="PARABOLA">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 2 exhibits a parabolic relationship between the response and the explanatory variable, which can be modeled using polynomial regression</data>
      <data key="d6">87ba4f416a28aabc3b396908f5913b54</data>
    </edge>
    <edge source="DATASET_3" target="OUTLIER">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 3 contains an outlier that has a strong influence on the fitted line</data>
      <data key="d6">84ffe1b8496dc660c47248c9f7b5bdea</data>
    </edge>
    <edge source="DATASET_3" target="SIMPLE_LINEAR_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 3 challenges the adequacy of a simple linear model due to its unique data structure</data>
      <data key="d6">b8ec334f8c87bf1d9cb6043fa1a64214</data>
    </edge>
    <edge source="DATASET_4" target="OUTLIER">
      <data key="d4">1.0</data>
      <data key="d5">Dataset 4 contains an outlier (a single unusual data point) that determines the slope of the line</data>
      <data key="d6">84ffe1b8496dc660c47248c9f7b5bdea</data>
    </edge>
    <edge source="DATASET_4" target="SIMPLE_LINEAR_MODEL">
      <data key="d4">2.0</data>
      <data key="d5">Dataset 4 raises questions about the applicability of a simple linear model due to the unique x-value
Dataset 4 questions the applicability of a simple linear model because the slope is heavily influenced by a single data point</data>
      <data key="d6">84ffe1b8496dc660c47248c9f7b5bdea,b8ec334f8c87bf1d9cb6043fa1a64214</data>
    </edge>
    <edge source="SIMPLE_LINEAR_MODEL" target="ANSCOME_QUARTET">
      <data key="d4">1.0</data>
      <data key="d5">Anscombe's quartet demonstrates the limitations of simple linear models in capturing the true nature of data relationships</data>
      <data key="d6">b8ec334f8c87bf1d9cb6043fa1a64214</data>
    </edge>
    <edge source="SIMPLE_LINEAR_MODEL" target="DATASAUROS_DOZEN">
      <data key="d4">1.0</data>
      <data key="d5">The Datasaurus Dozen further illustrates the importance of visualizing data and the limitations of simple linear models</data>
      <data key="d6">b8ec334f8c87bf1d9cb6043fa1a64214</data>
    </edge>
    <edge source="HISTOGRAMS" target="SCATTERPLOTS">
      <data key="d4">1.0</data>
      <data key="d5">Histograms and scatterplots are both tools used for exploratory data analysis, helping to visualize the distribution and relationships in data</data>
      <data key="d6">87ba4f416a28aabc3b396908f5913b54</data>
    </edge>
    <edge source="HISTOGRAMS" target="VOLUMEI">
      <data key="d4">1.0</data>
      <data key="d5">Histograms include the distribution of Volumei for initial exploratory analysis</data>
      <data key="d6">60cc94e681863c9fcc6f9be1e500f840</data>
    </edge>
    <edge source="HISTOGRAMS" target="DIAMETERI">
      <data key="d4">1.0</data>
      <data key="d5">Histograms include the distribution of Diameteri for initial exploratory analysis</data>
      <data key="d6">60cc94e681863c9fcc6f9be1e500f840</data>
    </edge>
    <edge source="HISTOGRAMS" target="HEIGHTI">
      <data key="d4">1.0</data>
      <data key="d5">Histograms include the distribution of Heighti for initial exploratory analysis</data>
      <data key="d6">60cc94e681863c9fcc6f9be1e500f840</data>
    </edge>
    <edge source="QUADRATIC_REGRESSION" target="ERRORS">
      <data key="d4">1.0</data>
      <data key="d5">Errors are part of the assumptions of the quadratic regression model. They are assumed to be iid (independent and identically distributed) N (0, &#963;^2)</data>
      <data key="d6">e5131a1158e58f1b7b44b21ced7b6f60</data>
    </edge>
    <edge source="QUADRATIC_REGRESSION" target="QUADRATIC_TERM">
      <data key="d4">1.0</data>
      <data key="d5">Quadratic term is part of the systematic component of the quadratic regression model. It is used to model the curvature in the relationship between the predictor and the response variable</data>
      <data key="d6">e5131a1158e58f1b7b44b21ced7b6f60</data>
    </edge>
    <edge source="QUADRATIC_REGRESSION" target="SUM_OF_SQUARED_DISTANCES">
      <data key="d4">1.0</data>
      <data key="d5">The sum of squared vertical distances between the observations and the parabola given by &#946;0 + &#946;1x + &#946;2x^2 is the criterion used in least squares estimation to determine the parameters of the quadratic regression model</data>
      <data key="d6">e5131a1158e58f1b7b44b21ced7b6f60</data>
    </edge>
    <edge source="QUADRATIC_REGRESSION" target="MODEL_EQUATIONS">
      <data key="d4">1.0</data>
      <data key="d5">Model equations in (2.1) expressed in matrix notation are part of the quadratic regression model</data>
      <data key="d6">e5131a1158e58f1b7b44b21ced7b6f60</data>
    </edge>
    <edge source="QUADRATIC_REGRESSION" target="COMPLEX_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">A quadratic regression model is an example of a complex model that can be used when a simple linear regression does not adequately describe the relationship</data>
      <data key="d6">15c7b5750483a382ce59751008e86751</data>
    </edge>
    <edge source="PARAMETERS" target="SUM_OF_SQUARED_DISTANCES">
      <data key="d4">1.0</data>
      <data key="d5">The parameters in a model are chosen to minimize the sum of squared distances, a metric used in least squares estimation to assess the fit of the model to the data</data>
      <data key="d6">87ba4f416a28aabc3b396908f5913b54</data>
    </edge>
    <edge source="PARAMETERS" target="FITTING_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Fitting the model involves finding the best set of values for the parameters</data>
      <data key="d6">bb31f1c77bbba73300f735a100086a67</data>
    </edge>
    <edge source="ERRORS" target="SEQUENTIAL_DATA">
      <data key="d4">1.0</data>
      <data key="d5">Sequential data can lead to time-correlated errors if the data points are not independent</data>
      <data key="d6">7cd6069e88e81548a237fa937adfecc6</data>
    </edge>
    <edge source="ERRORS" target="SPATIAL_DATA">
      <data key="d4">1.0</data>
      <data key="d5">Spatial data can lead to correlated errors if the data points are not independent</data>
      <data key="d6">7cd6069e88e81548a237fa937adfecc6</data>
    </edge>
    <edge source="ERRORS" target="HOMOSCEDASTICITY">
      <data key="d4">1.0</data>
      <data key="d5">Homoscedasticity is a property of the errors in a regression model, indicating that they have constant variance</data>
      <data key="d6">e361ac139c268d5c3f3623f920e68af2</data>
    </edge>
    <edge source="ERRORS" target="INDEPENDENCE">
      <data key="d4">1.0</data>
      <data key="d5">Independence is a property of the errors in a regression model, indicating that they are independent of each other</data>
      <data key="d6">e361ac139c268d5c3f3623f920e68af2</data>
    </edge>
    <edge source="ERRORS" target="NORMALITY">
      <data key="d4">1.0</data>
      <data key="d5">Normality is a property of the errors in a regression model, indicating that they have a normal distribution</data>
      <data key="d6">e361ac139c268d5c3f3623f920e68af2</data>
    </edge>
    <edge source="ERRORS" target="REMEDIAL_ACTIONS">
      <data key="d4">1.0</data>
      <data key="d5">Remedial actions are taken to address violations of the modelling assumptions, which can be indicated by the errors</data>
      <data key="d6">e361ac139c268d5c3f3623f920e68af2</data>
    </edge>
    <edge source="PLR_MODEL" target="FIGURE_2_5">
      <data key="d4">1.0</data>
      <data key="d5">The quadratic regression model plr.model is visually represented by the parabola of best fit in Figure 2.5</data>
      <data key="d6">084dadebfca8bcb6377c205c45bee295</data>
    </edge>
    <edge source="PLOT" target="SMOOTHING_CURVE">
      <data key="d4">1.0</data>
      <data key="d5">A smoothing curve is often added to a plot to help identify trends or patterns in the data</data>
      <data key="d6">b9ec8a6c7960cc6196ec94fd976f05b0</data>
    </edge>
    <edge source="PLOT" target="RESIDUAL_PLOTS">
      <data key="d4">1.0</data>
      <data key="d5">Residual plots are derived from a plot of the data, used to check the assumptions of a regression model</data>
      <data key="d6">b9ec8a6c7960cc6196ec94fd976f05b0</data>
    </edge>
    <edge source="ERROR_TERM" target="SALES_VOLUME">
      <data key="d4">1.0</data>
      <data key="d5">The error term represents the difference between the observed sales volume and the predicted sales volume, and is an important component of the linear regression model.</data>
      <data key="d6">7a605c3b689bec7ab2c46df9c123e3f3</data>
    </edge>
    <edge source="YI" target="XI">
      <data key="d4">1.0</data>
      <data key="d5">Yi is a function of the explanatory variable xi for the ith unit of observation in the quadratic regression model</data>
      <data key="d6">6c1684ed2a4840576c6b0f4d1a3a482f</data>
    </edge>
    <edge source="YI" target="EXERCISE_7">
      <data key="d4">1.0</data>
      <data key="d5">Exercise 7 involves the quadratic regression model equation for Yi</data>
      <data key="d6">6c1684ed2a4840576c6b0f4d1a3a482f</data>
    </edge>
    <edge source="YI" target="EPSILONI">
      <data key="d4">2.0</data>
      <data key="d5">Yi includes the random error term Epsiloni (&#1013;i) in all models, representing the unexplained variation
Yi includes the error term epsiloni, which is added to the linear combination before exponentiation</data>
      <data key="d6">34fceaaf7d835828b5ee2327325c37f8,90ed6030c5a5a0764b7dcd4115b4d4d3</data>
    </edge>
    <edge source="YI" target="XI,1">
      <data key="d4">1.0</data>
      <data key="d5">Yi is a function of xi,1 in various forms in the models, representing the relationship between the response and explanatory variable</data>
      <data key="d6">90ed6030c5a5a0764b7dcd4115b4d4d3</data>
    </edge>
    <edge source="YI" target="XI,2">
      <data key="d4">1.0</data>
      <data key="d5">Yi is a function of xi,2 in the logarithmic form in the fifth model, representing the relationship between the response and the logarithmic explanatory variable</data>
      <data key="d6">90ed6030c5a5a0764b7dcd4115b4d4d3</data>
    </edge>
    <edge source="YI" target="ZI">
      <data key="d4">1.0</data>
      <data key="d5">Zi and Yi are the explanatory and response variables, respectively, in the dataset for Exercise 9</data>
      <data key="d6">22093a562f5f05dc9891b45ab9bcbea8</data>
    </edge>
    <edge source="YI" target="EPSILON_I">
      <data key="d4">2.0</data>
      <data key="d5">The error term Epsilon_i (&#1013;i) represents the deviation of the observed log-transformed response variable Yi from the expected value, contributing to the model's uncertainty.
Epsilon_i is the error term for the ith observation, the difference between the observed and predicted Yi</data>
      <data key="d6">0fbc9037ca9a440e79e9ac05664b9b3d,90b7e0427699cc1bb461e37939935138</data>
    </edge>
    <edge source="YI" target="EXP">
      <data key="d4">1.0</data>
      <data key="d5">The exponential function Exp is used to transform the log-transformed response variable Yi back to its original scale, where the errors act multiplicatively.</data>
      <data key="d6">0fbc9037ca9a440e79e9ac05664b9b3d</data>
    </edge>
    <edge source="YI" target="MULTIPLICATIVE_ERRORS">
      <data key="d4">1.0</data>
      <data key="d5">In the original scale of the response variable Yi, the errors act multiplicatively rather than additively, reflecting the nature of the log-transformed model.</data>
      <data key="d6">0fbc9037ca9a440e79e9ac05664b9b3d</data>
    </edge>
    <edge source="YI" target="XI1">
      <data key="d4">1.0</data>
      <data key="d5">Yi is influenced by xi1, one of the predictor variables in the model</data>
      <data key="d6">34fceaaf7d835828b5ee2327325c37f8</data>
    </edge>
    <edge source="YI" target="XI2">
      <data key="d4">1.0</data>
      <data key="d5">Yi is influenced by xi2, one of the predictor variables in the model</data>
      <data key="d6">34fceaaf7d835828b5ee2327325c37f8</data>
    </edge>
    <edge source="YI" target="E">
      <data key="d4">1.0</data>
      <data key="d5">The expectation of Yi is greater than the exponential of the expectation of the log of Yi, due to Jensen's inequality</data>
      <data key="d6">34fceaaf7d835828b5ee2327325c37f8</data>
    </edge>
    <edge source="YI" target="LOG">
      <data key="d4">1.0</data>
      <data key="d5">The log of Yi is used to transform the response variable in the model</data>
      <data key="d6">34fceaaf7d835828b5ee2327325c37f8</data>
    </edge>
    <edge source="YI" target="ZB0">
      <data key="d4">1.0</data>
      <data key="d5">zb0 is the prediction for the logged response, which is back-transformed to predict Yi in the original scale</data>
      <data key="d6">34fceaaf7d835828b5ee2327325c37f8</data>
    </edge>
    <edge source="YI" target="YB_I">
      <data key="d4">1.0</data>
      <data key="d5">Yi is the observed value corresponding to the predicted value Yb_i</data>
      <data key="d6">1da117a2f92b2db00290d2a0bfc06beb</data>
    </edge>
    <edge source="YI" target="EB">
      <data key="d4">1.0</data>
      <data key="d5">As hii approaches 1, Eb_i tends to zero, implying y_hat_i will tend to yi</data>
      <data key="d6">5a0d392715f06d5e873f45ae06aa729a</data>
    </edge>
    <edge source="YI" target="Y_HAT_I">
      <data key="d4">1.0</data>
      <data key="d5">When hii approaches 1, the fitted value y_hat_i will tend to the observed value yi</data>
      <data key="d6">2685edb9e8031c8ea725c43a40af22a8</data>
    </edge>
    <edge source="YI" target="RI">
      <data key="d4">1.0</data>
      <data key="d5">Yi is the observed response value, used in the calculation of the raw residual Eb_i</data>
      <data key="d6">90b7e0427699cc1bb461e37939935138</data>
    </edge>
    <edge source="XI" target="HII">
      <data key="d4">1.0</data>
      <data key="d5">The distance of the ith observation (xi) from the mean (x_bar) influences the leverage (hii) of the data point</data>
      <data key="d6">6ee02b38ae842fd5eac9a11c4fd6659f</data>
    </edge>
    <edge source="DBH" target="UFCWC">
      <data key="d4">1.0</data>
      <data key="d5">Dbh is a variable in the ufcwc dataset</data>
      <data key="d6">2d5cdecc342ddacd2c090f1838430cee</data>
    </edge>
    <edge source="DBH" target="CREEK_STAND">
      <data key="d4">1.0</data>
      <data key="d5">The diameter of the trees (Dbh) is measured at the Creek stand</data>
      <data key="d6">656dce234514b9db38b5b5616557c1e9</data>
    </edge>
    <edge source="DBH" target="FIGURE_2_6">
      <data key="d4">1.0</data>
      <data key="d5">Dbh is plotted against height in Figure 2.6</data>
      <data key="d6">656dce234514b9db38b5b5616557c1e9</data>
    </edge>
    <edge source="HEIGHT" target="UFCWC">
      <data key="d4">1.0</data>
      <data key="d5">Height is a variable in the ufcwc dataset</data>
      <data key="d6">2d5cdecc342ddacd2c090f1838430cee</data>
    </edge>
    <edge source="HEIGHT" target="CREEK_STAND">
      <data key="d4">1.0</data>
      <data key="d5">The height of the trees is measured at the Creek stand</data>
      <data key="d6">656dce234514b9db38b5b5616557c1e9</data>
    </edge>
    <edge source="HEIGHT" target="FIGURE_2_6">
      <data key="d4">1.0</data>
      <data key="d5">Height is plotted against Dbh in Figure 2.6</data>
      <data key="d6">656dce234514b9db38b5b5616557c1e9</data>
    </edge>
    <edge source="HEIGHT" target="TREE_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Tree.model predicts the Height of Western red cedar trees based on the log2-transformed Dbh.</data>
      <data key="d6">c619949b08fc2b7edf3a7635b46dc147</data>
    </edge>
    <edge source="HEIGHT" target="VOLUME">
      <data key="d4">2.0</data>
      <data key="d5">Volume is predicted to be proportional to the square of the diameter and the height of the tree
Volume is proportional to the square of the diameter and the height of the tree</data>
      <data key="d6">9611ea31ff53888971694cdefe806f64,efeeb664622c1ee594e6a08a8322ffe3</data>
    </edge>
    <edge source="HEIGHT" target="TREE">
      <data key="d4">1.0</data>
      <data key="d5">The height is a measurement taken from the tree</data>
      <data key="d6">9611ea31ff53888971694cdefe806f64</data>
    </edge>
    <edge source="UFCWC" target="ALR4">
      <data key="d4">1.0</data>
      <data key="d5">ufcwc is a dataset contained in the alr4 package</data>
      <data key="d6">2d5cdecc342ddacd2c090f1838430cee</data>
    </edge>
    <edge source="UFCWC" target="UNIVERSITY IDAHO EXPERIMENTAL FOREST">
      <data key="d4">1.0</data>
      <data key="d5">University Idaho Experimental Forest is the location where the data for the ufcwc dataset were collected</data>
      <data key="d6">2d5cdecc342ddacd2c090f1838430cee</data>
    </edge>
    <edge source="UFCWC" target="UPPER FLAT CREEK STAND">
      <data key="d4">1.0</data>
      <data key="d5">Upper Flat Creek stand is the specific location within the University Idaho Experimental Forest where the data for the ufcwc dataset were collected</data>
      <data key="d6">2d5cdecc342ddacd2c090f1838430cee</data>
    </edge>
    <edge source="ALR4" target="WEISBERG">
      <data key="d4">1.0</data>
      <data key="d5">Weisberg is the author of the book that contains the alr4 package</data>
      <data key="d6">2d5cdecc342ddacd2c090f1838430cee</data>
    </edge>
    <edge source="DIAMETER" target="TREE">
      <data key="d4">1.0</data>
      <data key="d5">The diameter is a measurement taken from the tree</data>
      <data key="d6">9611ea31ff53888971694cdefe806f64</data>
    </edge>
    <edge source="DIAMETER" target="VOLUME">
      <data key="d4">1.0</data>
      <data key="d5">Volume is proportional to the square of the diameter and the height of the tree</data>
      <data key="d6">9611ea31ff53888971694cdefe806f64</data>
    </edge>
    <edge source="LOG2" target="PREDICTOR">
      <data key="d4">1.0</data>
      <data key="d5">Log2 is applied to the predictor variable (Dbh) to transform it for use in the linear regression model. This transformation makes the interpretation of the coefficients easier.</data>
      <data key="d6">c619949b08fc2b7edf3a7635b46dc147</data>
    </edge>
    <edge source="BASE_2" target="LOG2_DIAMETERS">
      <data key="d4">1.0</data>
      <data key="d5">Base 2 is used to transform the diameters into log2-diameters for the linear regression model</data>
      <data key="d6">25fce1af816975003128126b5cfea73b</data>
    </edge>
    <edge source="TREE_MODEL" target="LOG2_DBH">
      <data key="d4">1.0</data>
      <data key="d5">Log2(Dbh) is a parameter in the tree.model</data>
      <data key="d6">25fce1af816975003128126b5cfea73b</data>
    </edge>
    <edge source="TREE_MODEL" target="PREDICTOR">
      <data key="d4">1.0</data>
      <data key="d5">Tree.model uses the log2-transformed Dbh as the predictor variable to predict the Height of Western red cedar trees.</data>
      <data key="d6">c619949b08fc2b7edf3a7635b46dc147</data>
    </edge>
    <edge source="NATURAL_LOGARITHM" target="LOG2_X_PLUS_1">
      <data key="d4">1.0</data>
      <data key="d5">Natural logarithm is related to the base 2 logarithm through the expression log2(x) + 1</data>
      <data key="d6">25fce1af816975003128126b5cfea73b</data>
    </edge>
    <edge source="PREDICTOR" target="INTERACTION">
      <data key="d4">1.0</data>
      <data key="d5">The concept of interaction is relevant when considering the relationship between two or more predictor variables in a regression model</data>
      <data key="d6">b0ca3e6c22c4cf884d03b1f6f82be5df</data>
    </edge>
    <edge source="VARIABLE" target="LOG_TRANSFORMED_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">The variable can be transformed using a logarithmic function to create a log-transformed variable, which may improve the fit of a statistical model</data>
      <data key="d6">ae1e66f5b64284090abc285c1d4389f5</data>
    </edge>
    <edge source="VARIABLE" target="FIT">
      <data key="d4">1.0</data>
      <data key="d5">The fit of a statistical model can be assessed by how well the model describes the relationship between variables</data>
      <data key="d6">ae1e66f5b64284090abc285c1d4389f5</data>
    </edge>
    <edge source="LOG_TRANSFORMED_VARIABLE" target="LOGARITHM_BASE_10">
      <data key="d4">1.0</data>
      <data key="d5">The logarithm with base 10 can be used to transform a variable, often for interpretation in statistical practice, especially when considering a ten-fold increase in the predictor variable</data>
      <data key="d6">ae1e66f5b64284090abc285c1d4389f5</data>
    </edge>
    <edge source="ARITHMETIC_OPERATORS" target="INHIBITOR_FUNCTION_I">
      <data key="d4">1.0</data>
      <data key="d5">Arithmetic operators can be treated as such in R by using the inhibitor function I(), allowing for proper mathematical operations in statistical models</data>
      <data key="d6">ae1e66f5b64284090abc285c1d4389f5</data>
    </edge>
    <edge source="WESTERN_RED_CEDAR_DATA" target="LOG_TRANSFORM">
      <data key="d4">2.0</data>
      <data key="d5">The Western red cedar data was used as an example where the log-transform was applied to the explanatory variable
The Western red cedar data example demonstrates the use of the log-transform on the explanatory variable to address certain forms of heteroscedasticity.</data>
      <data key="d6">0fbc9037ca9a440e79e9ac05664b9b3d,c03eb12d07d48f9e94260f08dae10cdf</data>
    </edge>
    <edge source="EXERCISE_8" target="PARAMETER_VECTOR_BETA">
      <data key="d4">1.0</data>
      <data key="d5">Exercise 8 involves the use of a parameter vector &#946;, which contains the parameters of a statistical model, such as &#946;0, &#946;1, and &#946;2</data>
      <data key="d6">ae1e66f5b64284090abc285c1d4389f5</data>
    </edge>
    <edge source="MODEL_ADEQUACY" target="PARAMETER_ESTIMATION">
      <data key="d4">1.0</data>
      <data key="d5">Model adequacy is a criterion that affects the choice of parameter estimation methods and the interpretation of results</data>
      <data key="d6">768c516c8b27fb9800427e848f02fc33</data>
    </edge>
    <edge source="MODEL_ADEQUACY" target="PARSIMONY">
      <data key="d4">1.0</data>
      <data key="d5">Parsimony is a criterion for model adequacy, guiding the selection of simpler models that are easier to interpret and predict</data>
      <data key="d6">768c516c8b27fb9800427e848f02fc33</data>
    </edge>
    <edge source="MODEL_ADEQUACY" target="PLAUSIBILITY">
      <data key="d4">1.0</data>
      <data key="d5">Plausibility is a criterion for model adequacy, ensuring that the model makes practical sense in the context of the data</data>
      <data key="d6">768c516c8b27fb9800427e848f02fc33</data>
    </edge>
    <edge source="MODEL_ADEQUACY" target="WASSERSTEIN_R">
      <data key="d4">1.0</data>
      <data key="d5">R. Wasserstein's article discusses the importance of model adequacy in statistical practice</data>
      <data key="d6">768c516c8b27fb9800427e848f02fc33</data>
    </edge>
    <edge source="PLAUSIBLE_MODELS" target="CHOSEN_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Plausible models are compared to choose the most appropriate one</data>
      <data key="d6">bb31f1c77bbba73300f735a100086a67</data>
    </edge>
    <edge source="CHOSEN_MODEL" target="QUESTIONS_OF_INTEREST">
      <data key="d4">1.0</data>
      <data key="d5">The chosen model is used to answer the questions of interest</data>
      <data key="d6">bb31f1c77bbba73300f735a100086a67</data>
    </edge>
    <edge source="GEORGE_BOX" target="WASSERSTEIN_PAPER">
      <data key="d4">1.0</data>
      <data key="d5">The Wasserstein paper provides more information about George Box</data>
      <data key="d6">bb31f1c77bbba73300f735a100086a67</data>
    </edge>
    <edge source="WASSERSTEIN_PAPER" target="SIGNIFICANCE_JOURNAL">
      <data key="d4">1.0</data>
      <data key="d5">The Wasserstein paper was published in the Significance journal</data>
      <data key="d6">bb31f1c77bbba73300f735a100086a67</data>
    </edge>
    <edge source="SIGNIFICANCE_JOURNAL" target="ROYAL_STATISTICAL_SOCIETY">
      <data key="d4">1.0</data>
      <data key="d5">The Significance journal is published by the Royal Statistical Society</data>
      <data key="d6">bb31f1c77bbba73300f735a100086a67</data>
    </edge>
    <edge source="GEORGE E. BOX" target="WASSERSTEIN6">
      <data key="d4">1.0</data>
      <data key="d5">Wasserstein6 provides more information about George E. Box</data>
      <data key="d6">22061b1108c7f9963497b7a320be22b8</data>
    </edge>
    <edge source="WASSERSTEIN6" target="SIGNIFICANCE">
      <data key="d4">1.0</data>
      <data key="d5">Significance is the journal where Wasserstein6 was published</data>
      <data key="d6">22061b1108c7f9963497b7a320be22b8</data>
    </edge>
    <edge source="SIGNIFICANCE" target="ROYAL STATISTICAL SOCIETY">
      <data key="d4">1.0</data>
      <data key="d5">The Royal Statistical Society is the organization that publishes Significance</data>
      <data key="d6">22061b1108c7f9963497b7a320be22b8</data>
    </edge>
    <edge source="GAPMINDER" target="ECONOMIC INDICES">
      <data key="d4">1.0</data>
      <data key="d5">Gapminder provides data and visualizations on economic indices</data>
      <data key="d6">22061b1108c7f9963497b7a320be22b8</data>
    </edge>
    <edge source="PARSIMONY" target="OCKHAMS_RAZOR">
      <data key="d4">1.0</data>
      <data key="d5">Parsimony is often referred to as Ockham's razor, which is a principle that directs us to choose the simplest explanation</data>
      <data key="d6">188219b9e5b6b6368360840921877de9</data>
    </edge>
    <edge source="PARSIMONY" target="SIMPLE_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Parsimony directs us to choose the simplest model that still adequately fits the data</data>
      <data key="d6">188219b9e5b6b6368360840921877de9</data>
    </edge>
    <edge source="PARSIMONY" target="COMPLEX_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Parsimony advises against choosing unnecessarily complex models, as they can decrease the precision of estimation and prediction</data>
      <data key="d6">188219b9e5b6b6368360840921877de9</data>
    </edge>
    <edge source="PLAUSIBILITY" target="SIMPLER_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">A simpler model may be more plausible for prediction within a specific range of input values</data>
      <data key="d6">768c516c8b27fb9800427e848f02fc33</data>
    </edge>
    <edge source="PLAUSIBILITY" target="TRUE_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The true model is not always the most plausible for prediction, especially when considering a limited range of input values</data>
      <data key="d6">768c516c8b27fb9800427e848f02fc33</data>
    </edge>
    <edge source="PLAUSIBILITY" target="ACCELERATION_DUE_TO_GRAVITY">
      <data key="d4">1.0</data>
      <data key="d5">The assumption of constant acceleration due to gravity is plausible for modeling the path of a ball in a room but not in space</data>
      <data key="d6">768c516c8b27fb9800427e848f02fc33</data>
    </edge>
    <edge source="PREDICTOR_VARIABLES" target="PARAMETER_ESTIMATION">
      <data key="d4">1.0</data>
      <data key="d5">Predictor variables are used in parameter estimation to understand their relationship with the response variable</data>
      <data key="d6">768c516c8b27fb9800427e848f02fc33</data>
    </edge>
    <edge source="BALL" target="GRAVITY">
      <data key="d4">1.0</data>
      <data key="d5">The ball is influenced by gravity, which causes it to fall</data>
      <data key="d6">188219b9e5b6b6368360840921877de9</data>
    </edge>
    <edge source="BALL" target="ROOM">
      <data key="d4">1.0</data>
      <data key="d5">The path of the ball is modelled in the room, where the acceleration due to gravity is assumed to be constant</data>
      <data key="d6">188219b9e5b6b6368360840921877de9</data>
    </edge>
    <edge source="BALL" target="SPACE">
      <data key="d4">1.0</data>
      <data key="d5">The path of the ball in space is affected by gravity, but the relationship is only valid locally</data>
      <data key="d6">188219b9e5b6b6368360840921877de9</data>
    </edge>
    <edge source="COMPLEX_MODEL" target="NON-LINEARITY">
      <data key="d4">1.0</data>
      <data key="d5">A complex model can be used to address non-linearity when transformation of the explanatory variable is not sufficient</data>
      <data key="d6">b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </edge>
    <edge source="COMPLEX_MODEL" target="TRANSFORMATION">
      <data key="d4">1.0</data>
      <data key="d5">If transformations do not resolve issues, a complex model may be considered</data>
      <data key="d6">7347b44ffb25a066e43321f4eaf5a806</data>
    </edge>
    <edge source="RESIDUAL_PLOTS" target="MODEL_ASSUMPTIONS">
      <data key="d4">1.0</data>
      <data key="d5">Residual plots are used to visually assess the validity of model assumptions by plotting the residuals against the predicted values or other variables. They help identify patterns that may indicate violations of assumptions such as non-linearity, heteroscedasticity, or non-normality.</data>
      <data key="d6">e7494d6cfc3e38a4d2f3f6b21ef6445d</data>
    </edge>
    <edge source="RESIDUAL_PLOTS" target="HOMOSCEDASTICITY">
      <data key="d4">2.0</data>
      <data key="d5">Residual plots can be used to check for violations of the homoscedasticity assumption in a statistical model
Residual plots can be used to assess the assumption of homoscedasticity in the regression model</data>
      <data key="d6">7cd6069e88e81548a237fa937adfecc6,a60af43e42c72a41fa90da06beb29d1b</data>
    </edge>
    <edge source="RESIDUAL_PLOTS" target="NULL_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">A null plot is a specific type of residual plot that indicates no violations of model assumptions</data>
      <data key="d6">7cd6069e88e81548a237fa937adfecc6</data>
    </edge>
    <edge source="RESIDUAL_PLOTS" target="WESTERN_CEDAR_TREE_DATA">
      <data key="d4">1.0</data>
      <data key="d5">The Western cedar tree data is used as an example in the context of residual plots to illustrate issues with linearity</data>
      <data key="d6">b9ec8a6c7960cc6196ec94fd976f05b0</data>
    </edge>
    <edge source="RESIDUAL_PLOTS" target="ACCEPTABLE_RESIDUAL_PLOTS">
      <data key="d4">1.0</data>
      <data key="d5">Residual plots that are considered acceptable do not show any systematic patterns, indicating that the model assumptions are likely met. These plots are used to assess the fit of a regression model and identify any potential issues with the assumptions.</data>
      <data key="d6">23fc620f1238c6a1b5c5e3a08e149c53</data>
    </edge>
    <edge source="RESIDUAL_PLOTS" target="REMEDIAL_ACTIONS">
      <data key="d4">1.0</data>
      <data key="d5">When residual plots show patterns that indicate violations of model assumptions, remedial actions are necessary to address these issues. These actions can include transformations of the data, adding or removing variables, or using a different model.</data>
      <data key="d6">23fc620f1238c6a1b5c5e3a08e149c53</data>
    </edge>
    <edge source="RESIDUAL_PLOTS" target="SMOOTHING_CURVE">
      <data key="d4">1.0</data>
      <data key="d5">A smoothing curve can be added to residual plots to help identify any patterns or trends in the residuals. A relatively horizontal smoothing curve suggests that the residuals do not exhibit any systematic patterns, which is desirable for an acceptable residual plot.</data>
      <data key="d6">23fc620f1238c6a1b5c5e3a08e149c53</data>
    </edge>
    <edge source="RESIDUAL_PLOTS" target="CONSTANT_VARIANCE_ASSUMPTION">
      <data key="d4">1.0</data>
      <data key="d5">Residual plots are used to assess the constant variance assumption of linear regression models. A plot that shows no clear pattern in the spread of residuals across the range of fitted values supports the assumption of homoscedasticity.</data>
      <data key="d6">23fc620f1238c6a1b5c5e3a08e149c53</data>
    </edge>
    <edge source="RESIDUAL_PLOTS" target="FIGURE_4_5">
      <data key="d4">1.0</data>
      <data key="d5">Figure 4.5 is an example of a residual plot showing residuals versus fitted values for the log-transformed tree data</data>
      <data key="d6">a60af43e42c72a41fa90da06beb29d1b</data>
    </edge>
    <edge source="RESIDUAL_PLOTS" target="FIGURE_4_6">
      <data key="d4">1.0</data>
      <data key="d5">Figure 4.6 is another example of a residual plot showing residuals versus log-height and versus log-diameter</data>
      <data key="d6">a60af43e42c72a41fa90da06beb29d1b</data>
    </edge>
    <edge source="Q_Q_PLOTS" target="MODEL_ASSUMPTIONS">
      <data key="d4">1.0</data>
      <data key="d5">Q-Q plots are used to assess the normality assumption of the model by comparing the distribution of the residuals to a theoretical normal distribution. If the points on the plot form a straight line, it suggests that the residuals follow a normal distribution, which is one of the assumptions of the linear model.</data>
      <data key="d6">e7494d6cfc3e38a4d2f3f6b21ef6445d</data>
    </edge>
    <edge source="MODEL_ASSUMPTIONS" target="VIOLATIONS_OF_ASSUMPTIONS">
      <data key="d4">1.0</data>
      <data key="d5">Violations of assumptions can lead to biased or inefficient parameter estimates, incorrect standard errors, and invalid hypothesis tests. Identifying and addressing these violations is crucial for the reliability and validity of the model.</data>
      <data key="d6">e7494d6cfc3e38a4d2f3f6b21ef6445d</data>
    </edge>
    <edge source="MODEL_ASSUMPTIONS" target="NORMAL_LINEAR_MODEL">
      <data key="d4">2.0</data>
      <data key="d5">Model assumptions are necessary for the validity of the normal linear model, including the assumption that the response variable is measured on a continuous scale
The normal linear model has specific assumptions that need to be met for the model to be valid and reliable</data>
      <data key="d6">22093a562f5f05dc9891b45ab9bcbea8,c03eb12d07d48f9e94260f08dae10cdf</data>
    </edge>
    <edge source="MODEL_ASSUMPTIONS" target="NULL_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">Model assumptions, when satisfied, result in a null plot with no distinct patterns</data>
      <data key="d6">aa13c33a7e61206e6021e2736002ca9a</data>
    </edge>
    <edge source="MODEL_ASSUMPTIONS" target="HORIZONTAL_LINE_AT_ZERO">
      <data key="d4">1.0</data>
      <data key="d5">If the model assumptions hold, the smoothing curve should resemble a horizontal line at zero</data>
      <data key="d6">674b8d5bb1f830d0fb944942514d1a16</data>
    </edge>
    <edge source="MODEL_ASSUMPTIONS" target="DIAGNOSIS">
      <data key="d4">1.0</data>
      <data key="d5">Diagnosis is the process of checking whether the model assumptions are met</data>
      <data key="d6">c03eb12d07d48f9e94260f08dae10cdf</data>
    </edge>
    <edge source="BETA_HAT" target="YB">
      <data key="d4">3.0</data>
      <data key="d5">Beta hat (&#946;b) is used to compute the vector of fitted values Yb
YB is calculated as X&#946;b, where &#946;b is the least squares estimator
Yb is calculated as X&#946;b, where &#946;b is the least squares estimator of the parameter Beta</data>
      <data key="d6">2b6d31b6bff4eae3a4809451c4fb9fa6,5cc49d301d9cd1f8e20b92ab9d8346b0,6ee02b38ae842fd5eac9a11c4fd6659f</data>
    </edge>
    <edge source="BETA_HAT" target="YBJ">
      <data key="d4">1.0</data>
      <data key="d5">Beta hat (&#946;b) is used to compute the fitted value ybj for the jth unit of observation</data>
      <data key="d6">2b6d31b6bff4eae3a4809451c4fb9fa6</data>
    </edge>
    <edge source="BETA_HAT" target="ZJ">
      <data key="d4">1.0</data>
      <data key="d5">Zj is used in the calculation of the jth fitted value ybj, which is part of YB</data>
      <data key="d6">5cc49d301d9cd1f8e20b92ab9d8346b0</data>
    </edge>
    <edge source="BETA_HAT" target="EPSILON_BJ">
      <data key="d4">2.0</data>
      <data key="d5">Epsilon bj (&#1013;bj) is calculated using &#946;b, the least squares estimator
Beta hat (&#946;b) is used in the calculation of the residuals (&#1013;bj) as part of the fitted values</data>
      <data key="d6">255685e281cc5a9edf073c700f425a6b,5cc49d301d9cd1f8e20b92ab9d8346b0</data>
    </edge>
    <edge source="BETA_HAT" target="S">
      <data key="d4">8.0</data>
      <data key="d5">The sum of squared differences function S(&#946;) is minimized by the value of Beta hat (&#946;b) in the least squares estimationBeta hat (&#946;b) is the value that minimizes the sum of squared differences function S(&#946;) in the least squares estimation
S(&#946;) achieves its global minimum at Beta hat (&#946;b), which is the stationary point
S(&#946;) achieves its global minimum at Beta hat (&#946;b), indicating that &#946;b is the optimal parameter estimate
S(&#946;) is the function that Beta hat (&#946;b) minimizes to estimate Beta
S(&#946;) is minimized when Beta is equal to Beta hat (&#946;b), making Beta hat the global minimizer of S(&#946;)
S(&#946;) is the function that is minimized to find the least squares estimator Beta hat (&#946;b)
S(&#946;) is the function that is minimized by &#946;b to obtain the MLE for a given &#963;^2</data>
      <data key="d6">50a56c34050fb7f7709300a51399b150,6b55b41598d5264f8dc6b72769748722,7955aae3fd4ca51b9ef8843e13c1f517,9d300fc83afb3261af61b2ab9721cadc,9dddcd96af7b557e578b3f5f36efacd7,a4a817bb79d6ae8812c808ca41d47f43,aa195e72eb5285a4bcae9c856af30a87</data>
    </edge>
    <edge source="BETA_HAT" target="XT">
      <data key="d4">11.0</data>
      <data key="d5">XT is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator
XT is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator
XT is used in the calculation of Beta hat (&#946;b) and in the normal equations that Beta hat (&#946;b) satisfies
XT is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator
XT is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator
XT is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator
XT is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator
XT is used in the calculation of Beta hat (&#946;b) as part of the least squares estimate
XT is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator
XT is used in the calculation of &#946;b as part of the MLE
XT is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator</data>
      <data key="d6">255685e281cc5a9edf073c700f425a6b,2f2523c52c6d2869fb19f77b66ce8259,542f546c5a131196e4701fb33c9b1dee,6b55b41598d5264f8dc6b72769748722,7955aae3fd4ca51b9ef8843e13c1f517,82932abd152e0b84a1c26a2daa4c08df,9dddcd96af7b557e578b3f5f36efacd7,9fc2b1e8b2b61b557f88eb9e9c708597,a4a817bb79d6ae8812c808ca41d47f43,aa195e72eb5285a4bcae9c856af30a87,f9b615b879f72501f338f8983d4cac3d</data>
    </edge>
    <edge source="BETA_HAT" target="XTX">
      <data key="d4">7.0</data>
      <data key="d5">XTX is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator
XTX is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator
XTX is used in the calculation of Beta hat (&#946;b) and in the normal equations
XTX is part of the formula used to calculate Beta hat (b&#946;) in the least squares estimation
XTX is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator
XTX is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator
XTX is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator</data>
      <data key="d6">28cf5ff0c09fa5c0390267bb9aa3ce47,2f2523c52c6d2869fb19f77b66ce8259,56ff186fc629e1e42f2759fc4b984199,9d300fc83afb3261af61b2ab9721cadc,a4a817bb79d6ae8812c808ca41d47f43,d14413709de2897231aaa83be3aa346f,f9b615b879f72501f338f8983d4cac3d</data>
    </edge>
    <edge source="BETA_HAT" target="XTX_INVERSE">
      <data key="d4">1.0</data>
      <data key="d5">XTX^-1 is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator</data>
      <data key="d6">f9b615b879f72501f338f8983d4cac3d</data>
    </edge>
    <edge source="BETA_HAT" target="RANK_X">
      <data key="d4">1.0</data>
      <data key="d5">Rank (X) must be equal to p for the calculation of Beta hat (&#946;b) to be valid</data>
      <data key="d6">f9b615b879f72501f338f8983d4cac3d</data>
    </edge>
    <edge source="BETA_HAT" target="NORMAL_EQUATIONS">
      <data key="d4">3.0</data>
      <data key="d5">&#946;b is the stationary point that satisfies the normal equations
The normal equations are solved by the least squares estimate &#946;b, which is the maximum likelihood estimate for &#946;.
The normal equations are solved to find the least squares estimate Beta hat (&#946;b)</data>
      <data key="d6">21ec28dfe2b2c18030d541d63e51f45e,ad799500572246a07f983a3b92c0e61f,f632f01188d2c6e3091a965580cb4600</data>
    </edge>
    <edge source="BETA_HAT" target="S_BETA_BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">&#946;b is the point at which S(&#946;) achieves its global minimum</data>
      <data key="d6">21ec28dfe2b2c18030d541d63e51f45e</data>
    </edge>
    <edge source="BETA_HAT" target="XTY">
      <data key="d4">1.0</data>
      <data key="d5">XTY is part of the formula used to calculate Beta hat (b&#946;) in the least squares estimation</data>
      <data key="d6">28cf5ff0c09fa5c0390267bb9aa3ce47</data>
    </edge>
    <edge source="BETA_HAT" target="SXX">
      <data key="d4">1.0</data>
      <data key="d5">Sxx is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator</data>
      <data key="d6">2f2523c52c6d2869fb19f77b66ce8259</data>
    </edge>
    <edge source="BETA_HAT" target="X_BAR">
      <data key="d4">1.0</data>
      <data key="d5">x_bar is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator</data>
      <data key="d6">2f2523c52c6d2869fb19f77b66ce8259</data>
    </edge>
    <edge source="BETA_HAT" target="Y_BAR">
      <data key="d4">1.0</data>
      <data key="d5">y_bar is used in the calculation of Beta hat (&#946;b) as part of the least squares estimator</data>
      <data key="d6">2f2523c52c6d2869fb19f77b66ce8259</data>
    </edge>
    <edge source="BETA_HAT" target="GAMMA_HAT">
      <data key="d4">2.0</data>
      <data key="d5">Gamma hat (&#947;b) is algebraically related to Beta hat (&#946;b) through the transformation A&#946;b
Beta hat (&#946;b) is used in the calculation of Gamma hat (&#947;b) through the invertible matrix A</data>
      <data key="d6">82932abd152e0b84a1c26a2daa4c08df,d94760a5f9f6ea115fcc18024035a627</data>
    </edge>
    <edge source="BETA_HAT" target="LSE">
      <data key="d4">2.0</data>
      <data key="d5">Least squares estimation (LSE) is the method used to derive the estimator Beta hat (&#946;b)
&#946;b (Beta hat) is the least squares estimate for the parameter vector &#946;, which is identical to the MLE for &#946; under the assumption that errors are iid N(0, &#963;^2)</data>
      <data key="d6">9fc2b1e8b2b61b557f88eb9e9c708597,d738df7d83784c8a41b3948271c537b6</data>
    </edge>
    <edge source="BETA_HAT" target="MLE">
      <data key="d4">1.0</data>
      <data key="d5">MLE is the method used to calculate the estimate &#946;b</data>
      <data key="d6">9dddcd96af7b557e578b3f5f36efacd7</data>
    </edge>
    <edge source="BETA_HAT" target="L">
      <data key="d4">2.0</data>
      <data key="d5">L is the likelihood function that is maximized by &#946;b to obtain the MLE
Beta hat (&#946;b) is the least squares estimate derived from the likelihood function L(&#946;, &#963;^2|y)</data>
      <data key="d6">9dddcd96af7b557e578b3f5f36efacd7,f632f01188d2c6e3091a965580cb4600</data>
    </edge>
    <edge source="BETA_HAT" target="LOG_LIKELIHOOD">
      <data key="d4">2.0</data>
      <data key="d5">The log-likelihood function &#8467; is maximized by &#946;b for a given &#963;^2 to obtain the MLE
The log-likelihood function is maximised by the vector &#946; that minimises the residual sum of squares function S(&#946;), which is the least squares estimate &#946;b.</data>
      <data key="d6">9dddcd96af7b557e578b3f5f36efacd7,ad799500572246a07f983a3b92c0e61f</data>
    </edge>
    <edge source="BETA_HAT" target="RESIDUAL_SUM_SQUARES">
      <data key="d4">1.0</data>
      <data key="d5">The residual sum of squares function S(&#946;) is minimised by the least squares estimate &#946;b, which is the maximum likelihood estimate for &#946;.</data>
      <data key="d6">ad799500572246a07f983a3b92c0e61f</data>
    </edge>
    <edge source="BETA_HAT" target="BETA_HAT_Y">
      <data key="d4">1.0</data>
      <data key="d5">Beta hat (&#946;b) is a realization of the estimator Beta hat (&#946;b(Y)) when applied to the observed data</data>
      <data key="d6">2de7a36b32bf79c8f32612c8aaa9daa8</data>
    </edge>
    <edge source="BETA_HAT" target="NP">
      <data key="d4">4.0</data>
      <data key="d5">Np is the distribution of Beta hat (&#946;b) itself
Np is the distribution of Beta hat (&#946;b) itself
Np is the distribution of Beta hat (&#946;b) itself
Np is the distribution of Beta hat (&#946;b) itself</data>
      <data key="d6">3d357cfa3ef0d00f49cf4acaeac1c9d1,45f31b040576e9f3b4def6d0466cc016,542f546c5a131196e4701fb33c9b1dee,d14413709de2897231aaa83be3aa346f</data>
    </edge>
    <edge source="BETA_HAT" target="A">
      <data key="d4">1.0</data>
      <data key="d5">A is the matrix transformation applied to Y to obtain Beta hat (&#946;b)</data>
      <data key="d6">542f546c5a131196e4701fb33c9b1dee</data>
    </edge>
    <edge source="BETA_HAT" target="S_HAT_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">&#946;b is the estimator for &#946; used in the calculation of the unbiased estimator s^2(Y) for the error variance</data>
      <data key="d6">6648f0d6deed51fb4fb25e6992a71ddf</data>
    </edge>
    <edge source="BETA_HAT" target="S2">
      <data key="d4">1.0</data>
      <data key="d5">Beta hat (&#946;b) is used in the calculation of the unbiased estimator s^2</data>
      <data key="d6">9923e77ac6b3de95cb5026bc5e7fe8c0</data>
    </edge>
    <edge source="BETA_HAT" target="EXERCISE_18">
      <data key="d4">1.0</data>
      <data key="d5">Exercise 18 involves calculating the estimator Beta hat (&#946;b) for a given linear model</data>
      <data key="d6">fc5b725f3c662c5471af20efdcc2dbff</data>
    </edge>
    <edge source="BETA_HAT" target="YC">
      <data key="d4">1.0</data>
      <data key="d5">Beta hat (&#946;b) is used in the computation of the expected value of Yc, which is X&#946;</data>
      <data key="d6">679722cf8ce5ce5aee4e379528470efe</data>
    </edge>
    <edge source="BETA_HAT" target="PARALLEL_LINES_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The parallel lines model uses the estimated regression coefficient Beta hat (&#946;&#710;) for the price variable</data>
      <data key="d6">b2c33cb151a8e7724ebfb7b2d88bc45f</data>
    </edge>
    <edge source="BETA_HAT" target="STORE_BRAND">
      <data key="d4">1.0</data>
      <data key="d5">Store brand is a categorical variable whose effect on sales is quantified by the estimated coefficient for Beta (&#946;)</data>
      <data key="d6">248924760a2bfbc82501fd6b11cfa0aa</data>
    </edge>
    <edge source="BETA_HAT" target="BRAND_MODEL3">
      <data key="d4">1.0</data>
      <data key="d5">Brand_model3 is the model that provides the estimate for the price parameter Beta_hat</data>
      <data key="d6">6a6f85d0a6e46196ab3a901fcc82a720</data>
    </edge>
    <edge source="BETA_HAT" target="Z">
      <data key="d4">1.0</data>
      <data key="d5">Beta hat (b&#946;) is the maximum likelihood estimator for the parameter Beta, as mentioned in the context of distributional properties</data>
      <data key="d6">aac5b4f040b9c773bd1aa696dec469f6</data>
    </edge>
    <edge source="BETA_HAT" target="CHI_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">The chi-squared distribution is related to the distribution of the least squares estimator Beta hat (&#946;b) in certain conditions</data>
      <data key="d6">0ac60299320c55d642b3e38440c25f90</data>
    </edge>
    <edge source="BETA_HAT" target="S_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">The distributional properties of Beta hat (&#946;b) and S squared (s^2) are related in the context of linear regression models</data>
      <data key="d6">0ac60299320c55d642b3e38440c25f90</data>
    </edge>
    <edge source="BETA_BAR" target="COEF_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The function coef(model) returns the estimated parameter vector Beta bar</data>
      <data key="d6">01d5ee79489582b4135fc96f676b24a0</data>
    </edge>
    <edge source="YB" target="YA">
      <data key="d4">2.0</data>
      <data key="d5">YA is the back-transformed prediction for Y before the change in X1, and YB is the prediction after the change
YA is the predicted response before the increase in X1, used to calculate the change in YB</data>
      <data key="d6">21e429490eeefe7d9c245058fd48ca68,995fb26a0261f824952fa7b2fac3382e</data>
    </edge>
    <edge source="YB" target="Z">
      <data key="d4">1.0</data>
      <data key="d5">Z is used in the calculation of the fitted values Yb in the reparameterised model</data>
      <data key="d6">82932abd152e0b84a1c26a2daa4c08df</data>
    </edge>
    <edge source="YB" target="H">
      <data key="d4">1.0</data>
      <data key="d5">Yb is calculated as Hy, where H is the hat matrix</data>
      <data key="d6">6ee02b38ae842fd5eac9a11c4fd6659f</data>
    </edge>
    <edge source="YB" target="HII">
      <data key="d4">1.0</data>
      <data key="d5">The leverage (hii) of the ith data point influences the weight that the observed value yi has when computing the fitted value ybi</data>
      <data key="d6">6ee02b38ae842fd5eac9a11c4fd6659f</data>
    </edge>
    <edge source="YB" target="COOKS_DISTANCE">
      <data key="d4">1.0</data>
      <data key="d5">yb is used in the calculation of Cook's distance (Di) as the vector of fitted values</data>
      <data key="d6">09391efd3b8c510205098b548bc8dc74</data>
    </edge>
    <edge source="ZJ" target="YBJ">
      <data key="d4">1.0</data>
      <data key="d5">zj is the jth observation of the explanatory variable used to compute the fitted value ybj in simple linear regression</data>
      <data key="d6">2b6d31b6bff4eae3a4809451c4fb9fa6</data>
    </edge>
    <edge source="YBJ" target="EPSILON_BJ">
      <data key="d4">1.0</data>
      <data key="d5">Epsilon bj (&#1013;bj) is calculated as the difference between the observed value Yj and the fitted value Ybj, indicating the residual for the jth observation</data>
      <data key="d6">e6f79ceb0df54119a4dc71b2162ac50b</data>
    </edge>
    <edge source="YBJ" target="XTJ">
      <data key="d4">1.0</data>
      <data key="d5">XTj is used in the calculation of the fitted value Ybj, which is the predicted response for the jth observation</data>
      <data key="d6">e6f79ceb0df54119a4dc71b2162ac50b</data>
    </edge>
    <edge source="YBJ" target="BETA_B">
      <data key="d4">1.0</data>
      <data key="d5">Beta b (&#946;b) is used in the calculation of the fitted value Ybj, which is the predicted response for the jth observation</data>
      <data key="d6">e6f79ceb0df54119a4dc71b2162ac50b</data>
    </edge>
    <edge source="EPSILON_BJ" target="DEVIANCE">
      <data key="d4">1.0</data>
      <data key="d5">Deviance or Residual Sum of Squares (ResidSS) is calculated using the squared residuals &#1013;bj, indicating the sum of squared residuals</data>
      <data key="d6">e6f79ceb0df54119a4dc71b2162ac50b</data>
    </edge>
    <edge source="EPSILON_BJ" target="RESIDSS">
      <data key="d4">1.0</data>
      <data key="d5">The residuals (&#1013;bj) are squared and summed to calculate the residual sum of squares (ResidSS)</data>
      <data key="d6">255685e281cc5a9edf073c700f425a6b</data>
    </edge>
    <edge source="BETA_B" target="BRAND_A">
      <data key="d4">1.0</data>
      <data key="d5">Brand A's price effect is represented by Beta hat (b&#946;), indicating the average reduction in sales with every additional pound charged</data>
      <data key="d6">adbc52b340a69a8633c919c4fd2cd3f6</data>
    </edge>
    <edge source="PARAMETER_ESTIMATES" target="RESIDUAL_SUM_OF_SQUARES">
      <data key="d4">1.0</data>
      <data key="d5">Parameter estimates are chosen to minimize the residual sum of squares, optimizing the model's fit to the data</data>
      <data key="d6">22093a562f5f05dc9891b45ab9bcbea8</data>
    </edge>
    <edge source="RESIDUAL_SUM_OF_SQUARES" target="MODEL_DEVIANCE">
      <data key="d4">1.0</data>
      <data key="d5">Residual sum of squares and model deviance are synonymous terms, both measuring the discrepancy between the observed data and the model's predictions</data>
      <data key="d6">22093a562f5f05dc9891b45ab9bcbea8</data>
    </edge>
    <edge source="SIMPLE_REGRESSION_LINE" target="EXERCISE_9">
      <data key="d4">1.0</data>
      <data key="d5">The simple regression line is provided for Exercise 9, which requires calculating the fitted values, residuals, and deviance</data>
      <data key="d6">22093a562f5f05dc9891b45ab9bcbea8</data>
    </edge>
    <edge source="NORMAL_LINEAR_MODEL" target="TEXTBOOKS">
      <data key="d4">1.0</data>
      <data key="d5">The recommended textbooks cover material related to the normal linear model</data>
      <data key="d6">c03eb12d07d48f9e94260f08dae10cdf</data>
    </edge>
    <edge source="NORMAL_LINEAR_MODEL" target="MLE">
      <data key="d4">1.0</data>
      <data key="d5">The MLE for &#946; is derived within the context of the normal linear model</data>
      <data key="d6">d738df7d83784c8a41b3948271c537b6</data>
    </edge>
    <edge source="NORMALITY" target="NORMAL_Q_Q_PLOTS">
      <data key="d4">1.0</data>
      <data key="d5">Normal Q-Q plots are used to assess the normality assumption in a statistical model</data>
      <data key="d6">7cd6069e88e81548a237fa937adfecc6</data>
    </edge>
    <edge source="NORMALITY" target="STATISTICAL_INFERENCE">
      <data key="d4">1.0</data>
      <data key="d5">Normality is an assumption that is assessed in statistical inference to ensure the validity of the results</data>
      <data key="d6">ef24ca5edd06893b737e6a1c8a9825f6</data>
    </edge>
    <edge source="HETEROSCEDASTICITY" target="VARIANCE">
      <data key="d4">1.0</data>
      <data key="d5">Heteroscedasticity is characterized by non-constant variance of the error terms</data>
      <data key="d6">b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </edge>
    <edge source="HETEROSCEDASTICITY" target="NON-LINEARITY">
      <data key="d4">1.0</data>
      <data key="d5">Heteroscedasticity and non-linearity are issues that may occur together in a statistical model</data>
      <data key="d6">7347b44ffb25a066e43321f4eaf5a806</data>
    </edge>
    <edge source="HETEROSCEDASTICITY" target="LINEARITY_ASSUMPTION">
      <data key="d4">1.0</data>
      <data key="d5">Linearity is prioritized over addressing heteroscedasticity if both issues cannot be resolved</data>
      <data key="d6">7347b44ffb25a066e43321f4eaf5a806</data>
    </edge>
    <edge source="HETEROSCEDASTICITY" target="TRANSFORMATIONS">
      <data key="d4">1.0</data>
      <data key="d5">Transformations, particularly log transformations, are used to address heteroscedasticity in linear models</data>
      <data key="d6">07951ffe6787af44aa60c90c69e62f83</data>
    </edge>
    <edge source="DATA_COLLECTION" target="SEQUENTIAL_DATA">
      <data key="d4">1.0</data>
      <data key="d5">Sequential data collection can lead to violations of the independence assumption in the data collection process</data>
      <data key="d6">0da640a09a395a50b6e16e047fa8d0d6</data>
    </edge>
    <edge source="DATA_COLLECTION" target="SPATIAL_DATA">
      <data key="d4">1.0</data>
      <data key="d5">Spatial data collection can lead to violations of the independence assumption in the data collection process</data>
      <data key="d6">0da640a09a395a50b6e16e047fa8d0d6</data>
    </edge>
    <edge source="NORMAL_Q_Q_PLOTS" target="STANDARDISED_RESIDUALS">
      <data key="d4">1.0</data>
      <data key="d5">Normal Q-Q plots are used to assess the normality of the standardised residuals</data>
      <data key="d6">e361ac139c268d5c3f3623f920e68af2</data>
    </edge>
    <edge source="NULL_PLOT" target="SMOOTHER">
      <data key="d4">1.0</data>
      <data key="d5">A smoother is added to a null plot to help evaluate the pattern of residuals</data>
      <data key="d6">aa13c33a7e61206e6021e2736002ca9a</data>
    </edge>
    <edge source="NULL_PLOT" target="HORIZONTAL_LINE">
      <data key="d4">1.0</data>
      <data key="d5">A horizontal line at zero is expected in a null plot if the model assumptions hold</data>
      <data key="d6">aa13c33a7e61206e6021e2736002ca9a</data>
    </edge>
    <edge source="NULL_PLOT" target="VARIABILITY">
      <data key="d4">1.0</data>
      <data key="d5">Constant variability in the residuals is a characteristic of a null plot</data>
      <data key="d6">aa13c33a7e61206e6021e2736002ca9a</data>
    </edge>
    <edge source="SMOOTHER" target="RESIDUAL_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">The smoother is used in the residual plot to identify patterns in the residuals</data>
      <data key="d6">82cfcd5865cffe55e965a50745656e60</data>
    </edge>
    <edge source="SMOOTHED_RESIDUAL_PLOT" target="SMOOTHING_CURVE">
      <data key="d4">1.0</data>
      <data key="d5">The smoothing curve is added to the smoothed residual plot to estimate the mean of the residuals</data>
      <data key="d6">674b8d5bb1f830d0fb944942514d1a16</data>
    </edge>
    <edge source="SMOOTHED_RESIDUAL_PLOT" target="WELL_FITTING_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">A well-fitting model is illustrated by a smoothed residual plot where the smoothing curve resembles a horizontal line and the variation of the residuals appears relatively stable</data>
      <data key="d6">674b8d5bb1f830d0fb944942514d1a16</data>
    </edge>
    <edge source="SMOOTHING_CURVE" target="RESIDUAL_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">The smoothing curve is fitted to the data in the residual plot</data>
      <data key="d6">312309b45c59e1c84695ac3c7e202742</data>
    </edge>
    <edge source="UNACCEPTABLE_RESIDUAL_PLOTS" target="WESTERN_CEDAR_TREE_DATA">
      <data key="d4">1.0</data>
      <data key="d5">The Western cedar tree data is an example of an unacceptable residual plot</data>
      <data key="d6">674b8d5bb1f830d0fb944942514d1a16</data>
    </edge>
    <edge source="UNACCEPTABLE_RESIDUAL_PLOTS" target="CURVED_RELATIONSHIP">
      <data key="d4">1.0</data>
      <data key="d5">Unacceptable residual plots may indicate a curved relationship between the explanatory variable and the response variable</data>
      <data key="d6">674b8d5bb1f830d0fb944942514d1a16</data>
    </edge>
    <edge source="WESTERN_CEDAR_TREE_DATA" target="TRANSFORM">
      <data key="d4">1.0</data>
      <data key="d5">A transform was applied to the Western cedar tree data to address non-linearity</data>
      <data key="d6">15c7b5750483a382ce59751008e86751</data>
    </edge>
    <edge source="LINEARITY_ASSUMPTION" target="NON-LINEARITY">
      <data key="d4">1.0</data>
      <data key="d5">Non-linearity violates the linearity assumption in the relationship between the response and explanatory variables</data>
      <data key="d6">b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </edge>
    <edge source="LINEARITY_ASSUMPTION" target="TRANSFORMATION">
      <data key="d4">1.0</data>
      <data key="d5">The assumption of linearity is often addressed by using transformations, such as the log-transform, to ensure that the relationship between the explanatory variables and the response variable is linear.</data>
      <data key="d6">0fbc9037ca9a440e79e9ac05664b9b3d</data>
    </edge>
    <edge source="TRANSFORMATION" target="SQUARE_ROOT_TRANSFORM">
      <data key="d4">1.0</data>
      <data key="d5">The square root transform is a specific type of transformation that can be applied to the explanatory variable</data>
      <data key="d6">b9ec8a6c7960cc6196ec94fd976f05b0</data>
    </edge>
    <edge source="TRANSFORMATION" target="LOG_TRANSFORM">
      <data key="d4">2.0</data>
      <data key="d5">The log transform is a specific type of transformation that can be applied to the explanatory variable
Transformation methods include the log-transform, which is particularly common and used to stabilize variance and linearize relationships.</data>
      <data key="d6">0fbc9037ca9a440e79e9ac05664b9b3d,b9ec8a6c7960cc6196ec94fd976f05b0</data>
    </edge>
    <edge source="TRANSFORMATION" target="VARIATION">
      <data key="d4">1.0</data>
      <data key="d5">Transformation of the response variable is used to stabilize the variance</data>
      <data key="d6">7347b44ffb25a066e43321f4eaf5a806</data>
    </edge>
    <edge source="TRANSFORMATION" target="RESIDUAL_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">Residual plots are used to assess the effectiveness of transformations</data>
      <data key="d6">7347b44ffb25a066e43321f4eaf5a806</data>
    </edge>
    <edge source="SQUARE_ROOT_TRANSFORM" target="LOG_TRANSFORM">
      <data key="d4">1.0</data>
      <data key="d5">Square root and log transforms are both used to address non-linearity in the explanatory variable</data>
      <data key="d6">15c7b5750483a382ce59751008e86751</data>
    </edge>
    <edge source="LOG_TRANSFORM" target="POSITIVE_MEASUREMENTS">
      <data key="d4">1.0</data>
      <data key="d5">Log-transform is often applied to positive physical measurements to stabilize variance and make the distribution more symmetrical</data>
      <data key="d6">995fb26a0261f824952fa7b2fac3382e</data>
    </edge>
    <edge source="MONOTONIC_NON_LINEAR" target="TRANSFORM">
      <data key="d4">1.0</data>
      <data key="d5">A transform is applied to the explanatory variable to address monotonic but non-linear relationships</data>
      <data key="d6">15c7b5750483a382ce59751008e86751</data>
    </edge>
    <edge source="TRANSFORM" target="NON_MONOTONIC_NON_LINEAR">
      <data key="d4">1.0</data>
      <data key="d5">A transform will not address a non-monotonic non-linearity</data>
      <data key="d6">15c7b5750483a382ce59751008e86751</data>
    </edge>
    <edge source="NON_MONOTONIC_NON_LINEAR" target="FIGURE_3_3">
      <data key="d4">1.0</data>
      <data key="d5">Figure 3.3 shows an example of a non-monotonic and non-linear relationship between the response variable and the explanatory variable</data>
      <data key="d6">15c7b5750483a382ce59751008e86751</data>
    </edge>
    <edge source="RESIDUAL_PLOT" target="VARIANCE_INCREASING_WITH_FITTED_VALUES">
      <data key="d4">1.0</data>
      <data key="d5">The pattern of increasing variance with fitted values is observed in the residual plot</data>
      <data key="d6">82cfcd5865cffe55e965a50745656e60</data>
    </edge>
    <edge source="RESIDUAL_PLOT" target="REMEDIAL_ACTION">
      <data key="d4">1.0</data>
      <data key="d5">Residual plots guide the selection of remedial actions to address model issues</data>
      <data key="d6">7347b44ffb25a066e43321f4eaf5a806</data>
    </edge>
    <edge source="RESIDUAL_PLOT" target="RANDOM_VARIATION">
      <data key="d4">1.0</data>
      <data key="d5">Residual plots help distinguish between systematic features and random variation</data>
      <data key="d6">7347b44ffb25a066e43321f4eaf5a806</data>
    </edge>
    <edge source="RESIDUAL_PLOT" target="COURSEWORK">
      <data key="d4">1.0</data>
      <data key="d5">In coursework, students are expected to analyze and interpret residual plots</data>
      <data key="d6">7347b44ffb25a066e43321f4eaf5a806</data>
    </edge>
    <edge source="RESIDUAL_PLOT" target="ACCEPTABILITY">
      <data key="d4">1.0</data>
      <data key="d5">Acceptability of a model is determined by the features identified in the residual plot</data>
      <data key="d6">7347b44ffb25a066e43321f4eaf5a806</data>
    </edge>
    <edge source="VARIATION" target="HORIZONTAL_AXIS">
      <data key="d4">1.0</data>
      <data key="d5">Variation of observations can be observed as we move along the horizontal axis in a scatterplot or residual plot</data>
      <data key="d6">15c7b5750483a382ce59751008e86751</data>
    </edge>
    <edge source="VARIATION" target="CURVE">
      <data key="d4">1.0</data>
      <data key="d5">Curve is associated with an increase in variation as we move along the horizontal axis</data>
      <data key="d6">7347b44ffb25a066e43321f4eaf5a806</data>
    </edge>
    <edge source="NON_MONOTONIC_NON_LINEAR_RELATIONSHIP" target="QUADRATIC_REGRESSION_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">A quadratic regression model is a suitable choice to model the non-monotonic non-linear relationship</data>
      <data key="d6">82cfcd5865cffe55e965a50745656e60</data>
    </edge>
    <edge source="VARIANCE_INCREASING_WITH_FITTED_VALUES" target="TRANSFORM_RESPONSE_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">Transforming the response variable is a method to address the issue of increasing variance</data>
      <data key="d6">82cfcd5865cffe55e965a50745656e60</data>
    </edge>
    <edge source="VARIANCE" target="SQUARE_ROOT_TRANSFORMATION">
      <data key="d4">1.0</data>
      <data key="d5">Square root transformation is used to stabilize the variance of the response variable</data>
      <data key="d6">b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </edge>
    <edge source="VARIANCE" target="LOGARITHM_TRANSFORMATION">
      <data key="d4">1.0</data>
      <data key="d5">Logarithm transformation is used to stabilize the variance of the response variable, particularly when the response variable is positive</data>
      <data key="d6">b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </edge>
    <edge source="VARIANCE" target="MEGAPHONE_SHAPE_RESIDUAL_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">A megaphone shape in a residual plot indicates increasing variance with the explanatory variable</data>
      <data key="d6">b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </edge>
    <edge source="VARIANCE" target="PRECISION_OF_MEASUREMENT">
      <data key="d4">1.0</data>
      <data key="d5">The precision of measurement is higher for smaller observations, leading to a variance that is increasing with the mean</data>
      <data key="d6">66f7fae9d896ff2b3fd40186cc833503</data>
    </edge>
    <edge source="NON-LINEARITY" target="TRANSFORMATION_OF_EXPLANATORY_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">Transformation of the explanatory variable can address non-linearity in the relationship between the response and explanatory variables</data>
      <data key="d6">b9eb75001a4f68f7240b2ca9e0d79eb8</data>
    </edge>
    <edge source="REMEDIAL_ACTION" target="DIAGNOSIS">
      <data key="d4">1.0</data>
      <data key="d5">Remedial action is taken when the diagnosis reveals that the model assumptions are violated</data>
      <data key="d6">c03eb12d07d48f9e94260f08dae10cdf</data>
    </edge>
    <edge source="REMEDIAL_ACTIONS" target="MORE_COMPLEX_MODELS">
      <data key="d4">1.0</data>
      <data key="d5">Using more complex models is another remedial action that can be taken to address violations of the modelling assumptions</data>
      <data key="d6">e361ac139c268d5c3f3623f920e68af2</data>
    </edge>
    <edge source="SIMULATED_DATA" target="LINEAR_REGRESSION_MODELS">
      <data key="d4">1.0</data>
      <data key="d5">Simulated data can be used to test the performance of linear regression models under known conditions. This helps in verifying that the model works as expected and can provide insights into the model's behavior under various scenarios.</data>
      <data key="d6">23fc620f1238c6a1b5c5e3a08e149c53</data>
    </edge>
    <edge source="SIMULATED_DATA" target="LINEAR_MODEL_ASSUMPTIONS">
      <data key="d4">1.0</data>
      <data key="d5">Simulated data can be designed to satisfy the linear model assumptions, allowing for the testing of statistical methods or models under controlled conditions where the assumptions are known to be met.</data>
      <data key="d6">23fc620f1238c6a1b5c5e3a08e149c53</data>
    </edge>
    <edge source="SIMULATED_DATA" target="VARIANCE_ASSUMPTION">
      <data key="d4">1.0</data>
      <data key="d5">The constant variance assumption is tested using simulated data</data>
      <data key="d6">312309b45c59e1c84695ac3c7e202742</data>
    </edge>
    <edge source="DISTRIBUTION" target="VARIANCE_ASSUMPTION">
      <data key="d4">1.0</data>
      <data key="d5">The constant variance assumption is based on the distribution of the data</data>
      <data key="d6">312309b45c59e1c84695ac3c7e202742</data>
    </edge>
    <edge source="DISTRIBUTION" target="DI">
      <data key="d4">1.0</data>
      <data key="d5">The distribution on p and n - p degrees of freedom is used to determine if Di is large enough to flag the ith observation as influential</data>
      <data key="d6">323899f01972255cd3278bccee20d5d8</data>
    </edge>
    <edge source="STATISTICAL_INFERENCE" target="ROBUSTNESS">
      <data key="d4">1.0</data>
      <data key="d5">Robustness is a property of statistical inference that ensures its validity even when the normality assumption is not met</data>
      <data key="d6">ef24ca5edd06893b737e6a1c8a9825f6</data>
    </edge>
    <edge source="STATISTICAL_INFERENCE" target="NORMAL_Q_Q_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">The results of a normal Q-Q plot can influence the validity of statistical inferences</data>
      <data key="d6">521acf88540d5897188c9ec65b17e6a6</data>
    </edge>
    <edge source="ROBUSTNESS" target="SAMPLE_SIZE">
      <data key="d4">1.0</data>
      <data key="d5">Sample size (n) affects the robustness of statistical inference, with larger sample sizes leading to more robust results</data>
      <data key="d6">ef24ca5edd06893b737e6a1c8a9825f6</data>
    </edge>
    <edge source="ASSESSING_NORMALITY" target="NORMAL_Q_Q_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">A normal Q-Q plot is a tool used in assessing the normality of data or errors</data>
      <data key="d6">521acf88540d5897188c9ec65b17e6a6</data>
    </edge>
    <edge source="ASSESSING_NORMALITY" target="NORMALITY_ASSUMPTION">
      <data key="d4">1.0</data>
      <data key="d5">The normality assumption is a hypothesis that is tested using methods such as assessing normality</data>
      <data key="d6">521acf88540d5897188c9ec65b17e6a6</data>
    </edge>
    <edge source="ASSESSING_NORMALITY" target="LARGE_SAMPLE_SIZES">
      <data key="d4">1.0</data>
      <data key="d5">In large sample sizes, the assumption of normality is less critical for the validity of statistical inferences</data>
      <data key="d6">521acf88540d5897188c9ec65b17e6a6</data>
    </edge>
    <edge source="ASSESSING_NORMALITY" target="DEPARTURES_FROM_NORMALITY">
      <data key="d4">1.0</data>
      <data key="d5">Departures from normality can be identified and assessed using methods such as the normal Q-Q plot</data>
      <data key="d6">521acf88540d5897188c9ec65b17e6a6</data>
    </edge>
    <edge source="NORMAL_Q_Q_PLOT" target="PERCENTAGE_SCALE">
      <data key="d4">1.0</data>
      <data key="d5">Percentage scale can be used in the context of a normal Q-Q plot, although it is not directly related to the creation of the plot itself. It is mentioned in the context of different scales that can be used for data representation.</data>
      <data key="d6">eafa2cc6cc64d8bca1c080bdd2ad7654</data>
    </edge>
    <edge source="NORMAL_Q_Q_PLOT" target="NORMAL_SCORE_SCALE">
      <data key="d4">1.0</data>
      <data key="d5">Normal score scale is often used in the vertical axis of a normal Q-Q plot, which is a graphical technique for assessing the normality of a dataset.</data>
      <data key="d6">eafa2cc6cc64d8bca1c080bdd2ad7654</data>
    </edge>
    <edge source="NORMAL_Q_Q_PLOT" target="NORMAL_DISTRIBUTION">
      <data key="d4">1.0</data>
      <data key="d5">Normal distribution is the reference distribution against which the data are compared in a normal Q-Q plot. The plot is used to assess whether the data could have come from a normal distribution.</data>
      <data key="d6">eafa2cc6cc64d8bca1c080bdd2ad7654</data>
    </edge>
    <edge source="NORMAL_Q_Q_PLOT" target="STANDARDISED_RESIDUALS">
      <data key="d4">1.0</data>
      <data key="d5">Standardised residuals are plotted on the normal Q-Q plot to assess the normality of the residuals, which is an assumption of many statistical models.</data>
      <data key="d6">eafa2cc6cc64d8bca1c080bdd2ad7654</data>
    </edge>
    <edge source="NORMAL_Q_Q_PLOT" target="FITTED_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The fitted model's residuals are used to create the normal Q-Q plot, which helps in assessing the model's assumption of normality.</data>
      <data key="d6">eafa2cc6cc64d8bca1c080bdd2ad7654</data>
    </edge>
    <edge source="NORMAL_Q_Q_PLOT" target="FIGURE_3_9">
      <data key="d4">1.0</data>
      <data key="d5">Figure 3.9 shows two examples of normal Q-Q plots, one with data from a standard normal distribution and the other with data from a t-distribution on 2 degrees of freedom, demonstrating how the plots can be used to assess normality.</data>
      <data key="d6">eafa2cc6cc64d8bca1c080bdd2ad7654</data>
    </edge>
    <edge source="NORMAL_Q_Q_PLOT" target="T_DISTRIBUTION">
      <data key="d4">1.0</data>
      <data key="d5">T-distribution is used to simulate data for the right plot in Figure 3.9, which is a normal Q-Q plot. The plot shows how data from a t-distribution can deviate from the normal distribution, particularly in the tails.</data>
      <data key="d6">eafa2cc6cc64d8bca1c080bdd2ad7654</data>
    </edge>
    <edge source="NORMAL_DISTRIBUTION" target="Q_Q_PLOT">
      <data key="d4">2.0</data>
      <data key="d5">The Q-Q plot is used to compare the observed data against the normal distribution
The normal distribution is used as a reference in Q-Q plots to assess whether a dataset follows a normal distribution. If the data points deviate from the straight line, it indicates that the data do not follow a normal distribution.</data>
      <data key="d6">3bfc9b92571973e54c8095302acc1aaa,ee22e1f5947947f9bd3f7f8922745e48</data>
    </edge>
    <edge source="NORMAL_DISTRIBUTION" target="T_STATISTIC">
      <data key="d4">1.0</data>
      <data key="d5">The T-statistic is based on the assumption of a normal distribution for the errors in a linear model. This allows for the calculation of the distributional properties of the T-statistic, which are used in hypothesis testing.</data>
      <data key="d6">d7f3a28534ffe830fe6f4cef8c41a9b4</data>
    </edge>
    <edge source="STANDARDISED_RESIDUALS" target="MODEL_FIT">
      <data key="d4">1.0</data>
      <data key="d5">Standardised residuals are used to assess the model fit</data>
      <data key="d6">428db872e71a17a2cf7868b03a52def0</data>
    </edge>
    <edge source="STANDARDISED_RESIDUALS" target="INDEX_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">Index plot displays the absolute standardised residuals</data>
      <data key="d6">428db872e71a17a2cf7868b03a52def0</data>
    </edge>
    <edge source="STANDARDISED_RESIDUALS" target="REGRESSION_OUTLIER">
      <data key="d4">1.0</data>
      <data key="d5">Standardised residuals are used to identify regression outliers</data>
      <data key="d6">629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="STANDARDISED_RESIDUALS" target="PLOTS">
      <data key="d4">1.0</data>
      <data key="d5">Plots can be used to visualize standardized residuals</data>
      <data key="d6">629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="STANDARDISED_RESIDUALS" target="RULES_OF_THUMB">
      <data key="d4">1.0</data>
      <data key="d5">Rules of thumb can be used to interpret standardized residuals</data>
      <data key="d6">629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="FITTED_MODEL" target="STATISTICS">
      <data key="d4">1.0</data>
      <data key="d5">The fitted model is a product of statistical analysis, which is part of the field of statistics</data>
      <data key="d6">83bb91cf725e5116ca2f5748fddccfae</data>
    </edge>
    <edge source="T_DISTRIBUTION" target="Q_Q_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">The t-distribution is used in Q-Q plots when the sample size is small or the population variance is unknown. It is compared to the normal distribution to assess the tail behavior of the data.</data>
      <data key="d6">3bfc9b92571973e54c8095302acc1aaa</data>
    </edge>
    <edge source="T2_DISTRIBUTION" target="Q_Q_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">The Q-Q plot is used to compare the observed data against the t2 distribution</data>
      <data key="d6">ee22e1f5947947f9bd3f7f8922745e48</data>
    </edge>
    <edge source="Q_Q_PLOT" target="REFERENCE_LINE">
      <data key="d4">1.0</data>
      <data key="d5">The reference line is plotted on the Q-Q plot to compare the sample quantiles against the theoretical quantiles</data>
      <data key="d6">ee22e1f5947947f9bd3f7f8922745e48</data>
    </edge>
    <edge source="Q_Q_PLOT" target="SAMPLE_QUANTILES">
      <data key="d4">1.0</data>
      <data key="d5">Sample quantiles are plotted on the Q-Q plot to compare against the reference line</data>
      <data key="d6">ee22e1f5947947f9bd3f7f8922745e48</data>
    </edge>
    <edge source="Q_Q_PLOT" target="LEFT_TAIL">
      <data key="d4">1.0</data>
      <data key="d5">The left tail of the distribution is observed to have more observations than expected under a normal distribution</data>
      <data key="d6">ee22e1f5947947f9bd3f7f8922745e48</data>
    </edge>
    <edge source="Q_Q_PLOT" target="RIGHT_TAIL">
      <data key="d4">1.0</data>
      <data key="d5">The right tail of the distribution is observed to have more observations than expected under a normal distribution</data>
      <data key="d6">ee22e1f5947947f9bd3f7f8922745e48</data>
    </edge>
    <edge source="Q_Q_PLOT" target="STANDARD_NORMAL_DENSITY">
      <data key="d4">1.0</data>
      <data key="d5">The standard normal density is compared with the t2 density to illustrate the tail behavior</data>
      <data key="d6">ee22e1f5947947f9bd3f7f8922745e48</data>
    </edge>
    <edge source="Q_Q_PLOT" target="T2_DENSITY">
      <data key="d4">1.0</data>
      <data key="d5">The t2 density is compared with the standard normal density to illustrate the tail behavior</data>
      <data key="d6">ee22e1f5947947f9bd3f7f8922745e48</data>
    </edge>
    <edge source="E" target="M">
      <data key="d4">1.0</data>
      <data key="d5">&#181; is the mean of the normal distribution of log(Y), which is used to calculate the expected value of Y</data>
      <data key="d6">34fceaaf7d835828b5ee2327325c37f8</data>
    </edge>
    <edge source="E" target="YC">
      <data key="d4">1.0</data>
      <data key="d5">E is used to calculate the expected value of Yc</data>
      <data key="d6">1da117a2f92b2db00290d2a0bfc06beb</data>
    </edge>
    <edge source="E" target="EB">
      <data key="d4">1.0</data>
      <data key="d5">E is used to calculate the expected value of the residual vector Eb</data>
      <data key="d6">1da117a2f92b2db00290d2a0bfc06beb</data>
    </edge>
    <edge source="LOG" target="BRAIN_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">Logarithmic function is applied to the average body weight in the model to predict brain weight</data>
      <data key="d6">efeeb664622c1ee594e6a08a8322ffe3</data>
    </edge>
    <edge source="LOG" target="L">
      <data key="d4">1.0</data>
      <data key="d5">The logarithmic function is used in the calculation of the likelihood function L</data>
      <data key="d6">e7edd8b2874a350779ae20f1ecdf4733</data>
    </edge>
    <edge source="LOG_Y" target="LOGNORMAL_DISTRIBUTION">
      <data key="d4">1.0</data>
      <data key="d5">log(Y) follows a lognormal distribution when Y is lognormally distributed</data>
      <data key="d6">21e429490eeefe7d9c245058fd48ca68</data>
    </edge>
    <edge source="LOG_Y" target="GEOMETRIC_MEAN_Y">
      <data key="d4">1.0</data>
      <data key="d5">The geometric mean of Y is equal to exp[E(log(Y))] when Y is lognormally distributed</data>
      <data key="d6">21e429490eeefe7d9c245058fd48ca68</data>
    </edge>
    <edge source="BODY_WEIGHT" target="LOG_BODY_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">Body weight is transformed into log(body weight) to improve the linearity of the relationship between body weight and brain weight</data>
      <data key="d6">e2422d8b80004aab4ea74d5209587861</data>
    </edge>
    <edge source="BRAIN_WEIGHT" target="LOG_BRAIN_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">Brain weight is transformed into log(brain weight) to improve the linearity of the relationship between body weight and brain weight</data>
      <data key="d6">e2422d8b80004aab4ea74d5209587861</data>
    </edge>
    <edge source="BRAIN_WEIGHT" target="AVERAGE_BODY_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">Brain weight is predicted based on the average body weight, with a 7.4% increase for a 10% larger average body weight</data>
      <data key="d6">efeeb664622c1ee594e6a08a8322ffe3</data>
    </edge>
    <edge source="HUMAN" target="INFLUENTIAL_OBSERVATION">
      <data key="d4">1.0</data>
      <data key="d5">Human is flagged as an influential observation in the mammals dataset</data>
      <data key="d6">428db872e71a17a2cf7868b03a52def0</data>
    </edge>
    <edge source="BRAIN" target="BODY">
      <data key="d4">1.0</data>
      <data key="d5">Brain weight and body weight are variables in the mammals dataset that are plotted against each other in a scatterplot</data>
      <data key="d6">f9d6c3504b8f8b5c25550076e45f8270</data>
    </edge>
    <edge source="LOG_BODY_WEIGHT" target="LOG_BRAIN_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">The relationship between log(body weight) and log(brain weight) is likely to be linear, unlike the non-linear relationship between the original body weight and brain weight variables</data>
      <data key="d6">e2422d8b80004aab4ea74d5209587861</data>
    </edge>
    <edge source="LOG_BODY_WEIGHT" target="RESIDUALS_VS_LEVERAGE_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">The residuals vs leverage plot uses the residuals from the regression of log brain weight on log body weight to identify influential data points</data>
      <data key="d6">9e2ebbb113c00fa43f0af3c0696baf95</data>
    </edge>
    <edge source="LOG_BRAIN_WEIGHT" target="RESIDUALS_VS_LEVERAGE_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">The residuals vs leverage plot uses the residuals from the regression of log brain weight on log body weight to identify influential data points</data>
      <data key="d6">9e2ebbb113c00fa43f0af3c0696baf95</data>
    </edge>
    <edge source="LOG_BRAINI" target="BETA_HAT1">
      <data key="d4">1.0</data>
      <data key="d5">LOG_BRAINi is the log-transformed response variable in the model, which is related to the estimated slope coefficient BETA_HAT1</data>
      <data key="d6">86c401dda130c2d201c3339526062a24</data>
    </edge>
    <edge source="LOG_BODYI" target="BETA_HAT1">
      <data key="d4">1.0</data>
      <data key="d5">LOG_BODYi is the log-transformed explanatory variable in the model, which is related to the estimated slope coefficient BETA_HAT1</data>
      <data key="d6">86c401dda130c2d201c3339526062a24</data>
    </edge>
    <edge source="BETA_HAT1" target="YBA">
      <data key="d4">1.0</data>
      <data key="d5">BETA_HAT1 is used to predict the average brain weight YbA for species A</data>
      <data key="d6">86c401dda130c2d201c3339526062a24</data>
    </edge>
    <edge source="BETA_HAT1" target="YBB">
      <data key="d4">1.0</data>
      <data key="d5">BETA_HAT1 is used to predict the average brain weight YbB for species B</data>
      <data key="d6">86c401dda130c2d201c3339526062a24</data>
    </edge>
    <edge source="BETA_HAT1" target="SIGMA_SQUARED_MLE">
      <data key="d4">1.0</data>
      <data key="d5">Beta hat 1 (b&#946;1) is used in the calculation of Sigma squared MLE (&#963;b^2_MLE)</data>
      <data key="d6">09caa54ca1372d152e47051be4d44ede</data>
    </edge>
    <edge source="GIRTH" target="VOLUME">
      <data key="d4">1.0</data>
      <data key="d5">Volume is predicted to be proportional to the square of the diameter (girth) and the height of the tree</data>
      <data key="d6">efeeb664622c1ee594e6a08a8322ffe3</data>
    </edge>
    <edge source="VOLUME" target="TREE">
      <data key="d4">1.0</data>
      <data key="d5">The volume of timber is a property of the tree</data>
      <data key="d6">9611ea31ff53888971694cdefe806f64</data>
    </edge>
    <edge source="VOLUMEI" target="DIAMETERI">
      <data key="d4">1.0</data>
      <data key="d5">Volumei is calculated using Diameteri as one of the independent variables in the model</data>
      <data key="d6">60cc94e681863c9fcc6f9be1e500f840</data>
    </edge>
    <edge source="VOLUMEI" target="HEIGHTI">
      <data key="d4">1.0</data>
      <data key="d5">Volumei is calculated using Heighti as one of the independent variables in the model</data>
      <data key="d6">60cc94e681863c9fcc6f9be1e500f840</data>
    </edge>
    <edge source="VOLUMEI" target="&#917;I">
      <data key="d4">1.0</data>
      <data key="d5">&#1013;i is the error term in the model used to calculate Volumei</data>
      <data key="d6">60cc94e681863c9fcc6f9be1e500f840</data>
    </edge>
    <edge source="VOLUMEI" target="SCATTERPLOT_MATRIX">
      <data key="d4">1.0</data>
      <data key="d5">Scatterplot matrix includes scatterplots of Volumei against other variables for initial exploratory analysis</data>
      <data key="d6">60cc94e681863c9fcc6f9be1e500f840</data>
    </edge>
    <edge source="DIAMETERI" target="SCATTERPLOT_MATRIX">
      <data key="d4">1.0</data>
      <data key="d5">Scatterplot matrix includes scatterplots of Diameteri against other variables for initial exploratory analysis</data>
      <data key="d6">60cc94e681863c9fcc6f9be1e500f840</data>
    </edge>
    <edge source="HEIGHTI" target="SCATTERPLOT_MATRIX">
      <data key="d4">1.0</data>
      <data key="d5">Scatterplot matrix includes scatterplots of Heighti against other variables for initial exploratory analysis</data>
      <data key="d6">60cc94e681863c9fcc6f9be1e500f840</data>
    </edge>
    <edge source="LOG_TRANSFORMED_TREE_DATA" target="TREES_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The log-transformed tree data is used as the input data for the trees.model, which is a linear model</data>
      <data key="d6">a60af43e42c72a41fa90da06beb29d1b</data>
    </edge>
    <edge source="LOGTREES" target="TREES_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">The logTrees data frame is used as the data input for the trees.model</data>
      <data key="d6">a60af43e42c72a41fa90da06beb29d1b</data>
    </edge>
    <edge source="LOGTREES" target="TREES.MODEL">
      <data key="d4">1.0</data>
      <data key="d5">logTrees is the data frame used in the linear model trees.model</data>
      <data key="d6">9a28a6420fca4405488ca35762f9dc28</data>
    </edge>
    <edge source="TREES_MODEL" target="LOG_DIAMETER">
      <data key="d4">1.0</data>
      <data key="d5">Log-diameter is one of the parameters estimated by the trees.model</data>
      <data key="d6">a60af43e42c72a41fa90da06beb29d1b</data>
    </edge>
    <edge source="TREES_MODEL" target="LOG_HEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">Log-height is one of the parameters estimated by the trees.model</data>
      <data key="d6">a60af43e42c72a41fa90da06beb29d1b</data>
    </edge>
    <edge source="LOG_DIAMETER" target="LOG_VOLUME">
      <data key="d4">1.0</data>
      <data key="d5">Log-volume is regressed on log-diameter, indicating a relationship where changes in log-diameter are associated with changes in log-volume</data>
      <data key="d6">d71b402ab9edbb4347e09c7af3257cf5</data>
    </edge>
    <edge source="LOG_DIAMETER" target="COEFFICIENT_LOG_DIAMETER">
      <data key="d4">1.0</data>
      <data key="d5">The coefficient for log-diameter is associated with the independent variable log-diameter in the regression model</data>
      <data key="d6">d71b402ab9edbb4347e09c7af3257cf5</data>
    </edge>
    <edge source="LOG_HEIGHT" target="LOG_VOLUME">
      <data key="d4">1.0</data>
      <data key="d5">Log-volume is regressed on log-height, indicating a relationship where changes in log-height are associated with changes in log-volume</data>
      <data key="d6">d71b402ab9edbb4347e09c7af3257cf5</data>
    </edge>
    <edge source="TREES.MODEL" target="(INTERCEPT)">
      <data key="d4">1.0</data>
      <data key="d5">(Intercept) is the intercept coefficient in the linear model trees.model</data>
      <data key="d6">9a28a6420fca4405488ca35762f9dc28</data>
    </edge>
    <edge source="TREES.MODEL" target="LOGDIAMETER">
      <data key="d4">1.0</data>
      <data key="d5">logDiameter is a predictor variable in the linear model trees.model</data>
      <data key="d6">9a28a6420fca4405488ca35762f9dc28</data>
    </edge>
    <edge source="TREES.MODEL" target="LOGHEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">logHeight is a predictor variable in the linear model trees.model</data>
      <data key="d6">9a28a6420fca4405488ca35762f9dc28</data>
    </edge>
    <edge source="TREES.MODEL" target="LOGVOLUME">
      <data key="d4">1.0</data>
      <data key="d5">logVolume is the response variable in the linear model trees.model</data>
      <data key="d6">9a28a6420fca4405488ca35762f9dc28</data>
    </edge>
    <edge source="COEFFICIENT_LOG_DIAMETER" target="INTERCEPT_CYLINDER">
      <data key="d4">1.0</data>
      <data key="d5">The coefficient for log-diameter is used to calculate the intercept when the shape of a tree is approximated by a cylinder</data>
      <data key="d6">d71b402ab9edbb4347e09c7af3257cf5</data>
    </edge>
    <edge source="COEFFICIENT_LOG_DIAMETER" target="INTERCEPT_CONE">
      <data key="d4">1.0</data>
      <data key="d5">The coefficient for log-diameter is used to calculate the intercept when the shape of a tree is approximated by a cone</data>
      <data key="d6">d71b402ab9edbb4347e09c7af3257cf5</data>
    </edge>
    <edge source="INTERCEPT_CYLINDER" target="ESTIMATED_INTERCEPT">
      <data key="d4">1.0</data>
      <data key="d5">The intercept for the cylinder approximation is compared with the estimated intercept from the regression model</data>
      <data key="d6">d71b402ab9edbb4347e09c7af3257cf5</data>
    </edge>
    <edge source="INTERCEPT_CONE" target="ESTIMATED_INTERCEPT">
      <data key="d4">1.0</data>
      <data key="d5">The intercept for the cone approximation is compared with the estimated intercept from the regression model</data>
      <data key="d6">d71b402ab9edbb4347e09c7af3257cf5</data>
    </edge>
    <edge source="TRANSFORMATIONS" target="COMPLETE_DATASET">
      <data key="d4">1.0</data>
      <data key="d5">Transformations can be applied to the complete dataset to reduce the influence of data points</data>
      <data key="d6">83bb91cf725e5116ca2f5748fddccfae</data>
    </edge>
    <edge source="TRANSFORMATIONS" target="ROBUST_REGRESSION">
      <data key="d4">1.0</data>
      <data key="d5">Transformations, such as log transformation, can be seen as a less systematic approach compared to robust regression</data>
      <data key="d6">83bb91cf725e5116ca2f5748fddccfae</data>
    </edge>
    <edge source="S" target="A">
      <data key="d4">2.0</data>
      <data key="d5">Vector a is used in the calculation of S(&#946;) through various vector operationsMatrix A is used in the calculation of S(&#946;) through matrix multiplication</data>
      <data key="d6">2167274129d4cfa74a002c4cc39df8a8</data>
    </edge>
    <edge source="S" target="B">
      <data key="d4">2.0</data>
      <data key="d5">Vector b is used in the calculation of S(&#946;) through various vector operationsMatrix B is used in the calculation of S(&#946;) through matrix multiplication</data>
      <data key="d6">2167274129d4cfa74a002c4cc39df8a8</data>
    </edge>
    <edge source="S" target="J">
      <data key="d4">1.0</data>
      <data key="d5">J is used in the calculation of the function S, which represents the sum of squared errors</data>
      <data key="d6">eac62cdd5518e1269fed150639331c2c</data>
    </edge>
    <edge source="S" target="XTX">
      <data key="d4">2.0</data>
      <data key="d5">XTX is a symmetric matrix that is used in the calculation of the function S
XTX is used in the second term of S(&#946;), which is a sum of squares and must be non-negative</data>
      <data key="d6">a4a817bb79d6ae8812c808ca41d47f43,eac62cdd5518e1269fed150639331c2c</data>
    </edge>
    <edge source="S" target="XTY">
      <data key="d4">1.0</data>
      <data key="d5">XTY is a vector that is used in the calculation of the function S</data>
      <data key="d6">eac62cdd5518e1269fed150639331c2c</data>
    </edge>
    <edge source="S" target="PARTIAL_DERIVATIVE">
      <data key="d4">1.0</data>
      <data key="d5">The partial derivative of S(&#946;) with respect to Beta_0 is used to find the least squares estimate of Beta_0</data>
      <data key="d6">10ac76f99674a01ca0f4a55586dea07e</data>
    </edge>
    <edge source="S" target="PARTIAL_DERIVATIVES">
      <data key="d4">1.0</data>
      <data key="d5">The function S(&#946;) is differentiated to obtain the partial derivatives with respect to Beta_0 and Beta_1</data>
      <data key="d6">416494d940a9f505da9853caca26fe63</data>
    </edge>
    <edge source="S" target="L">
      <data key="d4">1.0</data>
      <data key="d5">S(&#946;) is derived from the likelihood function L(&#946;, &#963;^2|y) and is used in the calculation of the least squares estimate Beta hat (&#946;b)</data>
      <data key="d6">f632f01188d2c6e3091a965580cb4600</data>
    </edge>
    <edge source="S" target="RI">
      <data key="d4">2.0</data>
      <data key="d5">S is the estimated standard deviation used in the calculation of the standardised residual Ri
RI is calculated using s, the unbiased estimate of the error variance</data>
      <data key="d6">90b7e0427699cc1bb461e37939935138,c47968226557bc2eb5aec5bb7994fd0e</data>
    </edge>
    <edge source="S_BETA" target="BETA_HAT_0">
      <data key="d4">1.0</data>
      <data key="d5">S(&#946;) is minimized at the value of Beta_hat_0 (b&#946;0), which is the least squares estimate of Beta_0</data>
      <data key="d6">8f7a05b6d231105a6194eebdb2df372e</data>
    </edge>
    <edge source="S_BETA" target="BETA_HAT_1">
      <data key="d4">1.0</data>
      <data key="d5">S(&#946;) is minimized at the value of Beta_hat_1 (b&#946;1), which is the least squares estimate of Beta_1</data>
      <data key="d6">8f7a05b6d231105a6194eebdb2df372e</data>
    </edge>
    <edge source="BETA_HAT_0" target="Y_BAR">
      <data key="d4">1.0</data>
      <data key="d5">Y_bar is used in the calculation of Beta_hat_0 (b&#946;0)</data>
      <data key="d6">8f7a05b6d231105a6194eebdb2df372e</data>
    </edge>
    <edge source="BETA_HAT_0" target="X_BAR">
      <data key="d4">1.0</data>
      <data key="d5">X_bar is used in the calculation of Beta_hat_0 (b&#946;0)</data>
      <data key="d6">8f7a05b6d231105a6194eebdb2df372e</data>
    </edge>
    <edge source="BETA_HAT_0" target="BETA_HAT_1">
      <data key="d4">1.0</data>
      <data key="d5">Beta_hat_0 and Beta_hat_1 are the least squares estimates for the original model (2)</data>
      <data key="d6">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </edge>
    <edge source="BETA_HAT_0" target="Y_HAT_J">
      <data key="d4">1.0</data>
      <data key="d5">Y_hat_j is calculated using Beta_hat_0 as part of the fitted value</data>
      <data key="d6">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </edge>
    <edge source="BETA_HAT_1" target="X_BAR">
      <data key="d4">1.0</data>
      <data key="d5">X_bar is used in the calculation of Beta_hat_1 (b&#946;1)</data>
      <data key="d6">8f7a05b6d231105a6194eebdb2df372e</data>
    </edge>
    <edge source="BETA_HAT_1" target="Y_BAR">
      <data key="d4">1.0</data>
      <data key="d5">Y_bar is used in the calculation of Beta_hat_1 (b&#946;1)</data>
      <data key="d6">8f7a05b6d231105a6194eebdb2df372e</data>
    </edge>
    <edge source="BETA_HAT_1" target="Y_HAT_J">
      <data key="d4">1.0</data>
      <data key="d5">Y_hat_j is calculated using Beta_hat_1 as part of the fitted value</data>
      <data key="d6">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </edge>
    <edge source="Y_BAR" target="BETA_0_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Y_bar (y&#175;) is used in the calculation of Beta_0 hat (b&#946;0) as part of the least squares estimation</data>
      <data key="d6">3fdeeb7593174f5e8a9cff55a7cd92e3</data>
    </edge>
    <edge source="Y_BAR" target="BETA_1_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Y_bar (y&#175;) is used in the calculation of Beta_1 hat (b&#946;1) as part of the least squares estimation</data>
      <data key="d6">3fdeeb7593174f5e8a9cff55a7cd92e3</data>
    </edge>
    <edge source="Y_BAR" target="BETA1_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Y_bar is used in the calculation of Beta1_hat, the least squares estimator for &#946;1</data>
      <data key="d6">f9e7b2eac9f82681301da3d1e2f23328</data>
    </edge>
    <edge source="Y_BAR" target="BETA0_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Y_bar is used in the calculation of Beta0_hat, the least squares estimator for &#946;0</data>
      <data key="d6">f9e7b2eac9f82681301da3d1e2f23328</data>
    </edge>
    <edge source="Y_BAR" target="SXY">
      <data key="d4">1.0</data>
      <data key="d5">Y_bar is used in the calculation of Sxy as part of the covariance between x and y</data>
      <data key="d6">f5716ce115458c0652124734ca344806</data>
    </edge>
    <edge source="X_BAR" target="BETA_0_HAT">
      <data key="d4">1.0</data>
      <data key="d5">X_bar (x&#175;) is used in the calculation of Beta_0 hat (b&#946;0) as part of the least squares estimation</data>
      <data key="d6">3fdeeb7593174f5e8a9cff55a7cd92e3</data>
    </edge>
    <edge source="X_BAR" target="BETA_1_HAT">
      <data key="d4">1.0</data>
      <data key="d5">X_bar (x&#175;) is used in the calculation of Beta_1 hat (b&#946;1) as part of the least squares estimation</data>
      <data key="d6">3fdeeb7593174f5e8a9cff55a7cd92e3</data>
    </edge>
    <edge source="X_BAR" target="BETA1_HAT">
      <data key="d4">1.0</data>
      <data key="d5">X_bar is used in the calculation of Beta1_hat, the least squares estimator for &#946;1</data>
      <data key="d6">f9e7b2eac9f82681301da3d1e2f23328</data>
    </edge>
    <edge source="X_BAR" target="BETA0_HAT">
      <data key="d4">1.0</data>
      <data key="d5">X_bar is used in the calculation of Beta0_hat, the least squares estimator for &#946;0</data>
      <data key="d6">f9e7b2eac9f82681301da3d1e2f23328</data>
    </edge>
    <edge source="X_BAR" target="XTX">
      <data key="d4">1.0</data>
      <data key="d5">X_bar is used in the calculation of the elements of the matrix XTX</data>
      <data key="d6">56ff186fc629e1e42f2759fc4b984199</data>
    </edge>
    <edge source="X_BAR" target="SXY">
      <data key="d4">1.0</data>
      <data key="d5">X_bar is used in the calculation of Sxy as part of the covariance between x and y</data>
      <data key="d6">f5716ce115458c0652124734ca344806</data>
    </edge>
    <edge source="X_BAR" target="ALPHA">
      <data key="d4">2.0</data>
      <data key="d5">Bar X (x&#175;) is used in the transformation of the explanatory variable in the reparameterised model (1)
X_bar is used in the calculation of Alpha in the reparameterised model (1)</data>
      <data key="d6">5609007c6229060ffc85d8056a7fefde,82932abd152e0b84a1c26a2daa4c08df</data>
    </edge>
    <edge source="X_BAR" target="X_ALPHA">
      <data key="d4">1.0</data>
      <data key="d5">Mean X_bar is subtracted from each explanatory variable observation in X to obtain X_alpha</data>
      <data key="d6">6c66e9414880964ee899ceb0f16d22e9</data>
    </edge>
    <edge source="X_BAR" target="HII">
      <data key="d4">1.0</data>
      <data key="d5">The sample mean (x_bar) of the explanatory variable is used in calculating the leverage (hii) of the data points</data>
      <data key="d6">6ee02b38ae842fd5eac9a11c4fd6659f</data>
    </edge>
    <edge source="X_BAR" target="X_I">
      <data key="d4">1.0</data>
      <data key="d5">X_i is compared to X_bar to determine the leverage of the observation</data>
      <data key="d6">bd05fe6a05f9a13d33c4f1b5a771ada5</data>
    </edge>
    <edge source="BETA_0_HAT" target="VARIANCE_BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">VARIANCE_BETA_HAT includes the variance of BETA_0_HAT (b&#946;0)</data>
      <data key="d6">69ffba28a61d98d8d18f91c24b74dd4a</data>
    </edge>
    <edge source="BETA_0_HAT" target="COVARIANCE_BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">COVARIANCE_BETA_HAT includes the covariance between BETA_0_HAT (b&#946;0) and BETA_1_HAT (b&#946;1)</data>
      <data key="d6">69ffba28a61d98d8d18f91c24b74dd4a</data>
    </edge>
    <edge source="BETA_1_HAT" target="SXX">
      <data key="d4">1.0</data>
      <data key="d5">Sxx is used in the calculation of Beta_1 hat (b&#946;1) as part of the least squares estimation</data>
      <data key="d6">3fdeeb7593174f5e8a9cff55a7cd92e3</data>
    </edge>
    <edge source="BETA_1_HAT" target="SXY">
      <data key="d4">1.0</data>
      <data key="d5">Sxy is used in the calculation of Beta_1 hat (b&#946;1) as part of the least squares estimation</data>
      <data key="d6">3fdeeb7593174f5e8a9cff55a7cd92e3</data>
    </edge>
    <edge source="BETA_1_HAT" target="VARIANCE_BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">VARIANCE_BETA_HAT includes the variance of BETA_1_HAT (b&#946;1)</data>
      <data key="d6">69ffba28a61d98d8d18f91c24b74dd4a</data>
    </edge>
    <edge source="BETA_1_HAT" target="COVARIANCE_BETA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">COVARIANCE_BETA_HAT includes the covariance between BETA_0_HAT (b&#946;0) and BETA_1_HAT (b&#946;1)</data>
      <data key="d6">69ffba28a61d98d8d18f91c24b74dd4a</data>
    </edge>
    <edge source="SXX" target="BETA1_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Sxx is directly used in the calculation of Beta1_hat, the least squares estimator for &#946;1</data>
      <data key="d6">f9e7b2eac9f82681301da3d1e2f23328</data>
    </edge>
    <edge source="SXX" target="XTX">
      <data key="d4">1.0</data>
      <data key="d5">Sxx is used in the calculation of the inverse of the matrix XTX</data>
      <data key="d6">56ff186fc629e1e42f2759fc4b984199</data>
    </edge>
    <edge source="SXX" target="ALPHA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Sxx is used in the calculation of Alpha hat (&#945;b) as part of the least squares estimator in the reparameterized model</data>
      <data key="d6">f5716ce115458c0652124734ca344806</data>
    </edge>
    <edge source="SXY" target="BETA1_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Sxy is directly used in the calculation of Beta1_hat, the least squares estimator for &#946;1</data>
      <data key="d6">f9e7b2eac9f82681301da3d1e2f23328</data>
    </edge>
    <edge source="BETA1_HAT" target="BETA0_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Beta1_hat is used in the calculation of Beta0_hat, the least squares estimator for &#946;0</data>
      <data key="d6">f9e7b2eac9f82681301da3d1e2f23328</data>
    </edge>
    <edge source="BETA1_HAT" target="LOG_LIKELIHOOD">
      <data key="d4">1.0</data>
      <data key="d5">Beta1 hat is the value of Beta1 that maximizes the log-likelihood function</data>
      <data key="d6">87b717ba065d6d7c7431af284137eb12</data>
    </edge>
    <edge source="BETA0_HAT" target="LOG_LIKELIHOOD">
      <data key="d4">1.0</data>
      <data key="d5">Beta0 hat is the value of Beta0 that maximizes the log-likelihood function</data>
      <data key="d6">87b717ba065d6d7c7431af284137eb12</data>
    </edge>
    <edge source="XT" target="XTX">
      <data key="d4">1.0</data>
      <data key="d5">Matrix XT is multiplied by matrix X to form matrix XTX</data>
      <data key="d6">254a8a17b1be06702934341e3bf41e85</data>
    </edge>
    <edge source="XT" target="XTY">
      <data key="d4">1.0</data>
      <data key="d5">Matrix XT is multiplied by vector Y to form vector XTY</data>
      <data key="d6">254a8a17b1be06702934341e3bf41e85</data>
    </edge>
    <edge source="XT" target="ALPHA_HAT">
      <data key="d4">1.0</data>
      <data key="d5">XT is used in the calculation of Alpha hat (&#945;b) as part of the least squares estimator</data>
      <data key="d6">f5716ce115458c0652124734ca344806</data>
    </edge>
    <edge source="XT" target="H">
      <data key="d4">1.0</data>
      <data key="d5">Matrix H is calculated using the transpose of matrix X, making it dependent on XT</data>
      <data key="d6">46629f2efc6c82e81265a131b4bab2ee</data>
    </edge>
    <edge source="XTX" target="RANK">
      <data key="d4">1.0</data>
      <data key="d5">The rank of XTX is equal to p, indicating that XTX is non-singular and its inverse exists</data>
      <data key="d6">9d300fc83afb3261af61b2ab9721cadc</data>
    </edge>
    <edge source="XTX" target="H">
      <data key="d4">2.0</data>
      <data key="d5">Matrix H is calculated using the formula X(XTX)^-1XT, making it dependent on the XTX matrix
The trace of H is calculated using XTX, specifically tr(H) = tr(XTX(XTX)^-1XT)</data>
      <data key="d6">46629f2efc6c82e81265a131b4bab2ee,bd98ac7b4b5df4f63e7ecc8f4a821f57</data>
    </edge>
    <edge source="A" target="F_BETA">
      <data key="d4">1.0</data>
      <data key="d5">A is the matrix in the function f(&#946;) = &#946;T A&#946;</data>
      <data key="d6">21ec28dfe2b2c18030d541d63e51f45e</data>
    </edge>
    <edge source="A" target="GAMMA">
      <data key="d4">3.0</data>
      <data key="d5">A is the matrix transformation applied to Beta to obtain Gamma in the reparameterized model
A is used to transform Beta into Gamma
Gamma is related to Beta through the invertible matrix A in the reparameterisation of the model</data>
      <data key="d6">82932abd152e0b84a1c26a2daa4c08df,d94760a5f9f6ea115fcc18024035a627,f5716ce115458c0652124734ca344806</data>
    </edge>
    <edge source="A" target="ALPHA">
      <data key="d4">1.0</data>
      <data key="d5">A is the transformation matrix used to convert Beta into Alpha</data>
      <data key="d6">5609007c6229060ffc85d8056a7fefde</data>
    </edge>
    <edge source="A" target="X_ALPHA">
      <data key="d4">1.0</data>
      <data key="d5">Matrix A is used to transform X into X_alpha for the reparameterised model</data>
      <data key="d6">6c66e9414880964ee899ceb0f16d22e9</data>
    </edge>
    <edge source="A" target="AZ">
      <data key="d4">1.0</data>
      <data key="d5">A transforms Z into AZ, changing its distribution</data>
      <data key="d6">542f546c5a131196e4701fb33c9b1dee</data>
    </edge>
    <edge source="A" target="U">
      <data key="d4">2.0</data>
      <data key="d5">U is the result of the matrix transformation AZ
Matrix A is used to transform Z into U</data>
      <data key="d6">0ac60299320c55d642b3e38440c25f90,aac5b4f040b9c773bd1aa696dec469f6</data>
    </edge>
    <edge source="B" target="V">
      <data key="d4">2.0</data>
      <data key="d5">V is the result of the matrix transformation BZ
Matrix B is used to transform Z into V</data>
      <data key="d6">0ac60299320c55d642b3e38440c25f90,aac5b4f040b9c773bd1aa696dec469f6</data>
    </edge>
    <edge source="ALPHA_HAT" target="GAMMA">
      <data key="d4">1.0</data>
      <data key="d5">Gamma is the new parameter vector that Alpha hat (&#945;b) estimates in the reparameterized model</data>
      <data key="d6">f5716ce115458c0652124734ca344806</data>
    </edge>
    <edge source="ALPHA_HAT" target="Z">
      <data key="d4">1.0</data>
      <data key="d5">Z is the new design matrix used in the calculation of Alpha hat (&#945;b) as part of the least squares estimator in the reparameterized model</data>
      <data key="d6">f5716ce115458c0652124734ca344806</data>
    </edge>
    <edge source="GAMMA" target="GAMMA_HAT">
      <data key="d4">2.0</data>
      <data key="d5">Gamma is the true parameter that Gamma hat (&#947;b) estimates in the linear regression model
Gamma is the true parameter that Gamma hat (&#947;b) estimates in the reparameterised model</data>
      <data key="d6">82932abd152e0b84a1c26a2daa4c08df,d94760a5f9f6ea115fcc18024035a627</data>
    </edge>
    <edge source="Z" target="AZ">
      <data key="d4">1.0</data>
      <data key="d5">Z is transformed by A to produce AZ, changing its distribution</data>
      <data key="d6">542f546c5a131196e4701fb33c9b1dee</data>
    </edge>
    <edge source="Z" target="SIGMA_HAT_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">z1, ..., zn are the observed values used in the calculation of the unbiased estimator &#963;b^2 for the variance</data>
      <data key="d6">6648f0d6deed51fb4fb25e6992a71ddf</data>
    </edge>
    <edge source="Z" target="MULTIVARIATE_NORMAL_DISTRIBUTION">
      <data key="d4">1.0</data>
      <data key="d5">Z follows the multivariate normal distribution with mean &#181; and covariance matrix &#931;</data>
      <data key="d6">aac5b4f040b9c773bd1aa696dec469f6</data>
    </edge>
    <edge source="Z" target="U">
      <data key="d4">2.0</data>
      <data key="d5">U is obtained by transforming Z using matrix A
Vector Z is transformed by matrix A to obtain U</data>
      <data key="d6">0ac60299320c55d642b3e38440c25f90,aac5b4f040b9c773bd1aa696dec469f6</data>
    </edge>
    <edge source="Z" target="V">
      <data key="d4">2.0</data>
      <data key="d5">V is obtained by transforming Z using matrix B
Vector Z is transformed by matrix B to obtain V</data>
      <data key="d6">0ac60299320c55d642b3e38440c25f90,aac5b4f040b9c773bd1aa696dec469f6</data>
    </edge>
    <edge source="Z" target="CHI_SQUARED_DISTRIBUTION">
      <data key="d4">1.0</data>
      <data key="d5">The quadratic form (Z - &#181;)T &#931;-1 (Z - &#181;) follows a chi-squared distribution with n degrees of freedom, as stated in Lemma 10.2</data>
      <data key="d6">aac5b4f040b9c773bd1aa696dec469f6</data>
    </edge>
    <edge source="Z" target="S2">
      <data key="d4">1.0</data>
      <data key="d5">S2 is the unbiased estimator for the error variance, as mentioned in the context of distributional properties</data>
      <data key="d6">aac5b4f040b9c773bd1aa696dec469f6</data>
    </edge>
    <edge source="GAMMA_HAT" target="AT">
      <data key="d4">1.0</data>
      <data key="d5">AT is used in the calculation of Gamma hat (&#947;b) as part of the least squares estimator</data>
      <data key="d6">82932abd152e0b84a1c26a2daa4c08df</data>
    </edge>
    <edge source="ALPHA" target="A_INVERSE">
      <data key="d4">1.0</data>
      <data key="d5">A_inverse is the inverse transformation matrix used to convert Alpha back into Beta</data>
      <data key="d6">5609007c6229060ffc85d8056a7fefde</data>
    </edge>
    <edge source="ALPHA" target="X_ALPHA">
      <data key="d4">1.0</data>
      <data key="d5">X_alpha is the design matrix of the reparameterised model, obtained by transforming X_beta using A_inverse</data>
      <data key="d6">5609007c6229060ffc85d8056a7fefde</data>
    </edge>
    <edge source="ALPHA" target="C">
      <data key="d4">1.0</data>
      <data key="d5">Constant c is used to multiply all observations of the explanatory variable in the reparameterised model, affecting the relationship between Beta and Alpha</data>
      <data key="d6">6c66e9414880964ee899ceb0f16d22e9</data>
    </edge>
    <edge source="ALPHA_HAT_0" target="ALPHA_HAT_1">
      <data key="d4">1.0</data>
      <data key="d5">Alpha_hat_0 and Alpha_hat_1 are the least squares estimates for the reparameterised model (1)</data>
      <data key="d6">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </edge>
    <edge source="MAYA" target="AMBIENT_TEMPERATURE">
      <data key="d4">1.0</data>
      <data key="d5">Maya has fitted a simple linear regression model using ambient temperature as the explanatory variable</data>
      <data key="d6">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </edge>
    <edge source="AMBIENT_TEMPERATURE" target="FAHRENHEIT">
      <data key="d4">1.0</data>
      <data key="d5">Ambient temperature can be measured in Fahrenheit instead of Celsius</data>
      <data key="d6">d1b6fcd55d937c5fe2d6add69e0bcf05</data>
    </edge>
    <edge source="RESIDSS" target="S2">
      <data key="d4">1.0</data>
      <data key="d5">ResidSS is the residual sum of squares used in the calculation of the unbiased estimate s^2</data>
      <data key="d6">fc5b725f3c662c5471af20efdcc2dbff</data>
    </edge>
    <edge source="LSE" target="SHEATHER_BOOK">
      <data key="d4">1.0</data>
      <data key="d5">A Modern Approach to Regression with R (2009) by Sheather provides further reading on least squares estimation</data>
      <data key="d6">9fc2b1e8b2b61b557f88eb9e9c708597</data>
    </edge>
    <edge source="LOG_LIKELIHOOD" target="BETAK_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Beta_k hat is the value of Beta_k that maximizes the log-likelihood function</data>
      <data key="d6">87b717ba065d6d7c7431af284137eb12</data>
    </edge>
    <edge source="PI" target="L">
      <data key="d4">1.0</data>
      <data key="d5">Pi (&#960;) is used in the calculation of the likelihood function L</data>
      <data key="d6">e7edd8b2874a350779ae20f1ecdf4733</data>
    </edge>
    <edge source="D" target="L">
      <data key="d4">1.0</data>
      <data key="d5">D is the deviance or residual sum of squares, which is part of the likelihood function L</data>
      <data key="d6">e7edd8b2874a350779ae20f1ecdf4733</data>
    </edge>
    <edge source="L" target="SIGMA_HAT_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">Sigma hat squared (&#963;b^2MLE) is the maximum likelihood estimate of Sigma squared derived from the likelihood function L(&#946;, &#963;^2|y)</data>
      <data key="d6">f632f01188d2c6e3091a965580cb4600</data>
    </edge>
    <edge source="SIGMA_HAT_SQUARED" target="BIAS">
      <data key="d4">1.0</data>
      <data key="d5">The estimator for the error variance Sigma squared (&#963;b^2MLE) is biased</data>
      <data key="d6">f632f01188d2c6e3091a965580cb4600</data>
    </edge>
    <edge source="SIGMA_HAT_SQUARED" target="ERROR_VARIANCE">
      <data key="d4">1.0</data>
      <data key="d5">Error variance (&#963;^2) is estimated by Sigma hat squared (&#963;b^2MLE)</data>
      <data key="d6">f632f01188d2c6e3091a965580cb4600</data>
    </edge>
    <edge source="SIGMA_HAT_SQUARED" target="Z_BAR">
      <data key="d4">1.0</data>
      <data key="d5">Z_bar is the sample mean used in the calculation of the unbiased estimator &#963;b^2 for the variance</data>
      <data key="d6">6648f0d6deed51fb4fb25e6992a71ddf</data>
    </edge>
    <edge source="SIGMA_HAT_SQUARED" target="SIGMA_HAT_SQUARED_BIAS">
      <data key="d4">1.0</data>
      <data key="d5">&#963;b^2 (biased) is a related but biased version of the unbiased estimator &#963;b^2 for the variance</data>
      <data key="d6">6648f0d6deed51fb4fb25e6992a71ddf</data>
    </edge>
    <edge source="ERROR_VARIANCE" target="STANDARDISED_RESIDUAL">
      <data key="d4">1.0</data>
      <data key="d5">The standardised residual (ri) is calculated using an unbiased estimate of the error variance (&#963;^2)</data>
      <data key="d6">7e05f1b457a496c8b3630e7044fc5981</data>
    </edge>
    <edge source="ERROR_VARIANCE" target="S_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">s^2 is an unbiased estimate of &#963;^2, the error variance in the regression model</data>
      <data key="d6">09391efd3b8c510205098b548bc8dc74</data>
    </edge>
    <edge source="ERROR_VARIANCE" target="T_STATISTIC">
      <data key="d4">1.0</data>
      <data key="d5">The unbiased estimator for the error variance in a linear model is used in the calculation of the T-statistic. The T-statistic is calculated by dividing the estimated parameter by its standard error, which is based on the error variance.</data>
      <data key="d6">d7f3a28534ffe830fe6f4cef8c41a9b4</data>
    </edge>
    <edge source="AZ" target="MU">
      <data key="d4">1.0</data>
      <data key="d5">&#181; is the mean of Z, which is transformed by A to become the mean of AZ</data>
      <data key="d6">542f546c5a131196e4701fb33c9b1dee</data>
    </edge>
    <edge source="AZ" target="SIGMA">
      <data key="d4">1.0</data>
      <data key="d5">&#931; is the covariance matrix of Z, which is transformed by A to become the covariance matrix of AZ</data>
      <data key="d6">542f546c5a131196e4701fb33c9b1dee</data>
    </edge>
    <edge source="MU" target="BRAND_A">
      <data key="d4">1.0</data>
      <data key="d5">Mu (&#181;) is the intercept for the regression line of Brand A</data>
      <data key="d6">1d141ab04db553f78a313e430e54abb5</data>
    </edge>
    <edge source="MU" target="SALES_VOLUME">
      <data key="d4">1.0</data>
      <data key="d5">Mu is the intercept for brand A in the regression model</data>
      <data key="d6">b6870535f3975c49d45e62fbe475f198</data>
    </edge>
    <edge source="MU" target="BRAND_B">
      <data key="d4">1.0</data>
      <data key="d5">Mu (&#181;) is the intercept parameter in the regression model for brand B</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="MU" target="BRAND_C">
      <data key="d4">1.0</data>
      <data key="d5">Mu (&#181;) is the intercept parameter in the regression model for brand C</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="SIGMA_SQUARED_MLE" target="BETA_HAT0">
      <data key="d4">1.0</data>
      <data key="d5">Beta hat 0 (b&#946;0) is used in the calculation of Sigma squared MLE (&#963;b^2_MLE)</data>
      <data key="d6">09caa54ca1372d152e47051be4d44ede</data>
    </edge>
    <edge source="S_HAT_SQUARED" target="THEOREM_6_4">
      <data key="d4">1.0</data>
      <data key="d5">Theorem 6.4 provides the formula for s^2(Y), the unbiased estimator for the error variance</data>
      <data key="d6">6648f0d6deed51fb4fb25e6992a71ddf</data>
    </edge>
    <edge source="THEOREM_6_4" target="S2">
      <data key="d4">1.0</data>
      <data key="d5">Theorem 6.4 states that s^2 is an unbiased estimator for &#963;^2</data>
      <data key="d6">9923e77ac6b3de95cb5026bc5e7fe8c0</data>
    </edge>
    <edge source="S2" target="COOKS_DISTANCE">
      <data key="d4">1.0</data>
      <data key="d5">Cook's distance uses the estimated variance s^2 of the error term in the regression model to calculate the influence of an observation</data>
      <data key="d6">9e2ebbb113c00fa43f0af3c0696baf95</data>
    </edge>
    <edge source="S_SQUARED" target="DI">
      <data key="d4">1.0</data>
      <data key="d5">Di is indirectly related to S^2, the unbiased estimate of the error variance</data>
      <data key="d6">0443ab5e20a4f6b2f243c989ef6c723a</data>
    </edge>
    <edge source="H" target="Y_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Y hat (yb) is obtained by applying the hat matrix H to the observed values Y</data>
      <data key="d6">f470791d2d3fedede166f9bb11598c9c</data>
    </edge>
    <edge source="H" target="EPSILON_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Residuals (b&#1013;) are calculated as the difference between the observed values Y and the fitted values Y hat (yb), which are obtained by applying the hat matrix H to Y</data>
      <data key="d6">f470791d2d3fedede166f9bb11598c9c</data>
    </edge>
    <edge source="H" target="LEMMA_7_1">
      <data key="d4">1.0</data>
      <data key="d5">Lemma 7.1 describes the properties of the hat matrix H, including its symmetry, idempotence, and the properties of (In - H)</data>
      <data key="d6">f470791d2d3fedede166f9bb11598c9c</data>
    </edge>
    <edge source="H" target="IP">
      <data key="d4">2.0</data>
      <data key="d5">The trace of matrix H is equal to the trace of Ip, indicating a relationship between the hat matrix and the p x p identity matrix
The trace of H is equal to the trace of Ip, which is p</data>
      <data key="d6">46629f2efc6c82e81265a131b4bab2ee,bd98ac7b4b5df4f63e7ecc8f4a821f57</data>
    </edge>
    <edge source="H" target="HII">
      <data key="d4">2.0</data>
      <data key="d5">The diagonal elements of H, hii, represent the leverage of the ith data point
The hat matrix H is used to calculate the leverage hii of the ith data point</data>
      <data key="d6">0b650eb2f1dcd603b64fec3c4b5cd24b,bd98ac7b4b5df4f63e7ecc8f4a821f57</data>
    </edge>
    <edge source="H" target="YC">
      <data key="d4">4.0</data>
      <data key="d5">H is used to compute Yc as HY
H is used in the calculation of Yc as HY
H is used in the calculation of Yc
Yc is directly derived from H</data>
      <data key="d6">1da117a2f92b2db00290d2a0bfc06beb,679722cf8ce5ce5aee4e379528470efe,74d190f10bf6e6936242ca3cdfc4a09f,7d074208b1259e7d84f9f870d3828bb6</data>
    </edge>
    <edge source="H" target="EB">
      <data key="d4">2.0</data>
      <data key="d5">H is used in the calculation of EB as part of the transformation (In - H)
EB is indirectly derived from H through the matrix (In - H)</data>
      <data key="d6">74d190f10bf6e6936242ca3cdfc4a09f,7d074208b1259e7d84f9f870d3828bb6</data>
    </edge>
    <edge source="HII" target="H2">
      <data key="d4">1.0</data>
      <data key="d5">The diagonal elements of H2 are related to the squared leverage values hii</data>
      <data key="d6">679722cf8ce5ce5aee4e379528470efe</data>
    </edge>
    <edge source="HII" target="HIK">
      <data key="d4">1.0</data>
      <data key="d5">hii is the sum of its squared value and the sum of all other elements in the same row, excluding the diagonal element itself</data>
      <data key="d6">679722cf8ce5ce5aee4e379528470efe</data>
    </edge>
    <edge source="HII" target="YB_I">
      <data key="d4">1.0</data>
      <data key="d5">hii is the leverage value corresponding to the predicted value Yb_i</data>
      <data key="d6">1da117a2f92b2db00290d2a0bfc06beb</data>
    </edge>
    <edge source="HII" target="EB">
      <data key="d4">1.0</data>
      <data key="d5">The variance of the ith residual Eb_i is influenced by the leverage value hii</data>
      <data key="d6">5a0d392715f06d5e873f45ae06aa729a</data>
    </edge>
    <edge source="HII" target="EI">
      <data key="d4">1.0</data>
      <data key="d5">As hii approaches 1, the ith residual Ei tends to zero</data>
      <data key="d6">2685edb9e8031c8ea725c43a40af22a8</data>
    </edge>
    <edge source="HII" target="VAR_EI">
      <data key="d4">1.0</data>
      <data key="d5">The variance of the ith residual Var(Ei) is influenced by the leverage value hii</data>
      <data key="d6">2685edb9e8031c8ea725c43a40af22a8</data>
    </edge>
    <edge source="HII" target="RI">
      <data key="d4">2.0</data>
      <data key="d5">hii is used in the calculation of the standardised residual Ri, as part of the denominator
RI is adjusted by hii, the leverage value for the ith observation</data>
      <data key="d6">90b7e0427699cc1bb461e37939935138,c47968226557bc2eb5aec5bb7994fd0e</data>
    </edge>
    <edge source="HII" target="DI">
      <data key="d4">1.0</data>
      <data key="d5">Di is calculated using Hii, the leverage value for the ith observation</data>
      <data key="d6">0443ab5e20a4f6b2f243c989ef6c723a</data>
    </edge>
    <edge source="YC" target="VAR">
      <data key="d4">2.0</data>
      <data key="d5">Var is used to calculate the variance of Yc
Var is used to calculate the variance of Yc</data>
      <data key="d6">1da117a2f92b2db00290d2a0bfc06beb,74d190f10bf6e6936242ca3cdfc4a09f</data>
    </edge>
    <edge source="YC" target="EB">
      <data key="d4">1.0</data>
      <data key="d5">The covariance between EB and Yc is equal to the zero matrix</data>
      <data key="d6">74d190f10bf6e6936242ca3cdfc4a09f</data>
    </edge>
    <edge source="YC" target="COV">
      <data key="d4">2.0</data>
      <data key="d5">Cov is used to calculate the covariance between EB and Yc
The covariance between Yc and Eb is 0n&#215;n</data>
      <data key="d6">74d190f10bf6e6936242ca3cdfc4a09f,7d074208b1259e7d84f9f870d3828bb6</data>
    </edge>
    <edge source="VAR" target="EB">
      <data key="d4">1.0</data>
      <data key="d5">Var is used to calculate the variance of EB</data>
      <data key="d6">74d190f10bf6e6936242ca3cdfc4a09f</data>
    </edge>
    <edge source="YB_I" target="COOKS_DISTANCE">
      <data key="d4">2.0</data>
      <data key="d5">Cook's distance uses the fitted values yb(i) calculated from the dataset with the ith observation removed to measure the influence of the ith observation
yb(i) is used in the calculation of Cook's distance (Di) as the fitted value with the ith observation removed</data>
      <data key="d6">09391efd3b8c510205098b548bc8dc74,9e2ebbb113c00fa43f0af3c0696baf95</data>
    </edge>
    <edge source="YB_I" target="DI">
      <data key="d4">1.0</data>
      <data key="d5">Di is calculated using Yb(i), the fitted value from the dataset with the ith observation removed</data>
      <data key="d6">0443ab5e20a4f6b2f243c989ef6c723a</data>
    </edge>
    <edge source="EB" target="Y_HAT_I">
      <data key="d4">1.0</data>
      <data key="d5">As hii approaches 1, Eb_i tends to zero, implying y_hat_i will tend to yi</data>
      <data key="d6">5a0d392715f06d5e873f45ae06aa729a</data>
    </edge>
    <edge source="EB" target="COV">
      <data key="d4">2.0</data>
      <data key="d5">Cov is used to calculate the covariance between EB and Y
The covariance between Yc and Eb is 0n&#215;n</data>
      <data key="d6">74d190f10bf6e6936242ca3cdfc4a09f,7d074208b1259e7d84f9f870d3828bb6</data>
    </edge>
    <edge source="VAR_EI" target="&#931;_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">The variance of the ith residual Var(Ei) is given by &#963;^2(1 - hii)</data>
      <data key="d6">2685edb9e8031c8ea725c43a40af22a8</data>
    </edge>
    <edge source="COOKS_DISTANCE" target="INFLUENTIAL_OBSERVATION">
      <data key="d4">1.0</data>
      <data key="d5">Cook's distance is used to measure the influence of observations</data>
      <data key="d6">428db872e71a17a2cf7868b03a52def0</data>
    </edge>
    <edge source="COOKS_DISTANCE" target="BETA_HAT_I">
      <data key="d4">1.0</data>
      <data key="d5">Cook's distance uses the parameter estimates &#946;b(i) calculated from the dataset with the ith observation removed to measure the influence of the ith observation</data>
      <data key="d6">9e2ebbb113c00fa43f0af3c0696baf95</data>
    </edge>
    <edge source="COOKS_DISTANCE" target="DI">
      <data key="d4">1.0</data>
      <data key="d5">Di is a specific instance of Cook's distance for the ith observation</data>
      <data key="d6">323899f01972255cd3278bccee20d5d8</data>
    </edge>
    <edge source="COOKS_DISTANCE" target="FIGURE_8_4">
      <data key="d4">1.0</data>
      <data key="d5">Cook's distances are plotted in Figure 8.4 for the regression analysis</data>
      <data key="d6">323899f01972255cd3278bccee20d5d8</data>
    </edge>
    <edge source="COOKS_DISTANCE" target="STANDARDISED_RESIDUAL">
      <data key="d4">1.0</data>
      <data key="d5">The standardised residual (ri) is related to Cook's distance as both are measures of influence in regression analysis</data>
      <data key="d6">7e05f1b457a496c8b3630e7044fc5981</data>
    </edge>
    <edge source="COOKS_DISTANCE" target="INFLUENTIAL_DATA_POINT">
      <data key="d4">2.0</data>
      <data key="d5">Cook's distance (Di) measures the influence of the ith observation on the regression model
Cook's distance is a measure used to identify influential data points</data>
      <data key="d6">09391efd3b8c510205098b548bc8dc74,629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="COOKS_DISTANCE" target="F_DISTRIBUTION">
      <data key="d4">1.0</data>
      <data key="d5">The F-distribution (Fp,n-p(0.5)) is used as a threshold for Cook's distance (Di) to identify influential data points</data>
      <data key="d6">09391efd3b8c510205098b548bc8dc74</data>
    </edge>
    <edge source="COOKS_DISTANCE" target="PLOTS">
      <data key="d4">1.0</data>
      <data key="d5">Plots can be used to visualize Cook's distance</data>
      <data key="d6">629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="COOKS_DISTANCE" target="RULES_OF_THUMB">
      <data key="d4">1.0</data>
      <data key="d5">Rules of thumb can be used to interpret Cook's distance</data>
      <data key="d6">629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="X_I" target="LEVERAGE">
      <data key="d4">1.0</data>
      <data key="d5">Leverage is calculated based on the distance of X_i from X_bar</data>
      <data key="d6">bd05fe6a05f9a13d33c4f1b5a771ada5</data>
    </edge>
    <edge source="LEVERAGE" target="INFLUENCE_INDEX_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">InfluenceIndexPlot is used to visualize the leverages of data points</data>
      <data key="d6">bd05fe6a05f9a13d33c4f1b5a771ada5</data>
    </edge>
    <edge source="LEVERAGE" target="INFLUENTIAL_OBSERVATION">
      <data key="d4">1.0</data>
      <data key="d5">Influential observations may have high leverage</data>
      <data key="d6">428db872e71a17a2cf7868b03a52def0</data>
    </edge>
    <edge source="LEVERAGE" target="STANDARDISED_RESIDUAL">
      <data key="d4">1.0</data>
      <data key="d5">Leverage is used in the calculation of the standardised residual (ri) to assess the influence of each observation</data>
      <data key="d6">7e05f1b457a496c8b3630e7044fc5981</data>
    </edge>
    <edge source="LEVERAGE" target="INFLUENTIAL_DATA_POINT">
      <data key="d4">1.0</data>
      <data key="d5">Leverage is a measure used to identify influential data points by assessing their distance from the center of the predictor space</data>
      <data key="d6">09391efd3b8c510205098b548bc8dc74</data>
    </edge>
    <edge source="LEVERAGE" target="HIGH_LEVERAGE_DATA_POINT">
      <data key="d4">1.0</data>
      <data key="d5">Leverage is a measure used to identify high leverage data points</data>
      <data key="d6">629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="LEVERAGE" target="PLOTS">
      <data key="d4">1.0</data>
      <data key="d5">Plots can be used to visualize leverage</data>
      <data key="d6">629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="LEVERAGE" target="RULES_OF_THUMB">
      <data key="d4">1.0</data>
      <data key="d5">Rules of thumb can be used to interpret leverage values</data>
      <data key="d6">629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="INFLUENCE_INDEX_PLOT" target="CAR_PACKAGE">
      <data key="d4">1.0</data>
      <data key="d5">InfluenceIndexPlot is a function provided by the car package</data>
      <data key="d6">bd05fe6a05f9a13d33c4f1b5a771ada5</data>
    </edge>
    <edge source="INFLUENCE_INDEX_PLOT" target="FIGURE_8_1">
      <data key="d4">1.0</data>
      <data key="d5">Figure 8.1 is the output of the InfluenceIndexPlot function for the mammals dataset</data>
      <data key="d6">bd05fe6a05f9a13d33c4f1b5a771ada5</data>
    </edge>
    <edge source="REGRESSION" target="LOGARITHM">
      <data key="d4">1.0</data>
      <data key="d5">The logarithm transformation is applied to both the average brain weight and average body weight in the regression model.</data>
      <data key="d6">f0b1289a0623b82a686b3b7dfb3a6ee8</data>
    </edge>
    <edge source="REGRESSION" target="LOG_AVERAGE_BRAIN_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">Log average brain weight is the dependent variable in the regression analysis</data>
      <data key="d6">428db872e71a17a2cf7868b03a52def0</data>
    </edge>
    <edge source="REGRESSION" target="LOG_AVERAGE_BODY_WEIGHT">
      <data key="d4">1.0</data>
      <data key="d5">Log average body weight is the independent variable in the regression analysis</data>
      <data key="d6">428db872e71a17a2cf7868b03a52def0</data>
    </edge>
    <edge source="RI" target="EBI">
      <data key="d4">1.0</data>
      <data key="d5">Eb_i is the raw residual, used in the calculation of the standardised residual Ri</data>
      <data key="d6">90b7e0427699cc1bb461e37939935138</data>
    </edge>
    <edge source="RI" target="EPSILON_BI">
      <data key="d4">1.0</data>
      <data key="d5">RI is calculated using &#1013;bi as part of the standardised residual formula</data>
      <data key="d6">c47968226557bc2eb5aec5bb7994fd0e</data>
    </edge>
    <edge source="RI" target="DI">
      <data key="d4">1.0</data>
      <data key="d5">Di is calculated using ri, the standardised residual for the ith observation</data>
      <data key="d6">98d6982108f2d42fe0437bff8c666e17</data>
    </edge>
    <edge source="EPSILON_BI" target="DI">
      <data key="d4">1.0</data>
      <data key="d5">Di is calculated using Epsilon bi (&#1013;bi), the residual for the ith observation</data>
      <data key="d6">0443ab5e20a4f6b2f243c989ef6c723a</data>
    </edge>
    <edge source="DATASET_SIZE" target="THRESHOLD">
      <data key="d4">1.0</data>
      <data key="d5">The dataset size determines the threshold for identifying outliers based on the standardised residuals</data>
      <data key="d6">c47968226557bc2eb5aec5bb7994fd0e</data>
    </edge>
    <edge source="DATASET_SIZE" target="MODEL_FIT">
      <data key="d4">1.0</data>
      <data key="d5">The size of the dataset affects the model fit</data>
      <data key="d6">428db872e71a17a2cf7868b03a52def0</data>
    </edge>
    <edge source="HUMAN_OBSERVATION" target="RESIDUALS_VS_LEVERAGE_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">The residuals vs leverage plot flags the human observation as potentially influential</data>
      <data key="d6">9e2ebbb113c00fa43f0af3c0696baf95</data>
    </edge>
    <edge source="HUMAN_OBSERVATION" target="FIGURE_8_4">
      <data key="d4">1.0</data>
      <data key="d5">The observation for Human is highlighted in Figure 8.4 as having the largest Cook's distance</data>
      <data key="d6">323899f01972255cd3278bccee20d5d8</data>
    </edge>
    <edge source="WATER_OPOSSUM_OBSERVATION" target="RESIDUALS_VS_LEVERAGE_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">The residuals vs leverage plot flags the water opossum observation as potentially influential</data>
      <data key="d6">9e2ebbb113c00fa43f0af3c0696baf95</data>
    </edge>
    <edge source="LOG_AVERAGE_BRAIN_WEIGHT" target="FIGURE_8_4">
      <data key="d4">1.0</data>
      <data key="d5">Logarithm of average brain weight is the dependent variable in the regression analysis whose results are plotted in Figure 8.4</data>
      <data key="d6">323899f01972255cd3278bccee20d5d8</data>
    </edge>
    <edge source="LOG_AVERAGE_BODY_WEIGHT" target="FIGURE_8_4">
      <data key="d4">1.0</data>
      <data key="d5">Logarithm of average body weight is the independent variable in the regression analysis whose results are plotted in Figure 8.4</data>
      <data key="d6">323899f01972255cd3278bccee20d5d8</data>
    </edge>
    <edge source="INFLUENTIAL_OBSERVATION" target="RESIDUALS_VS_LEVERAGE_PLOT">
      <data key="d4">1.0</data>
      <data key="d5">Residuals vs leverage plot is used to identify influential observations</data>
      <data key="d6">428db872e71a17a2cf7868b03a52def0</data>
    </edge>
    <edge source="INFLUENTIAL_OBSERVATION" target="WATER_OPOSSUM">
      <data key="d4">1.0</data>
      <data key="d5">Water opossum is flagged as an influential observation in the mammals dataset</data>
      <data key="d6">428db872e71a17a2cf7868b03a52def0</data>
    </edge>
    <edge source="INFLUENTIAL_OBSERVATION" target="MUSK_SHREW">
      <data key="d4">1.0</data>
      <data key="d5">Musk shrew is flagged as an influential observation in the mammals dataset</data>
      <data key="d6">428db872e71a17a2cf7868b03a52def0</data>
    </edge>
    <edge source="RESIDUALS_VS_LEVERAGE_PLOT" target="MUSK_SHREW_OBSERVATION">
      <data key="d4">1.0</data>
      <data key="d5">The residuals vs leverage plot flags the musk shrew observation as potentially influential</data>
      <data key="d6">9e2ebbb113c00fa43f0af3c0696baf95</data>
    </edge>
    <edge source="BETA_HAT_I" target="DI">
      <data key="d4">1.0</data>
      <data key="d5">Di is calculated using Beta hat (&#946;b(i)), the parameter estimate from the dataset with the ith observation removed</data>
      <data key="d6">0443ab5e20a4f6b2f243c989ef6c723a</data>
    </edge>
    <edge source="DI" target="TXTX">
      <data key="d4">1.0</data>
      <data key="d5">Di is calculated using the matrix product TXTX</data>
      <data key="d6">0443ab5e20a4f6b2f243c989ef6c723a</data>
    </edge>
    <edge source="DI" target="PS_SQUARED">
      <data key="d4">1.0</data>
      <data key="d5">Di is calculated using Ps^2, the estimated variance</data>
      <data key="d6">0443ab5e20a4f6b2f243c989ef6c723a</data>
    </edge>
    <edge source="DI" target="R_SQUARED_I">
      <data key="d4">1.0</data>
      <data key="d5">Di is calculated using Ri^2, the squared standardised residual for the ith observation</data>
      <data key="d6">0443ab5e20a4f6b2f243c989ef6c723a</data>
    </edge>
    <edge source="DI" target="BI">
      <data key="d4">1.0</data>
      <data key="d5">bi is part of the subscript used in the calculation of the squared error term that contributes to the Cook's distance Di</data>
      <data key="d6">98d6982108f2d42fe0437bff8c666e17</data>
    </edge>
    <edge source="DI" target="PS2">
      <data key="d4">1.0</data>
      <data key="d5">ps2 is part of the variable used in the calculation of the squared error term that contributes to the Cook's distance Di</data>
      <data key="d6">98d6982108f2d42fe0437bff8c666e17</data>
    </edge>
    <edge source="DI" target="HI">
      <data key="d4">1.0</data>
      <data key="d5">hi is part of the subscript used in the calculation of the leverage and influence terms that contribute to the Cook's distance Di</data>
      <data key="d6">98d6982108f2d42fe0437bff8c666e17</data>
    </edge>
    <edge source="DI" target="F_DISTRIBUTION">
      <data key="d4">1.0</data>
      <data key="d5">Di is compared to the F-distribution to determine if the ith observation is influential</data>
      <data key="d6">98d6982108f2d42fe0437bff8c666e17</data>
    </edge>
    <edge source="DI" target="FIGURE_8_4">
      <data key="d4">1.0</data>
      <data key="d5">Di is plotted in Figure 8.4, an index plot of the Cook's distances for the regression</data>
      <data key="d6">98d6982108f2d42fe0437bff8c666e17</data>
    </edge>
    <edge source="DI" target="FP_N_P">
      <data key="d4">1.0</data>
      <data key="d5">Di is compared to Fp,n-p(0.5) to determine if the ith observation is influential</data>
      <data key="d6">323899f01972255cd3278bccee20d5d8</data>
    </edge>
    <edge source="DATA_ENTRY_ERROR" target="ANOTHER_POPULATION">
      <data key="d4">1.0</data>
      <data key="d5">A data entry error can result in a data point that appears to be from another population</data>
      <data key="d6">83bb91cf725e5116ca2f5748fddccfae</data>
    </edge>
    <edge source="ROBUST_REGRESSION" target="HIGH_LEVERAGE_DATA_POINT">
      <data key="d4">1.0</data>
      <data key="d5">Robust regression is designed to handle high leverage data points by being less sensitive to their influence</data>
      <data key="d6">629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="ROBUST_REGRESSION" target="REGRESSION_OUTLIER">
      <data key="d4">1.0</data>
      <data key="d5">Robust regression is designed to handle regression outliers by being less sensitive to their influence</data>
      <data key="d6">629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="ROBUST_REGRESSION" target="INFLUENTIAL_DATA_POINT">
      <data key="d4">1.0</data>
      <data key="d5">Robust regression is designed to handle influential data points by being less sensitive to their influence</data>
      <data key="d6">629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="ROBUST_REGRESSION" target="GENERALIZED_LINEAR_MODELS_BOOK">
      <data key="d4">1.0</data>
      <data key="d5">The book covers material related to robust regression</data>
      <data key="d6">629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="ROBUST_REGRESSION" target="DATA_ANALYSIS_AND_GRAPHICS_BOOK">
      <data key="d4">1.0</data>
      <data key="d5">The book covers material related to robust regression</data>
      <data key="d6">629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="STANDARDISED_RESIDUAL" target="INFLUENTIAL_DATA_POINT">
      <data key="d4">1.0</data>
      <data key="d5">Standardised residuals are used to identify influential data points by assessing the size of the residuals relative to their standard deviation</data>
      <data key="d6">09391efd3b8c510205098b548bc8dc74</data>
    </edge>
    <edge source="INFLUENTIAL_DATA_POINT" target="REGRESSION_OUTLIER">
      <data key="d4">1.0</data>
      <data key="d5">A regression outlier can be an influential data point if it has a large residual</data>
      <data key="d6">09391efd3b8c510205098b548bc8dc74</data>
    </edge>
    <edge source="INFLUENTIAL_DATA_POINT" target="HANDLING_INFLUENTIAL_DATA_POINTS">
      <data key="d4">1.0</data>
      <data key="d5">Options on how to handle influential data points are relevant for dealing with influential data points</data>
      <data key="d6">629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="CATEGORICAL_PREDICTOR_VARIABLES" target="GENDER">
      <data key="d4">1.0</data>
      <data key="d5">Gender is an example of a categorical predictor variable</data>
      <data key="d6">629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="CATEGORICAL_PREDICTOR_VARIABLES" target="DEGREE_COURSE">
      <data key="d4">1.0</data>
      <data key="d5">Degree course is an example of a categorical predictor variable</data>
      <data key="d6">629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="GENDER" target="QUALITATIVE_PREDICTOR">
      <data key="d4">1.0</data>
      <data key="d5">Gender is a specific example of a qualitative predictor variable</data>
      <data key="d6">39aef0392258a09378ce45d8b03a268a</data>
    </edge>
    <edge source="DEGREE_COURSE" target="LEVELS">
      <data key="d4">1.0</data>
      <data key="d5">Degree course has levels such as Data Science, MathStat, and MORSE</data>
      <data key="d6">629ce6550294d332948e19171a4acd2d</data>
    </edge>
    <edge source="DEGREE_COURSE" target="QUALITATIVE_PREDICTOR">
      <data key="d4">1.0</data>
      <data key="d5">Degree course is a specific example of a qualitative predictor variable</data>
      <data key="d6">39aef0392258a09378ce45d8b03a268a</data>
    </edge>
    <edge source="QUANTITATIVE_PREDICTOR" target="QUALITATIVE_PREDICTOR">
      <data key="d4">1.0</data>
      <data key="d5">Quantitative and qualitative predictor variables are both used in statistical models to predict outcomes, but they differ in their nature and the way they are analyzed</data>
      <data key="d6">39aef0392258a09378ce45d8b03a268a</data>
    </edge>
    <edge source="RETAIL_DATASET" target="COMPARATIVE_BOXPLOTS">
      <data key="d4">2.0</data>
      <data key="d5">Comparative boxplots can be used to visualize the relationship between a categorical variable and a quantitative variable in the Retail dataset
Comparative boxplots are used to visualize the relationship between sales volumes and brands in the Retail dataset</data>
      <data key="d6">39aef0392258a09378ce45d8b03a268a,ab898d123f48e380384aa01e035a83ca</data>
    </edge>
    <edge source="RETAIL_DATASET" target="SALES_VOLUMES">
      <data key="d4">1.0</data>
      <data key="d5">The Retail dataset contains sales volumes data</data>
      <data key="d6">ab898d123f48e380384aa01e035a83ca</data>
    </edge>
    <edge source="RETAIL_DATASET" target="BRAND_C">
      <data key="d4">1.0</data>
      <data key="d5">The Retail dataset contains information about Brand C</data>
      <data key="d6">ab898d123f48e380384aa01e035a83ca</data>
    </edge>
    <edge source="RETAIL_DATASET" target="BRAND_A">
      <data key="d4">1.0</data>
      <data key="d5">The Retail dataset contains information about Brand A</data>
      <data key="d6">ab898d123f48e380384aa01e035a83ca</data>
    </edge>
    <edge source="RETAIL_DATASET" target="BRAND_B">
      <data key="d4">1.0</data>
      <data key="d5">The Retail dataset contains information about Brand B</data>
      <data key="d6">ab898d123f48e380384aa01e035a83ca</data>
    </edge>
    <edge source="RETAIL_DATASET" target="REGRESSION_MODELS">
      <data key="d4">1.0</data>
      <data key="d5">Regression models can be used to analyze the relationship between sales volumes and brands in the Retail dataset</data>
      <data key="d6">ab898d123f48e380384aa01e035a83ca</data>
    </edge>
    <edge source="COMPARATIVE_BOXPLOTS" target="BOXPLOT_COMMAND">
      <data key="d4">1.0</data>
      <data key="d5">The boxplot command is used to produce comparative boxplots</data>
      <data key="d6">39aef0392258a09378ce45d8b03a268a</data>
    </edge>
    <edge source="SALES_VOLUMES" target="BRAND_C">
      <data key="d4">1.0</data>
      <data key="d5">Sales volumes of Brand C stores are higher, on average, than those of other brands</data>
      <data key="d6">ab898d123f48e380384aa01e035a83ca</data>
    </edge>
    <edge source="SALES_VOLUMES" target="BRAND_A">
      <data key="d4">1.0</data>
      <data key="d5">Sales volumes of Brand A stores are lower, on average, than those of Brand C</data>
      <data key="d6">ab898d123f48e380384aa01e035a83ca</data>
    </edge>
    <edge source="SALES_VOLUMES" target="BRAND_B">
      <data key="d4">1.0</data>
      <data key="d5">Sales volumes of Brand B stores are lower, on average, than those of Brand C</data>
      <data key="d6">ab898d123f48e380384aa01e035a83ca</data>
    </edge>
    <edge source="BRAND_C" target="SALES_VOLUME">
      <data key="d4">3.0</data>
      <data key="d5">Brand C has an average sales volume of 126,680 units, which is substantially higher than the other two brands.
Brand C's sales volume is influenced by factors other than price, as indicated by the observations lying above the fitted regression line.
The sales volume for Brand C stores is predicted by the model</data>
      <data key="d6">096afa471635bc59c3bfa9af4d04d625,7a605c3b689bec7ab2c46df9c123e3f3,e079b7c92d5c0b009ff02040eb652bc6</data>
    </edge>
    <edge source="BRAND_C" target="SALESJ">
      <data key="d4">1.0</data>
      <data key="d5">Brand C's indicator variable xjC is used in the model for Salesj</data>
      <data key="d6">228bdca7843406def245d755e8df49f6</data>
    </edge>
    <edge source="BRAND_C" target="AVERAGE_PRICE">
      <data key="d4">1.0</data>
      <data key="d5">At the average price, the expected number of units sold by Brand C stores can be calculated</data>
      <data key="d6">9854704301b8df256ca1013b8d53dfac</data>
    </edge>
    <edge source="BRAND_C" target="CEO">
      <data key="d4">1.0</data>
      <data key="d5">The CEO is responsible for overseeing the stores of Brand C, and is interested in the performance of these stores</data>
      <data key="d6">9854704301b8df256ca1013b8d53dfac</data>
    </edge>
    <edge source="BRAND_C" target="FACTOR_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">Factor variable defines the group of Brand C stores</data>
      <data key="d6">906eb7d6b49fa360e7e5b65c56cd4d76</data>
    </edge>
    <edge source="BRAND_C" target="ALPHA_C">
      <data key="d4">2.0</data>
      <data key="d5">Alpha C (&#945;C) represents the difference in intercept between the regression line for Brand C and that for Brand A
Alpha C (&#945;C) is the parameter for brand C in the regression model</data>
      <data key="d6">1d141ab04db553f78a313e430e54abb5,825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="BRAND_C" target="X_C">
      <data key="d4">1.0</data>
      <data key="d5">X_C (xjC) is an indicator variable for Brand C</data>
      <data key="d6">1d141ab04db553f78a313e430e54abb5</data>
    </edge>
    <edge source="BRAND_C" target="XJC">
      <data key="d4">1.0</data>
      <data key="d5">Brand C is represented by the indicator variable xjC in the design matrix</data>
      <data key="d6">c103c6d096d52868eda26d991194b5f2</data>
    </edge>
    <edge source="BRAND_C" target="BRAND_A">
      <data key="d4">1.0</data>
      <data key="d5">Brand A is the baseline category against which Brand C is compared in terms of sales volume</data>
      <data key="d6">baa0dc3d4ec0e51c0a321e5579caf8aa</data>
    </edge>
    <edge source="BRAND_C" target="PARALLEL_LINES_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Brand C is analyzed using the parallel lines model to assess the fit of the regression line</data>
      <data key="d6">0cb40986e6c2bb439e1ffcaae2df96ac</data>
    </edge>
    <edge source="BRAND_C" target="STORE_J">
      <data key="d4">1.0</data>
      <data key="d5">Store j can be of brand C, which has its own regression line</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="BRAND_C" target="BRAND_B">
      <data key="d4">1.0</data>
      <data key="d5">Brand B and Brand C are different brands in the dataset, each with its own regression line</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="BRAND_C" target="GAMMA_C">
      <data key="d4">1.0</data>
      <data key="d5">Gamma C (&#947;C) describes the difference in slope between the regression line for Brand C and Brand A</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="BRAND_C" target="ALPHA_B_C">
      <data key="d4">1.0</data>
      <data key="d5">Brand C's intercept difference from Brand A is represented by Alpha hat for Brand C (&#945;bC)</data>
      <data key="d6">adbc52b340a69a8633c919c4fd2cd3f6</data>
    </edge>
    <edge source="BRAND_C" target="GAMMA_B_C">
      <data key="d4">1.0</data>
      <data key="d5">Brand C's price effect difference from Brand A is represented by Gamma hat for Brand C (&#947;bC)</data>
      <data key="d6">adbc52b340a69a8633c919c4fd2cd3f6</data>
    </edge>
    <edge source="BRAND_C" target="FIGURE_9_5">
      <data key="d4">1.0</data>
      <data key="d5">Figure 9.5 visualizes the sales model for Brand C stores, showing the relationship between sales and price</data>
      <data key="d6">3dd24a54028976ba54304ec7169bb74b</data>
    </edge>
    <edge source="BRAND_C" target="INTERACTION_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">In the interaction model, the effect of price on sales volume for Brand C stores is compared to that of Brand A and Brand B</data>
      <data key="d6">1820d10ee0f23f34b3ea88ba475bc52d</data>
    </edge>
    <edge source="BRAND_A" target="SALES_VOLUME">
      <data key="d4">2.0</data>
      <data key="d5">Brand A has an average sales volume of 109,679 units, which is lower than Brand C's average sales volume.
Brand A's sales volume is influenced by factors other than price, as indicated by the observations lying below the fitted regression line.</data>
      <data key="d6">7a605c3b689bec7ab2c46df9c123e3f3,e079b7c92d5c0b009ff02040eb652bc6</data>
    </edge>
    <edge source="BRAND_A" target="SALESJ">
      <data key="d4">1.0</data>
      <data key="d5">Brand A's indicator variable xjA is used in the model for Salesj, calculated as 1 - xjB - xjC</data>
      <data key="d6">228bdca7843406def245d755e8df49f6</data>
    </edge>
    <edge source="BRAND_A" target="AVERAGE_PRICE">
      <data key="d4">1.0</data>
      <data key="d5">At the average price, the expected number of units sold by Brand A stores can be calculated</data>
      <data key="d6">9854704301b8df256ca1013b8d53dfac</data>
    </edge>
    <edge source="BRAND_A" target="CEO">
      <data key="d4">1.0</data>
      <data key="d5">The CEO is responsible for overseeing the stores of Brand A, and is interested in the performance of these stores</data>
      <data key="d6">9854704301b8df256ca1013b8d53dfac</data>
    </edge>
    <edge source="BRAND_A" target="FACTOR_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">Factor variable defines the group of Brand A stores</data>
      <data key="d6">906eb7d6b49fa360e7e5b65c56cd4d76</data>
    </edge>
    <edge source="BRAND_A" target="ALPHA_B">
      <data key="d4">1.0</data>
      <data key="d5">Alpha_B (&#945;B) represents the expected difference in sales volume of Brand B stores compared to Brand A stores for a fixed product price</data>
      <data key="d6">baa0dc3d4ec0e51c0a321e5579caf8aa</data>
    </edge>
    <edge source="BRAND_A" target="ALPHA_C">
      <data key="d4">1.0</data>
      <data key="d5">Alpha_C (&#945;C) represents the expected difference in sales volume of Brand C stores compared to Brand A stores for a fixed product price</data>
      <data key="d6">baa0dc3d4ec0e51c0a321e5579caf8aa</data>
    </edge>
    <edge source="BRAND_A" target="BRAND_B">
      <data key="d4">1.0</data>
      <data key="d5">Brand A is the baseline category against which Brand B is compared in terms of sales volume</data>
      <data key="d6">baa0dc3d4ec0e51c0a321e5579caf8aa</data>
    </edge>
    <edge source="BRAND_A" target="TREATMENT_CODING">
      <data key="d4">1.0</data>
      <data key="d5">Treatment coding uses Brand A as the reference category for comparing the sales volumes of other brands</data>
      <data key="d6">baa0dc3d4ec0e51c0a321e5579caf8aa</data>
    </edge>
    <edge source="BRAND_A" target="PARALLEL_LINES_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Brand A is analyzed using the parallel lines model to assess the fit of the regression line</data>
      <data key="d6">0cb40986e6c2bb439e1ffcaae2df96ac</data>
    </edge>
    <edge source="BRAND_A" target="MU_B">
      <data key="d4">1.0</data>
      <data key="d5">Brand A's intercept in the model is represented by Mu hat (&#181;b)</data>
      <data key="d6">adbc52b340a69a8633c919c4fd2cd3f6</data>
    </edge>
    <edge source="BRAND_A" target="FIGURE_9_5">
      <data key="d4">1.0</data>
      <data key="d5">Figure 9.5 visualizes the sales model for Brand A stores, showing the relationship between sales and price</data>
      <data key="d6">3dd24a54028976ba54304ec7169bb74b</data>
    </edge>
    <edge source="BRAND_A" target="INTERACTION_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">In the interaction model, the effect of price on sales volume for Brand A stores differs from that of Brand C</data>
      <data key="d6">1820d10ee0f23f34b3ea88ba475bc52d</data>
    </edge>
    <edge source="BRAND_B" target="SALES_VOLUME">
      <data key="d4">2.0</data>
      <data key="d5">Brand B has an average sales volume of 105,728 units, which is lower than Brand C's average sales volume.
Brand B's sales volume is influenced by factors other than price, as indicated by the observations lying below the fitted regression line.</data>
      <data key="d6">7a605c3b689bec7ab2c46df9c123e3f3,e079b7c92d5c0b009ff02040eb652bc6</data>
    </edge>
    <edge source="BRAND_B" target="SALESJ">
      <data key="d4">1.0</data>
      <data key="d5">Brand B's indicator variable xjB is used in the model for Salesj</data>
      <data key="d6">228bdca7843406def245d755e8df49f6</data>
    </edge>
    <edge source="BRAND_B" target="AVERAGE_PRICE">
      <data key="d4">1.0</data>
      <data key="d5">At the average price, the expected number of units sold by Brand B stores can be calculated</data>
      <data key="d6">9854704301b8df256ca1013b8d53dfac</data>
    </edge>
    <edge source="BRAND_B" target="CEO">
      <data key="d4">1.0</data>
      <data key="d5">The CEO is responsible for overseeing the stores of Brand B, and is interested in the performance of these stores</data>
      <data key="d6">9854704301b8df256ca1013b8d53dfac</data>
    </edge>
    <edge source="BRAND_B" target="FACTOR_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">Factor variable defines the group of Brand B stores</data>
      <data key="d6">906eb7d6b49fa360e7e5b65c56cd4d76</data>
    </edge>
    <edge source="BRAND_B" target="ALPHA_B">
      <data key="d4">1.0</data>
      <data key="d5">Alpha B (&#945;B) represents the difference in intercept between the regression line for Brand B and that for Brand A</data>
      <data key="d6">1d141ab04db553f78a313e430e54abb5</data>
    </edge>
    <edge source="BRAND_B" target="X_B">
      <data key="d4">1.0</data>
      <data key="d5">X_B (xjB) is an indicator variable for Brand B</data>
      <data key="d6">1d141ab04db553f78a313e430e54abb5</data>
    </edge>
    <edge source="BRAND_B" target="XJB">
      <data key="d4">1.0</data>
      <data key="d5">Brand B is represented by the indicator variable xjB in the design matrix</data>
      <data key="d6">c103c6d096d52868eda26d991194b5f2</data>
    </edge>
    <edge source="BRAND_B" target="PARALLEL_LINES_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Brand B is analyzed using the parallel lines model to assess the fit of the regression line</data>
      <data key="d6">0cb40986e6c2bb439e1ffcaae2df96ac</data>
    </edge>
    <edge source="BRAND_B" target="STORE_J">
      <data key="d4">1.0</data>
      <data key="d5">Store j can be of brand B, which has its own regression line</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="BRAND_B" target="ALPHA_B_B">
      <data key="d4">1.0</data>
      <data key="d5">Brand B's intercept difference from Brand A is represented by Alpha hat for Brand B (&#945;bB)</data>
      <data key="d6">adbc52b340a69a8633c919c4fd2cd3f6</data>
    </edge>
    <edge source="BRAND_B" target="GAMMA_B_B">
      <data key="d4">1.0</data>
      <data key="d5">Brand B's price effect difference from Brand A is represented by Gamma hat for Brand B (&#947;bB)</data>
      <data key="d6">adbc52b340a69a8633c919c4fd2cd3f6</data>
    </edge>
    <edge source="BRAND_B" target="FIGURE_9_5">
      <data key="d4">1.0</data>
      <data key="d5">Figure 9.5 visualizes the sales model for Brand B stores, showing the relationship between sales and price</data>
      <data key="d6">3dd24a54028976ba54304ec7169bb74b</data>
    </edge>
    <edge source="BRAND_B" target="INTERACTION_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">In the interaction model, the effect of price on sales volume for Brand B stores differs from that of Brand C</data>
      <data key="d6">1820d10ee0f23f34b3ea88ba475bc52d</data>
    </edge>
    <edge source="REGRESSION_MODELS" target="MEDIAN">
      <data key="d4">1.0</data>
      <data key="d5">The median is a statistical measure, but regression models focus on predicting the mean, not the median.</data>
      <data key="d6">e079b7c92d5c0b009ff02040eb652bc6</data>
    </edge>
    <edge source="REGRESSION_MODELS" target="SALES_VOLUME">
      <data key="d4">1.0</data>
      <data key="d5">Regression models are used to predict sales volume based on independent variables like price and brand.</data>
      <data key="d6">e079b7c92d5c0b009ff02040eb652bc6</data>
    </edge>
    <edge source="SALES_VOLUME" target="FIGURE_9.2">
      <data key="d4">1.0</data>
      <data key="d5">Figure 9.2 visualizes the relationship between sales volume and price, with color-coded data points according to brand.</data>
      <data key="d6">e079b7c92d5c0b009ff02040eb652bc6</data>
    </edge>
    <edge source="SALES_VOLUME" target="MU_A">
      <data key="d4">1.0</data>
      <data key="d5">&#181;A is the intercept parameter for Brand A in the linear regression model, and is used to predict sales volume for Brand A when price is zero.</data>
      <data key="d6">7a605c3b689bec7ab2c46df9c123e3f3</data>
    </edge>
    <edge source="SALES_VOLUME" target="MU_B">
      <data key="d4">1.0</data>
      <data key="d5">&#181;B is the intercept parameter for Brand B in the linear regression model, and is used to predict sales volume for Brand B when price is zero.</data>
      <data key="d6">7a605c3b689bec7ab2c46df9c123e3f3</data>
    </edge>
    <edge source="SALES_VOLUME" target="MU_C">
      <data key="d4">1.0</data>
      <data key="d5">&#181;C is the intercept parameter for Brand C in the linear regression model, and is used to predict sales volume for Brand C when price is zero.</data>
      <data key="d6">7a605c3b689bec7ab2c46df9c123e3f3</data>
    </edge>
    <edge source="SALES_VOLUME" target="PRODUCT_PRICE">
      <data key="d4">1.0</data>
      <data key="d5">Sales volume is influenced by the product price, which is an independent variable in the regression model</data>
      <data key="d6">baa0dc3d4ec0e51c0a321e5579caf8aa</data>
    </edge>
    <edge source="SALES_VOLUME" target="MODEL_FITTED_IN_H">
      <data key="d4">1.0</data>
      <data key="d5">The model fitted in h. predicts the sales volume for Brand C stores</data>
      <data key="d6">096afa471635bc59c3bfa9af4d04d625</data>
    </edge>
    <edge source="SALES_VOLUME" target="MODEL_FITTED_IN_C">
      <data key="d4">1.0</data>
      <data key="d5">The model fitted in c. predicts the sales volume for Brand C stores, which is compared to the prediction from the model fitted in h.</data>
      <data key="d6">096afa471635bc59c3bfa9af4d04d625</data>
    </edge>
    <edge source="SALES_VOLUME" target="STORE">
      <data key="d4">1.0</data>
      <data key="d5">The sales volume is observed at the store level</data>
      <data key="d6">b6870535f3975c49d45e62fbe475f198</data>
    </edge>
    <edge source="SALES_VOLUME" target="ALPHA_B">
      <data key="d4">1.0</data>
      <data key="d5">Alpha B represents the difference in intercept for brand B compared to brand A in the regression model</data>
      <data key="d6">b6870535f3975c49d45e62fbe475f198</data>
    </edge>
    <edge source="SALES_VOLUME" target="ALPHA_C">
      <data key="d4">1.0</data>
      <data key="d5">Alpha C represents the difference in intercept for brand C compared to brand A in the regression model</data>
      <data key="d6">b6870535f3975c49d45e62fbe475f198</data>
    </edge>
    <edge source="SALES_VOLUME" target="GAMMA_B">
      <data key="d4">1.0</data>
      <data key="d5">Gamma B represents the difference in slope for brand B compared to brand A in the regression model</data>
      <data key="d6">b6870535f3975c49d45e62fbe475f198</data>
    </edge>
    <edge source="SALES_VOLUME" target="GAMMA_C">
      <data key="d4">1.0</data>
      <data key="d5">Gamma C represents the difference in slope for brand C compared to brand A in the regression model</data>
      <data key="d6">b6870535f3975c49d45e62fbe475f198</data>
    </edge>
    <edge source="SALES_VOLUME" target="INTERACTION">
      <data key="d4">1.0</data>
      <data key="d5">The expected sales volume can be influenced by the interaction between price and brand, affecting the response variable</data>
      <data key="d6">b0ca3e6c22c4cf884d03b1f6f82be5df</data>
    </edge>
    <edge source="FIGURE_9.2" target="DATAPOINTS">
      <data key="d4">1.0</data>
      <data key="d5">Datapoints in Figure 9.2 are color-coded and have different plotting symbols according to brand, showing the relationship between sales volume and price.</data>
      <data key="d6">e079b7c92d5c0b009ff02040eb652bc6</data>
    </edge>
    <edge source="BRAND_MODEL1" target="MUA">
      <data key="d4">1.0</data>
      <data key="d5">MuA is a parameter in the model Brand.model1, representing the intercept for Brand A</data>
      <data key="d6">ee295ebc4c2d6a2a5c738796fcc2ab71</data>
    </edge>
    <edge source="BRAND_MODEL1" target="MUB">
      <data key="d4">1.0</data>
      <data key="d5">MuB is a parameter in the model Brand.model1, representing the intercept for Brand B</data>
      <data key="d6">ee295ebc4c2d6a2a5c738796fcc2ab71</data>
    </edge>
    <edge source="BRAND_MODEL1" target="MUC">
      <data key="d4">1.0</data>
      <data key="d5">MuC is a parameter in the model Brand.model1, representing the intercept for Brand C</data>
      <data key="d6">ee295ebc4c2d6a2a5c738796fcc2ab71</data>
    </edge>
    <edge source="BRAND_MODEL1" target="FIGURE_9_3">
      <data key="d4">1.0</data>
      <data key="d5">Brand.model1 is the model whose results are visualized in Figure 9.3</data>
      <data key="d6">ee295ebc4c2d6a2a5c738796fcc2ab71</data>
    </edge>
    <edge source="MUA" target="SALESJ">
      <data key="d4">1.0</data>
      <data key="d5">muA is a parameter in the model for Salesj, representing the effect of Brand A</data>
      <data key="d6">228bdca7843406def245d755e8df49f6</data>
    </edge>
    <edge source="MUA" target="SALESI">
      <data key="d4">1.0</data>
      <data key="d5">muA is the intercept parameter for Brand A in the salesi vector</data>
      <data key="d6">925e17c26fb7d979f52538f4632333e7</data>
    </edge>
    <edge source="MUB" target="SALESJ">
      <data key="d4">1.0</data>
      <data key="d5">muB is a parameter in the model for Salesj, representing the effect of Brand B</data>
      <data key="d6">228bdca7843406def245d755e8df49f6</data>
    </edge>
    <edge source="MUB" target="SALESI">
      <data key="d4">1.0</data>
      <data key="d5">muB is the intercept parameter for Brand B in the salesi vector</data>
      <data key="d6">925e17c26fb7d979f52538f4632333e7</data>
    </edge>
    <edge source="MUB" target="ALPHAB">
      <data key="d4">1.0</data>
      <data key="d5">alphaB is the difference in intercept for Brand B compared to Brand A, affecting muB</data>
      <data key="d6">925e17c26fb7d979f52538f4632333e7</data>
    </edge>
    <edge source="MUB" target="BRAND_MODEL4">
      <data key="d4">1.0</data>
      <data key="d5">Mu hat (&#181;b) is the estimated intercept parameter from brand.model4</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="MUC" target="SALESJ">
      <data key="d4">1.0</data>
      <data key="d5">muC is a parameter in the model for Salesj, representing the effect of Brand C</data>
      <data key="d6">228bdca7843406def245d755e8df49f6</data>
    </edge>
    <edge source="MUC" target="SALESI">
      <data key="d4">1.0</data>
      <data key="d5">muC is the intercept parameter for Brand C in the salesi vector</data>
      <data key="d6">925e17c26fb7d979f52538f4632333e7</data>
    </edge>
    <edge source="MUC" target="ALPHAC">
      <data key="d4">1.0</data>
      <data key="d5">alphaC is the difference in intercept for Brand C compared to Brand A, affecting muC</data>
      <data key="d6">925e17c26fb7d979f52538f4632333e7</data>
    </edge>
    <edge source="FIGURE_9_3" target="PARALLEL_LINES_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">Figure 9.3 displays the fitted regression lines from the parallel lines model</data>
      <data key="d6">b2c33cb151a8e7724ebfb7b2d88bc45f</data>
    </edge>
    <edge source="PARALLEL_LINES_MODEL" target="MU_HAT_A">
      <data key="d4">1.0</data>
      <data key="d5">The parallel lines model uses the estimated intercept Mu hat A (&#181;&#710;A) for Brand A</data>
      <data key="d6">b2c33cb151a8e7724ebfb7b2d88bc45f</data>
    </edge>
    <edge source="PARALLEL_LINES_MODEL" target="MU_HAT_B">
      <data key="d4">1.0</data>
      <data key="d5">The parallel lines model uses the estimated intercept Mu hat B (&#181;&#710;B) for Brand B</data>
      <data key="d6">b2c33cb151a8e7724ebfb7b2d88bc45f</data>
    </edge>
    <edge source="PARALLEL_LINES_MODEL" target="MU_HAT_C">
      <data key="d4">1.0</data>
      <data key="d5">The parallel lines model uses the estimated intercept Mu hat C (&#181;&#710;C) for Brand C</data>
      <data key="d6">b2c33cb151a8e7724ebfb7b2d88bc45f</data>
    </edge>
    <edge source="PARALLEL_LINES_MODEL" target="ALPHA_B">
      <data key="d4">1.0</data>
      <data key="d5">Alpha B is a parameter in the parallel lines model</data>
      <data key="d6">0cb40986e6c2bb439e1ffcaae2df96ac</data>
    </edge>
    <edge source="PARALLEL_LINES_MODEL" target="ALPHA_C">
      <data key="d4">1.0</data>
      <data key="d5">Alpha C is a parameter in the parallel lines model</data>
      <data key="d6">0cb40986e6c2bb439e1ffcaae2df96ac</data>
    </edge>
    <edge source="PARALLEL_LINES_MODEL" target="GAMMA_A">
      <data key="d4">1.0</data>
      <data key="d5">Gamma A is a parameter in the parallel lines model</data>
      <data key="d6">0cb40986e6c2bb439e1ffcaae2df96ac</data>
    </edge>
    <edge source="PARALLEL_LINES_MODEL" target="GAMMA_B">
      <data key="d4">1.0</data>
      <data key="d5">Gamma B is a parameter in the parallel lines model</data>
      <data key="d6">0cb40986e6c2bb439e1ffcaae2df96ac</data>
    </edge>
    <edge source="PARALLEL_LINES_MODEL" target="INDICATOR_VARIABLES">
      <data key="d4">1.0</data>
      <data key="d5">Indicator variables are used in the parallel lines model to represent the brand of the store</data>
      <data key="d6">0cb40986e6c2bb439e1ffcaae2df96ac</data>
    </edge>
    <edge source="PARALLEL_LINES_MODEL" target="INTERACTION">
      <data key="d4">1.0</data>
      <data key="d5">Interaction is a concept used in the parallel lines model to assess the effect of one explanatory variable on the response depending on the value of another explanatory variable</data>
      <data key="d6">0cb40986e6c2bb439e1ffcaae2df96ac</data>
    </edge>
    <edge source="PARALLEL_LINES_MODEL" target="FIGURE_9_4">
      <data key="d4">1.0</data>
      <data key="d5">Figure 9.4 is a graphical representation of the parallel lines model</data>
      <data key="d6">0cb40986e6c2bb439e1ffcaae2df96ac</data>
    </edge>
    <edge source="STORE_BRAND" target="XJA">
      <data key="d4">1.0</data>
      <data key="d5">XjA is an indicator variable that encodes the store brand information for brand A</data>
      <data key="d6">248924760a2bfbc82501fd6b11cfa0aa</data>
    </edge>
    <edge source="STORE_BRAND" target="XJB">
      <data key="d4">1.0</data>
      <data key="d5">XjB is an indicator variable that encodes the store brand information for brand B</data>
      <data key="d6">248924760a2bfbc82501fd6b11cfa0aa</data>
    </edge>
    <edge source="STORE_BRAND" target="XJC">
      <data key="d4">1.0</data>
      <data key="d5">XjC is an indicator variable that encodes the store brand information for brand C</data>
      <data key="d6">248924760a2bfbc82501fd6b11cfa0aa</data>
    </edge>
    <edge source="XJB" target="DESIGN_MATRIX_X">
      <data key="d4">1.0</data>
      <data key="d5">xjB is a column in the design matrix X, representing the presence of Brand B in each store</data>
      <data key="d6">c103c6d096d52868eda26d991194b5f2</data>
    </edge>
    <edge source="XJC" target="DESIGN_MATRIX_X">
      <data key="d4">1.0</data>
      <data key="d5">xjC is a column in the design matrix X, representing the presence of Brand C in each store</data>
      <data key="d6">c103c6d096d52868eda26d991194b5f2</data>
    </edge>
    <edge source="SALESJ" target="PRICEJ">
      <data key="d4">1.0</data>
      <data key="d5">Pricej is a variable in the model for Salesj</data>
      <data key="d6">228bdca7843406def245d755e8df49f6</data>
    </edge>
    <edge source="PRICEJ" target="SALESI">
      <data key="d4">1.0</data>
      <data key="d5">pricej is the price for the jth store, influencing salesi</data>
      <data key="d6">925e17c26fb7d979f52538f4632333e7</data>
    </edge>
    <edge source="BRANDA" target="BRAND_MODEL2">
      <data key="d4">1.0</data>
      <data key="d5">BrandA is one of the brands analyzed in Brand.model2, with a specific coefficient</data>
      <data key="d6">93da9813e10a119798de6982977f1239</data>
    </edge>
    <edge source="BRANDB" target="BRAND_MODEL2">
      <data key="d4">1.0</data>
      <data key="d5">BrandB is one of the brands analyzed in Brand.model2, with a specific coefficient</data>
      <data key="d6">93da9813e10a119798de6982977f1239</data>
    </edge>
    <edge source="BRANDC" target="BRAND_MODEL2">
      <data key="d4">1.0</data>
      <data key="d5">BrandC is one of the brands analyzed in Brand.model2, with a specific coefficient</data>
      <data key="d6">93da9813e10a119798de6982977f1239</data>
    </edge>
    <edge source="C_PRICE" target="BRAND_MODEL2">
      <data key="d4">1.0</data>
      <data key="d5">c_price is a variable in Brand.model2, used to adjust for price differences</data>
      <data key="d6">93da9813e10a119798de6982977f1239</data>
    </edge>
    <edge source="BRAND_MODEL3" target="MU_HAT">
      <data key="d4">1.0</data>
      <data key="d5">Brand_model3 is the model that provides the estimate for the intercept parameter Mu_hat</data>
      <data key="d6">6a6f85d0a6e46196ab3a901fcc82a720</data>
    </edge>
    <edge source="BRAND_MODEL3" target="ALPHA_HAT_B">
      <data key="d4">1.0</data>
      <data key="d5">Brand_model3 is the model that provides the estimate for the brand B parameter Alpha_hat_B</data>
      <data key="d6">6a6f85d0a6e46196ab3a901fcc82a720</data>
    </edge>
    <edge source="BRAND_MODEL3" target="ALPHA_HAT_C">
      <data key="d4">1.0</data>
      <data key="d5">Brand_model3 is the model that provides the estimate for the brand C parameter Alpha_hat_C</data>
      <data key="d6">6a6f85d0a6e46196ab3a901fcc82a720</data>
    </edge>
    <edge source="SA" target="SALESI">
      <data key="d4">1.0</data>
      <data key="d5">The salesi vector contains sales data for observations in the set SA</data>
      <data key="d6">925e17c26fb7d979f52538f4632333e7</data>
    </edge>
    <edge source="SA" target="NA">
      <data key="d4">1.0</data>
      <data key="d5">nA is the number of elements in the set SA</data>
      <data key="d6">925e17c26fb7d979f52538f4632333e7</data>
    </edge>
    <edge source="SB" target="SALESI">
      <data key="d4">1.0</data>
      <data key="d5">The salesi vector contains sales data for observations in the set SB</data>
      <data key="d6">925e17c26fb7d979f52538f4632333e7</data>
    </edge>
    <edge source="SB" target="NB">
      <data key="d4">1.0</data>
      <data key="d5">nB is the number of elements in the set SB</data>
      <data key="d6">925e17c26fb7d979f52538f4632333e7</data>
    </edge>
    <edge source="SC" target="SALESI">
      <data key="d4">1.0</data>
      <data key="d5">The salesi vector contains sales data for observations in the set SC</data>
      <data key="d6">925e17c26fb7d979f52538f4632333e7</data>
    </edge>
    <edge source="SC" target="NC">
      <data key="d4">1.0</data>
      <data key="d5">nC is the number of elements in the set SC</data>
      <data key="d6">925e17c26fb7d979f52538f4632333e7</data>
    </edge>
    <edge source="REFERENCE_CATEGORY" target="INDICATOR_VARIABLES">
      <data key="d4">1.0</data>
      <data key="d5">The reference category is determined by the categorical predictor and is the level not represented by an indicator variable in the model</data>
      <data key="d6">77e76692753fdf53493182b09018e6bc</data>
    </edge>
    <edge source="INTERACTION" target="FACTOR">
      <data key="d4">1.0</data>
      <data key="d5">Factors, such as brand, can interact with quantitative variables, like price, in regression models</data>
      <data key="d6">b0ca3e6c22c4cf884d03b1f6f82be5df</data>
    </edge>
    <edge source="INTERACTION" target="PRODUCT_TERMS">
      <data key="d4">1.0</data>
      <data key="d5">Product terms are introduced into linear models to represent interaction, where the effect of one explanatory variable on the response variable depends on the value of another explanatory variable</data>
      <data key="d6">77e76692753fdf53493182b09018e6bc</data>
    </edge>
    <edge source="INTERACTION" target="PARALLEL_LINES_REGRESSION_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">An interaction between the categorical predictor and the quantitative predictor can be introduced into a parallel lines regression model to allow for the relationship between the response and the quantitative predictor to vary across levels of the categorical predictor.</data>
      <data key="d6">d7f3a28534ffe830fe6f4cef8c41a9b4</data>
    </edge>
    <edge source="INDICATOR_VARIABLES" target="CATEGORICAL_PREDICTORS">
      <data key="d4">1.0</data>
      <data key="d5">Categorical predictors are encoded using indicator variables in linear models to accommodate their discrete nature within the model framework</data>
      <data key="d6">77e76692753fdf53493182b09018e6bc</data>
    </edge>
    <edge source="BRAND_MODEL4" target="BBETA">
      <data key="d4">1.0</data>
      <data key="d5">Beta hat (b&#946;) is the estimated coefficient for the price predictor from brand.model4</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="BRAND_MODEL4" target="ALPHAB_B">
      <data key="d4">1.0</data>
      <data key="d5">Alpha hat for brand B (&#945;bB) is the estimated parameter for brand B from brand.model4</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="BRAND_MODEL4" target="ALPHAB_C">
      <data key="d4">1.0</data>
      <data key="d5">Alpha hat for brand C (&#945;bC) is the estimated parameter for brand C from brand.model4</data>
      <data key="d6">825b600cbab3535ce67e9f561ddcb84b</data>
    </edge>
    <edge source="FACTOR" target="INDICATOR_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">Indicator variables are used to represent factors in regression models, allowing for the accommodation of categorical predictors</data>
      <data key="d6">b0ca3e6c22c4cf884d03b1f6f82be5df</data>
    </edge>
    <edge source="FACTOR" target="DUMMY_VARIABLE">
      <data key="d4">1.0</data>
      <data key="d5">Dummy variables are a specific type of indicator variable used to encode factors in regression models</data>
      <data key="d6">b0ca3e6c22c4cf884d03b1f6f82be5df</data>
    </edge>
    <edge source="CATEGORICAL_PREDICTORS" target="PARALLEL_LINES_REGRESSION_MODEL">
      <data key="d4">1.0</data>
      <data key="d5">A parallel lines regression model can be extended by introducing an interaction between the categorical predictor and the quantitative predictor. This allows for the relationship between the response and the quantitative predictor to vary across levels of the categorical predictor.</data>
      <data key="d6">d7f3a28534ffe830fe6f4cef8c41a9b4</data>
    </edge>
    <edge source="T_STATISTIC" target="MAXIMUM_LIKELIHOOD_ESTIMATOR">
      <data key="d4">1.0</data>
      <data key="d5">The maximum likelihood estimator for the parameters of a linear model is used in the calculation of the T-statistic. The T-statistic is calculated by dividing the estimated parameter by its standard error, which is based on the maximum likelihood estimator.</data>
      <data key="d6">d7f3a28534ffe830fe6f4cef8c41a9b4</data>
    </edge>
    <edge source="U" target="V">
      <data key="d4">2.0</data>
      <data key="d5">U and V are independent if their covariance is zero, as stated in Lemma 10.3
U and V are independent random variables when their covariance is zero</data>
      <data key="d6">0ac60299320c55d642b3e38440c25f90,aac5b4f040b9c773bd1aa696dec469f6</data>
    </edge>
    <edge source="U" target="COV_U_V">
      <data key="d4">1.0</data>
      <data key="d5">The covariance between U and V being zero indicates that U and V are uncorrelated</data>
      <data key="d6">0ac60299320c55d642b3e38440c25f90</data>
    </edge>
    <edge source="V" target="COV_U_V">
      <data key="d4">1.0</data>
      <data key="d5">The covariance between U and V being zero indicates that U and V are uncorrelated</data>
      <data key="d6">0ac60299320c55d642b3e38440c25f90</data>
    </edge>
  </graph>
</graphml>