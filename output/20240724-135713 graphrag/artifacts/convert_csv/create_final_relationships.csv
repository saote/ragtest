source,target,weight,description,text_unit_ids,id,human_readable_id,source_degree,target_degree,rank
PYTHON 3.10-3.12,POETRY,1.0,"Python 3.10-3.12 is the environment in which Poetry operates, providing the necessary runtime for executing Poetry commands and managing dependencies for GraphRAG",['4cf772ca8a1ffad729902e9b630e1ec0'],a87aa935dccf49cd98b40fb5afe7ad5c,0,2,4,6
PYTHON 3.10-3.12,GRAPHRAG SYSTEM,1.0,"The GraphRAG system is compatible with Python versions 3.10 to 3.12, which are the supported versions for running the system",['84d24b5db902baca7217b5e3bb6ec462'],36870a3393f6413e9bf647168eb6977a,1,2,4,6
POETRY,INDEXING ENGINE,1.0,"Poetry is used to execute the Indexing Engine, which is a part of GraphRAG, by running the 'poe index' command",['4cf772ca8a1ffad729902e9b630e1ec0'],4fe3ff52700c491f8cc650aadb4d7cb0,2,4,1,5
POETRY,QUERY ENGINE,1.0,"Poetry is used to execute the Query Engine, which is a part of GraphRAG, by running the 'poe query' command",['4cf772ca8a1ffad729902e9b630e1ec0'],f1f6f6435a444e388d67e16e847afca6,3,4,6,10
POETRY,LIFECYCLE SCRIPTS,1.0,"Poetry is used to manage and execute the Lifecycle Scripts, which are essential for building, testing, and executing the GraphRAG package",['4cf772ca8a1ffad729902e9b630e1ec0'],0af2ca1c090843ea92679fd14c1fbc9a,4,4,1,5
AZURITE,UNIT AND SMOKE TESTS,1.0,"Azurite is used in unit and smoke tests to emulate Azure resources, providing a testing environment for GraphRAG",['4cf772ca8a1ffad729902e9b630e1ec0'],1b06d3e53ffd4771952fbef04d1e666c,5,1,1,2
QUERY ENGINE,INDEXING PIPELINE,1.0,"The Query Engine and the Indexing Pipeline are related as they are the two main components of the Graph RAG library, working together to process and retrieve information. The Indexing Pipeline prepares data for the Query Engine to perform searches and generate answers",['f8cf53ce98a8bc52581f7907ad98ef70'],b8e966b34cba4b11b9995106767212ba,6,6,4,10
QUERY ENGINE,LOCAL SEARCH,1.0,The Query Engine uses the Local Search method to generate answers by combining relevant data from the AI-extracted knowledge-graph with text chunks of the raw documents. This method is suitable for questions that require an understanding of specific entities mentioned in the documents,['f8cf53ce98a8bc52581f7907ad98ef70'],f6de923de6474d2cab6a9c2f0d81fa59,7,6,7,13
QUERY ENGINE,GLOBAL SEARCH,1.0,The Query Engine uses the Global Search method to generate answers by searching over all AI-generated community reports in a map-reduce fashion. This method is resource-intensive but gives good responses for questions that require an understanding of the dataset as a whole,['f8cf53ce98a8bc52581f7907ad98ef70'],6915637e8d124fdc8473111d501e3703,8,6,5,11
QUERY ENGINE,QUESTION GENERATION,1.0,The Query Engine uses the Question Generation functionality to take a list of user queries and generate the next candidate questions. This is useful for generating follow-up questions in a conversation or for generating a list of questions for the investigator to dive deeper into the dataset,['f8cf53ce98a8bc52581f7907ad98ef70'],2233f31929194eac89333ce8731a5584,9,6,11,17
QUERY ENGINE,CLI DOCUMENTATION,1.0,"The CLI documentation is related to the Query Engine, as it provides guidance on how to use the command-line interface to run queries against the indexed data, including examples of different query methods.",['7c1bad237a1ef86cb41b6c5dbad4ffc3'],61f1dc4267314470ac820b6a46c61f7b,10,6,2,8
CLI,POETRY RUN POE QUERY,1.0,"The CLI is used to execute the poetry run poe query command, which runs the Query CLI for executing queries through the command line interface.",['563caa38fe33c495449888d62950b959'],f0c578614b224345974c3e4c110878af,11,11,1,12
CLI,POETRY BUILD,1.0,"The CLI is used to execute the poetry build command, which builds a wheel file and other distributable artifacts for the package.",['563caa38fe33c495449888d62950b959'],7ffb88ebc729492c897ccfb569d7f6d0,12,11,1,12
CLI,POETRY RUN POE TEST,1.0,"The CLI is used to execute the poetry run poe test command, which runs all tests for the package to ensure its functionality and integrity.",['563caa38fe33c495449888d62950b959'],60dce7d8bc1b4729a038178a400b9a59,13,11,1,12
CLI,POETRY RUN POE TEST_UNIT,1.0,"The CLI is used to execute the poetry run poe test_unit command, which runs unit tests to verify the correctness of individual units of code.",['563caa38fe33c495449888d62950b959'],4cbb4e238c5b4656803fb9b4b6c3512e,14,11,1,12
CLI,POETRY RUN POE TEST_INTEGRATION,1.0,"The CLI is used to execute the poetry run poe test_integration command, which runs integration tests to verify the interaction between different parts of the system.",['563caa38fe33c495449888d62950b959'],652873bcd6d5432187e5deafc4fc5211,15,11,1,12
CLI,POETRY RUN POE TEST_SMOKE,1.0,"The CLI is used to execute the poetry run poe test_smoke command, which runs smoke tests to ensure the system is in a stable state before more extensive testing.",['563caa38fe33c495449888d62950b959'],78f9b30c08134ac5abb4f4e0bff0f7f2,16,11,1,12
CLI,POETRY RUN POE CHECK,1.0,"The CLI is used to execute the poetry run poe check command, which performs a suite of static checks across the package, including formatting, documentation formatting, linting, security patterns, and type-checking.",['563caa38fe33c495449888d62950b959'],f33e4e897b1e422bb516e8a2c941d9dc,17,11,1,12
CLI,POETRY RUN POE FIX,1.0,"The CLI is used to execute the poetry run poe fix command, which applies any available auto-fixes to the package, typically limited to formatting fixes.",['563caa38fe33c495449888d62950b959'],fac4e1553a9840e990bbfff46e64ff27,18,11,1,12
CLI,POETRY RUN POE FIX_UNSAFE,1.0,"The CLI is used to execute the poetry run poe fix_unsafe command, which applies any available auto-fixes to the package, including those that may be unsafe.",['563caa38fe33c495449888d62950b959'],029a55d327ee4fb3a8314b36d52bdf34,19,11,1,12
CLI,POETRY RUN POE FORMAT,1.0,"The CLI is used to execute the poetry run poe format command, which explicitly runs the formatter across the package to ensure consistent code style and formatting.",['563caa38fe33c495449888d62950b959'],5a636c894c384532bff66212cf9d5824,20,11,1,12
CLI,TROUBLESHOOTING,1.0,"The CLI may be used in conjunction with the Troubleshooting section, which provides solutions to common problems encountered when using the software or executing commands.",['563caa38fe33c495449888d62950b959'],a9c468ef78704e9aabfc0317a5b1b42d,21,11,1,12
RUNTIMEERROR,LLVM_CONFIG,1.0,"The RuntimeError encountered during the 'poetry install' process is related to the LLVM_CONFIG environment variable, as the error message suggests setting this variable to the path of the llvm-config executable. This relationship indicates that the error is due to a missing or incorrect configuration of the LLVM environment.",['0dc1f5e4f8fb5903f12acf8e141fb205'],5df80c25d33a4d148a14aa614343cc6b,22,6,1,7
RUNTIMEERROR,LLVM-9,1.0,"The RuntimeError encountered during the 'poetry install' process is related to the llvm-9 software package, as the error message suggests installing llvm-9 and llvm-9-dev. This relationship indicates that the error is due to the absence of the required LLVM components.",['0dc1f5e4f8fb5903f12acf8e141fb205'],6a87f06ed55a46f29b24f77e548a3f1d,23,6,1,7
RUNTIMEERROR,LLVM-9-DEV,1.0,"The RuntimeError encountered during the 'poetry install' process is related to the llvm-9-dev software package, as the error message suggests installing llvm-9 and llvm-9-dev. This relationship indicates that the error is due to the absence of the required LLVM development components.",['0dc1f5e4f8fb5903f12acf8e141fb205'],0daf88ac4ec94cbb868e27e956c6d7f1,24,6,1,7
RUNTIMEERROR,POETRY INSTALL,1.0,"The RuntimeError encountered during the 'poetry install' process is directly related to the execution of the 'poetry install' command. This relationship indicates that the error occurs as a result of running this command, which is intended to install project dependencies.",['0dc1f5e4f8fb5903f12acf8e141fb205'],9ed120043e6247be9965e4904920991b,25,6,1,7
RUNTIMEERROR,PYTHON.H,1.0,"The RuntimeError encountered during the 'poetry install' process is related to the missing Python.h file, as indicated by the error message ""numba/_pymodule.h:6:10: fatal error: Python.h: No such file or directory"". This relationship indicates that the error is due to the absence of the required Python header file.",['0dc1f5e4f8fb5903f12acf8e141fb205'],94d81d7de9254ae4b3b16fcc69aa22ea,26,6,1,7
RUNTIMEERROR,PYTHON3.10-DEV,1.0,"The RuntimeError encountered during the 'poetry install' process is related to the python3.10-dev software package, as the error message suggests installing python3.10-dev to resolve the issue with the missing Python.h file. This relationship indicates that the error is due to the absence of the required Python development components.",['0dc1f5e4f8fb5903f12acf8e141fb205'],60c9212246f84ae5b6ab254127a39262,27,6,1,7
GRAPHRAG_LLM_THREAD_COUNT,GRAPHRAG_EMBEDDING_THREAD_COUNT,1.0,"The GRAPHRAG_LLM_THREAD_COUNT and GRAPHRAG_EMBEDDING_THREAD_COUNT environment variables are related to each other as they both determine the level of concurrency in the GraphRAG system. Modifying these values can help reduce the concurrency and improve system stability, as they are both set to 50 by default, which can lead to high concurrency and potential performance issues.",['0dc1f5e4f8fb5903f12acf8e141fb205'],0f8d0c36a4274526a9eddedae5e63881,28,1,3,4
GRAPHRAG_EMBEDDING_THREAD_COUNT,GRAPHRAG_EMBEDDING_THREAD_STAGGER,1.0,"The GRAPHRAG_EMBEDDING_THREAD_STAGGER setting is related to the GRAPHRAG_EMBEDDING_THREAD_COUNT as it determines the delay between starting threads, which can affect the efficiency and resource usage when multiple threads are specified",['2b777e3d591ce1511a03abd1a6d8dc73'],6aedd377efbe4f07ae42e546996e7bfa,29,3,1,4
GRAPHRAG_EMBEDDING_THREAD_COUNT,GRAPHRAG_EMBEDDING_CONCURRENT_REQUESTS,1.0,"The GRAPHRAG_EMBEDDING_CONCURRENT_REQUESTS setting is related to the GRAPHRAG_EMBEDDING_THREAD_COUNT as it specifies the number of concurrent requests that can be processed, which can be influenced by the number of threads available for processing",['2b777e3d591ce1511a03abd1a6d8dc73'],1aa8484562784f378851c33843c89687,30,3,1,4
GRAPHRAG,GPT-4 TURBO,1.0,GraphRAG uses GPT-4 Turbo to generate knowledge graphs from text data. The model's ability to create detailed and structured representations of information is essential for the GraphRAG process.,['e6fa3bdaf65c92df6b3430f02804321a'],f1a65d05dd5d456b889217020475ef80,31,26,1,27
GRAPHRAG,MICROSOFT RESEARCH BLOG POST,1.0,The Microsoft Research Blog Post provides information about GraphRAG and its applications. It is a resource for users who want to learn more about how GraphRAG can enhance the ability of LLMs to reason about private data.,['e6fa3bdaf65c92df6b3430f02804321a'],c077d92b48b6477db91e1a0460600f52,32,26,1,27
GRAPHRAG,GITHUB REPOSITORY,1.0,"The GitHub Repository is a resource for developers who want to access, contribute to, and collaborate on the GraphRAG project. It contains the source code and documentation for GraphRAG.",['e6fa3bdaf65c92df6b3430f02804321a'],5ca888df9b884e54accdd2ff29d125c1,33,26,1,27
GRAPHRAG,GRAPHRAG ARXIV,1.0,"GraphRAG Arxiv is a repository for research papers and documentation related to GraphRAG. It is a resource for users who want to learn more about the theory, implementation, and applications of GraphRAG.",['e6fa3bdaf65c92df6b3430f02804321a'],8290a6212d6c4430ae0056c7e8eccd5f,34,26,1,27
GRAPHRAG,SOLUTION ACCELERATOR,1.0,The Solution Accelerator is a package that provides a user-friendly end-to-end experience with Azure resources for quickstarting the GraphRAG system. It is recommended for users who want to start using GraphRAG with ease.,['e6fa3bdaf65c92df6b3430f02804321a'],14f8ac195fdb4e06a0b9ebc6ef391180,35,26,1,27
GRAPHRAG,GET STARTED GUIDE,2.0,"The Get Started Guide, a comprehensive resource meticulously crafted by GraphRAG, serves as an invaluable starting point for users looking to familiarize themselves with the software's rich array of features and functionalities. This guide is specifically designed to cater to newcomers, offering clear, step-by-step instructions that facilitate a smooth onboarding process and enable users to harness the full potential of GraphRAG from the get-go. By providing detailed guidance on how to begin using the system effectively, the Get Started Guide ensures that users can quickly and confidently navigate through GraphRAG's sophisticated interface, maximizing their productivity and leveraging the software's capabilities to meet their specific needs.",['32603b739bed06b4695b0cc3915b2c4b' 'e6fa3bdaf65c92df6b3430f02804321a'],667ee58a79194316ae2b82eadd3fc575,36,26,1,27
GRAPHRAG,INDEXER,2.0,"The Indexer, a critical sub-system of GraphRAG, specializes in processing raw text to construct a knowledge graph, thereby facilitating the creation of a structured information representation. This subsystem is pivotal in enhancing GraphRAG's efficiency in data organization and retrieval, working in tandem with the main software to optimize question-and-answer capabilities. Through its sophisticated mechanisms, the Indexer significantly contributes to GraphRAG's overall performance, making it an indispensable component in the software's functionality.",['32603b739bed06b4695b0cc3915b2c4b' 'e6fa3bdaf65c92df6b3430f02804321a'],b0e3ee2324054c88adacdf80db13278f,37,26,12,38
GRAPHRAG,QUERY PACKAGE,2.0,"The Query package, a vital subsystem of GraphRAG, serves as a powerful tool for users to interact with the indexed data and conduct searches within the knowledge graph. This feature facilitates the retrieval of relevant information, making it an essential component for the software's functionality and user engagement. As part of GraphRAG, the Query package ensures that users can efficiently and effectively access the data they need, enhancing the overall utility of the system.",['32603b739bed06b4695b0cc3915b2c4b' 'e6fa3bdaf65c92df6b3430f02804321a'],28b7457ca5dc4a38a488946a3f8e207e,38,26,1,27
GRAPHRAG,SOLUTION ACCELERATOR PACKAGE,1.0,"The Solution Accelerator package includes GraphRAG, which is a component that enhances the user experience by providing advanced RAG capabilities for better handling of complex information and reasoning about private datasets.",['32603b739bed06b4695b0cc3915b2c4b'],8029a14d15404e6db95ddf5e2bf9fc15,39,26,1,27
GRAPHRAG,BASELINE RAG,2.0,"GraphRAG, an evolved iteration of Baseline RAG, is meticulously designed to surmount the constraints of its predecessor, especially in managing intricate data and reasoning over private datasets. This advanced system showcases significant enhancements in question-and-answer efficiency and reasoning skills, excelling in connecting disjointed information fragments and grasping summarized semantic ideas across extensive data repositories. GraphRAG's superior performance and mastery in these domains clearly outshine those of Baseline RAG, positioning it as a more capable and intelligent solution for handling complex information landscapes.",['32603b739bed06b4695b0cc3915b2c4b' 'd441b136505c273cf3577b6867e872e4'],389314ca89d445888c8d4985864dd733,40,26,1,27
GRAPHRAG,LLMS,1.0,"LLMs are used in GraphRAG to create a knowledge graph from an input corpus. The LLMs extract entities, relationships, and key claims from the TextUnits, which are then used to build the graph and enhance the query responses in GraphRAG.",['d441b136505c273cf3577b6867e872e4'],87fe1462b9064d5692641ab48e826301,41,26,5,31
GRAPHRAG,LEIDEN TECHNIQUE,2.0,"GraphRAG, a sophisticated tool for social network analysis, utilizes the Leiden technique for hierarchical clustering of the graph. This method significantly enhances the visualization and analysis of entities and their communities within the graph. By employing the Leiden technique, GraphRAG is able to effectively represent the clustering of entities and relationships, which is a critical step in the process of understanding the structure and dynamics of specialized professional networks. This approach enables users to identify key influencers, collaboration opportunities, and knowledge gaps in the field, particularly in the Motor Control and Drive Systems domain.",['369b39fdfd649d6df32a5d7b4cc559b7' 'd441b136505c273cf3577b6867e872e4'],a55175ac57014df696ca09d0def9604b,42,26,1,27
GRAPHRAG,TEXTUNITS,1.0,"GraphRAG process involves slicing the input corpus into TextUnits, which are used as analyzable units for entity and relationship extraction.",['369b39fdfd649d6df32a5d7b4cc559b7'],1766e8858d7b45ed97f71cb5a39e96ea,43,26,1,27
GRAPHRAG,LLM,1.0,"GraphRAG utilizes LLM for entity, relationship, and key claim extraction from the TextUnits.",['369b39fdfd649d6df32a5d7b4cc559b7'],6191e014f3f64e46a0777063ed4ac19a,44,26,11,37
GRAPHRAG,COMMUNITY SUMMARIES,1.0,GraphRAG generates Community Summaries from the bottom-up to provide a holistic understanding of each community and its constituents.,['369b39fdfd649d6df32a5d7b4cc559b7'],21b0499cf14342269c46170c291d0535,45,26,13,39
GRAPHRAG,GLOBAL SEARCH,2.0,"Global Search is a sophisticated query mode integrated within the GraphRAG process, designed to facilitate reasoning and answer holistic questions concerning the entire corpus. By leveraging the community summaries and the structure of the LLM-generated knowledge graph, Global Search enables the identification of themes and semantic clusters within the dataset. This capability significantly enhances the aggregation of information, making the process more effective and efficient. GraphRAG, in this context, serves as the backbone, creating a knowledge graph that Global Search utilizes to uncover deeper insights and connections within the data.",['369b39fdfd649d6df32a5d7b4cc559b7' '3e143a60e2aeb57eb418a68d1484bbb3'],c1ef05b38b3f4d59888150fc0dd26826,46,26,5,31
GRAPHRAG,LOCAL SEARCH,2.0,"Local Search, a feature within the GraphRAG (Graph Representation and Analysis of Graphs) process, is a query mode designed to facilitate reasoning about specific entities. This is achieved by exploring the immediate network around the entity, fanning out to its neighbors and associated concepts within the graph. GraphRAG, as a tool, enables users to analyze and understand the relationships and connections between entities in a graph database, making Local Search a powerful technique for uncovering insights and knowledge hidden within the data. By leveraging Local Search, users can efficiently investigate the context and connections of particular entities, enhancing their understanding of the graph's structure and dynamics.",['369b39fdfd649d6df32a5d7b4cc559b7' '849698743b07680402ff8572b1c6c469'],74cb9b3510e84498b9aee0d904316e8b,47,26,7,33
GRAPHRAG,PROMPT TUNING,2.0,"Prompt Tuning is a specialized technique recommended for optimizing the performance of GraphRAG, particularly when working with specific data sets. This method involves fine-tuning prompts in accordance with the documentation to better suit the data and tasks at hand, ensuring the best possible results are achieved. By leveraging Prompt Tuning, users can enhance the effectiveness of GraphRAG in various applications, making it a valuable strategy for maximizing the system's potential.",['369b39fdfd649d6df32a5d7b4cc559b7' '849698743b07680402ff8572b1c6c469'],043d764b2e1b4d1294651ff938df5391,48,26,8,34
GRAPHRAG,LLM-GENERATED KNOWLEDGE GRAPH,1.0,"GraphRAG utilizes the LLM-generated knowledge graph to organize data into semantic clusters and summarize themes, enabling it to respond to user queries with relevant information",['812b3414c467da0b62f7932d2adcbad4'],31f2170fef004f3281c533a4a60dc3f3,49,26,1,27
GRAPHRAG,GLOBAL SEARCH METHOD,1.0,"GraphRAG employs the global search method to process user queries, using LLM-generated community reports as context data to generate intermediate and final responses",['812b3414c467da0b62f7932d2adcbad4'],57f186c5c2754483ba66750e98222f95,50,26,4,30
GRAPHRAG,EVALUATION APPROACH,1.0,"Graph RAG's performance has been evaluated using an approach that has limitations, as it has only examined a certain class of sensemaking questions for two corpora in the region of 1 million tokens",['e015335cdcae20e6546fe7cbdef56c1a'],4b3fc569d91f4a7aa6501ad4fcf67b7a,51,26,2,28
GRAPHRAG,TEMPLATE GENERATION ALGORITHM,1.0,"GraphRAG utilizes the Template Generation Algorithm to create domain adaptive templates for the generation of knowledge graphs. The algorithm is a core component of GraphRAG, enabling it to adapt to different domains and improve the results of Index Runs by generating customized prompts based on the input data and specified parameters.",['9b364093aeecfc789c70fc5bd9503487'],cbc1667556f84a5eadf867a823e6986c,52,26,1,27
GRAPHRAG,INITIALIZATION PROCESS,1.0,"The Initialization Process is a prerequisite for using GraphRAG effectively. Before running the automatic template generation, the workspace must be initialized using the graphrag.index --init command. This process creates the necessary configuration files and default prompts, allowing GraphRAG to function properly and ensuring that the tool is ready for use.",['9b364093aeecfc789c70fc5bd9503487'],a876d1ab79864396bc47a039225fd5c7,53,26,1,27
GRAPHRAG,.ENV,1.0,"GraphRAG uses the .env file to store environment variables that are referenced in the settings.yaml file, essential for the proper configuration and operation of the software.",['12294feb07a1d202b27241eaaf64718b'],c09f67d4f25448c99f7c0552c30b7706,54,26,6,32
GRAPHRAG,SETTINGS.YAML,1.0,GraphRAG uses the settings.yaml file to store configuration settings necessary for its operation. This file is created during the initialization process and is referenced by the software.,['12294feb07a1d202b27241eaaf64718b'],c0866306dc8c4da2a8a81c0c3a78b657,55,26,6,32
GRAPHRAG,PROMPTS/,1.0,GraphRAG uses the prompts/ directory to store default prompts that can be modified or new ones generated through the Auto Prompt Tuning command. These prompts are essential for the software's operations.,['12294feb07a1d202b27241eaaf64718b'],3884c37eb13a4c9097ee2c5be4eeefaf,56,26,4,30
INDEXER,COMMUNITY_LEVEL,1.0,"The Indexer uses the community_level parameter to determine which level of community reports to load from the Leiden community hierarchy, affecting the granularity of the data processed.",['8c70a7321fb0e945054d226a8c69abee'],90764eb2cab74cffb1c7d72d28b965cc,57,12,2,14
INDEXER,RESPONSE_TYPE,1.0,"The Indexer's output format and type are influenced by the response_type parameter, which dictates the structure of the generated reports.",['8c70a7321fb0e945054d226a8c69abee'],01abe16e67c241a887aa62abe22d155c,58,12,3,15
INDEXER,METHOD,1.0,"The method parameter influences how the Indexer answers queries, either using a local or global approach, impacting the scope and methodology of the analysis.",['8c70a7321fb0e945054d226a8c69abee'],37049be0a2c240c6a06acf9339237b8b,59,12,3,15
INDEXER,GRAPHRAG_API_KEY,1.0,"The GRAPHRAG_API_KEY environment variable is required for the Indexer to execute, providing the necessary API Key for model execution.",['8c70a7321fb0e945054d226a8c69abee'],e785c52881704d95bf4ec03d2720f8ae,60,12,5,17
INDEXER,GRAPHRAG_LLM_MODEL,1.0,"The GRAPHRAG_LLM_MODEL environment variable specifies the model the Indexer uses for Chat Completions, affecting the conversational capabilities of the tool.",['8c70a7321fb0e945054d226a8c69abee'],654689c65613476b9905d7afb3809cd2,61,12,1,13
INDEXER,GRAPHRAG_EMBEDDING_MODEL,1.0,"The GRAPHRAG_EMBEDDING_MODEL environment variable determines the model the Indexer uses for Embeddings, impacting the representation and processing of data.",['8c70a7321fb0e945054d226a8c69abee'],15dfb45a6ffa4d34ad72cfe4b3c5cc0d,62,12,1,13
INDEXER,GRAPHRAG_LLM_API_BASE,1.0,"The GRAPHRAG_LLM_API_BASE environment variable can be set to customize the API Base URL for the Indexer's LLM operation, allowing for flexibility in deployment environments.",['8c70a7321fb0e945054d226a8c69abee'],427c3b7458f148d8bace1b768e2b5b7c,63,12,4,16
INDEXER,GRAPHRAG_LLM_TYPE,1.0,"The GRAPHRAG_LLM_TYPE environment variable defines the LLM operation type used by the Indexer, influencing the method of interaction with the language model.",['8c70a7321fb0e945054d226a8c69abee'],95d506750fd94e72bbd9cf2d3fe18e28,64,12,5,17
INDEXER,GRAPHRAG_LLM_MAX_RETRIES,1.0,"The GRAPHRAG_LLM_MAX_RETRIES environment variable sets the maximum number of retries the Indexer will attempt when a request fails, affecting the tool's resilience and reliability.",['8c70a7321fb0e945054d226a8c69abee'],bf0138ccbcc740089a55fd0c24897360,65,12,2,14
INDEXER,GLOBAL SEARCH,1.0,"The Indexer is a prerequisite for using the Global Search method, as it processes the data to make it searchable and ready for high-level questions",['ae6e91a8cc5773dbd4789773c9ef5a30'],83cd5df42643494396b00d6cb6376def,66,12,5,17
INDEXER,LOCAL SEARCH,1.0,"The Indexer is a prerequisite for using the Local Search method, as it processes the data to make it searchable and ready for specific questions about particular aspects or entities within the dataset",['ae6e91a8cc5773dbd4789773c9ef5a30'],909d28e443fd4e0bac189373125c8309,67,12,7,19
LLMS,ENTITY GRAPH,1.0,"LLMs are capable of understanding the rich descriptive text associated with homogeneous nodes in the entity graph, which is crucial for global, query-focused summarization",['6dace8e490674ac8e031aed987a63789'],efbc2439e5034801af83ac1a0b440535,68,5,6,11
LLMS,RAGAS,1.0,"LLMs are used by RAGAS to evaluate the performance of conventional RAG systems, automatically assessing qualities such as context relevance, faithfulness, and answer relevance.",['53455f8552b0787cb13c5a03eb550842'],b9a2ef791a064f038cac2059ebea1138,69,5,1,6
LLMS,GRAPH RAG,1.0,Graph RAG and LLMs are connected through the use of large language models in the creation and analysis of graph indexes for advanced information retrieval.,['40f2d6a0270e54743e7ace239369da96'],1ce2b24bc93442148dc2240d3c6223b1,70,5,19,24
LLMS,KNOWLEDGE GRAPH CREATION,1.0,"LLMs are used in the creation of knowledge graphs, as described in the research study by Trajanoska et al., indicating a direct connection between LLMs and knowledge graph creation techniques.",['40f2d6a0270e54743e7ace239369da96'],804c1e94e7974332a817931363ddb643,71,5,2,7
LLM,GLOBAL SEARCH,1.0,"The LLM is used in Global Search to summarize themes identified in the dataset's semantic clusters, responding to user queries that require understanding of the entire dataset",['3e143a60e2aeb57eb418a68d1484bbb3'],32dc0b572ad84c75a64a2007788eb981,72,11,5,16
LLM,GLOBALSEARCH CLASS,1.0,"The GlobalSearch Class uses the LLM for response generation, following the map-reduce process.",['1a4bca0786d529c91073997b63412adc'],f5c11a5ac94e40068bca8be178a6bcd6,73,11,7,18
LLM,PARALLELIZATION,1.0,"llm and parallelization are related because the language model's configuration can influence how tasks are distributed across multiple processors or threads, affecting the overall performance and efficiency of the system.",['d27237468a1b9e89110eeeca8080f63c'],ea28ff7f127e4677a913952595dce2f5,74,11,5,16
LLM,ASYNC_MODE,1.0,"llm and async_mode are related because the language model's operation in asynchronous mode can impact how the model processes tasks concurrently, potentially affecting the throughput and response time of the system.",['d27237468a1b9e89110eeeca8080f63c'],192a6d23595045f38b0d46a3d8e52fd6,75,11,5,16
LLM,ENTITY EXTRACTION,1.0,"The Entity Extraction section includes the LLM property, specifying the language model to use for text analysis",['abac77a5673e907cf8d65161c2612784'],ef67c9fc60284b50aa15ac655b06a155,76,11,9,20
LLM,SUMMARIZE_DESCRIPTIONS,1.0,"The llm setting is used in the summarize_descriptions process, specifying the language model to be used for generating summaries",['9cbd4e21339eeed5e22a638e52a094cb'],cc8201cce1024b5192056fe8e98fda22,77,11,6,17
LLM,CLAIM_EXTRACTION,1.0,"The llm setting is used in the claim_extraction process, specifying the language model to be used for identifying claims",['9cbd4e21339eeed5e22a638e52a094cb'],97e097f9022540b88ab7c13d2805c25f,78,11,5,16
LLM,COMMUNITY_REPORTS,1.0,"The llm setting is used in the community_reports process, specifying the language model to be used for generating reports",['9cbd4e21339eeed5e22a638e52a094cb'],829a6299a5fa4e7b8ff4020020a0be05,79,11,6,17
LLM,ENTITY RESOLUTION,1.0,"LLM is used in the process of Entity Resolution to determine which entities should be merged based on their representation of the same real-world entity but with different names. The current implementation is destructive, but future implementations aim to be non-destructive.",['d44248ff7b7bfd969a7208eb3d6e2a78'],dde2742459c24fb4a91172aa5c1a7620,80,11,6,17
LLM,CLAIM EXTRACTION,1.0,LLM is used in the Claim Extraction process to identify positive factual statements with an evaluated status and time-bounds from source TextUnits. These claims are emitted as Covariates.,['d44248ff7b7bfd969a7208eb3d6e2a78'],323979a67d79498fa271acdf8cd1a0c2,81,11,6,17
COMMUNITY SUMMARIES,CORPUS,1.0,"The corpus can be summarized or analyzed to create community summaries, which provide condensed versions of the information contained in the corpus",['849698743b07680402ff8572b1c6c469'],c7e8b188b45841a0a1bcb22f3445ea6e,82,13,1,14
COMMUNITY SUMMARIES,LOCAL TO GLOBAL GRAPH RAG APPROACH,1.0,The Local to Global Graph RAG Approach utilizes Community Summaries to generate partial responses to a given question. These summaries are pre-generated for groups of closely-related entities and are combined into a final response.,['f76c18c7582167c3626f8741c2c9374f'],5a4ad077106a4a3f951f43d2e01499b0,83,13,4,17
COMMUNITY SUMMARIES,ENTITY KNOWLEDGE GRAPH,1.0,"The entity knowledge graph is used to generate community summaries for groups of closely-related entities, which are then used to generate partial responses to questions",['b149708d0b4ac3ff417565739ea6b03b'],a7ec8df038d7461689d28f1bdea84d9b,84,13,3,16
COMMUNITY SUMMARIES,GRAPHCOMMUNITIES,1.0,"Community Summaries are created for each community in the Leiden hierarchy, providing a detailed report of the structure and semantics of the dataset",['a660289d2bf43f25d3524d35cd2d9a96'],8ddefa32e2ed4eaf8f76d17a676f74f3,85,13,2,15
COMMUNITY SUMMARIES,GLOBAL QUERIES,1.0,Community summaries are used to answer global queries by providing structured information that can be searched or analyzed to address the broader themes or questions posed by the user,['93d4d4effbf989e6ef1c4c3b4f42494e'],95ec30ce8dbe4ca28714e3e3735da8f3,86,13,1,14
COMMUNITY SUMMARIES,USER QUERY,1.0,"A user query can be answered using community summaries, as the summaries provide relevant information that can be matched to the query to provide detailed or thematic responses",['93d4d4effbf989e6ef1c4c3b4f42494e'],259e7f5e2ec04418937513413b6d51d1,87,13,3,16
COMMUNITY SUMMARIES,PODCAST DATASET,1.0,The Podcast Dataset's graph structure influences the number of community summaries at different levels of the graph community hierarchy,['d08fc91bbfe9749abab38a99a1a88dc6'],2289f06dd3804a3c84371dda0bab091e,88,13,4,17
COMMUNITY SUMMARIES,NEWS DATASET,1.0,The News Dataset's graph structure influences the number of community summaries at different levels of the graph community hierarchy,['d08fc91bbfe9749abab38a99a1a88dc6'],34ff8ef897804691842071f9ff78708e,89,13,4,17
COMMUNITY SUMMARIES,SOURCE TEXTS,1.0,"Community Summaries are derived from Source Texts, representing a condensed version of the original content. The relationship indicates that summaries are created to provide a more concise representation of the source material.",['71f14506a6b15dfabd93fd1606a67b73'],a7401447d994439993da7cc57f127649,90,13,2,15
COMMUNITY SUMMARIES,GRAPH RAG,2.0,"Graph RAG, a sophisticated retrieval-augmented generation model, integrates community summaries as a critical component of its self-memory system. This integration allows Graph RAG to leverage the rich context and information contained within community summaries, significantly enhancing its retrieval capabilities. The relationship between Graph RAG and community summaries is characterized by a high strength, as the summaries are directly utilized in the question answering process. This direct use of community summaries in Graph RAG's methodology leads to notable improvements in the comprehensiveness and diversity of answers generated, making community summaries an indispensable element in the model's operation.",['71f14506a6b15dfabd93fd1606a67b73' '7da3d8d244b67f09425a4a7783e4bb55'],754b0f2616064b18abb90f409ef0539a,91,13,19,32
COMMUNITY SUMMARIES,GRAPH INDEX,1.0,"The decision to invest in building a graph index depends on the value obtained from other aspects of the graph index, including the generic community summaries",['7040ba36a7c09899a355d14a30d65375'],acd35bb6b3cb4979a3f3fb68a86b3b05,92,13,10,23
COMMUNITY SUMMARIES,FUTURE WORK,1.0,"Future work includes the possibility of refining and adapting the current Graph RAG approach, which can involve the consideration of the generic community summaries",['7040ba36a7c09899a355d14a30d65375'],9e1e7f67ba044c7fbf64723af1ade58e,93,13,7,20
GLOBAL SEARCH,QUERY ENGINE DOCS,1.0,"The Global Search method is described and explained in the Query Engine Docs, which provide detailed information on how to use this search technique effectively to ask high-level questions about the dataset",['ae6e91a8cc5773dbd4789773c9ef5a30'],57e16ff087a84b8ebd70de1e7e534225,94,5,2,7
LOCAL SEARCH,QUESTION GENERATION,2.0,"Question Generation and Local Search are closely intertwined functionalities within the realm of information retrieval and processing. Question Generation leverages the context-building approach synonymous with Local Search to sift through and prioritize pertinent data. Both methodologies are instrumental in generating and addressing queries, utilizing input documents and structured data derived from a knowledge graph. This synergy enables a comprehensive understanding and response to inquiries, making these entities indispensable in the domain of data analysis and information extraction.",['1415949832ba3fee570ea961998a8ac4' '364624242a84e1859e758069d914d8c8'],bbf4007dc9c0486b8ea76d616045467a,95,7,11,18
LOCAL SEARCH,ENTITY-BASED REASONING,1.0,Local Search is related to Entity-based Reasoning as Entity-based Reasoning is an approach used within the Local Search method to reason about information based on entities and their relationships,['364624242a84e1859e758069d914d8c8'],9535f4d754044e128cd3951a9d2e3702,96,7,2,9
LOCAL SEARCH,QUESTION GENERATION FUNCTION,1.0,"The Local Search method uses the Question Generation Function to generate context for the search, which is then used to find semantically similar content within the dataset",['3e143a60e2aeb57eb418a68d1484bbb3'],e1ed13e29ee946d4aaafac50aaa3b68f,97,7,1,8
LOCAL SEARCH,QUERY ENGINE DOCS,1.0,"The Local Search method is described and explained in the Query Engine Docs, which provide detailed information on how to use this search technique effectively to ask specific questions about particular aspects or entities within the dataset",['ae6e91a8cc5773dbd4789773c9ef5a30'],eb961d47a30c4870a1134b4a4672a8b2,98,7,2,9
PROMPT TUNING,AUTO TEMPLATING,1.0,"Prompt Tuning includes the Auto Templating feature, which is a method for creating domain adaptive templates for the generation of the knowledge graph. This relationship indicates that Auto Templating is a part of the broader Prompt Tuning capabilities",['bdb8f9e797229f596744d9636ab857b0'],5b019e8652264136b95306bac70a2e25,99,8,1,9
PROMPT TUNING,MANUAL CONFIGURATION,1.0,"Prompt Tuning includes the option for Manual Configuration, which allows for advanced customization of the prompts and templates used in the generation of the knowledge graph. This relationship indicates that Manual Configuration is an alternative method within the Prompt Tuning feature set",['bdb8f9e797229f596744d9636ab857b0'],325fc9e2b37043b7af9f6ad338b09469,100,8,1,9
PROMPT TUNING,GRAPHRAG_ENTITY_EXTRACTION_PROMPT_FILE,1.0,The GRAPHRAG_ENTITY_EXTRACTION_PROMPT_FILE is a configuration variable that can be modified during Prompt Tuning to customize the entity extraction process,['4f37c0e9c3c9bac4e5c1c6821eea442e'],6bb11aa08b414232b5b45f10f5766f62,101,8,1,9
PROMPT TUNING,GRAPHRAG_COMMUNITY_REPORT_PROMPT_FILE,1.0,The GRAPHRAG_COMMUNITY_REPORT_PROMPT_FILE is a configuration variable that can be modified during Prompt Tuning to customize the community report generation process,['4f37c0e9c3c9bac4e5c1c6821eea442e'],179737fd23c943babdfae01ac5c6bfc3,102,8,1,9
PROMPT TUNING,GRAPHRAG_SUMMARIZE_DESCRIPTIONS_PROMPT_FILE,1.0,The GRAPHRAG_SUMMARIZE_DESCRIPTIONS_PROMPT_FILE is a configuration variable that can be modified during Prompt Tuning to customize the summarization of descriptions process,['4f37c0e9c3c9bac4e5c1c6821eea442e'],65a31e4da283411fb7c971f63d606723,103,8,1,9
PROMPT TUNING,GRAPHRAG INDEXER,1.0,"The GraphRAG Indexer allows for the customization of its default prompts through the process of Prompt Tuning, enabling better alignment with specific use cases in knowledge discovery",['6a7157695d90d434b2625c3f05420916'],de31810d43174a52aa2f31b72f4542f5,104,8,3,11
PROMPT TUNING,CUSTOM PROMPT FILE,1.0,"A Custom Prompt File is created as part of the Prompt Tuning process to override default prompts, allowing for the customization of the GraphRAG indexer's behavior",['6a7157695d90d434b2625c3f05420916'],a6ae1d99330443fcacb06ace15a0d937,105,8,2,10
INDEXING PIPELINE,CLI DOCUMENTATION,1.0,"The CLI documentation is related to the Indexing pipeline, as it explains how to use the command-line interface to run the indexing process, including the specific Python script and parameters required.",['7c1bad237a1ef86cb41b6c5dbad4ffc3'],5174cdabb6024de0975762d3a80b059f,106,4,2,6
INDEXING PIPELINE,PROMPT TUNING COMMAND,1.0,"The Prompt Tuning command can be run before or after the Indexing Pipeline, as it adapts the prompts to better fit the data being indexed",['d0f7c236538005bc3056b7daed2401d8'],e379fba901174b529250169e62d98c09,107,4,2,6
INDEXING PIPELINE,CONFIGURATION DOCUMENTATION,1.0,"The Indexing Pipeline is a process that can be run after configuring GraphRAG as detailed in the Configuration documentation, allowing for the indexing of data for use with the system.",['32e96c66a531ecd0a8edc7414aec0803'],81ee8bb20bbb4d37bc0db642f1c75b8e,108,4,5,9
QUESTION GENERATION,GLOBAL SEARCH DOCUMENTATION,1.0,"The Global Search documentation is related to Question Generation as it provides more information about the functionality that Question Generation is a part of, which is searching and retrieving information across various sources",['364624242a84e1859e758069d914d8c8'],93b4aa6ce6e44123a861d4c3b3d509a2,109,11,1,12
QUESTION GENERATION,STRUCTURED DATA,1.0,Question Generation combines structured data from a knowledge graph to generate candidate questions related to specific entities,['1415949832ba3fee570ea961998a8ac4'],ee8414e314f547eeb369849cdb51bac2,110,11,1,12
QUESTION GENERATION,UNSTRUCTURED DATA,1.0,Question Generation combines unstructured data from input documents to generate candidate questions related to specific entities,['1415949832ba3fee570ea961998a8ac4'],9f77aa8888bd4f94abba8a77c4b0565c,111,11,1,12
QUESTION GENERATION,KNOWLEDGE GRAPH,1.0,Question Generation uses structured data from the knowledge graph to generate candidate questions,['1415949832ba3fee570ea961998a8ac4'],dcf33412678340319e7ec8f7be267ef9,112,11,1,12
QUESTION GENERATION,OPENAI MODEL,1.0,Question Generation uses an OpenAI model for response generation,['1415949832ba3fee570ea961998a8ac4'],4aa1e0fa00c048939a5d006bfd305fb4,113,11,1,12
QUESTION GENERATION,CONTEXT BUILDER,1.0,Question Generation uses a context builder to prepare context data from collections of knowledge model objects,['1415949832ba3fee570ea961998a8ac4'],03053ab4a9054384a5f5e88d28841621,114,11,2,13
QUESTION GENERATION,SYSTEM PROMPT,1.0,Question Generation uses a system prompt template to generate candidate questions,['1415949832ba3fee570ea961998a8ac4'],9fd0f20997d541bca46c4ec9843a5d0f,115,11,1,12
QUESTION GENERATION,LLM PARAMETERS,1.0,Question Generation uses LLM parameters to customize the behavior of the LLM call,['1415949832ba3fee570ea961998a8ac4'],27168beee1ff456696c330c9c3b3259f,116,11,1,12
QUESTION GENERATION,CONTEXT BUILDER PARAMETERS,1.0,Question Generation uses context builder parameters to customize the context-building process,['1415949832ba3fee570ea961998a8ac4'],e1c20e06aeac436788a9c6e918bcb844,117,11,1,12
ENTITY-BASED REASONING,EMBEDDING,1.0,Entity-based Reasoning is related to Embedding as Embedding is a technique used in the Entity-based Reasoning approach to represent entities and text in a numerical format that can be processed by machine learning models,['364624242a84e1859e758069d914d8c8'],344417f626ef4da4be4539ef4037bf3f,118,2,1,3
ENTITY-TEXT UNIT MAPPING,RANKING + FILTERING,1.0,Entity-Text Unit Mapping is related to Ranking + Filtering as Ranking + Filtering is a technique used after Entity-Text Unit Mapping to prioritize and select the most relevant text units based on their relevance to a user query,['364624242a84e1859e758069d914d8c8'],8b1fff87c350475fb1d411a26c3c5b0c,119,1,4,5
RANKING + FILTERING,ENTITY-REPORT MAPPING,1.0,Entity-Report Mapping is related to Ranking + Filtering as Ranking + Filtering is a technique used after Entity-Report Mapping to prioritize and select the most relevant community reports based on their relevance to a user query,['364624242a84e1859e758069d914d8c8'],898a9458adfb4c13a1eafacf6a1068f6,120,4,1,5
RANKING + FILTERING,ENTITY-ENTITY RELATIONSHIPS,1.0,Entity-Entity Relationships are related to Ranking + Filtering as Ranking + Filtering is a technique used to prioritize and select the most relevant entity relationships based on their relevance to a user query,['364624242a84e1859e758069d914d8c8'],5448f05781de44ea96e3dea40b285842,121,4,1,5
RANKING + FILTERING,ENTITY-COVARIATE MAPPINGS,1.0,Entity-Covariate Mappings are related to Ranking + Filtering as Ranking + Filtering is a technique used to prioritize and select the most relevant covariates based on their relevance to a user query,['364624242a84e1859e758069d914d8c8'],76b1e69904b84d09ba05c4b7efc48f32,122,4,1,5
USER QUERY,LOCAL SEARCH DATAFLOW,1.0,"The User Query initiates the Local Search Dataflow, guiding the search process and influencing the prioritization of entities, relationships, and covariates",['3a0742c280217fe600b9af2d06b58eea'],3f5590a604894d268603b4b27c3348b5,123,3,7,10
USER QUERY,GLOBAL SEARCH METHOD,1.0,"The global search method is triggered by a user query, which serves as the input for generating responses based on the LLM-generated knowledge graph and semantic clusters",['812b3414c467da0b62f7932d2adcbad4'],68f998c9c8c34bb7a994de5a998bb9a0,124,3,4,7
CONVERSATION HISTORY,LOCAL SEARCH DATAFLOW,1.0,"The Conversation History provides context for the Local Search Dataflow, influencing the prioritization of entities, relationships, and covariates based on previous interactions",['3a0742c280217fe600b9af2d06b58eea'],aafc13d02ade40adae13d3bee241817a,125,2,7,9
CONVERSATION HISTORY,GLOBAL SEARCH METHOD,1.0,The global search method can take conversation history as additional input to provide more context for generating informed and relevant responses to user queries,['812b3414c467da0b62f7932d2adcbad4'],81a4818e5cf84ea085abf09de385c86e,126,2,4,6
LOCAL SEARCH DATAFLOW,PRIORITIZED TEXT UNITS,1.0,"The Local Search Dataflow extracts and prioritizes the Prioritized Text Units, selecting relevant text chunks from the input documents",['3a0742c280217fe600b9af2d06b58eea'],b69851bf63e34ced83827b0021628543,127,7,1,8
LOCAL SEARCH DATAFLOW,PRIORITIZED COMMUNITY REPORTS,1.0,"The Local Search Dataflow extracts and prioritizes the Prioritized Community Reports, selecting relevant reports from the knowledge graph",['3a0742c280217fe600b9af2d06b58eea'],b83a4e11bfa64559954327714b73293f,128,7,1,8
LOCAL SEARCH DATAFLOW,PRIORITIZED ENTITIES,1.0,"The Local Search Dataflow identifies and prioritizes the Prioritized Entities, serving as access points into the knowledge graph",['3a0742c280217fe600b9af2d06b58eea'],de23b974cc90497eb4363e26d931a57c,129,7,1,8
LOCAL SEARCH DATAFLOW,PRIORITIZED RELATIONSHIPS,1.0,"The Local Search Dataflow identifies and prioritizes the Prioritized Relationships, providing context about the connections between entities",['3a0742c280217fe600b9af2d06b58eea'],a9de65176e234a9f9073b8df9d675e90,130,7,1,8
LOCAL SEARCH DATAFLOW,PRIORITIZED COVARIATES,1.0,"The Local Search Dataflow identifies and prioritizes the Prioritized Covariates, providing additional details about the entities and their attributes",['3a0742c280217fe600b9af2d06b58eea'],09a1bd11eb9347a9b466edad1a562cc5,131,7,1,8
LOCALSEARCH CLASS,QUESTION GENERATION METHOD,1.0,The LocalSearch class is related to the Question Generation method as it uses a similar context-building approach to extract and prioritize relevant information for generating questions related to specific entities,['25797740f434cc2bf16365fc498791f6'],11d74eab1dcb4fcba7c45def5f0ee22d,132,2,1,3
LOCALSEARCH CLASS,CONFIGURATION PARAMETERS,1.0,"The Configuration Parameters are essential for the LocalSearch class as they define how the class operates, including the model, context builder, and various settings that affect the search and response generation process",['25797740f434cc2bf16365fc498791f6'],4f6a6fd018a948f4bd0e630266b8bf61,133,2,1,3
LLM COMPLETION STREAMING EVENTS,CALLBACKS,1.0,"Callbacks can be used to handle LLM Completion Streaming Events, providing custom processing or reactions to the information generated by the LLM during the completion of tasks or queries",['1415949832ba3fee570ea961998a8ac4'],17dbfbecfaf0436bb11ed8f867c0caa1,134,1,2,3
CONTEXT BUILDER,GLOBALSEARCH CLASS,1.0,The GlobalSearch Class utilizes the Context Builder to prepare context data from community reports for the map-reduce process.,['1a4bca0786d529c91073997b63412adc'],2b1ec99684574c2ab26bb050d5b57a4d,135,2,7,9
CALLBACKS,LLM CALL,1.0,"The LLM call can trigger callbacks, which are optional functions that handle custom events, such as completion streaming events, for real-time processing or logging.",['e0cc1cf05b92456e09100790815186fe'],1ccce5d1892a4b6995bbaec22882d34d,136,2,4,6
LLM (LANGUAGE MODEL),FEW-SHOT EXAMPLES,1.0,"The LLM is trained using few-shot examples specialized to various domains, which helps it to understand and perform tasks in those specific fields",['805a07a8f9c2ed5da2d9a61356aafa77'],51cd93f89fbe4bcf883cdb2ca6774cd6,137,8,2,10
LLM (LANGUAGE MODEL),SECONDARY EXTRACTION PROMPT,1.0,"The LLM uses the secondary extraction prompt to gather additional information or covariates associated with the extracted node instances, enhancing the detail and context of the extracted data",['805a07a8f9c2ed5da2d9a61356aafa77'],5f353b18fadb438f95ba0ea8feae137c,138,8,1,9
LLM (LANGUAGE MODEL),GLEANING PROCESS,1.0,"The LLM employs the gleaning process to ensure that all entities are detected, improving the completeness and accuracy of the data extraction",['805a07a8f9c2ed5da2d9a61356aafa77'],947d70dd14b34cf398a1ab6dbdc51161,139,8,1,9
LLM (LANGUAGE MODEL),ELEMENT SUMMARIES,1.0,"The LLM generates element summaries, which are descriptions of entities, relationships, and claims represented in source texts, providing meaningful and concise information",['805a07a8f9c2ed5da2d9a61356aafa77'],90f5597a558a4652bded9001a4ec2e56,140,8,3,11
LLM (LANGUAGE MODEL),SUMMARIZATION QUERIES,1.0,"LLM is used to generate summarization queries that require understanding of the entire corpus, aiding in the evaluation of RAG systems for data sensemaking tasks",['8e69f04648f5fc24c299591365f1aa68'],9532cf83e9324ea0a46e5ac89bac407d,141,8,3,11
LLM (LANGUAGE MODEL),ACTIVITY-CENTERED APPROACH,1.0,"The Activity-Centered Approach utilizes the LLM to identify users, tasks, and generate questions for evaluation",['a739018eb63cbb6c26b779bd37afc233'],8919fa72a9e74d1daff801e8f4c15b2b,142,8,1,9
LLM (LANGUAGE MODEL),EVALUATION DATASETS,1.0,"The LLM generates questions for the Evaluation Datasets, resulting in 125 test questions per dataset when N = 5",['a739018eb63cbb6c26b779bd37afc233'],bef38889bb86413895d7dd25b4c3137c,143,8,4,12
LLM (LANGUAGE MODEL),COMMUNITY REPORTS,1.0,"Community Reports are generated using the LLM (Language Model) to summarize the distinct information within each community, offering insights from high-level to low-level perspectives",['5b2968b8f1c891d47ecbe641c3391663'],f770bc07cecf4aba8fe2d2c33fdc5542,144,8,8,16
GLOBAL SEARCH METHOD,AGGREGATED INTERMEDIATE RESPONSES,1.0,"The global search method produces aggregated intermediate responses by filtering and selecting the most important points from intermediate responses, which are then used to generate the final response",['812b3414c467da0b62f7932d2adcbad4'],13cd49512d5642989c2c72bb5e674807,145,4,1,5
GRAPH'S COMMUNITY HIERARCHY,COMMUNITY REPORTS,1.0,"The Graph's Community Hierarchy influences the level of detail in Community Reports, which are segmented into text chunks during the map step of the map-reduce process.",['1a4bca0786d529c91073997b63412adc'],e5c5c87a281b43868c344ff60f44c100,146,1,8,9
MAP-REDUCE PROCESS,GLOBALSEARCH CLASS,1.0,The GlobalSearch Class implements the Map-Reduce Process for generating responses from community reports.,['1a4bca0786d529c91073997b63412adc'],a562ffbe986247b7943990e7151f4d69,147,1,7,8
COMMUNITY REPORTS,INTERMEDIATE RESPONSE,1.0,"Community Reports are segmented into text chunks, which are used to produce an Intermediate Response containing points rated for importance.",['1a4bca0786d529c91073997b63412adc'],7ea0bc1467e84184842de2d5e5bdd78e,148,8,2,10
COMMUNITY REPORTS,DEFAULT PROMPTS,1.0,"Default Prompts include the function of generating Community Reports, which provide insights and summaries based on the input data. This relationship indicates that Community Reports are one of the outputs provided by the Default Prompts",['bdb8f9e797229f596744d9636ab857b0'],056f23eb710f471393ae5dc417d83fd9,149,8,4,12
COMMUNITY REPORTS,CONFIGURATION DOCUMENTATION,1.0,The Configuration Documentation is related to Community Reports as it provides guidelines on how to configure the settings that affect the generation of these reports,['21cdf11c58927ae505d3d375d1b75c82'],e1ae27016d63447a8dfa021370cba0fa,150,8,5,13
COMMUNITY REPORTS,PROMPT SOURCE,1.0,The Prompt Source is related to Community Reports as it is the origin of the input text that is used to generate the reports,['21cdf11c58927ae505d3d375d1b75c82'],f8c10f61a8f344cea7bdafa2d8af14b8,151,8,1,9
COMMUNITY REPORTS,TOKENS,1.0,"Tokens are related to Community Reports as they contain the data, such as the input text, that is analyzed and presented in the reports",['21cdf11c58927ae505d3d375d1b75c82'],aa7d003f25624e19bc88d3951d4dc943,152,8,1,9
COMMUNITY REPORTS,DOCUMENT PROCESSING,1.0,"Community Reports are processed in the Document Processing phase, where they are augmented, linked to TextUnits, and their embeddings are averaged to create the Documents table",['3e292d936b7efa377ba9530456cfd888'],1c97184ce5ea4049be417a3fd125357b,153,8,7,15
INTERMEDIATE RESPONSE,FINAL RESPONSE,1.0,"The Intermediate Response, containing points rated for importance, is aggregated during the reduce step to generate the Final Response.",['1a4bca0786d529c91073997b63412adc'],13a044c404394c34af1e9b07c48aa985,154,2,1,3
GLOBALSEARCH CLASS,MAP SYSTEM PROMPT,1.0,The GlobalSearch Class uses the Map System Prompt as a template for the map step of the map-reduce process.,['1a4bca0786d529c91073997b63412adc'],69ef1ac7b1f44372979149e82ecbc860,155,7,1,8
GLOBALSEARCH CLASS,REDUCE SYSTEM PROMPT,1.0,The GlobalSearch Class uses the Reduce System Prompt as a template for the reduce step of the map-reduce process.,['1a4bca0786d529c91073997b63412adc'],6e26ce67bacc4fa089296843463f69ad,156,7,1,8
GLOBALSEARCH CLASS,RESPONSE TYPE,1.0,The GlobalSearch Class includes the Response Type as a parameter to specify the format of the final response.,['1a4bca0786d529c91073997b63412adc'],ae0d3104647f4e6ab3ec2cf8e60be5ca,157,7,1,8
GLOBALSEARCH CLASS,ALLOW GENERAL KNOWLEDGE,1.0,The GlobalSearch Class includes the Allow General Knowledge setting to control whether general knowledge is included in the final response.,['1a4bca0786d529c91073997b63412adc'],49e24b5f2c1d40d7857afe327db4f554,158,7,1,8
MAP_SYSTEM_PROMPT,REDUCE_SYSTEM_PROMPT,1.0,The map_system_prompt and reduce_system_prompt are related as they both serve as templates guiding the processing of data in the map and reduce stages respectively,['e442fbb7a67e97ebc4de131b25c639e1'],587f39a32e93412395d9c22ad0ac2f94,159,1,2,3
REDUCE_SYSTEM_PROMPT,RESPONSE_TYPE,1.0,The response_type is related to the reduce_system_prompt as it influences the structure and format of the output generated during the reduce stage,['e442fbb7a67e97ebc4de131b25c639e1'],8d9ded5fc9cf4c4faba8c6c8cd50e2f4,160,2,3,5
RESPONSE_TYPE,GRAPHRAG QUERY CLI,1.0,"The GraphRAG query CLI's output is customized by response_type, which dictates the format and type of response generated by the query engine.",['e0cc1cf05b92456e09100790815186fe'],595a841aa6034c93bd3dc55681e17710,161,3,3,6
ALLOW_GENERAL_KNOWLEDGE,GENERAL_KNOWLEDGE_INCLUSION_PROMPT,1.0,The allow_general_knowledge setting is related to the general_knowledge_inclusion_prompt as enabling the former triggers the inclusion of the latter in the reduce_system_prompt,['e442fbb7a67e97ebc4de131b25c639e1'],d0e58b78e8e84a0c8796e707b1f95f65,162,1,1,2
MAX_DATA_TOKENS,CONTEXT_BUILDER_PARAMS,1.0,"The max_data_tokens property is related to the context_builder_params as it sets a limit on the amount of data that can be processed, which the context_builder must adhere to when building the context window",['e442fbb7a67e97ebc4de131b25c639e1'],215fcc6a3b5e452da123aa7f9ef0cbc9,163,1,2,3
REDUCE_LLM_PARAMS,LLM CALL,1.0,"The LLM call is configured by reduce_llm_params, which specifies additional parameters for the reduce stage, influencing the output of the LLM call.",['e0cc1cf05b92456e09100790815186fe'],0d0fc5d4ecb548079b28979186f19bf6,164,1,4,5
CONTEXT_BUILDER_PARAMS,LLM CALL,1.0,"The LLM call's effectiveness in the map stage is enhanced by context_builder_params, which customize the context window for better understanding of the input data.",['e0cc1cf05b92456e09100790815186fe'],e7d3fe0f87ff47f5a4c8d9572d27245a,165,2,4,6
CONCURRENT_COROUTINES,LLM CALL,1.0,"The performance of the LLM call in the map stage is influenced by concurrent_coroutines, which determines the level of parallelism in processing tasks.",['e0cc1cf05b92456e09100790815186fe'],6f7165b558ae427ca14b2b16d1e8e204,166,1,4,5
GRAPHRAG QUERY CLI,DATA,1.0,"The GraphRAG query CLI uses data, typically in .parquet files, as input for queries and responses, enabling searches and generation of outputs based on indexed data.",['e0cc1cf05b92456e09100790815186fe'],2ec093d2a76d45f88ec508e45ba8c6a3,167,3,1,4
GRAPHRAG QUERY CLI,COMMUNITY_LEVEL,1.0,"The GraphRAG query CLI's functionality is influenced by community_level, which specifies the level of detail in community reports, affecting the granularity of the search results.",['e0cc1cf05b92456e09100790815186fe'],16d5a528d6374612b87a5656e8d95193,168,3,2,5
METHOD,ROOT,2.0,"ROOT and METHOD are integral components in the document selection and template generation process within a project. ROOT specifies the project's root directory, which serves as the primary location for input data and may house configuration files that impact the document selection method. The method property, in conjunction with ROOT, determines the approach for selecting text units from the input data stored in the project directory, facilitating the creation of templates. This interplay between ROOT and METHOD ensures a structured and customizable document selection process, enabling efficient template generation based on the project's specific requirements.",['9243633f55cccd0885ba553e14fa5e3f' 'ce9cc3ed2e5f890d02e867ed0b0f8ff9'],40293e74dbc643e8ab6546dff759ac7c,169,3,6,9
METHOD,LIMIT,1.0,"METHOD and LIMIT are related as the method chosen for selecting documents (all, random, or top) can affect how the limit of text units is applied",['9243633f55cccd0885ba553e14fa5e3f'],1834b753dc7f4a8b98c2317a551b56ee,170,3,2,5
GRAPHRAG_API_KEY,GRAPHRAG PIPELINE,1.0,The GraphRAG pipeline uses the GRAPHRAG_API_KEY for authentication when making requests to the OpenAI API or Azure OpenAI endpoint. This key is essential for the pipeline to access and utilize the AI services provided by these APIs.,['5aaa26fbe97dc7573cd1a56d6fb11213'],d9b127eab2f64e338d7adcd186786a45,171,5,4,9
GRAPHRAG_API_KEY,SETTINGS.YAML,1.0,"The settings.yaml file includes the GRAPHRAG_API_KEY, which is an environment variable that holds the API key for the OpenAI API or Azure OpenAI endpoint. This key is essential for the GraphRAG pipeline to authenticate and access the respective API services.",['5aaa26fbe97dc7573cd1a56d6fb11213'],a18f7c9f58ca49d6acf18e1ca69d3033,172,5,6,11
GRAPHRAG_API_KEY,GRAPHRAG_API_BASE,2.0,"GRAPHRAG_API_KEY and GRAPHRAG_API_BASE are integral components for accessing the LLM service API. GRAPHRAG_API_KEY serves as the authentication mechanism, ensuring secure and authorized access to the service. Meanwhile, GRAPHRAG_API_BASE specifies the foundational URL for the LLM service API, determining the endpoint to which requests are directed. The relationship between these two entities is robust and essential, as both are required for successful interaction with the API. Without the API key for authentication and the base URL for endpoint identification, accessing the services provided by the LLM service would not be possible.",['3da10b454f926a257b9fdf5d2487c0a5' '8ac79ce92be1254dfda9a10eb54ab703'],f3c3dd44cf50495c81e362174991242e,173,5,2,7
GRAPHRAG_API_KEY,GRAPHRAG_API_VERSION,1.0,"GRAPHRAG_API_KEY and GRAPHRAG_API_VERSION are related because GRAPHRAG_API_KEY is used for authentication to access the LLM service, and GRAPHRAG_API_VERSION specifies the version of the LLM service API. Together, they ensure compatibility between the system and the LLM service by specifying the correct version of the API to use.",['8ac79ce92be1254dfda9a10eb54ab703'],86c2b3749a3c4342bbb3a8c70c3a76a0,174,5,3,8
GRAPHRAG_LLM_API_BASE,GRAPHRAG_LLM_TYPE,1.0,"GRAPHRAG_LLM_API_BASE and GRAPHRAG_LLM_TYPE are related as they both configure the LLM operations, with the API Base URL and the type of operation, respectively",['1ef6439b7c457ba43993467ff734eedf'],571f65acb3134490932feeb91b01cca3,175,4,5,9
GRAPHRAG_LLM_API_BASE,GRAPHRAG_LLM_MAX_RETRIES,1.0,"GRAPHRAG_LLM_API_BASE and GRAPHRAG_LLM_MAX_RETRIES are related as they both pertain to the configuration of LLM operations, with the API Base URL and the maximum number of retries for failed requests, respectively",['1ef6439b7c457ba43993467ff734eedf'],d3faf86c153f440eaa410305b3dc6617,176,4,2,6
GRAPHRAG_LLM_API_BASE,AZURE OPENAI,1.0,The Azure OpenAI service requires the GRAPHRAG_LLM_API_BASE configuration to determine the base URL for API requests. This relationship is necessary for establishing a connection to the service and sending requests to the correct endpoint.,['7b45dafa74553d3899e2291a3c9fb86e'],f85786004b0540349192d2ca05b15264,177,4,6,10
GRAPHRAG_LLM_TYPE,GRAPHRAG_LLM_DEPLOYMENT_NAME,1.0,GRAPHRAG_LLM_TYPE and GRAPHRAG_LLM_DEPLOYMENT_NAME are related because the language model type and the deployment name together determine the specific language model to be used for text generation. The deployment name is crucial for identifying the correct model within the specified type. The strength of this relationship is high because both settings are required for successful text generation.,['3da10b454f926a257b9fdf5d2487c0a5'],cf56bfc9fa7d47fe9cb553dd09f2b412,178,5,2,7
GRAPHRAG_LLM_TYPE,GRAPHRAG_LLM_MODEL_SUPPORTS_JSON,1.0,GRAPHRAG_LLM_TYPE and GRAPHRAG_LLM_MODEL_SUPPORTS_JSON are related because the language model type and the model's support for JSON input together determine the format of the input data that can be processed by the model. The model's support for JSON is crucial for ensuring that the input data is in a compatible format. The strength of this relationship is high because both settings are required for successful text generation.,['3da10b454f926a257b9fdf5d2487c0a5'],a077dbcd38b644f6929cf05272c2fb9d,179,5,2,7
GRAPHRAG_LLM_TYPE,GRAPHRAG_INPUT_TYPE,1.0,GRAPHRAG_INPUT_TYPE and GRAPHRAG_LLM_TYPE are related because the input data type and the language model type together determine the compatibility of the input data with the model being used for text generation. The input data type is crucial for ensuring that the data is in a format that can be processed by the specified model. The strength of this relationship is high because both settings are required for successful text generation.,['3da10b454f926a257b9fdf5d2487c0a5'],d2659a32b9de406eb750a35d078c9774,180,5,4,9
GRAPHRAG_EMBEDDING_API_BASE,GRAPHRAG_EMBEDDING_TYPE,1.0,"GRAPHRAG_EMBEDDING_API_BASE and GRAPHRAG_EMBEDDING_TYPE are related as they both configure the embedding operations, with the API Base URL and the type of embedding client, respectively",['1ef6439b7c457ba43993467ff734eedf'],0b26876307ad4cc48839b61a21a1d03a,181,3,2,5
GRAPHRAG_EMBEDDING_API_BASE,GRAPHRAG_EMBEDDING_MAX_RETRIES,1.0,"GRAPHRAG_EMBEDDING_API_BASE and GRAPHRAG_EMBEDDING_MAX_RETRIES are related as they both pertain to the configuration of embedding operations, with the API Base URL and the maximum number of retries for failed requests, respectively",['1ef6439b7c457ba43993467ff734eedf'],c68e6c694a554256846d12178ddb12dc,182,3,2,5
GRAPHRAG_EMBEDDING_API_BASE,APHRAG_API_KEY,1.0,APHRAG_API_KEY is related to GRAPHRAG_EMBEDDING_API_BASE as both are configuration variables that may be required for accessing and using the embedding API. The absence of APHRAG_API_KEY might affect the functionality or access to the API specified by GRAPHRAG_EMBEDDING_API_BASE.,['485c17007ccb3102887eaa47d6a6100f'],ff25ce2e8ace4bdcb765c863b483852b,183,3,1,4
GRAPHRAG_EMBEDDING_TYPE,GRAPHRAG_LLM_DEPLOYMENT_NAME,1.0,GRAPHRAG_EMBEDDING_TYPE and GRAPHRAG_LLM_DEPLOYMENT_NAME are related because the embedding model type and the deployment name together determine the specific embedding model to be used for text embedding. The deployment name is crucial for identifying the correct model within the specified type. The strength of this relationship is high because both settings are required for successful text embedding.,['3da10b454f926a257b9fdf5d2487c0a5'],757e402cb7ee4601ac1bc8c4fafb5207,184,2,2,4
GRAPHRAG_EMBEDDING_MAX_RETRIES,GRAPHRAG_EMBEDDING_MAX_RETRY_WAIT,1.0,"The GRAPHRAG_EMBEDDING_MAX_RETRIES setting is related to the GRAPHRAG_EMBEDDING_MAX_RETRY_WAIT as they both determine the retry mechanism for embedding operations, with the number of retries and the wait time between retries",['2b777e3d591ce1511a03abd1a6d8dc73'],62e8f5f04cd04384b246291cef3a9e4d,185,2,1,3
GRAPHRAG_LOCAL_SEARCH_TEXT_UNIT_PROP,GRAPHRAG_LOCAL_SEARCH_COMMUNITY_PROP,1.0,"GRAPHRAG_LOCAL_SEARCH_TEXT_UNIT_PROP and GRAPHRAG_LOCAL_SEARCH_COMMUNITY_PROP are related as they both configure the proportions of the context window dedicated to related text units and community reports, respectively",['1ef6439b7c457ba43993467ff734eedf'],c04abbd5e59b4c64b023908f6db05498,186,1,1,2
GRAPHRAG_LOCAL_SEARCH_MAX_TOKENS,GRAPHRAG_LOCAL_SEARCH_LLM_MAX_TOKENS,1.0,"GRAPHRAG_LOCAL_SEARCH_MAX_TOKENS and GRAPHRAG_LOCAL_SEARCH_LLM_MAX_TOKENS are related as they both are configuration properties that can be adjusted based on the token limit of the model being used, affecting the local search context window and language model token limits respectively",['2efb1fec56fe3b0543d395dd541295c3'],6bb9bed2e39c4e31a81f12479af3d16c,187,2,1,3
GRAPHRAG_LOCAL_SEARCH_MAX_TOKENS,GRAPHRAG_GLOBAL_SEARCH_MAX_TOKENS,1.0,"GRAPHRAG_LOCAL_SEARCH_MAX_TOKENS and GRAPHRAG_GLOBAL_SEARCH_MAX_TOKENS are related as they both are configuration properties that can be adjusted based on the token limit of the model being used, affecting the local and global search context window token limits respectively",['2efb1fec56fe3b0543d395dd541295c3'],26c926c6016d4639b05427f01ba629f5,188,2,3,5
GRAPHRAG_GLOBAL_SEARCH_MAX_TOKENS,GRAPHRAG_GLOBAL_SEARCH_DATA_MAX_TOKENS,1.0,Both GRAPHRAG_GLOBAL_SEARCH_MAX_TOKENS and GRAPHRAG_GLOBAL_SEARCH_DATA_MAX_TOKENS are related as they both pertain to the token limits for global search and should be adjusted based on the model's token limit,['2049798d3000849f8bec3e88c0006807'],8f6872eeb81b432b91405d327636113c,189,3,1,4
GRAPHRAG_GLOBAL_SEARCH_MAX_TOKENS,GRAPHRAG_GLOBAL_SEARCH_REDUCE_MAX_TOKENS,1.0,GRAPHRAG_GLOBAL_SEARCH_MAX_TOKENS and GRAPHRAG_GLOBAL_SEARCH_REDUCE_MAX_TOKENS are related as they both pertain to the token limits for global search and should be adjusted based on the model's token limit,['2049798d3000849f8bec3e88c0006807'],ac80a99fda2b488285d29596dd4d1471,190,3,1,4
GRAPHRAG KNOWLEDGE MODEL,GRAPHRAG INDEXER,1.0,"The GraphRAG Knowledge Model is aligned with the outputs of the GraphRAG Indexer, which means the data processed by the Indexer is structured according to the Knowledge Model for compatibility with the GraphRAG system",['25e04f0e9a961dcdc3f6eae6df7807b2'],67d6a3481e4b419292247cef5cd5b737,191,1,3,4
GRAPHRAG INDEXER,GRAPHRAG QUERY ENGINE,1.0,"The GraphRAG Indexer's outputs are loaded into a database system, which is then accessed by the GraphRAG Query Engine to process queries based on the indexed data",['25e04f0e9a961dcdc3f6eae6df7807b2'],904cd052ec194654bb72f4027e43daa3,192,3,1,4
DATASHAPER,GRAPHRAG INDEXING PIPELINE,1.0,"The GraphRAG Indexing Pipeline is built on top of DataShaper, utilizing its data processing capabilities to transform and index data for the GraphRAG system",['25e04f0e9a961dcdc3f6eae6df7807b2'],7e88fd2e835147fbb71866612735e8d4,193,2,12,14
DATASHAPER,WORKFLOW,1.0,"DataShaper provides the framework for defining and executing Workflows, which are sequences of steps (verbs) that transform data tables through a pipeline",['81031e23c0b000ee60cd9b06950f96cd'],029d1a8c3b184aa5bb21228f40cd12fd,194,2,2,4
WORKFLOW,VERB,1.0,"A Workflow in DataShaper is composed of Verbs, which are steps that model relational concepts and transform input data tables",['81031e23c0b000ee60cd9b06950f96cd'],a1ebc53a0bc74a0eb6dbdd18cf3c88cd,195,2,3,5
GRAPHRAG INDEXING PIPELINE,WORKFLOW GRAPHS,1.0,"Workflow Graphs are a fundamental concept in the GraphRAG Indexing Pipeline, where they are used to represent the series of interdependent workflows that form the data indexing process.",['d19a57bca2c14fc9c2bf5058958380fd'],a51d063ad4c744049edb359eb88407b7,196,12,3,15
GRAPHRAG INDEXING PIPELINE,PREPARE,1.0,"The Prepare step is part of the GraphRAG Indexing Pipeline, where it is used to prepare data for subsequent processing tasks.",['d19a57bca2c14fc9c2bf5058958380fd'],b67268f90338474e8e53b9a6715b6833,197,12,2,14
GRAPHRAG INDEXING PIPELINE,CHUNK,1.0,"The Chunk step is part of the GraphRAG Indexing Pipeline, where it is used to break down data into smaller, manageable pieces for more efficient processing.",['d19a57bca2c14fc9c2bf5058958380fd'],acb53370e72b4430a752d9ea18c17352,198,12,4,16
GRAPHRAG INDEXING PIPELINE,EXTRACTGRAPH,1.0,"The ExtractGraph step is part of the GraphRAG Indexing Pipeline, where it is used to extract graph structures from data.",['d19a57bca2c14fc9c2bf5058958380fd'],a8738c7de11543df930169741381c252,199,12,3,15
GRAPHRAG INDEXING PIPELINE,EMBEDDOCUMENTS,1.0,"The EmbedDocuments step is part of the GraphRAG Indexing Pipeline, where it is used to convert documents into numerical representations for machine learning or information retrieval.",['d19a57bca2c14fc9c2bf5058958380fd'],3f8b5b2727924ba0b62e6286063b6861,200,12,3,15
GRAPHRAG INDEXING PIPELINE,GENERATEREPORTS,1.0,"The GenerateReports step is part of the GraphRAG Indexing Pipeline, where it is used to create reports based on the processed data.",['d19a57bca2c14fc9c2bf5058958380fd'],bb5010633113442eaf814852995cfa22,201,12,3,15
GRAPHRAG INDEXING PIPELINE,EMBEDGRAPH,1.0,"The EmbedGraph step is part of the GraphRAG Indexing Pipeline, where it is used to convert graph structures into numerical representations for machine learning algorithms.",['d19a57bca2c14fc9c2bf5058958380fd'],9eb8c635538243a690366f8bc1de34e0,202,12,3,15
GRAPHRAG INDEXING PIPELINE,ENTITYRESOLUTION,1.0,"The EntityResolution step is part of the GraphRAG Indexing Pipeline, where it is used to resolve ambiguities in data, such as identifying and merging duplicate entities.",['d19a57bca2c14fc9c2bf5058958380fd'],050c5b770d51409cb40f9c52f02d1329,203,12,2,14
GRAPHRAG INDEXING PIPELINE,SAMPLE WORKFLOW DAG,1.0,"The Sample Workflow DAG is a visual representation of the directed acyclic graph (DAG) that is part of the GraphRAG Indexing Pipeline, showing the dependencies between different workflows.",['d19a57bca2c14fc9c2bf5058958380fd'],9e12f514d26d48dfab65807568a6cff9,204,12,1,13
GRAPHRAG INDEXING PIPELINE,DATAFRAME MESSAGE FORMAT,1.0,"The Dataframe Message Format is used in the GraphRAG Indexing Pipeline as the primary unit of communication between workflows and workflow steps, facilitating data-centric and table-centric data processing.",['d19a57bca2c14fc9c2bf5058958380fd'],97f98b1623104f48aa93196a1f7dede2,205,12,1,13
GRAPHRAG INDEXING PIPELINE,LLM CACHING,1.0,LLM Caching is a technique used in the GraphRAG Indexing Pipeline to improve the resilience of the indexer to network issues by caching the results of Large Language Model (LLM) interactions.,['d19a57bca2c14fc9c2bf5058958380fd'],87718ef799a34104b6ef9c2df6621cbc,206,12,1,13
VERB,INPUT TABLE,1.0,"A Verb in DataShaper operates on an Input Table, transforming it according to the verb's specific function",['81031e23c0b000ee60cd9b06950f96cd'],f64e87431d674f298c533f6878458b95,207,3,1,4
VERB,OUTPUT TABLE,1.0,"A Verb in DataShaper produces an Output Table, which is the result of the transformation applied to the Input Table",['81031e23c0b000ee60cd9b06950f96cd'],e6d44d0db58f42799a02eacbd6b14543,208,3,1,4
GRAPHRAG'S INDEXING PIPELINE,LLM-BASED WORKFLOW STEPS,1.0,GraphRAG's Indexing Pipeline implements custom LLM-based Workflow Steps that utilize Large Language Models to perform data enrichment and extraction tasks,['81031e23c0b000ee60cd9b06950f96cd'],64961fbc3a1641378be10bcb3b0955e1,209,2,1,3
GRAPHRAG'S INDEXING PIPELINE,WORKFLOW GRAPHS,1.0,"GraphRAG's Indexing Pipeline uses Workflow Graphs to represent the complex interdependencies between multiple workflows, forming a DAG for scheduling processing",['81031e23c0b000ee60cd9b06950f96cd'],59bcc2ec512c4c1ba44272446b419230,210,2,3,5
WORKFLOW GRAPHS,DAG (DIRECTED ACYCLIC GRAPH),1.0,Workflow Graphs in GraphRAG's Indexing Pipeline are represented as a DAG (Directed Acyclic Graph) to manage the dependencies between different workflow steps,['81031e23c0b000ee60cd9b06950f96cd'],8f39ae56f8b54b1b94faf04dbd0b9d11,211,3,1,4
PREPARE,CHUNK,1.0,"Prepare may be followed by Chunk in a workflow, where data is prepared and then divided into smaller, manageable pieces",['81031e23c0b000ee60cd9b06950f96cd'],f3018b934ac241639a33c925c24bc507,212,2,4,6
CHUNK,EXTRACTGRAPH,1.0,"Chunk may be followed by ExtractGraph in a workflow, where data chunks are analyzed to extract graph structures",['81031e23c0b000ee60cd9b06950f96cd'],ddedfd5179e64700adced4803c75cdba,213,4,3,7
CHUNK,DOCUMENTS,1.0,"Chunk is related to Documents as chunks are often derived from documents, with a user-configurable size, and there is a strict 1-to-many relationship between Documents and TextUnits by default",['6f92ce3fcd05dd5697ded83586f7bc08'],07d501edd4614e1d9d08d01b702688a3,214,4,4,8
EXTRACTGRAPH,EMBEDDOCUMENTS,1.0,"ExtractGraph may be followed by EmbedDocuments in a workflow, where graph structures are used to inform the embedding of documents into a vector space",['81031e23c0b000ee60cd9b06950f96cd'],f745075dedcf444daa9370cf32403d31,215,3,3,6
EMBEDDOCUMENTS,GENERATEREPORTS,1.0,"EmbedDocuments may be followed by GenerateReports in a workflow, where embedded documents are used to generate reports based on the processed data",['81031e23c0b000ee60cd9b06950f96cd'],1ef48284d238405f94190125092a3e28,216,3,3,6
GENERATEREPORTS,EMBEDGRAPH,1.0,"GenerateReports may be followed by EmbedGraph in a workflow, where reports are used to inform the embedding of graph structures into a vector space",['81031e23c0b000ee60cd9b06950f96cd'],8806b817446447e3b50f5bc85ff497e1,217,3,3,6
EMBEDGRAPH,ENTITYRESOLUTION,1.0,"EmbedGraph may be followed by EntityResolution in a workflow, where embedded graph structures are used to resolve entities within the data",['81031e23c0b000ee60cd9b06950f96cd'],7303ee20690449db8c168df3fe008bc5,218,3,2,5
GRAPHRAG LIBRARY,LLM INTERACTIONS,1.0,The GraphRAG library is designed to facilitate and optimize LLM interactions by addressing common issues such as network latency and throttling errors through the implementation of a caching mechanism.,['6335601c6ec22bd6f15c8b69c26f854b'],2f1c535a14b14758bf1cacca81c74878,219,2,2,4
GRAPHRAG LIBRARY,CACHING,1.0,The GraphRAG library incorporates caching as a core feature to improve the efficiency and reliability of LLM interactions by storing and reusing results when the same input set is used.,['6335601c6ec22bd6f15c8b69c26f854b'],3b78cc7ce8224afcab3e4bbe550cde10,220,2,2,4
LLM INTERACTIONS,CACHING,1.0,"Caching is a strategy used in LLM interactions to enhance system performance by storing and reusing results, which helps in mitigating network issues and improving the efficiency of the interactions.",['6335601c6ec22bd6f15c8b69c26f854b'],29ec9dd9f5864170a7e75c46c11c0090,221,2,2,4
LOCAL TO GLOBAL GRAPH RAG APPROACH,RETRIEVAL-AUGMENTED GENERATION (RAG),1.0,The Local to Global Graph RAG Approach builds upon the concept of Retrieval-Augmented Generation (RAG) by addressing its limitations in handling global questions. It extends RAG's capabilities to include query-focused summarization tasks over large text corpora.,['f76c18c7582167c3626f8741c2c9374f'],7893ee15f0e941cbacad8cc1feaacbaf,222,4,2,6
LOCAL TO GLOBAL GRAPH RAG APPROACH,QUERY-FOCUSED SUMMARIZATION (QFS),1.0,The Local to Global Graph RAG Approach incorporates elements of Query-Focused Summarization (QFS) to scale to the quantities of text indexed by typical RAG systems. It aims to combine the strengths of QFS and RAG to handle both the generality of user questions and the quantity of source text.,['f76c18c7582167c3626f8741c2c9374f'],f53397f743ca4d7397c0a694fe787da0,223,4,4,8
LOCAL TO GLOBAL GRAPH RAG APPROACH,ENTITY KNOWLEDGE GRAPH,1.0,The Local to Global Graph RAG Approach uses an Entity Knowledge Graph as a foundational component. The graph is derived from source documents and is used to identify closely-related entities for generating community summaries.,['f76c18c7582167c3626f8741c2c9374f'],0041db9da3694ad397f37c76f8477770,224,4,3,7
RETRIEVAL-AUGMENTED GENERATION (RAG),QUERY-FOCUSED SUMMARIZATION (QFS),1.0,"Retrieval-Augmented Generation (RAG) is a specific approach within the broader task of query-focused summarization, but it is designed for situations where answers are contained locally within regions of text, whereas QFS focuses on generating summaries in response to user queries",['c7669e6a1add9a2829b09196256b1492'],a7c2a64e06374091adce74adb36801ab,225,2,4,6
QUERY-FOCUSED SUMMARIZATION (QFS),ABSTRACTIVE SUMMARIZATION,2.0,"Query-Focused Summarization (QFS) is a specialized subset of Abstractive Summarization, a technique that generates concise, natural language summaries. Unlike generic summarization methods, QFS is tailored to create summaries that are directly relevant to specific queries. This process involves the creation of new sentences that accurately capture the information sought by the query, rather than simply extracting and concatenating existing sentences from the source text. QFS's focus on abstractive summarization ensures that the generated summaries are not merely a collection of excerpts, but rather a coherent and meaningful representation of the original content, specifically addressing the information needs indicated by the query.",['85eff07c379a9dc24db0edb983acf3c9' 'c7669e6a1add9a2829b09196256b1492'],107568a67cac472c89dfce4bbe11157c,226,4,2,6
QUERY-FOCUSED SUMMARIZATION (QFS),EXTRACTIVE SUMMARIZATION,1.0,"Query-Focused Summarization (QFS) contrasts with extractive summarization, as it focuses on generating new sentences in response to user queries, rather than selecting and concatenating existing sentences",['c7669e6a1add9a2829b09196256b1492'],3d78aa9d14714ac189e4020f78b15d24,227,4,2,6
ENTITY KNOWLEDGE GRAPH,GRAPH-BASED TEXT INDEX,1.0,"The graph-based text index method involves the creation of an entity knowledge graph from source documents, which is used to generate community summaries for groups of closely-related entities",['b149708d0b4ac3ff417565739ea6b03b'],ce0366abadef410d9b65e2bfbbf0b0f9,228,3,2,5
GRAPH-BASED TEXT INDEX,GLOBAL SENSEMAKING QUESTIONS,1.0,"The graph-based text index method is particularly effective for answering global sensemaking questions over datasets in the 1 million token range, as it improves the comprehensiveness and diversity of generated answers",['b149708d0b4ac3ff417565739ea6b03b'],f4370806deb84d0eb7e85e742e7d4bbf,229,2,2,4
GLOBAL SENSEMAKING QUESTIONS,GRAPH RAG,1.0,"Graph RAG leads to substantial improvements over a naive RAG baseline for answering global sensemaking questions, as it uses a graph-based text index to improve the comprehensiveness and diversity of generated answers",['b149708d0b4ac3ff417565739ea6b03b'],c92392d168c2443e8ed7b04992d0c92b,230,2,19,21
GRAPH RAG,SOURCE TEXTS,1.0,"Graph RAG is compared against Source Texts in terms of summarization and question answering effectiveness. Graph RAG generally provides a small but consistent improvement in answer comprehensiveness and diversity over source texts, especially with community summaries.",['71f14506a6b15dfabd93fd1606a67b73'],b5800c807edd4087a2420007272d15d0,231,19,2,21
GRAPH RAG,SOURCE TEXT SUMMARIZATION,1.0,"Graph RAG requires fewer context tokens for both low-level (C3) and root-level (C0) community summaries compared to source text summarization, indicating a scalability advantage",['ed433e2f5d5387b47376eb0e45ca1c99'],aa247540e90d4a7abc5bca6fafaaffa1,232,19,1,20
GRAPH RAG,LOW-LEVEL COMMUNITY SUMMARIES (C3),1.0,"Graph RAG requires 26-33% fewer context tokens for low-level community summaries (C3) compared to source text summarization, showing a scalability advantage",['ed433e2f5d5387b47376eb0e45ca1c99'],34537afa1e954e08bdb52ead3a49e2f3,233,19,1,20
GRAPH RAG,ROOT-LEVEL COMMUNITY SUMMARIES (C0),1.0,"Graph RAG requires over 97% fewer context tokens for root-level community summaries (C0) compared to source text summarization, demonstrating a significant scalability advantage",['ed433e2f5d5387b47376eb0e45ca1c99'],ae043af0299f4b32a98cf187efd2a5db,234,19,1,20
GRAPH RAG,EMPOWERMENT,1.0,"Empowerment comparisons showed mixed results for Graph RAG versus naive RAG and source text summarization, indicating that Graph RAG may need tuning to retain more details in the index to better empower users",['ed433e2f5d5387b47376eb0e45ca1c99'],6016863be3414d5a92397f2d45fdfd78,235,19,3,22
GRAPH RAG,PARALLEL GENERATION OF COMMUNITY ANSWERS,1.0,"Graph RAG uses parallel generation of community answers as a technique for improving the efficiency and effectiveness of retrieval and generation. This relationship indicates that parallel generation of community answers is a key feature of Graph RAG, enabling faster and more accurate retrieval and generation.",['7da3d8d244b67f09425a4a7783e4bb55'],a9b900821b8444d69f432da08a77539f,236,19,1,20
GRAPH RAG,ITERATIVE RETRIEVAL-GENERATION STRATEGY,1.0,"Graph RAG incorporates iterative retrieval-generation strategy as a method for continuous refinement and improvement of the retrieval and generation process. This relationship indicates that iterative retrieval-generation strategy is a core component of Graph RAG, allowing for iterative cycles of retrieval and generation.",['7da3d8d244b67f09425a4a7783e4bb55'],1fee51d6f4614127a3e1cc80d018506e,237,19,1,20
GRAPH RAG,FEDERATED RETRIEVAL-GENERATION STRATEGY,1.0,"Graph RAG uses federated retrieval-generation strategy as a method for sharing resources and information across multiple systems or nodes. This relationship indicates that federated retrieval-generation strategy is a key feature of Graph RAG, enabling distributed and collaborative retrieval and generation.",['7da3d8d244b67f09425a4a7783e4bb55'],00dc2c0748214e52bc799ca3e25204e9,238,19,1,20
GRAPH RAG,MULTI-DOCUMENT SUMMARIZATION,1.0,"Graph RAG bears resemblance to multi-document summarization techniques, which are used for creating a concise and coherent summary of multiple documents. This relationship indicates that multi-document summarization is a related concept to Graph RAG, sharing similarities in the handling of multiple documents or data sources.",['7da3d8d244b67f09425a4a7783e4bb55'],42d1a9e749ad40daa34c7b0b695f8751,239,19,1,20
GRAPH RAG,MULTI-HOP QUESTION ANSWERING,1.0,"Graph RAG is related to multi-hop question answering techniques, which are used for answering questions that require reasoning over multiple pieces of information or documents. This relationship indicates that multi-hop question answering is a related concept to Graph RAG, sharing similarities in the handling of complex questions and information retrieval.",['7da3d8d244b67f09425a4a7783e4bb55'],20de9a1af6ab4e88acf003cb7be0217c,240,19,1,20
GRAPH RAG,HIERARCHICAL INDEX,1.0,"Graph RAG uses a hierarchical index as a data structure for organizing information in a hierarchical manner. This relationship indicates that hierarchical index is a key component of Graph RAG, improving the efficiency and effectiveness of information retrieval.",['7da3d8d244b67f09425a4a7783e4bb55'],f3229f10a5a54cb1b91a26ffa6ee77a3,241,19,1,20
GRAPH RAG,SUMMARIZATION,1.0,"Graph RAG incorporates summarization techniques for creating a concise and coherent summary of a document or set of documents. This relationship indicates that summarization is a related concept to Graph RAG, sharing similarities in the handling of document summarization and information retrieval.",['7da3d8d244b67f09425a4a7783e4bb55'],5154b4a4f3ac43729703c69fccb54633,242,19,1,20
GRAPH RAG,TREE OF CLARIFICATIONS,1.0,"Tree of Clarifications and Graph RAG are both research studies that involve advanced information retrieval and analysis, with Tree of Clarifications focusing on ambiguous questions and Graph RAG on self-generated graph indexes.",['40f2d6a0270e54743e7ace239369da96'],2091070e709e45f5ae56d40a9da45520,243,19,2,21
GRAPH RAG,SELFCHECKGPT,1.0,Comparing fabrication rates using approaches like SelfCheckGPT can improve the current analysis and potentially enhance the performance of Graph RAG,['7040ba36a7c09899a355d14a30d65375'],09045ef5c4314dde9a631a206274563f,244,19,2,21
GRAPH RAG,GRAPH INDEX,1.0,"The graph index is a key component in the Graph RAG approach, which consistently achieves the best head-to-head results against other methods",['7040ba36a7c09899a355d14a30d65375'],1b9baa98ede84164883e8cdcbc7000c1,245,19,10,29
GRAPH RAG,FUTURE WORK,1.0,"Future work includes the possibility of refining and adapting the current Graph RAG approach, which can involve the Graph RAG model",['7040ba36a7c09899a355d14a30d65375'],e4f3fcc475a74756925b730caffcb70d,246,19,7,26
LARGE LANGUAGE MODELS (LLMS),SCIENTIFIC DISCOVERY,1.0,"Large language models are being used to automate human-like sensemaking in the domain of scientific discovery, where the process of making new and significant contributions to scientific knowledge is supported by the use of artificial intelligence",['b149708d0b4ac3ff417565739ea6b03b'],7f3d5282303f4fc3a009e04f7de0ad84,247,2,1,3
LARGE LANGUAGE MODELS (LLMS),INTELLIGENCE ANALYSIS,1.0,"Large language models are being used to automate human-like sensemaking in the domain of intelligence analysis, where the process of gathering, processing, and analyzing information to support decision-making is supported by the use of artificial intelligence",['b149708d0b4ac3ff417565739ea6b03b'],1219a14eaf5f49ab84c9287ebf58db7a,248,2,1,3
AUTOMATED SENSEMAKING,HUMAN-LED SENSEMAKING,1.0,Automated sensemaking complements human-led sensemaking by providing tools and techniques to support humans in understanding complex domains and refining their mental model of the data,['c7669e6a1add9a2829b09196256b1492'],efaa386bd5e9454b87e1851cd8b28ac3,249,1,1,2
ABSTRACTIVE SUMMARIZATION,EXTRACTIVE SUMMARIZATION,1.0,"Abstractive Summarization is distinct from Extractive Summarization in that it generates new sentences to convey the meaning of the original text, whereas Extractive Summarization selects and reorders existing sentences from the source text. Abstractive Summarization is more flexible and can provide a more coherent summary, while Extractive Summarization is more literal and may not capture the essence of the text as effectively.",['85eff07c379a9dc24db0edb983acf3c9'],073241be9b6a4952ad01dd14b94fb89c,250,2,2,4
TRANSFORMER ARCHITECTURE,LLMS (LARGE LANGUAGE MODELS),1.0,"The Transformer Architecture is foundational to the development of LLMs (Large Language Models), which have shown substantial improvements in various natural language processing tasks, including summarization. The transformer's self-attention mechanism allows LLMs to process and generate text more effectively, making them highly capable in summarization tasks.",['85eff07c379a9dc24db0edb983acf3c9'],f7ac6bc4a9ca4250ad29a3adb5d08657,251,1,4,5
LLMS (LARGE LANGUAGE MODELS),GPT (GENERATIVE PRE-TRAINED TRANSFORMER),1.0,"GPT (Generative Pre-trained Transformer) is a type of LLM (Large Language Model) that has been particularly effective in summarization tasks. It uses the transformer architecture to generate coherent and contextually relevant text, making it a powerful tool for summarization and other NLP tasks.",['85eff07c379a9dc24db0edb983acf3c9'],ac2ee54e75a2492c8db372dadfccd083,252,4,1,5
LLMS (LARGE LANGUAGE MODELS),LLAMA,1.0,"Llama is a type of LLM (Large Language Model) that is designed to handle complex language tasks, including summarization. It is based on the transformer architecture and can generate human-like text, making it a valuable resource for summarization and other NLP tasks.",['85eff07c379a9dc24db0edb983acf3c9'],ee895ad0b8cd40c29465e8527748d847,253,4,1,5
LLMS (LARGE LANGUAGE MODELS),GEMINI,1.0,"Gemini is a type of LLM (Large Language Model) that is capable of understanding and generating text, making it suitable for various NLP tasks, including summarization. It is based on the transformer architecture and can process and generate text effectively, making it a powerful tool for summarization tasks.",['85eff07c379a9dc24db0edb983acf3c9'],fe38c996c2d64bc899eabd6389034075,254,4,1,5
"BROWN ET AL., 2020","LLAMA (TOUVRON ET AL., 2023)",1.0,"Brown et al., 2020, and Llama (Touvron et al., 2023) are related in that they both discuss the use of in-context learning for summarization tasks within the context window of LLMs",['3fc3718256cb7f614fcde622af2ed912'],c0e28ae832c94405b8ddd4d2ad978be5,255,1,2,3
"LLAMA (TOUVRON ET AL., 2023)","GEMINI (ANIL ET AL., 2023)",1.0,"Llama (Touvron et al., 2023) and Gemini (Anil et al., 2023) are related in that they both explore the application of in-context learning for summarization tasks, focusing on different series that can summarize content within the context window of LLMs",['3fc3718256cb7f614fcde622af2ed912'],7a4573a19ef94e25b4480cb4d953ae7a,256,2,1,3
IN-CONTEXT LEARNING,QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION,1.0,"In-context learning is related to query-focused abstractive summarization in that it is a technique used by LLMs to adapt their responses based on the context provided, which is essential for generating summaries in response to specific queries",['3fc3718256cb7f614fcde622af2ed912'],05f6639803524537b67a7f2b0c66ad23,257,1,4,5
QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION,LLM CONTEXT WINDOW LIMITS,1.0,"Query-focused abstractive summarization is constrained by LLM context window limits, as the volumes of text in entire corpora can greatly exceed the processing capacity of LLMs",['3fc3718256cb7f614fcde622af2ed912'],21bfd14cbc1f4cbc8ac59f7fd8c75b31,258,4,2,6
QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION,NAIVE RAG (RETRIEVAL-AUGMENTED GENERATION),1.0,"Naive RAG (Retrieval-Augmented Generation) is related to query-focused abstractive summarization in that it is a technique that directly retrieves text chunks for summarization, which may not be sufficient for summarization tasks over large corpora",['3fc3718256cb7f614fcde622af2ed912'],c19cf2d7b067421990ab9f3acec9e736,259,4,2,6
QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION,GRAPH RAG APPROACH,1.0,"The Graph RAG approach is related to query-focused abstractive summarization in that it is a technique based on global summarization of an LLM-derived knowledge graph, which can address the limitations of naive RAG for summarization tasks over large corpora",['3fc3718256cb7f614fcde622af2ed912'],3e1981b9301c4d339a9228ae7a089a04,260,4,8,12
LLM CONTEXT WINDOW LIMITS,INFORMATION LOSS IN LONGER CONTEXTS,1.0,"LLM context window limits are related to information loss in longer contexts, as the middle part of very long texts may not receive adequate attention, leading to potential loss of information",['3fc3718256cb7f614fcde622af2ed912'],0948efa844814529b4c023aacbc23d64,261,2,1,3
NAIVE RAG (RETRIEVAL-AUGMENTED GENERATION),ENTITY-BASED GRAPH INDEX,1.0,"The Entity-based Graph Index achieves superior performance compared to Naive RAG (Retrieval-Augmented Generation), offering a more efficient and effective data index for root-level communities and global queries.",['e31d2d134cf501c93f9445914d7350f9'],fcdc0cc5ff93453eb0b94b9254760999,262,2,3,5
GRAPH RAG APPROACH,STRUCTURED RETRIEVAL AND TRAVERSAL,1.0,"Structured retrieval and traversal is related to the Graph RAG approach in that it exploits the structured nature of graph indexes for efficient information retrieval and navigation, which is a key component of the Graph RAG approach",['3fc3718256cb7f614fcde622af2ed912'],0ec4ad4398a8457ab3d71bd2561858dc,263,8,2,10
GRAPH RAG APPROACH,GRAPH MODULARITY,1.0,"Graph modularity is related to the Graph RAG approach in that it is a property of graphs that allows them to be partitioned into modular communities of closely-related nodes, which is a key aspect of the Graph RAG approach",['3fc3718256cb7f614fcde622af2ed912'],3c06988555334a389eab093f98679e85,264,8,1,9
GRAPH RAG APPROACH,COMMUNITY DETECTION ALGORITHMS,1.0,"Community detection algorithms are related to the Graph RAG approach in that they are techniques used to identify groups of closely-related nodes in a graph, which can be useful for summarization tasks within the Graph RAG approach",['3fc3718256cb7f614fcde622af2ed912'],81ceb8db419b4697ad24e9d7f46422ff,265,8,4,12
GRAPH RAG APPROACH,TEXT CHUNKS,1.0,The Graph RAG approach involves processing text chunks extracted from source documents. The granularity of these chunks affects the efficiency and quality of the information retrieval and augmentation process in the Graph RAG technique.,['d2399fd0aae5bd200639806ca87184f8'],fd05d8198d0947b39b8fa1b16f3ecf5f,266,8,7,15
GRAPH RAG APPROACH,EMBEDDING-BASED MATCHING,1.0,"The Graph RAG approach utilizes embedding-based matching as one of its methods to refine and adapt the current approach by operating in a more local manner, matching user queries and graph annotations",['5e2933c9646c751e6a60c9de12a255f2'],d984f08ad62f47ab9aabb9aeec1b245e,267,8,1,9
GRAPH RAG APPROACH,HYBRID RAG SCHEMES,1.0,"The Graph RAG approach can be enhanced by implementing hybrid RAG schemes that combine embedding-based matching against community reports before employing map-reduce summarization mechanisms, improving the comprehensiveness and diversity of answers",['5e2933c9646c751e6a60c9de12a255f2'],43603c7868164ac38c659bce7a77f45a,268,8,1,9
GRAPH RAG APPROACH,MAP-REDUCE SUMMARIZATION,1.0,"The Graph RAG approach uses map-reduce summarization as a mechanism to summarize large amounts of data, which is particularly useful for global queries over the same dataset, providing summaries of root-level communities in the entity-based graph index",['5e2933c9646c751e6a60c9de12a255f2'],54a20cc6062d4b7193d023b6ff20461f,269,8,2,10
STRUCTURED RETRIEVAL AND TRAVERSAL,LLM-DERIVED KNOWLEDGE GRAPH,1.0,The LLM-derived knowledge graph is related to structured retrieval and traversal because the graph structure facilitates efficient and effective information retrieval and navigation. The inherent modularity of the graph and the use of community detection algorithms enable the identification of relevant information for specific queries.,['d39abd5380fb3fe0468ea1e122512091'],6bb190069a704ccca3d8e1648a384185,270,2,1,3
COMMUNITY DETECTION ALGORITHMS,MODULARITY,1.0,"Modularity is related to community detection algorithms because these algorithms are designed to identify and optimize the modularity of a graph by partitioning it into communities of closely-related nodes. The algorithms aim to maximize the modularity score, which measures the quality of the partitioning.",['d39abd5380fb3fe0468ea1e122512091'],47d2036509bf408095ab440bd052ac24,271,4,1,5
COMMUNITY DETECTION ALGORITHMS,ENTITY GRAPH,1.0,Community Detection Algorithms are applied to the entity graph to partition it into communities of closely-related entities,['6dace8e490674ac8e031aed987a63789'],c20e6b1418a140389c31c7b71a6eba0c,272,4,6,10
COMMUNITY DETECTION ALGORITHMS,LEIDEN ALGORITHM,1.0,The Leiden Algorithm is a type of Community Detection Algorithm that is specifically used in the text for its ability to efficiently recover the hierarchical community structure of large-scale graphs,['a660289d2bf43f25d3524d35cd2d9a96'],ad96e5294247465a9c7d5ea8161dc305,273,4,3,7
LOUVAIN,LEIDEN,1.0,"Louvain is related to Leiden because Leiden is an extension of the Louvain algorithm for community detection. It builds upon the Louvain algorithm by adding a refinement step that allows for the detection of smaller communities, improving the resolution and stability of the partitioning.",['d39abd5380fb3fe0468ea1e122512091'],25c968bf5a4f48369fded6c260f71540,274,1,1,2
QUERY-FOCUSED SUMMARIZATION,MAP-REDUCE APPROACH,1.0,"Query-focused summarization is related to the map-reduce approach because the map-reduce approach can be used to implement query-focused summarization on large datasets. The map step involves using each community summary to answer the query independently and in parallel, while the reduce step summarizes all relevant partial answers into a final global answer.",['d39abd5380fb3fe0468ea1e122512091'],269b441634a144219f539202309bc9fb,275,1,1,2
ACTIVITY-CENTERED SENSEMAKING QUESTIONS,PODCAST TRANSCRIPTS,1.0,Activity-centered sensemaking questions are related to podcast transcripts because the questions can be derived from short descriptions of podcast transcripts to help users understand the content and context of the podcasts. The questions are intended to guide the user in making sense of the underlying data and its implications.,['d39abd5380fb3fe0468ea1e122512091'],d0baf2392635468db7f5657f89eb2024,276,2,4,6
ACTIVITY-CENTERED SENSEMAKING QUESTIONS,NEWS ARTICLES,1.0,Activity-centered sensemaking questions are related to news articles because the questions can be derived from short descriptions of news articles to help users understand the events and issues reported in the news. The questions are intended to guide the user in making sense of the underlying data and its implications.,['d39abd5380fb3fe0468ea1e122512091'],4f29bcf5377d4c9f94ff3f8ca2f8d941,277,2,5,7
PODCAST TRANSCRIPTS,DATASET,1.0,The dataset is related to podcast transcripts as they are a specific type of data within the dataset. Podcast transcripts are used for understanding tech leaders' views on policy and regulation.,['aed2ea39de8a027cc818c7f4557f0514'],e7072a582d9b4c1ea8b171ee940d4d6e,278,4,3,7
PODCAST TRANSCRIPTS,TECH JOURNALIST,1.0,"A tech journalist is related to podcast transcripts as they use these transcripts to find insights and trends in the tech industry, specifically focusing on tech leaders' views on policy and regulation.",['aed2ea39de8a027cc818c7f4557f0514'],cb6fcf84e3d04ef59b01f97ac94823a1,279,4,1,5
PODCAST TRANSCRIPTS,NEWS ARTICLES,1.0,"Both Podcast Transcripts and News Articles are datasets selected for evaluation in the one million token range, representative of the kind of corpora that users may encounter in their real-world activities",['5d04129d46662571f635a4e63cb4d6b7'],97a21db5f5954e2c8868b298a3f0090e,280,4,5,9
NEWS ARTICLES,DATASET,1.0,The dataset is related to news articles as they are a specific type of data within the dataset. News articles are used for teaching about health and wellness.,['aed2ea39de8a027cc818c7f4557f0514'],c8f3e6cadcf34c8fafe8987e4a9b66f8,281,5,3,8
NEWS ARTICLES,EDUCATOR,2.0,"The educator, a pivotal figure in the academic landscape, leverages news articles as a valuable resource to enrich the learning experience. By integrating current affairs into the curricula, particularly focusing on health and wellness, educators ensure that students are not only well-informed about contemporary issues but also develop a deeper understanding of various topics. News articles serve as a bridge between the classroom and the real world, enabling educators to provide relevant and up-to-date information that enhances the educational process. This approach not only broadens students' knowledge but also fosters critical thinking and awareness of global events.",['5a5a94f85dfc4d119ebb87f3037fd1cc' 'aed2ea39de8a027cc818c7f4557f0514'],26c9c44e5059429bb8abc3308bc6c814,282,5,2,7
NEWS ARTICLES,CURRENT POLICIES,1.0,"News articles often discuss current policies and their implications, providing insights into how policies are perceived and how they might evolve",['5a5a94f85dfc4d119ebb87f3037fd1cc'],7cea9903153f43b895c0b23d25bc90a3,283,5,1,6
DIVERSE ACTIVITY-CENTERED SENSE-MAKING QUESTIONS,REAL-WORLD DATASETS,1.0,"Diverse activity-centered sense-making questions are generated from real-world datasets, which include podcast transcripts and news articles. These datasets provide the context and content necessary for developing questions that aim to be comprehensive, diverse, and empowering.",['d2399fd0aae5bd200639806ca87184f8'],b54436ccc23745c88d24edcc3fdd8ed1,284,1,2,3
REAL-WORLD DATASETS,"COMPREHENSIVENESS, DIVERSITY, EMPOWERMENT",1.0,"Real-world datasets are used to create sense-making questions that aim to be comprehensive, diverse, and empowering. The datasets serve as the foundation for developing questions that foster understanding of broad issues and themes.",['d2399fd0aae5bd200639806ca87184f8'],977c895bb98d4136a76e8749533154b6,285,2,2,4
"COMPREHENSIVENESS, DIVERSITY, EMPOWERMENT",HIERARCHICAL LEVEL OF COMMUNITY SUMMARIES,1.0,"The target qualities of comprehensiveness, diversity, and empowerment are assessed by exploring the impact of varying the hierarchical level of community summaries used to answer queries. This relationship helps in evaluating the effectiveness of different summarization techniques in meeting these criteria.",['d2399fd0aae5bd200639806ca87184f8'],8d75cfea884248aba1f372de5e1b82a9,286,2,3,5
HIERARCHICAL LEVEL OF COMMUNITY SUMMARIES,NAIVE RAG,1.0,The hierarchical level of community summaries is compared to naive RAG to evaluate its performance in terms of comprehensiveness and diversity. This comparison helps in understanding the advantages and limitations of each approach in summarization tasks.,['d2399fd0aae5bd200639806ca87184f8'],90f4ee186bcd4996ad8002888569fffc,287,3,3,6
HIERARCHICAL LEVEL OF COMMUNITY SUMMARIES,GLOBAL MAP-REDUCE SUMMARIZATION,1.0,The hierarchical level of community summaries is compared to global map-reduce summarization to assess its effectiveness in providing comprehensive and diverse insights. This comparison is crucial for determining the best summarization technique based on the target qualities.,['d2399fd0aae5bd200639806ca87184f8'],4bb78401581b4240b0967309e96af00b,288,3,1,4
NAIVE RAG,MAP-REDUCE SUMMARIZATION,1.0,"Naive RAG and Map-Reduce Summarization are related in the context of summarization and question answering, as both are methods used to process and generate responses from source texts. However, Naive RAG is noted for its directness and simplicity, whereas Map-Reduce Summarization is more resource-intensive.",['71f14506a6b15dfabd93fd1606a67b73'],a18dd9ea4143411cb32e261db056cf0c,289,3,2,5
NAIVE RAG,ADVANCED RAG,1.0,"Advanced RAG builds upon the foundational principles of Naive RAG, addressing its limitations by incorporating more sophisticated retrieval and generation strategies, leading to improved information retrieval and context augmentation",['38feec52b8bfbd3fd8e03635acdaec97'],cd8d9795f540413390927ea2a9e77c26,290,3,4,7
TEXT CHUNKS,SOURCE DOCUMENTS,1.0,Source Documents are split into Text Chunks for processing by LLM prompts. The granularity of this split affects the efficiency and effectiveness of information extraction,['e7caf4256ddea71533af1c4c50444146'],2917f3b478b04ffcacd4b47602f4d0f5,291,7,1,8
TEXT CHUNKS,LLM PROMPTS,1.0,Text Chunks are processed by LLM Prompts to extract graph index elements. The size of the text chunks impacts the number of LLM calls and the recall of the extraction process,['e7caf4256ddea71533af1c4c50444146'],3984bd063b384901862e68506c77cc68,292,7,2,9
TEXT CHUNKS,ENTITY REFERENCES,1.0,"The number of Entity References extracted is influenced by the size of the Text Chunks. Smaller chunks tend to extract more references, but the process needs to balance recall and precision",['e7caf4256ddea71533af1c4c50444146'],4137a2c7dd884bc2a8469b7fa937346c,293,7,1,8
TEXT CHUNKS,GRAPH NODES,1.0,Text Chunks are the source from which Graph Nodes are identified and extracted. The relationship indicates that the processing of text chunks leads to the identification of entities represented as graph nodes.,['e50740c4332fdedb8739773592e2a402'],60b6bf585ccc477d830d4b69b8c7b62a,294,7,2,9
TEXT CHUNKS,GRAPH EDGES,1.0,"Text Chunks are the source from which Graph Edges are identified and extracted. The relationship indicates that the processing of text chunks leads to the identification of relationships between entities, represented as graph edges.",['e50740c4332fdedb8739773592e2a402'],4330f73cb78a4bb39a384eb29112201b,295,7,1,8
TEXT CHUNKS,LLM PROMPT,1.0,The LLM Prompt is used to process Text Chunks for the identification of entities and relationships. The relationship indicates that the prompt guides the extraction of information from text chunks.,['e50740c4332fdedb8739773592e2a402'],45c4ed77967746e485ec9e52c0dcc0d2,296,7,4,11
LLM PROMPTS,GRAPH INDEX,1.0,LLM Prompts are used to construct the Graph Index by identifying and extracting instances of graph nodes and edges from the Text Chunks,['e7caf4256ddea71533af1c4c50444146'],17c2cc25d00347c3bf2422d4f7a4ad7e,297,2,10,12
GRAPH INDEX,PODCAST DATASET,1.0,"The Graph Index was created using a context window size of 600 tokens with 1 gleaning for the Podcast dataset, indicating that the Podcast dataset was used in the indexing process.",['53455f8552b0787cb13c5a03eb550842'],0057fb2ddc0e4088ae5099b7ffa137da,298,10,4,14
GRAPH INDEX,NEWS DATASET,1.0,"The Graph Index was created using a context window size of 600 tokens with 0 gleanings for the News dataset, indicating that the News dataset was used in the indexing process.",['53455f8552b0787cb13c5a03eb550842'],d67d67cc3698438db76eb4a7f75e1ea0,299,10,4,14
GRAPH INDEX,GLOBAL SUMMARIZATION,1.0,"The decision to invest in building a graph index depends on multiple factors, including the performance of global summarization of source texts, which can be competitive in many cases",['7040ba36a7c09899a355d14a30d65375'],c23761290af24cf29adc1ee8644bdad0,300,10,2,12
GRAPH INDEX,COMPUTE BUDGET,1.0,"The decision to invest in building a graph index depends on the compute budget, as it can influence the feasibility of creating and maintaining the index",['7040ba36a7c09899a355d14a30d65375'],de51b828ce1f442bbb19a7b20bce9dda,301,10,2,12
GRAPH INDEX,LIFETIME QUERIES,1.0,"The decision to invest in building a graph index depends on the expected number of lifetime queries per dataset, as it can affect the value obtained from the index",['7040ba36a7c09899a355d14a30d65375'],4a3ff6a3471945fd8c7fd5c171c56d56,302,10,2,12
GRAPH INDEX,GRAPH-RELATED RAG APPROACHES,1.0,"The decision to invest in building a graph index depends on the value obtained from other aspects of the graph index, including the use of other graph-related RAG approaches",['7040ba36a7c09899a355d14a30d65375'],31bb84eb2a834dabacc0ed51af4fcefd,303,10,2,12
GRAPH INDEX,FUTURE WORK,1.0,"Future work includes the possibility of refining and adapting the current Graph RAG approach, which can involve the graph index",['7040ba36a7c09899a355d14a30d65375'],5070012e83e7442381bcba1cdacdb7d8,304,10,7,17
GRAPH NODES,COVARIATE PROMPT,1.0,The Covariate Prompt is used to associate additional attributes with Graph Nodes. The relationship indicates that the prompt helps in enriching the information associated with the nodes extracted from the text.,['e50740c4332fdedb8739773592e2a402'],5eda9074df124f5497f17b61badd52ac,305,2,1,3
LLM PROMPT,FEW-SHOT EXAMPLES,1.0,"The LLM Prompt utilizes Few-Shot Examples for in-context learning, enhancing its ability to identify entities and relationships specific to the domain of the document corpus.",['e50740c4332fdedb8739773592e2a402'],4cf4107b0e2842778aaa658a1a85f3b3,306,4,2,6
LLM PROMPT,NAMED ENTITIES,1.0,The LLM Prompt is used to identify Named Entities within the text chunks. The relationship indicates that the prompt facilitates the extraction of named entities from the text.,['e50740c4332fdedb8739773592e2a402'],7f4857f94b4e4e49be7236a42071e167,307,4,1,5
LLM PROMPT,SPECIALIZED KNOWLEDGE,1.0,The LLM Prompt can be tailored to incorporate Specialized Knowledge by using domain-specific few-shot examples. The relationship indicates that the prompt can be adapted to better handle specialized knowledge.,['e50740c4332fdedb8739773592e2a402'],d21a1fef903f4a399bd3cd366aad3c9e,308,4,1,5
ELEMENT SUMMARIES,LLM (LARGE LANGUAGE MODEL),1.0,"The LLM generates Element Summaries by processing Element Instances, creating condensed representations of information for each graph element, such as entity nodes, relationship edges, and claim covariates",['a73d3e7b661743b7583d8a0fd412b6a7'],fc596a598ff74a4c843e405b597551b5,309,3,1,4
ELEMENT SUMMARIES,ELEMENT INSTANCES,1.0,"Element Summaries are derived from Element Instances, as the LLM processes these instances to create condensed representations of information for each graph element",['a73d3e7b661743b7583d8a0fd412b6a7'],e2aacff6b4404574b818e7a3ece57b5b,310,3,1,4
ENTITY GRAPH,CONNECTIVITY,1.0,"Connectivity is essential for the resilience of the entity graph approach to variations in entity names, ensuring that all variations are connected to a shared set of closely-related entities",['6dace8e490674ac8e031aed987a63789'],2ec5cae98c7a485881f0680fbca6d67f,311,6,1,7
ENTITY GRAPH,RICH DESCRIPTIVE TEXT,1.0,"Rich Descriptive Text is used in the entity graph to provide detailed information about homogeneous nodes, aligning with the capabilities of LLMs",['6dace8e490674ac8e031aed987a63789'],c87b815d61af448596d3194a804b57b3,312,6,1,7
ENTITY GRAPH,KNOWLEDGE GRAPHS,1.0,"The entity graph is differentiated from typical knowledge graphs by its use of rich descriptive text and its focus on global, query-focused summarization",['6dace8e490674ac8e031aed987a63789'],2f92fc82c3b74417896bad3bd8e61f5e,313,6,1,7
ENTITY GRAPH,LEIDEN ALGORITHM,1.0,"The Leiden Algorithm is used in the entity graph pipeline for community detection, due to its efficiency in handling large-scale graphs",['6dace8e490674ac8e031aed987a63789'],fb61c68efe5b4d69a9623e531e7c639c,314,6,3,9
LEIDEN ALGORITHM,GRAPHCOMMUNITIES,1.0,The Leiden Algorithm is used to generate GraphCommunities by partitioning the graph into communities of nodes with stronger connections to one another than to the other nodes in the graph,['a660289d2bf43f25d3524d35cd2d9a96'],dc61e34c1ca8419e923aeeff7d83d949,315,3,2,5
CHUNKS OF PRE-SPECIFIED TOKEN SIZE,INTERMEDIATE ANSWERS,1.0,Chunks of pre-specified token size are related to intermediate answers as they are the input for generating these answers. The process ensures that each chunk is analyzed independently to produce relevant intermediate answers.,['aed2ea39de8a027cc818c7f4557f0514'],697fb824eef34759852f1d5588921aec,316,1,2,3
INTERMEDIATE ANSWERS,GLOBAL ANSWER,1.0,Intermediate answers are related to the global answer as they are sorted and combined to create the final context used for generating the global answer. The helpfulness score of each intermediate answer determines its inclusion in the global answer.,['aed2ea39de8a027cc818c7f4557f0514'],b872fcc5b18a4f32b976f4693f22e88e,317,2,1,3
DATASET,RUN_PIPELINE,1.0,run_pipeline function takes the dataset as input and processes it according to the workflows specified,['f3a07680cbe8ab1f6055369da05f4f38'],64be9b98299f4d349e0f4358685ca235,318,3,3,6
EDUCATOR,HEALTH LITERACY,1.0,"Educators can use health articles and current affairs to highlight the importance of health literacy, teaching students how to understand and use health information effectively",['5a5a94f85dfc4d119ebb87f3037fd1cc'],8302a03f6ede471bb955c0bbf44a4b3c,319,2,1,3
PRIVACY LAWS,TECHNOLOGY DEVELOPMENT,1.0,Privacy laws can impact technology development by setting restrictions on data usage and influencing the design and implementation of products and services,['5a5a94f85dfc4d119ebb87f3037fd1cc'],a02263dd89964a1c8ab2d0e9aba0f4eb,320,1,2,3
TECHNOLOGY DEVELOPMENT,ETHICAL CONSIDERATIONS,1.0,"Technology development is influenced by ethical considerations, which ensure that innovations are developed and used responsibly, considering the impact on individuals and society",['5a5a94f85dfc4d119ebb87f3037fd1cc'],6b7aa6ce4cac4edbaaab831286e67e5e,321,2,1,3
COLLABORATIONS,TECH COMPANIES,1.0,"Collaborations between tech companies and governments can lead to the development of new technologies, policies, or solutions that benefit society",['5a5a94f85dfc4d119ebb87f3037fd1cc'],655d40ea08e348ad94ae49785797da90,322,1,1,2
HEALTH EDUCATION CURRICULA,PREVENTIVE MEDICINE,1.0,"Health education curricula can include topics on preventive medicine, teaching students about practices that prevent diseases and promote health",['5a5a94f85dfc4d119ebb87f3037fd1cc'],254cea99330f4f2aa062c771146da7ea,323,1,1,2
HEALTH ARTICLES,PUBLIC HEALTH PRIORITIES,1.0,Health articles can provide insights into public health priorities based on the topics they cover and the emphasis they place on certain health issues,['5a5a94f85dfc4d119ebb87f3037fd1cc'],a2836232227c4e3383d166db860cb2a3,324,1,1,2
HOTPOTQA,MULTIHOP-RAG,1.0,"HotPotQA, MultiHop-RAG, and MT-Bench are all benchmark datasets for open-domain question answering, with a focus on explicit fact retrieval rather than summarization for data sensemaking",['5d04129d46662571f635a4e63cb4d6b7'],8a9247ee9bac45bdbf69c9d0bb8419b5,325,2,2,4
HOTPOTQA,DATA SENSEMAKING,1.0,"HotPotQA, as a benchmark dataset for open-domain question answering, does not target data sensemaking as its questions focus on explicit fact retrieval rather than summarization for understanding data",['8e69f04648f5fc24c299591365f1aa68'],757a0f78fcdd4bf6b8326a75fcee9e15,326,2,4,6
MULTIHOP-RAG,DATA SENSEMAKING,1.0,"MultiHop-RAG, as a benchmark dataset for open-domain question answering, does not target data sensemaking as its questions focus on explicit fact retrieval rather than summarization for understanding data",['8e69f04648f5fc24c299591365f1aa68'],b5235cb24b8f440389f250ebd5b6e2f8,327,2,4,6
MT-BENCH,DATA SENSEMAKING,1.0,"MT-Bench, as a benchmark dataset for open-domain question answering, does not target data sensemaking as its questions focus on explicit fact retrieval rather than summarization for understanding data",['8e69f04648f5fc24c299591365f1aa68'],bdee1849252749efa2e671ed87641f61,328,1,4,5
DATA SENSEMAKING,SUMMARIZATION QUERIES,1.0,"Summarization queries are essential for data sensemaking as they aim to extract a high-level understanding of dataset contents, facilitating the process of inspecting, engaging with, and contextualizing data within real-world activities",['8e69f04648f5fc24c299591365f1aa68'],057641c1476247958d8c357e17095d8e,329,4,3,7
SUMMARIZATION QUERIES,RAG (RETRIEVAL-AUGMENTED GENERATION) SYSTEMS,1.0,"RAG systems are evaluated using summarization queries to assess their effectiveness in global sensemaking tasks, where a high-level understanding of dataset contents is required rather than details of specific texts",['8e69f04648f5fc24c299591365f1aa68'],b61dfd0b24664f37af4046bdf0cb7b19,330,3,1,4
EVALUATION DATASETS,GRAPH RAG (RETRIEVAL-AUGMENTED GENERATION),1.0,Graph RAG uses summaries from different levels of graph communities to answer queries in the Evaluation Datasets,['a739018eb63cbb6c26b779bd37afc233'],0bc00f14e6194df7b0fe9ef9ba28d34f,331,4,1,5
EVALUATION DATASETS,TEXT SUMMARIZATION METHOD,1.0,The Text Summarization Method is applied to the Evaluation Datasets to generate summaries for comparison,['a739018eb63cbb6c26b779bd37afc233'],b823c5d22037423da919eee6c35c4c8b,332,4,1,5
EVALUATION DATASETS,NAIVE SEMANTIC SEARCH RAG APPROACH,1.0,The Naive Semantic Search RAG Approach is used on the Evaluation Datasets as a baseline for comparison,['a739018eb63cbb6c26b779bd37afc233'],cd7f555e4ab948ba94bade14e262ff84,333,4,1,5
C1,C2,1.0,"C1 communities are higher-level summaries that can be projected down to form C2 communities, which are sub-communities of C1 if C1 is present. This relationship indicates a hierarchical structure in the community summaries.",['88847c4d3e6c5a64a5b44d9d99d06237'],86cd53087b2542f898d6cecca31e6145,334,2,2,4
C1,C0,1.0,"C0 communities can be projected down to form C1 communities if C0 is present. This relationship indicates a hierarchical structure in the community summaries, with C1 being a sub-community of C0.",['88847c4d3e6c5a64a5b44d9d99d06237'],5dc3480806b04fdd8089a3be46e22540,335,2,1,3
C2,C3,1.0,"C2 communities are higher-level summaries that can be projected down to form C3 communities, which are sub-communities of C2 if C2 is present. This relationship indicates a hierarchical structure in the community summaries.",['88847c4d3e6c5a64a5b44d9d99d06237'],50c91820a91f488d8606198540aba894,336,2,1,3
PODCAST DATASET,NEWS DATASET,2.0,"The Podcast Dataset and the News Dataset are integral components in the domain of language model evaluation and natural language processing research. These datasets serve dual purposes, contributing to the assessment of language models' performance under different context window sizes and facilitating experiments in summarization and question answering. The News Dataset, larger in scale with a higher density of nodes and edges in the graph generated through indexing, complements the Podcast Dataset in size and scope. Both datasets are pivotal in gauging the effectiveness of summarization methods, where certain levels of community summaries have demonstrated remarkable outcomes in terms of comprehensiveness and diversity. Through their utilization in various research contexts, these datasets offer valuable insights into the capabilities and limitations of language models and summarization techniques.",['3900d15a5f3ace358fc06038c34cdf79' '71f14506a6b15dfabd93fd1606a67b73'],a38eace89e7e40de8f007fde24597e9e,337,4,4,8
PODCAST DATASET,WINDOWSIZE,1.0,"The windowsize of 8k tokens is used in the indexing process for the Podcast Dataset, affecting the resulting graph's structure and size",['d08fc91bbfe9749abab38a99a1a88dc6'],5d75097d065e4b049a1678deab40949b,338,4,2,6
NEWS DATASET,WINDOWSIZE,1.0,"The windowsize of 8k tokens is used in the indexing process for the News Dataset, affecting the resulting graph's structure and size",['d08fc91bbfe9749abab38a99a1a88dc6'],c277134d380a42cd886a14a953554792,339,4,2,6
"WANG ET AL., 2023A","LLM AS-A-JUDGE, ZHENG ET AL., 2024",1.0,"Wang et al., 2023a, and LLM as-a-judge, Zheng et al., 2024, are related through their contributions to the field of LLMs, particularly in the context of head-to-head comparisons of competing outputs",['cbfd4a09b266218f64dc6e6d80f8a77e'],b680be879404440885b1d3af5b9af583,340,1,1,2
"RAGAS, ES ET AL., 2023",GRAPH RAG MECHANISM,1.0,"RAGAS, Es et al., 2023, and the Graph RAG mechanism are related in the context of evaluating RAG systems, where the Graph RAG mechanism is a multi-stage method that could potentially be assessed using the evaluation criteria discussed in RAGAS, Es et al., 2023",['cbfd4a09b266218f64dc6e6d80f8a77e'],4cc609b1a64a442aac6b72078a315ac6,341,1,1,2
HEAD-TO-HEAD COMPARISON APPROACH,LLM EVALUATOR,1.0,"The head-to-head comparison approach is related to the LLM evaluator, as the LLM evaluator is used as a tool to implement the head-to-head comparison approach in evaluating different methods or outputs",['cbfd4a09b266218f64dc6e6d80f8a77e'],a3ee323c9c9a4f81b5907030122b80d2,342,1,6,7
LLM EVALUATOR,COMPREHENSIVENESS,1.0,The LLM Evaluator uses Comprehensiveness as one of the metrics to assess the quality of answers. It evaluates how well the answers cover all aspects and details of the question.,['2a5e1212b351d63d059ba1a1dec2811f'],19aa5f0b738c4f4a96668c80c3e93331,343,6,3,9
LLM EVALUATOR,DIVERSITY,1.0,The LLM Evaluator uses Diversity as one of the metrics to assess the quality of answers. It evaluates how varied and rich the answers are in providing different perspectives and insights on the question.,['2a5e1212b351d63d059ba1a1dec2811f'],f8402b10349f4db888ac4fb6fd81723a,344,6,3,9
LLM EVALUATOR,EMPOWERMENT,1.0,The LLM Evaluator uses Empowerment as one of the metrics to assess the quality of answers. It evaluates how well the answers help the reader understand and make informed judgements about the topic.,['2a5e1212b351d63d059ba1a1dec2811f'],5927f9089289429da4adf2bbd5641e44,345,6,3,9
LLM EVALUATOR,DIRECTNESS,1.0,The LLM Evaluator uses Directness as one of the metrics to assess the quality of answers. It evaluates how specifically and clearly the answers address the question.,['2a5e1212b351d63d059ba1a1dec2811f'],60724b8b268044b69a4b3d939f1757e2,346,6,2,8
LLM EVALUATOR,TABLE 2,1.0,"Table 2 is an output of the LLM Evaluator, showing an example of the assessment generated by the tool based on the metrics and conditions evaluated.",['2a5e1212b351d63d059ba1a1dec2811f'],d931685d35e149909472f736114ca62f,347,6,1,7
TARGET METRICS,CONTROL METRIC (DIRECTNESS),1.0,"The target metrics are related to the control metric (directness) in the context of evaluation, as the control metric serves as a baseline for assessing the validity of the target metrics in evaluating the performance of methods or outputs",['cbfd4a09b266218f64dc6e6d80f8a77e'],3f5e9927a4114a958d75f5ed313526a8,348,1,1,2
COMPREHENSIVENESS,OPTIMUM CONTEXT SIZE,1.0,"The optimum context size (8k) was found to have the best performance on the comprehensiveness metric, with an average win rate of 58.1%. This indicates that the 8k context window size provides the most comprehensive answers or responses among the tested sizes.",['3900d15a5f3ace358fc06038c34cdf79'],4728bf0cb7564bbd85c90ceaa846f290,349,3,4,7
COMPREHENSIVENESS,GLOBAL APPROACHES,1.0,Global Approaches achieved higher comprehensiveness win rates for both Podcast transcripts and News articles,['d08fc91bbfe9749abab38a99a1a88dc6'],cdac6338c3234797a0d3a32cd68d1b2e,350,3,3,6
DIVERSITY,OPTIMUM CONTEXT SIZE,1.0,"The optimum context size (8k) was found to have comparable performance on the diversity metric, with an average win rate of 52.4%. This indicates that the 8k context window size provides answers or responses with a range and uniqueness similar to those generated with larger context sizes.",['3900d15a5f3ace358fc06038c34cdf79'],372f78df13f9452b84d898c703a1ba95,351,3,4,7
DIVERSITY,GLOBAL APPROACHES,1.0,Global Approaches achieved higher diversity win rates for both Podcast transcripts and News articles,['d08fc91bbfe9749abab38a99a1a88dc6'],7af06d2b32a941a4b044579a7c423371,352,3,3,6
EMPOWERMENT,OPTIMUM CONTEXT SIZE,1.0,"The optimum context size (8k) was found to have comparable performance on the empowerment metric, with an average win rate of 51.3%. This indicates that the 8k context window size provides answers or responses that are as empowering as those generated with larger context sizes.",['3900d15a5f3ace358fc06038c34cdf79'],a10b8fad74744ae981747dadf7234b78,353,3,4,7
DIRECTNESS,NAIVE RAG (SS) APPROACH,1.0,"The Naive RAG (SS) Approach produced the most direct responses across all comparisons, as measured by the directness validity test",['d08fc91bbfe9749abab38a99a1a88dc6'],0cb2118ecc87439a91409deef7ef9830,354,2,2,4
COMPARISON METHOD,STOCHASTICITY,1.0,The Comparison Method accounts for the stochasticity of LLMs by running each comparison five times and using mean scores to determine the outcome.,['2a5e1212b351d63d059ba1a1dec2811f'],ea27218042d640fd81c23eb64aff6b46,355,2,1,3
COMPARISON METHOD,FIGURE 4,1.0,"Figure 4 visualizes the results of the head-to-head comparisons conducted using the Comparison Method, showing the win rate percentages across different conditions and metrics.",['2a5e1212b351d63d059ba1a1dec2811f'],9e5d626681094933abf87cf797f2fa46,356,2,1,3
HEADWINRATEPERCENTAGES,GRAPHRAGCONDITIONS,1.0,"The headwin rate percentages are related to the performance of GraphRAG conditions, as they measure the success rates of these conditions across datasets, metrics, and questions. GraphRAG conditions outperformed naive RAG on comprehensiveness and diversity.",['b83d819b03401fb8332316960610e5d6'],545358ff14f84601a22e9f39f5ef1534,357,1,2,3
GRAPHRAGCONDITIONS,CONTEXTWINDOWSIZE,1.0,"The GraphRAG conditions are related to the context window size, as varying the context window size can affect the performance of GraphRAG conditions. The optimum context size for the baseline condition (SS) was determined and then used for all query-time LLM use, which can impact the performance of GraphRAG conditions.",['b83d819b03401fb8332316960610e5d6'],1b0e7dbc7c5944a7833f6540bde1fa4f,358,2,1,3
VARYING CONTEXT WINDOW SIZE,OPTIMUM CONTEXT SIZE,1.0,"The relationship between varying the context window size and determining the optimum context size is that the optimum context size was found through testing different context window sizes (8k, 16k, 32k, 64k) and evaluating their performance on comprehensiveness, diversity, and empowerment metrics. The smallest context window size (8k) was found to be universally better for comprehensiveness and comparable for diversity and empowerment, leading to its selection as the optimum context size.",['3900d15a5f3ace358fc06038c34cdf79'],0c0f2d8c623949f1ae89c67d0753aeab,359,1,4,5
GLOBAL APPROACHES,NAIVE RAG (SS) APPROACH,1.0,Global Approaches outperformed the Naive RAG (SS) Approach in terms of comprehensiveness and diversity metrics across datasets,['d08fc91bbfe9749abab38a99a1a88dc6'],20c3844c80a140ac97b62dc444feee41,360,3,2,5
INFORMED UNDERSTANDING,TUNING ELEMENT EXTRACTION PROMPTS,1.0,"Tuning Element Extraction Prompts can contribute to a higher level of Informed Understanding by ensuring that more detailed information is retained in the Graph RAG index, thus providing a richer context for comprehension",['38feec52b8bfbd3fd8e03635acdaec97'],c5fac1bea509464d9dc934275d938039,361,1,1,2
GRAPH RAG INDEX,RAG APPROACHES,1.0,"RAG Approaches, including Naive RAG and Advanced RAG, are integral to the functionality of the Graph RAG Index, as they determine how information is retrieved and integrated into the index to support informed understanding",['38feec52b8bfbd3fd8e03635acdaec97'],45b64fbddd8f4abdb86a9c3c6f53f802,362,1,1,2
ADVANCED RAG,CAUSAL GRAPH EXTRACTION,1.0,"Causal Graph Extraction and Advanced RAG are both research studies that involve the use of LLMs in the context of advanced information retrieval and analysis, suggesting a shared interest in graph-based techniques.",['40f2d6a0270e54743e7ace239369da96'],0e504b58cbda4d9188050bc43004c01f,363,4,2,6
ADVANCED RAG,KAPING,1.0,"Advanced RAG and KAPING are both research studies that involve the use of knowledge graphs as an index for advanced retrieval and analysis of information, indicating a connection in their research focus and methodology.",['40f2d6a0270e54743e7ace239369da96'],c06bd37e120e4af49ec8bd6ce399473b,364,4,2,6
ADVANCED RAG,LLMS FOR CAUSAL GRAPH EXTRACTION,1.0,"LLMs for causal graph extraction and Advanced RAG are related as they both involve the use of LLMs for extracting information from text, with causal graph extraction focusing on causal relationships and Advanced RAG focusing on retrieval-augmented generation",['7383c69e93bb8c8648181f5355d2c9a7'],5d507985f2f540d8a1fa2d1191eae2a8,365,4,1,5
LLM’S CONTEXT WINDOW,ADVANCED RAG SYSTEMS,1.0,"Advanced RAG systems are designed to overcome the limitations of LLM’s context window by incorporating pre-retrieval, retrieval, and post-retrieval strategies. This relationship indicates that Advanced RAG systems are an evolution of LLM’s context window, addressing its drawbacks and enhancing its capabilities.",['7da3d8d244b67f09425a4a7783e4bb55'],8e0b5b4011d74bbb8dc09fa05d88369c,366,1,2,3
ADVANCED RAG SYSTEMS,MODULAR RAG SYSTEMS,1.0,"Modular RAG systems are a type of Advanced RAG systems that include patterns for iterative and dynamic cycles of interleaved retrieval and generation. This relationship indicates that Modular RAG systems are a specific implementation of Advanced RAG systems, focusing on modularity and flexibility.",['7da3d8d244b67f09425a4a7783e4bb55'],5d8184f5d52040d8bb67d1a6b889e9fe,367,2,1,3
CAIRE-COVID,ITRG,1.0,"Both CAiRE-COVID and ITRG are research studies that involve the use of LLMs and RAG, but CAiRE-COVID focuses on the impact of COVID-19, while ITRG deals with multi-hop question answering.",['40f2d6a0270e54743e7ace239369da96'],b3bf669489ae4913bb60ddfe50e41697,368,1,2,3
ITRG,IR-COT,1.0,"ITRG and IR-CoT are both research studies that deal with multi-hop question answering, indicating a connection in their research focus and methodology.",['40f2d6a0270e54743e7ace239369da96'],0eba9d55a3ff46298665a0c292e2237f,369,2,2,4
IR-COT,DSP,1.0,"IR-CoT and DSP are both research studies that deal with multi-hop question answering, suggesting a shared interest in advanced question answering techniques.",['40f2d6a0270e54743e7ace239369da96'],55e3f4a200eb4619ae2b6efb645464d1,370,2,1,3
RAPTOR,TREE OF CLARIFICATIONS,1.0,"RAPTOR and Tree of Clarifications are both research studies that involve advanced text processing techniques, with RAPTOR focusing on text embeddings and Tree of Clarifications on answering ambiguous questions.",['40f2d6a0270e54743e7ace239369da96'],c44324c171674d00a743413042e9b944,371,1,2,3
KNOWLEDGE GRAPH CREATION,KNOWLEDGE GRAPH COMPLETION,1.0,"Knowledge Graph Creation and Knowledge Graph Completion are both research studies that involve the use of LLMs in the context of knowledge graphs, suggesting a connection in their research focus and methodology.",['40f2d6a0270e54743e7ace239369da96'],4bdaba79a3274241ab98e27aeaf98f57,372,2,2,4
KNOWLEDGE GRAPH COMPLETION,CAUSAL GRAPH EXTRACTION,1.0,"Knowledge Graph Completion and Causal Graph Extraction are both research studies that involve the use of LLMs in the context of graph analysis, indicating a connection in their research focus and methodology.",['40f2d6a0270e54743e7ace239369da96'],7c8c464ed7044a7896adfeb35f58a04d,373,2,2,4
KAPING,G-RETRIEVER,1.0,"KAPING and G-Retriever are related as they both involve querying specific parts of a graph structure, with KAPING focusing on subsets of the graph and G-Retriever focusing on retrieving specific parts of the graph",['7383c69e93bb8c8648181f5355d2c9a7'],5fa2eec73bec481b85eba22ea7a2a927,374,2,1,3
LLMS FOR KNOWLEDGE GRAPH CREATION,LLMS FOR KNOWLEDGE GRAPH COMPLETION,1.0,"LLMs for knowledge graph creation and LLMs for knowledge graph completion are related as they both involve the use of LLMs in the context of knowledge graphs, with creation focusing on the initial generation and completion focusing on enhancing existing graphs",['7383c69e93bb8c8648181f5355d2c9a7'],e6aa5eedca984c56b5fa5e179127951d,375,1,1,2
GRAPHTOOLFORMER,SURGE,1.0,"GraphToolFormer and SURGE are related as they both involve the use of graph data, with GraphToolFormer focusing on derived graph metrics and SURGE focusing on generating narratives based on retrieved subgraphs",['7383c69e93bb8c8648181f5355d2c9a7'],1c4bd4ba4ef64a93acd55faa8fd97ca9,376,1,1,2
FABULA,SYSTEM FOR MULTI-HOP QUESTION ANSWERING,1.0,"FABULA and the system for multi-hop question answering are related as they both involve the use of graph data for generating narratives or answering questions, with FABULA focusing on event plots and the system for multi-hop question answering focusing on complex question answering",['7383c69e93bb8c8648181f5355d2c9a7'],5b85c70d578c4d67b5cb4743552bd559,377,1,1,2
LANGCHAIN,LLAMAINDEX,2.0,"LangChain and LlamaIndex are two sophisticated libraries that share a common purpose: they facilitate the creation and navigation of text-relationship graphs, which are essential for multi-hop question answering. These libraries are designed to be versatile, as they are compatible with a wide range of graph databases, making them valuable assets for RAG (Retrieval-Augmented Generation) applications. Both LangChain and LlamaIndex offer tools and interfaces that enable users to effectively work with graph data, enhancing the capabilities of systems that rely on graph databases for information retrieval and analysis.",['7383c69e93bb8c8648181f5355d2c9a7' 'e015335cdcae20e6546fe7cbdef56c1a'],956113fb770840c38bce65bb5832f988,378,3,3,6
LANGCHAIN,NEO4J,1.0,"LangChain supports the use of Neo4J, a graph database that can be used to create and reason over knowledge graphs",['e015335cdcae20e6546fe7cbdef56c1a'],785bb55e79954b0c84a4a53cd7f0b454,379,3,2,5
LANGCHAIN,NEBULAGRAPH,1.0,"LangChain supports the use of NebulaGraph, a graph database that can be used to create and reason over knowledge graphs",['e015335cdcae20e6546fe7cbdef56c1a'],1239281fd3774b91a99358c9c1e6ee1c,380,3,2,5
LLAMAINDEX,NEO4J,1.0,"LlamaIndex supports the use of Neo4J, a graph database that can be used to create and reason over knowledge graphs",['e015335cdcae20e6546fe7cbdef56c1a'],32b29a842b224f4c99fa1d5c764efc9a,381,3,2,5
LLAMAINDEX,NEBULAGRAPH,1.0,"LlamaIndex supports the use of NebulaGraph, a graph database that can be used to create and reason over knowledge graphs",['e015335cdcae20e6546fe7cbdef56c1a'],f5ae7dc11fd64822a3a15e7d3839031a,382,3,2,5
EVALUATION APPROACH,SELFCHECKGPT,1.0,Using SelfCheckGPT to compare fabrication rates would improve the current analysis of Graph RAG's performance,['e015335cdcae20e6546fe7cbdef56c1a'],e1e254e67719488894eaa3553112a8cf,383,2,2,4
1 MILLION TOKENS,QUESTION TYPES,1.0,Understanding how performance varies across different ranges of question types is crucial for analyzing the effectiveness of models or systems when dealing with a region of 1 million tokens,['7040ba36a7c09899a355d14a30d65375'],ebdd79169d7d41b99faf09b039a66204,384,3,4,7
1 MILLION TOKENS,DATA TYPES,1.0,Understanding how performance varies across different data types is crucial for analyzing the effectiveness of models or systems when dealing with a region of 1 million tokens,['7040ba36a7c09899a355d14a30d65375'],e036534e17b24dd2895167a20873230f,385,3,4,7
1 MILLION TOKENS,DATASET SIZES,1.0,Understanding how performance varies across different dataset sizes is crucial for analyzing the effectiveness of models or systems when dealing with a region of 1 million tokens,['7040ba36a7c09899a355d14a30d65375'],a00bc5e4be634b08b1f084b6a07abafd,386,3,4,7
QUESTION TYPES,DATA TYPES,1.0,Understanding how performance varies across different data types is crucial for analyzing the effectiveness of models or systems when dealing with various question types,['7040ba36a7c09899a355d14a30d65375'],ce8241c964724429bb361b7b53867007,387,4,4,8
QUESTION TYPES,DATASET SIZES,1.0,Understanding how performance varies across different dataset sizes is crucial for analyzing the effectiveness of models or systems when dealing with various question types,['7040ba36a7c09899a355d14a30d65375'],61cd7f168f7f44d6a23415e9497f1e65,388,4,4,8
QUESTION TYPES,END USERS,1.0,Validating sensemaking questions and target metrics with end users is crucial for understanding how performance varies across different question types,['7040ba36a7c09899a355d14a30d65375'],3be77a7b57e34c55acc1f1dfbc64ee10,389,4,3,7
DATA TYPES,DATASET SIZES,1.0,Understanding how performance varies across different dataset sizes is crucial for analyzing the effectiveness of models or systems when dealing with various data types,['7040ba36a7c09899a355d14a30d65375'],751c564f8ff6444d9d4c8de4a677e655,390,4,4,8
DATA TYPES,END USERS,1.0,Validating sensemaking questions and target metrics with end users is crucial for understanding how performance varies across different data types,['7040ba36a7c09899a355d14a30d65375'],96963c158fb64680bded290f442ff9aa,391,4,3,7
DATASET SIZES,END USERS,1.0,Validating sensemaking questions and target metrics with end users is crucial for understanding how performance varies across different dataset sizes,['7040ba36a7c09899a355d14a30d65375'],bdbfbde5dd244447a2a0674b30ae3e8f,392,4,3,7
GLOBAL SUMMARIZATION,FUTURE WORK,1.0,"Future work includes the possibility of refining and adapting the current Graph RAG approach, which can involve the global summarization technique",['7040ba36a7c09899a355d14a30d65375'],f970bfe31db74929abff6ea38e5d18e6,393,2,7,9
COMPUTE BUDGET,FUTURE WORK,1.0,"Future work includes the possibility of refining and adapting the current Graph RAG approach, which can involve the consideration of the compute budget",['7040ba36a7c09899a355d14a30d65375'],6f0c2a8b79e6406a8ab7a20864ae2ce2,394,2,7,9
LIFETIME QUERIES,FUTURE WORK,1.0,"Future work includes the possibility of refining and adapting the current Graph RAG approach, which can involve the consideration of the expected number of lifetime queries per dataset",['7040ba36a7c09899a355d14a30d65375'],7b09e60e33f44ffdab9c656c5b9c1d50,395,2,7,9
GRAPH-RELATED RAG APPROACHES,FUTURE WORK,1.0,"Future work includes the possibility of refining and adapting the current Graph RAG approach, which can involve the consideration of other graph-related RAG approaches",['7040ba36a7c09899a355d14a30d65375'],8b7beab7c0a143aea7bffc31df7528d5,396,2,7,9
ANSWER IIVENESS AND DIVERSITY,GLOBAL BUT GRAPH-FREE APPROACH,1.0,"The Answer Iiveness and Diversity can be compared to the results obtained from a Global but Graph-free Approach, which uses map-reduce source text summarization. The comparison helps to evaluate the effectiveness and efficiency of different methods in generating diverse and rich answers or solutions.",['e31d2d134cf501c93f9445914d7350f9'],d03eb34a0612420680555ab9f10d03d5,397,1,1,2
ENTITY-BASED GRAPH INDEX,ROOT-LEVEL COMMUNITIES,1.0,"The Entity-based Graph Index provides summaries of root-level communities, which are the fundamental or top-level groups within a dataset. The summaries help to improve the data index and facilitate global queries over the same dataset.",['e31d2d134cf501c93f9445914d7350f9'],b066746cdff7440c8a3591f0c098201d,398,3,1,4
ENTITY-BASED GRAPH INDEX,GLOBAL METHODS,1.0,The Entity-based Graph Index achieves competitive performance to other Global Methods at a fraction of the token cost. This indicates that the Entity-based Graph Index is a more cost-effective and efficient method for handling global queries over large datasets.,['e31d2d134cf501c93f9445914d7350f9'],1e2eded8ef7b4b458c33fbc2d36c4380,399,3,1,4
GRAPHRAG INDEXING,INDEXING PIPELINES,1.0,"GraphRAG Indexing includes Indexing Pipelines as a core component of its suite, which are responsible for the extraction and transformation of data from unstructured text into structured formats. The pipelines are configurable and can be customized to meet specific needs, making them integral to the overall functionality of GraphRAG Indexing.",['251e8d332b451d900df961cbe215bca0'],c59e3e931b0f4cf888c2eb70857ee753,400,3,6,9
GRAPHRAG INDEXING,DEFAULT CONFIGURATION MODE,1.0,"The GraphRAG Indexing system includes the Default Configuration Mode as one of its configuration options, which is designed for simplicity and ease of use for most users",['ccd2de9e2219521fbca779843c65af58'],305b80bb4df5488b8a34129daeeae0c7,401,3,2,5
GRAPHRAG INDEXING,CUSTOM CONFIGURATION MODE,1.0,"The GraphRAG Indexing system includes the Custom Configuration Mode as an advanced configuration option, which is designed for users who require deeper control over the system's configuration",['ccd2de9e2219521fbca779843c65af58'],66fa0de756da440bad8da583306410c4,402,3,3,6
INDEXING PIPELINES,ENTITY EXTRACTION,1.0,Indexing Pipelines utilize Entity Extraction as one of their functions to identify and extract meaningful entities from unstructured text. This step is essential for the subsequent analysis and transformation of data within the pipelines.,['251e8d332b451d900df961cbe215bca0'],d1e9c550a0e74c48ae81c319f26ccafc,403,6,9,15
INDEXING PIPELINES,RELATIONSHIP DETECTION,1.0,"Indexing Pipelines incorporate Relationship Detection to identify relationships between entities extracted from text. This function is crucial for understanding the context and connections within the data, enhancing the structured outputs of the pipelines.",['251e8d332b451d900df961cbe215bca0'],3730b5d759ba4fd28a54af0a02151f09,404,6,1,7
INDEXING PIPELINES,COMMUNITY DETECTION,1.0,"Indexing Pipelines use Community Detection to identify groups of related entities within the extracted data. This function aids in summarizing and reporting on the text at multiple levels of granularity, contributing to the structured data outputs of the pipelines.",['251e8d332b451d900df961cbe215bca0'],82b7f7c27e2348f880c94ffb80942de7,405,6,4,10
INDEXING PIPELINES,DATA EMBEDDING,1.0,"Indexing Pipelines employ Data Embedding to transform extracted entities and text chunks into vector representations. This process facilitates further analysis and storage of the structured data, making it an integral part of the pipelines' functionality.",['251e8d332b451d900df961cbe215bca0'],0980c4f558654466b4d691d0cb7ce16d,406,6,1,7
INDEXING PIPELINES,OUTPUT FORMATS,1.0,"Indexing Pipelines generate structured data that can be stored in various Output Formats, including JSON and Parquet. These formats, along with the option to access outputs via the Python API, provide flexibility in how the data is handled and used.",['251e8d332b451d900df961cbe215bca0'],f1e47cf5daa441649c3474c3339bb704,407,6,1,7
ENTITY EXTRACTION,FIELDS,1.0,"The Entity Extraction section contains the Fields, which are specific configuration options for entity extraction settings",['abac77a5673e907cf8d65161c2612784'],0964dcfbff934c92af8961155673ac7f,408,9,8,17
ENTITY EXTRACTION,PARALLELIZATION,1.0,"The Entity Extraction section includes the Parallelization property, specifying the parallelization settings for processing text",['abac77a5673e907cf8d65161c2612784'],51b82bcdffe04056bad1c082c3830047,409,9,5,14
ENTITY EXTRACTION,ASYNC MODE,1.0,"The Entity Extraction section includes the Async Mode property, specifying whether to process text asynchronously",['abac77a5673e907cf8d65161c2612784'],c62bb148852b49a98e2779ca23a0919d,410,9,1,10
ENTITY EXTRACTION,PROMPT,1.0,"The Entity Extraction section includes the Prompt property, specifying the prompt file to use for guiding the text analysis",['abac77a5673e907cf8d65161c2612784'],72b5a0c357c24b739084d501b9354bc1,411,9,1,10
ENTITY EXTRACTION,ENTITY TYPES,1.0,"The Entity Extraction section includes the Entity Types property, specifying the types of entities to identify",['abac77a5673e907cf8d65161c2612784'],c827b62ebf134e55a3ccf0b63f976870,412,9,1,10
ENTITY EXTRACTION,MAX GLEANINGS,1.0,"The Entity Extraction section includes the Max Gleanings property, specifying the maximum number of gleaning cycles to use",['abac77a5673e907cf8d65161c2612784'],b51ef388758845e880e736309ae791e3,413,9,1,10
ENTITY EXTRACTION,STRATEGY,1.0,"The Entity Extraction section includes the Strategy property, specifying the strategy to fully override the entity extraction process",['abac77a5673e907cf8d65161c2612784'],0a841cd4b6664423b033f22e3a80f33c,414,9,5,14
COMMUNITY DETECTION,COMMUNITY SUMMARIZATION,2.0,"Community Detection and Community Summarization are intricately linked processes within the domain of Social Network Analysis. Community Detection involves the identification of groups of related entities within a graph, which is a crucial step in understanding the structure of specialized professional networks. This process enables the pinpointing of key influencers and mapping of complex relationships, thereby facilitating the identification of collaboration opportunities and knowledge gaps in fields such as Motor Control and Drive Systems.

Community Summarization, on the other hand, relies heavily on the outcomes of Community Detection. It involves the aggregation and analysis of the characteristics of communities identified through detection, providing a concise and comprehensive overview of each group's dynamics, composition, and influence. This summarization is essential for gaining insights into the collective behavior and trends within communities, further enriching the understanding of the network's overall structure and facilitating strategic decision-making and network navigation.",['493f38f41b89e767fc23d84e1fa5ba20' '6f92ce3fcd05dd5697ded83586f7bc08'],16911c51c65b42f8a2d04c05f45b2c58,415,4,5,9
COMMUNITY DETECTION,COMMUNITY TABLES,1.0,"Community Tables are related to Community Detection as they are often used to store and organize the results of community detection algorithms, including details about the communities and their members",['6f92ce3fcd05dd5697ded83586f7bc08'],fc3f77f29574410d991a2aa333950bf6,416,4,2,6
COMMUNITY DETECTION,PHASE 3: GRAPH AUGMENTATION,1.0,"Community Detection is a subprocess of Phase 3: Graph Augmentation, aimed at understanding the community structure of the graph",['a6bcb4514cb6de67e3d74ad0ea62452d'],4f847eb72cbe48678d5634dcf93fc0e2,417,4,3,7
CONFIG FILE,TIMESTAMPED OUTPUT FOLDER,1.0,The Timestamped Output Folder is related to the Config File as the Config File may contain settings that determine the naming and location of the Timestamped Output Folder,['919cb44d9688a14bf48fa7c98163ed81'],829e64159ae04301982e88e93a2f0e49,418,4,1,5
CONFIG FILE,PROGRESS REPORTER,1.0,The Config File is related to the Progress Reporter as it may contain settings that determine the type of Progress Reporter to be used during the process,['919cb44d9688a14bf48fa7c98163ed81'],cf37d3d4bc154f65b3d79c831c587763,419,4,1,5
CONFIG FILE,TABLE OUTPUT FORMATS,1.0,The Config File is related to the Table Output Formats as it may contain settings that determine the formats in which the pipeline should emit the table output,['919cb44d9688a14bf48fa7c98163ed81'],4b4fce341d554012bc73d7886860749e,420,4,1,5
CONFIG FILE,CACHING MECHANISM,1.0,The Config File is related to the Caching Mechanism as it may contain settings that determine whether the Caching Mechanism is enabled or disabled,['919cb44d9688a14bf48fa7c98163ed81'],9f6e7a08bd814d19b45fac58928027f8,421,4,1,5
NODE,ENTITY,1.0,"Nodes contain layout information for rendered graph-views of the entities, showing how entities are embedded and clustered",['85e50a4d70697a2c4420e7a9fc82f22d'],ff9410fed5e64c04a875e040e3d182b2,422,3,6,9
NODE,COMMUNITY REPORT,1.0,"Community Reports are related to the Nodes in the graph, as they provide insights and summaries for the communities represented by the nodes",['493f38f41b89e767fc23d84e1fa5ba20'],1161272728914953b568f384d7a9f2f1,423,3,3,6
NODE,DEFAULT CONFIGURATION WORKFLOW,1.0,"Nodes are part of the Default Configuration Workflow, as they are used in the visualization and analysis of the graph created by the workflow",['493f38f41b89e767fc23d84e1fa5ba20'],f09c82eb89944ae9846df82135123b90,424,3,7,10
COL1,COL_MULTIPLIED,1.0,"The values in col1 are used as one of the inputs to calculate the values in col_multiplied, which is the result of multiplying col1 and col2",['f3a07680cbe8ab1f6055369da05f4f38'],d221b743a51d464b87de3b72b85f6b59,425,2,2,4
COL1,WORKFLOW2,1.0,"In the workflow2 process, col1 is used as an input in the derive step to process data",['76d9dcb9a27c2caea1f46bb5050851c6'],9fd31a28e1384b40a9d1658a765871cd,426,2,5,7
COL2,COL_MULTIPLIED,1.0,"The values in col2 are used as one of the inputs to calculate the values in col_multiplied, which is the result of multiplying col1 and col2",['f3a07680cbe8ab1f6055369da05f4f38'],0119f233c8394b9584e55fadcce173f0,427,2,2,4
COL2,WORKFLOW2,1.0,"In the workflow2 process, col2 is used as an input in the derive step to process data",['76d9dcb9a27c2caea1f46bb5050851c6'],5c20b469b92446dabb1b68976807be7c,428,2,5,7
RUN_PIPELINE,WORKFLOWS,1.0,run_pipeline function uses the workflows to determine how to process the dataset,['f3a07680cbe8ab1f6055369da05f4f38'],2c2392247a35456da663adfcffd12e73,429,3,2,5
RUN_PIPELINE,OUTPUTS,1.0,The results of the run_pipeline function are collected in the outputs list,['f3a07680cbe8ab1f6055369da05f4f38'],167a32ff67ce4471baa8cf019ee7c17b,430,3,2,5
WORKFLOWS,WORKFLOW NAME,1.0,"The Workflows property is related to the Workflow Name property, as the workflow name is used to define and reference specific workflows within the workflows section",['a3e5bacdf64bcaf080a04c7dd8218484'],3280fc12ef414827838e6ac7089f0618,431,2,2,4
OUTPUTS,PIPELINE_RESULT,1.0,"The last element in the outputs list, pipeline_result, represents the final result of the pipeline execution",['f3a07680cbe8ab1f6055369da05f4f38'],556fba72a0854ce4831f6cfea6fd035e,432,2,1,3
DEFAULT PROMPTS,ENTITY/RELATIONSHIP EXTRACTION,1.0,"Default Prompts include the function of Entity/Relationship Extraction, which is a fundamental step in the creation of a knowledge graph. This relationship indicates that Entity/Relationship Extraction is one of the functions provided by the Default Prompts",['bdb8f9e797229f596744d9636ab857b0'],8e2e6eeed5a04c9f80efbcfc624ced95,433,4,2,6
DEFAULT PROMPTS,ENTITY/RELATIONSHIP DESCRIPTION SUMMARIZATION,1.0,"Default Prompts include the function of Entity/Relationship Description Summarization, which provides concise summaries of entity and relationship descriptions. This relationship indicates that Entity/Relationship Description Summarization is one of the functions provided by the Default Prompts",['bdb8f9e797229f596744d9636ab857b0'],ea6d546f1caa4b4aaacdad8b8af195ec,434,4,1,5
DEFAULT PROMPTS,CLAIM EXTRACTION,1.0,"Default Prompts include the function of Claim Extraction, which identifies and extracts claims from the input data. This relationship indicates that Claim Extraction is one of the functions provided by the Default Prompts",['bdb8f9e797229f596744d9636ab857b0'],267ce44e6dae43ee94d0d375ec08ef17,435,4,6,10
ENTITY/RELATIONSHIP EXTRACTION,TOKEN-REPLACEMENTS,1.0,"Entity/Relationship Extraction utilizes Token-Replacements to process input text and generate tuples representing entities or relationships, enhancing the flexibility and specificity of the extraction process",['6a7157695d90d434b2625c3f05420916'],b37e5d15f3154ee39df016b8eac8de66,436,2,3,5
CLAIM EXTRACTION,ENTITY RESOLUTION,1.0,"Entity Resolution is related to Claim Extraction, as the resolution of entities that refer to the same real-world object or concept is used in the identification of claims or statements about entities in the text",['493f38f41b89e767fc23d84e1fa5ba20'],e13eb574e885414b80f0b66992767ef2,437,6,6,12
CLAIM EXTRACTION,GRAPH TABLES,1.0,"Claim Extraction is related to Graph Tables, as the identification of claims or statements about entities in the text is used in the creation of the graph, which is represented in the Graph Tables",['493f38f41b89e767fc23d84e1fa5ba20'],93f4140f654e41ccba908c6f6dc65f17,438,6,2,8
CLAIM EXTRACTION,TEXT UNITS,1.0,Claim Extraction is related to Text Units as the process often operates on Text Units to identify claims or assertions made in the text,['6f92ce3fcd05dd5697ded83586f7bc08'],a102d091986749ef90b45d411e707bef,439,6,3,9
CLAIM EXTRACTION,COVARIATES,1.0,"Claim Extraction results in the emission of Covariates, which are positive factual statements with an evaluated status and time-bounds.",['d44248ff7b7bfd969a7208eb3d6e2a78'],cd6ae38a5a6742899d14f4a064f42c19,440,6,3,9
ROOT,DOMAIN,1.0,"The root property specifies the path to the project directory, which contains the input data for the specified domain. The domain property is used to tailor the prompt generation to a specific subject area, which is determined by the input data located in the project directory specified by the root property.",['ce9cc3ed2e5f890d02e867ed0b0f8ff9'],fe18688bd4ef44d1a184ec6d1451a5cf,441,6,2,8
ROOT,LIMIT,1.0,"The root property specifies the path to the project directory, which contains the input data that is processed using the limit property to control the number of text units selected for template generation. The limit property determines the size of the sample used for prompt generation, which is taken from the input data located in the project directory specified by the root property.",['ce9cc3ed2e5f890d02e867ed0b0f8ff9'],0f1282bdfedb4f6e8765007a90dd2959,442,6,2,8
ROOT,LANGUAGE,1.0,"The root property specifies the path to the project directory, which contains the input data that is processed in the language specified by the language property. The language property ensures that the prompt generation is tailored to the language of the input documents, which are located in the project directory specified by the root property.",['ce9cc3ed2e5f890d02e867ed0b0f8ff9'],540af5c5d4cd41ceb29c40c5fb02e2fe,443,6,3,9
ROOT,STORAGE ACCOUNT BLOB URL,1.0,"The Root is the base for the Storage Account Blob URL, as the URL is relative to the root directory specified in the configuration",['abac77a5673e907cf8d65161c2612784'],bbf83708095f47019eaee93d6879bc77,444,6,3,9
ROOT,CLI ARGUMENTS,1.0,"The root argument is a CLI Argument that specifies the data root directory for the GraphRAG Indexer CLI, which contains the input data and environment variables.",['f239de6498e0f471bf418974c00f1e36'],245a56f01d1b48a7b4d88ed0e354155a,445,6,8,14
DOMAIN,LANGUAGE,1.0,"DOMAIN and LANGUAGE are related as specifying the domain can help in determining the appropriate language for input processing, especially if the domain is associated with a specific language or if translation is needed",['9243633f55cccd0885ba553e14fa5e3f'],d3aa564fb4eb430a8ca6813ca76bfff6,446,2,3,5
LANGUAGE,MAX_TOKENS,1.0,"The LANGUAGE option can influence the MAX_TOKENS setting, as the language used for input processing might affect the tokenization process and thus the maximum token count for prompt generation",['9243633f55cccd0885ba553e14fa5e3f'],d9b948357d96419ca135065ce1c360ef,447,3,2,5
MAX_TOKENS,MODEL,1.0,"The model and max_tokens are related because the model defines the LLM (Language Model) to be used, and the max_tokens sets the limit on the output size of that model",['647be47c939b4d72f1c0b29a2e0d2cb2'],20a79ddd91ba48e4bb7bc194c79baaf6,448,2,1,3
CHUNK_SIZE,OUTPUT,1.0,CHUNK_SIZE and OUTPUT are related as the size of chunks generated from input documents can impact the number and size of prompts saved in the output folder,['9243633f55cccd0885ba553e14fa5e3f'],b95728a0b96b405cbccafa6c12fd8722,449,1,1,2
CHUNK SIZE PARAMETER,RANDOM SELECTION METHOD,1.0,The Chunk Size Parameter influences the Random Selection Method by determining the size of text units that are randomly selected for template generation,['4f37c0e9c3c9bac4e5c1c6821eea442e'],5d6dc034d2014e8c930fde69c31b99cf,450,3,1,4
CHUNK SIZE PARAMETER,TOP SELECTION METHOD,1.0,The Chunk Size Parameter influences the Top Selection Method by determining the size of text units from which the head n units are selected for template generation,['4f37c0e9c3c9bac4e5c1c6821eea442e'],127cbb53940f4efa8e1807b4452375ba,451,3,1,4
CHUNK SIZE PARAMETER,ALL SELECTION METHOD,1.0,The Chunk Size Parameter influences the All Selection Method by determining the size of text units that are all used for template generation,['4f37c0e9c3c9bac4e5c1c6821eea442e'],f1ea6ef9539043ab887bcce22ccf9625,452,3,1,4
CUSTOM PROMPT FILE,TOKEN-REPLACEMENTS,1.0,"Token-Replacements are a key feature of the Custom Prompt File, enabling the customization of prompts through the use of placeholders that are replaced with actual values",['6a7157695d90d434b2625c3f05420916'],b50c4f053f0546029c4095b7b93aa05e,453,2,3,5
TOKEN-REPLACEMENTS,SUMMARIZE ENTITY/RELATIONSHIP DESCRIPTIONS,1.0,"Summarize Entity/Relationship Descriptions uses Token-Replacements to process a list of descriptions for an entity or relationship, facilitating the summarization of these descriptions",['6a7157695d90d434b2625c3f05420916'],0cea7f7a7fab49339cdd6fb02d0d183e,454,3,1,4
RECORD_DELIMITER,TUPLE_DELIMITER,1.0,"The record_delimiter is used to separate tuple instances, and the tuple_delimiter is used to separate values within a tuple. These delimiters work together to structure and organize data in a clear and readable format",['853bfe9a74a916130a20f81506bcaf09'],5b89f0d8101c419b86e1959cca2db848,455,1,1,2
ENTITY_NAME,DESCRIPTION_LIST,1.0,"The entity_name is associated with the description_list, as the descriptions provide detailed information about the entity identified by the entity_name",['853bfe9a74a916130a20f81506bcaf09'],cdb407fc600b45caa6f94f82e89d2e4f,456,2,1,3
ENTITY_NAME,INPUT_TEXT,1.0,"The input_text contains the entity_name, which is a unique identifier for an entity within the text. The entity_name is extracted from the input_text for further processing and analysis",['853bfe9a74a916130a20f81506bcaf09'],7f4905fcb43e4d6ca23e6d2b40f6958e,457,2,1,3
CONFIGURATION DOCUMENTATION,.ENV,1.0,"The Configuration documentation provides guidance on how to properly configure the .env file, which is essential for the operation of GraphRAG.",['12294feb07a1d202b27241eaaf64718b'],f5ad4fe84df544c69db25f0e30c6eace,458,5,6,11
CONFIGURATION DOCUMENTATION,SETTINGS.YAML,1.0,"The Configuration documentation provides guidance on how to properly configure the settings.yaml file, which is essential for the operation of GraphRAG.",['12294feb07a1d202b27241eaaf64718b'],237a46cc973b41dc9af4190c71c5c9e1,459,5,6,11
CONFIGURATION DOCUMENTATION,PROMPTS/,1.0,"The Configuration documentation provides guidance on how to properly configure the prompts/ directory, including how to modify existing prompts or generate new ones through the Auto Prompt Tuning command.",['12294feb07a1d202b27241eaaf64718b'],aaa27aa0b1024e3aa3c87a6ec821a348,460,5,4,9
GRAPHRAG SYSTEM,GRAPHRAG ACCELERATOR SOLUTION,1.0,"The GraphRAG Accelerator Solution is a recommended way to get started with the GraphRAG system, providing a user-friendly end-to-end experience with Azure resources for setting up and using the system",['84d24b5db902baca7217b5e3bb6ec462'],f0a28fe3f68546dba7850815f7933275,461,4,1,5
GRAPHRAG SYSTEM,INDEXING PIPELINE OVERVIEW,1.0,"The Indexing Pipeline Overview is a component of the GraphRAG system that describes the process of indexing text data, which is a key functionality of the system",['84d24b5db902baca7217b5e3bb6ec462'],45b59feba7134bc18632cb42530c189a,462,4,1,5
GRAPHRAG SYSTEM,QUERY ENGINE OVERVIEW,1.0,"The Query Engine Overview is a component of the GraphRAG system that describes the process of querying indexed data, which is another key functionality of the system",['84d24b5db902baca7217b5e3bb6ec462'],7747cd2048f94d378e83265b9561d921,463,4,1,5
GRAPHRAG PIPELINE,SETTINGS.YAML,1.0,"The GraphRAG pipeline relies on the settings.yaml file for configuration. This file contains settings that can be modified to customize the pipeline's behavior, including the API key and additional settings for Azure OpenAI users.",['5aaa26fbe97dc7573cd1a56d6fb11213'],c4e9532dbc734264a0e3e827bc8014c6,464,4,6,10
GRAPHRAG PIPELINE,OPENAI API,1.0,"The GraphRAG pipeline can be configured to use the OpenAI API for various functionalities, such as language models and embeddings. The pipeline requires an API key for authentication, which is specified in the .env file.",['5aaa26fbe97dc7573cd1a56d6fb11213'],003e5d505a01434596c6d65ff20b0bdf,465,4,1,5
GRAPHRAG PIPELINE,AZURE OPENAI,1.0,"The GraphRAG pipeline can be configured to use Azure OpenAI for AI capabilities. Azure OpenAI users need to set specific variables in the settings.yaml file, including the API base URL, API version, and deployment name, to integrate with the pipeline.",['5aaa26fbe97dc7573cd1a56d6fb11213'],f79358f3535045d9aad3b828df59293b,466,4,6,10
AZURE OPENAI,GRAPHRAG_API_VERSION,1.0,The Azure OpenAI service requires the GRAPHRAG_API_VERSION configuration to specify the API version for compatibility and functionality. This relationship is essential for ensuring that the service requests are processed correctly.,['7b45dafa74553d3899e2291a3c9fb86e'],7d375c18c1e2415faecd9f7397068a32,467,6,3,9
AZURE OPENAI,GRAPHRAG_LLM_API_KEY,1.0,"The Azure OpenAI service uses the GRAPHRAG_LLM_API_KEY for authentication. This relationship is critical for accessing and using the service, as the API key verifies the user's identity and permissions.",['7b45dafa74553d3899e2291a3c9fb86e'],dfa0e847a6704c93a0fe014b01858ff7,468,6,1,7
AZURE OPENAI,GRAPHRAG_LLM_API_VERSION,1.0,"The Azure OpenAI service uses the GRAPHRAG_LLM_API_VERSION configuration to specify the API version for language model requests. This relationship is crucial for compatibility and functionality, ensuring that the service requests are processed correctly.",['7b45dafa74553d3899e2291a3c9fb86e'],9e91823feb174cd1b6a3bf8d0a5cb86b,469,6,1,7
AZURE OPENAI,GRAPHRAG_LLM_MODEL_SUPPORTS_JSON,1.0,"The Azure OpenAI service's functionality is influenced by the GRAPHRAG_LLM_MODEL_SUPPORTS_JSON configuration, which indicates whether the language model can handle JSON data. This relationship is important for determining the capabilities of the service and how it can be used in various applications.",['7b45dafa74553d3899e2291a3c9fb86e'],ad76c8dc8dd94412a5e79005cf8e0f2f,470,6,2,8
SETTINGS.YAML,PYTHON -M GRAPHRAG.INDEX,1.0,The python -m graphrag.index command creates the settings.yaml file when the --init option is used. This file contains the configuration settings necessary for the operation of GraphRAG.,['12294feb07a1d202b27241eaaf64718b'],26a03482961e41918ea049018080af7a,471,6,3,9
SETTINGS.YAML,.ENV,1.0,".env is referenced in settings.yaml for environment variable settings, allowing for token replacements in the configuration document using ${ENV_VAR} syntax.",['32e96c66a531ecd0a8edc7414aec0803'],1cfd220ff4d2493ca4b92d725d171d32,472,6,6,12
API_BASE,GRAPHRAG CONFIGURATION DOCUMENTATION,1.0,"The api_base is a configuration property that is documented in the GraphRAG configuration documentation, providing guidance on how to set up the base URL for accessing the Azure OpenAI API.",['7c1bad237a1ef86cb41b6c5dbad4ffc3'],97738fe0830d405ba53598b5cb1e5e38,473,2,4,6
API_BASE,REQUEST_TIMEOUT,1.0,The request_timeout and api_base are related because the request_timeout defines the timeout for requests made to the API specified by api_base,['647be47c939b4d72f1c0b29a2e0d2cb2'],354cea4f6e164a48ad12122c28a5b30d,474,2,1,3
API_VERSION,GRAPHRAG CONFIGURATION DOCUMENTATION,1.0,"The api_version is a configuration property that is documented in the GraphRAG configuration documentation, offering information on how to specify the version of the Azure OpenAI API to be used.",['7c1bad237a1ef86cb41b6c5dbad4ffc3'],1ee2380c1eda4ebb8c9304820750ac88,475,2,4,6
API_VERSION,ORGANIZATION,1.0,"The api_version and organization are related because the api_version specifies the version of the API used by the LLM (Language Model) service, which is associated with the organization using the service",['647be47c939b4d72f1c0b29a2e0d2cb2'],57e00d4d4e0e4679a150f048deb80af3,476,2,1,3
DEPLOYMENT_NAME,GRAPHRAG CONFIGURATION DOCUMENTATION,1.0,"The deployment_name is a configuration property that is documented in the GraphRAG configuration documentation, explaining how to set the name of the Azure model deployment for accessing the model.",['7c1bad237a1ef86cb41b6c5dbad4ffc3'],c1e4a9dbe55c4fb89f0d927c9fb067a4,477,3,4,7
DEPLOYMENT_NAME,MODEL_SUPPORTS_JSON,1.0,"The deployment_name and model_supports_json are related because the deployment_name specifies the deployment to use for Azure-based LLM (Language Model) services, and model_supports_json indicates whether the model deployed supports JSON output",['647be47c939b4d72f1c0b29a2e0d2cb2'],1474a72a5cff4b72ae6f99e804ceaa95,478,3,2,5
DEPLOYMENT_NAME,URL ENDPOINT,1.0,The url endpoint is related to the deployment_name as the endpoint is specific to the deployment specified by the deployment_name. The deployment_name determines the correct endpoint to use for accessing the model.,['3c66b7e86b3675fce14fe0047ae731aa'],738fda68df7a49a0bae96673a8711afc,479,3,2,5
GRAPHRAG CONFIGURATION DOCUMENTATION,INITIALIZATION DOCUMENTATION,1.0,"The GraphRAG configuration documentation is related to the Initialization documentation, as both provide information necessary for setting up the environment and preparing for data indexing and querying.",['7c1bad237a1ef86cb41b6c5dbad4ffc3'],89dd5a0943c64247adae624abbc95afb,480,4,1,5
DEFAULT CONFIGURATION MODE,INIT COMMAND,1.0,The Default Configuration Mode supports the use of the Init Command to easily set up the GraphRAG system with the necessary configuration files,['ccd2de9e2219521fbca779843c65af58'],405e9907440d4deab71f3960ae36f47b,481,2,4,6
CUSTOM CONFIGURATION MODE,ENCODING_MODEL,1.0,The encoding_model is related to Custom Configuration Mode as it is a configuration setting that can be customized in the advanced use-case of Custom Configuration Mode,['b70cb2eda62c6afad9e8d22daafe61cc'],f91e7c9600ca4623a8cc4a56d2dccd07,482,3,1,4
CUSTOM CONFIGURATION MODE,SKIP_WORKFLOWS,1.0,The skip_workflows is related to Custom Configuration Mode as it is a configuration property that can be defined in the advanced use-case of Custom Configuration Mode to skip specific workflows,['b70cb2eda62c6afad9e8d22daafe61cc'],3af2a8619c394be6adf06e4bc742b7ec,483,3,1,4
INIT COMMAND,.ENV FILE,1.0,"The init command creates the .env file, which contains environment variables necessary for the configuration of GraphRAG",['d0f7c236538005bc3056b7daed2401d8'],c10ffc51dcb54708a1dc757693010bfe,484,4,1,5
INIT COMMAND,SETTINGS.YAML FILE,1.0,"The init command creates the settings.yaml file, which contains the configuration settings for GraphRAG",['d0f7c236538005bc3056b7daed2401d8'],e67ce34d48364422973ccf3a6b57af83,485,4,1,5
INIT COMMAND,PROMPTS FOLDER,1.0,"The init command creates the prompts folder, which contains the default prompts used by GraphRAG and can be modified or adapted",['d0f7c236538005bc3056b7daed2401d8'],98773a34c9bb474d8a789ea08f57250e,486,4,1,5
.ENV,PYTHON -M GRAPHRAG.INDEX,1.0,The python -m graphrag.index command creates the .env file when the --init option is used. This file is necessary for storing environment variables referenced in the settings.yaml file.,['12294feb07a1d202b27241eaaf64718b'],ae260498423e4d55aa413423cd0eb20b,487,6,3,9
.ENV,CONFIG.JSON,1.0,".env is used alongside config.json for environment variable token replacements, allowing for dynamic configuration settings in GraphRAG.",['32e96c66a531ecd0a8edc7414aec0803'],4aeecb9d885743ca9373337a43957dd8,488,6,4,10
.ENV,CONFIG.YML,1.0,".env is used alongside config.yml for environment variable token replacements, allowing for dynamic configuration settings in GraphRAG.",['32e96c66a531ecd0a8edc7414aec0803'],1121b50f7858427fa679d81861238825,489,6,1,7
PROMPTS/,PYTHON -M GRAPHRAG.INDEX,1.0,The python -m graphrag.index command creates the prompts/ directory when the --init option is used. This directory contains default prompts used by GraphRAG and can be modified or new ones generated through the Auto Prompt Tuning command.,['12294feb07a1d202b27241eaaf64718b'],6e3c8aa3abab475bb0148faa9112f0bf,490,4,3,7
PROMPTS/,PROMPT TUNING COMMAND,1.0,"The prompts/ directory contains default prompts that can be modified or adapted using the Prompt Tuning command, enhancing the performance of GraphRAG for specific data sets.",['32e96c66a531ecd0a8edc7414aec0803'],948a00e8ee1246cc90c47b292d03ddff,491,4,2,6
CONFIG.JSON,API KEY,1.0,"The API Key is a part of the Config.json file, specifically located within the llm section. It is a critical configuration property for accessing the LLM service.",['f135654a3c057c66b9e5f97a960d302f'],45c42e619f5e488f914608780dcf0579,492,4,1,5
CONFIG.JSON,INPUT CONFIGURATION,1.0,The Input Configuration is a section within the Config.json file that defines how input data should be processed. It includes various fields that are necessary for configuring the input handling process.,['f135654a3c057c66b9e5f97a960d302f'],2b3bea0d9ede41f193828526bcb8e02c,493,4,1,5
CONFIG.JSON,LLM CONFIGURATION,1.0,The LLM Configuration is a section within the Config.json file that specifies settings for the LLM (Language Model) service. It includes the API Key and other parameters that are essential for the operation of the LLM service.,['f135654a3c057c66b9e5f97a960d302f'],6b2586cc1f8e4dc8af64913af63d9837,494,4,1,5
API_KEY,TYPE,1.0,"The api_key and type are related because the api_key is required for authentication when using the specified type of LLM (Language Model) service, such as OpenAI or Azure OpenAI",['647be47c939b4d72f1c0b29a2e0d2cb2'],7983bfa8d173414685272b3844d6612e,495,1,2,3
INPUT,WORKFLOW2,1.0,"The input data for workflow2 is specified as a file type, with details such as base directory and file pattern, which are necessary for the process to execute",['76d9dcb9a27c2caea1f46bb5050851c6'],09294e8220a445e288ea8841f234a440,496,7,5,12
INPUT,FILE_TYPE,1.0,The input property is related to the file_type as the file_type specifies the type of file that the input property is configured to read,['3900b87693f02c43b4294e38647eb7cd'],d4e043cf972c4d129b6b855f1731caae,497,7,1,8
INPUT,BASE_DIR,1.0,The input property is related to the base_dir as the base_dir specifies the directory from which the input property reads the files,['3900b87693f02c43b4294e38647eb7cd'],e0d63137270c426dbbfe7fcf78c474de,498,7,2,9
INPUT,FILE_PATTERN,1.0,The input property is related to the file_pattern as the file_pattern is used by the input property to identify and select the files to be read,['3900b87693f02c43b4294e38647eb7cd'],c50bca18bc454a98b935df012b7fd6f9,499,7,1,8
INPUT,SOURCE_COLUMN,1.0,The input property is related to the source_column as the source_column is a part of the input configuration that specifies which column contains the source or author of the data,['3900b87693f02c43b4294e38647eb7cd'],434b133c64bd46219e67c6eb296ad0ff,500,7,1,8
INPUT,TEXT_COLUMN,1.0,The input property is related to the text_column as the text_column is a part of the input configuration that specifies which column contains the text of the data,['3900b87693f02c43b4294e38647eb7cd'],cb895bf7e7c147e6b5d923b6c8f67d63,501,7,1,8
INPUT,POST PROCESS,1.0,The Input is related to the Post Process as the post-process steps are applied to the input data after it is read from the CSV file. The relationship is established through the 'post_process' section in the input that specifies the filtering step based on the 'title' column with the value 'My document',['6839baed839d7a5e837af1da93e462e5'],87776e869a01402499a317cb9cf09453,502,7,2,9
TYPE,FIELDS,1.0,"The Fields include the Type property, which specifies the type of storage to use",['abac77a5673e907cf8d65161c2612784'],d1e5359d2e344260bf1b83823df839b7,503,2,8,10
CONNECTION_STRING,CONTAINER_NAME,1.0,"The connection_string and container_name are related because the connection_string provides the necessary details to access the Azure Blob storage, while the container_name specifies the exact container within that storage where data is stored",['647be47c939b4d72f1c0b29a2e0d2cb2'],0522f6580b824bc39792b695fc8be66b,504,1,1,2
BASE_DIR,STORAGE_ACCOUNT_BLOB_URL,1.0,"The base_dir and storage_account_blob_url are related because the base_dir specifies the directory from which to read input data, and the storage_account_blob_url provides the direct access point to the Azure storage account blob where the data is located",['647be47c939b4d72f1c0b29a2e0d2cb2'],580fd6d19460460fa40613f66b3ee200,505,2,1,3
PROXY,COGNITIVE_SERVICES_ENDPOINT,1.0,"The proxy and cognitive_services_endpoint are related because the proxy can be used to route requests to the cognitive_services_endpoint, which provides additional AI services",['647be47c939b4d72f1c0b29a2e0d2cb2'],84f4684a7a5241c18bb087ccb00550d3,506,1,1,2
MODEL_SUPPORTS_JSON,URL ENDPOINT,1.0,The model_supports_json is related to the url endpoint as it indicates whether the model at the specified endpoint supports JSON-mode output. This affects how requests are formatted and how responses are interpreted.,['3c66b7e86b3675fce14fe0047ae731aa'],9607ba4a796f46be8d4f79bc7065d60b,507,2,2,4
TOKENS_PER_MINUTE,REQUESTS_PER_MINUTE,2.0,"The entities ""TOKENS_PER_MINUTE"" and ""REQUESTS_PER_MINUTE"" are intricately related in the context of managing the LLM (Language Model) service. These parameters act in concert to set throttle limits on the service, ensuring a controlled rate of consumption and processing. Specifically, ""TOKENS_PER_MINUTE"" governs the number of tokens that can be processed by the service, while ""REQUESTS_PER_MINUTE"" regulates the number of requests that can be made. Together, they ensure that the service can handle requests efficiently without being overwhelmed, maintaining optimal performance and resource allocation.",['3c66b7e86b3675fce14fe0047ae731aa' '647be47c939b4d72f1c0b29a2e0d2cb2'],236dd7dce9ee4cf5918fddd44b4863e5,508,1,2,3
REQUESTS_PER_MINUTE,SLEEP_ON_RATE_LIMIT_RECOMMENDATION,1.0,The sleep_on_rate_limit_recommendation is related to the requests_per_minute as it controls the behavior when the rate limit set by requests_per_minute is reached. It determines whether the system should sleep according to recommendations when the rate limit is exceeded.,['3c66b7e86b3675fce14fe0047ae731aa'],9e92fed814a64d9d88bfab9a227859d3,509,2,1,3
MAX_RETRIES,MAX_RETRY_WAIT,2.0,"The entities MAX_RETRIES and MAX_RETRY_WAIT are integral components of the retry mechanism for handling failed requests to the LLM (Language Model) service. MAX_RETRIES sets the upper limit on the number of times a failed request can be retried, ensuring that the system does not attempt to resend requests indefinitely. Complementing this, MAX_RETRY_WAIT specifies the maximum backoff time before each retry, providing a crucial parameter for managing the frequency and timing of retry attempts. Together, these two entities play a pivotal role in optimizing the efficiency and reliability of the communication between the system and the LLM service.",['3c66b7e86b3675fce14fe0047ae731aa' '647be47c939b4d72f1c0b29a2e0d2cb2'],7dccecb29d3a419093b279b22e207539,510,2,1,3
MAX_RETRIES,CONCURRENT_REQUESTS,1.0,"The concurrent_requests is related to the max_retries as they both manage the handling of requests. The concurrent_requests specifies the number of requests that can be open at once, while the max_retries determines how many times a failed request should be retried.",['3c66b7e86b3675fce14fe0047ae731aa'],89857eb61e63461cbad7c5014f5098f9,511,2,1,3
TEMPERATURE,TOP_P,1.0,"The temperature is related to the top_p as they both influence the generation of completions. The temperature affects the randomness of the output, while the top_p affects the diversity of the output by controlling the selection of likely completions.",['3c66b7e86b3675fce14fe0047ae731aa'],7b2e7a0d910c4988a7b64489f4159a65,512,2,1,3
TEMPERATURE,N,1.0,"The n is related to the temperature as they both determine the output of the model. The n specifies the number of completions to generate, while the temperature influences the randomness of those completions.",['3c66b7e86b3675fce14fe0047ae731aa'],38630cf0996f4cff8d32b2dbdaa5ba85,513,2,1,3
STAGGER,NUM_THREADS,1.0,"The stagger is related to the num_threads as they both influence the parallelization of processing. The stagger specifies the threading stagger value, while the num_threads determines the number of threads used for processing.",['3c66b7e86b3675fce14fe0047ae731aa'],bd0fb68ac7014b91a314c93ec55897f5,514,1,1,2
ASYNC_MODE,SUMMARIZE_DESCRIPTIONS,1.0,"The async_mode setting is used in the summarize_descriptions process, indicating how the summarization tasks are handled asynchronously",['9cbd4e21339eeed5e22a638e52a094cb'],f24dcb3cd6d644f8af2b6c47983e280b,515,5,6,11
ASYNC_MODE,CLAIM_EXTRACTION,1.0,"The async_mode setting is used in the claim_extraction process, indicating how the claim extraction tasks are handled asynchronously",['9cbd4e21339eeed5e22a638e52a094cb'],b1cad695afbc4ec3bbcd46ea34bd26ca,516,5,5,10
ASYNC_MODE,COMMUNITY_REPORTS,1.0,"The async_mode setting is used in the community_reports process, indicating how the report generation tasks are handled asynchronously",['9cbd4e21339eeed5e22a638e52a094cb'],72f7974758d74e5d89ddb64ad739abb8,517,5,6,11
ASYNC_MODE,GRAPHRAG_MAX_CLUSTER_SIZE,1.0,ASYNC_MODE and GRAPHRAG_MAX_CLUSTER_SIZE are related as they both are configuration properties that can affect the performance and behavior of the system,['1b24101de07b1c195448240237b84b37'],e6ee83249adf4e14b98d1676b1c6b05f,518,5,2,7
BATCH_SIZE,BATCH_MAX_TOKENS,1.0,"batch_size and batch_max_tokens are related because they both define parameters for batch processing, with batch_size controlling the number of items and batch_max_tokens controlling the token limit, which together influence the efficiency and resource usage of the system.",['d27237468a1b9e89110eeeca8080f63c'],f805fd9fe42947a38b92a3db6e8cc986,519,1,1,2
TARGET,STRATEGY,1.0,"target and strategy are related because the strategy for text-embedding can be fully overridden, which includes how the target set of embeddings is emitted, affecting the output and customization of the text-embedding process.",['d27237468a1b9e89110eeeca8080f63c'],e8b956218d5c4e5d9d390abcf527a514,520,1,5,6
STRATEGY,SUMMARIZE_DESCRIPTIONS,1.0,"The strategy setting is used in the summarize_descriptions process, allowing for the customization of the summarization algorithm",['9cbd4e21339eeed5e22a638e52a094cb'],9525aa223d774e62ad856c2201cfab1b,521,5,6,11
STRATEGY,CLAIM_EXTRACTION,1.0,"The strategy setting is used in the claim_extraction process, allowing for the customization of the claim extraction algorithm",['9cbd4e21339eeed5e22a638e52a094cb'],1087596b06d1400a8f863d0ac1af64a4,522,5,5,10
STRATEGY,COMMUNITY_REPORTS,1.0,"The strategy setting is used in the community_reports process, allowing for the customization of the report generation algorithm",['9cbd4e21339eeed5e22a638e52a094cb'],39058965295643c8a7738350cc18ceac,523,5,6,11
SIZE,OVERLAP,1.0,"size and overlap are related because they both influence the chunking process, with size defining the maximum chunk size and overlap specifying the overlap between chunks, which together impact the context preservation and processing efficiency of text segments.",['d27237468a1b9e89110eeeca8080f63c'],9a8a2e5e3f2645619a0403532d935afe,524,1,1,2
PARALLELIZATION,SUMMARIZE_DESCRIPTIONS,1.0,"The parallelization setting is used in the summarize_descriptions process, defining how tasks are processed in parallel",['9cbd4e21339eeed5e22a638e52a094cb'],f0c21c67baac47f097f74f5055b89877,525,5,6,11
PARALLELIZATION,CLAIM_EXTRACTION,1.0,"The parallelization setting is used in the claim_extraction process, defining how tasks are processed in parallel",['9cbd4e21339eeed5e22a638e52a094cb'],323a4c7407ac401db79a6023c3a5a17d,526,5,5,10
PARALLELIZATION,COMMUNITY_REPORTS,1.0,"The parallelization setting is used in the community_reports process, defining how tasks are processed in parallel",['9cbd4e21339eeed5e22a638e52a094cb'],686bc2bd59644e398dde88ffd37bf49b,527,5,6,11
CACHE,STORAGE,2.0,"CACHE and STORAGE are intricately related within the context of data management systems. CACHE primarily focuses on temporary storage solutions designed for quick access, acting as a caching strategy in the pipeline. This role is crucial for enhancing system performance by minimizing latency and improving data retrieval speeds. On the other hand, STORAGE is concerned with long-term data management, concentrating on the output strategy. It ensures the reliability and integrity of data over extended periods, playing a pivotal role in resource management and system efficiency. Both entities are essential components of data management systems, working in tandem to optimize performance, resource allocation, and data reliability.",['d27237468a1b9e89110eeeca8080f63c' 'e01c546120a27319dcbdf7a6b89bab26'],e368f8e9c9864acc880fdb5113631f3f,528,1,4,5
STORAGE,STORAGE ACCOUNT BLOB URL,1.0,The Storage section includes the Storage Account Blob URL as a configuration property for blob storage type,['abac77a5673e907cf8d65161c2612784'],05063c19ddb847a89ae1746588464288,529,4,3,7
STORAGE,FIELDS,1.0,"The Storage section contains the Fields, which are specific configuration options for storage settings",['abac77a5673e907cf8d65161c2612784'],019b34e800414f7b87f38a14adf2eb67,530,4,8,12
STORAGE,ROOT_DIR,1.0,"root_dir is related to the storage configuration as it specifies the base directory for storing data, which is a critical component of the storage strategy",['e01c546120a27319dcbdf7a6b89bab26'],1064a663ca4742a78e743128546f6d87,531,4,2,6
REPORTING,STORAGE ACCOUNT BLOB URL,1.0,The Reporting section includes the Storage Account Blob URL as a configuration property for blob reporting type,['abac77a5673e907cf8d65161c2612784'],9a5e0a4ae34f46b39a5a028cbc135264,532,2,3,5
REPORTING,FIELDS,1.0,"The Reporting section contains the Fields, which are specific configuration options for reporting settings",['abac77a5673e907cf8d65161c2612784'],5a224002ecbc4725abeb5a424aaca6a6,533,2,8,10
FIELDS,CONNECTION STRING,1.0,"The Fields include the Connection String property, which is used for blob storage type",['abac77a5673e907cf8d65161c2612784'],8826a17bbda34012b3ea84d58ae531eb,534,8,2,10
FIELDS,CONTAINER NAME,1.0,"The Fields include the Container Name property, which is used for blob storage type",['abac77a5673e907cf8d65161c2612784'],bab69d76defb402da2a2a358739f1497,535,8,2,10
FIELDS,BASE DIR,1.0,"The Fields include the Base Dir property, which specifies the base directory for writing reports",['abac77a5673e907cf8d65161c2612784'],ea465e5cd92247829f52ff0c8591d1bb,536,8,1,9
FIELDS,SUMMARIZE DESCRIPTIONS,1.0,"The Summarize Descriptions section contains the Fields, which are specific configuration options for summarizing descriptions settings",['abac77a5673e907cf8d65161c2612784'],2dbac25b512c4f21965169a95a910a94,537,8,1,9
CONNECTION STRING,REPORTING TYPE,1.0,"The Reporting Type property is related to the Connection String property, as the connection string is only relevant when the reporting type is set to blob",['a3e5bacdf64bcaf080a04c7dd8218484'],97958ed004f645b1b331fa0e66faa313,538,2,3,5
CONTAINER NAME,REPORTING TYPE,1.0,"The Reporting Type property is related to the Container Name property, as the container name is only relevant when the reporting type is set to blob",['a3e5bacdf64bcaf080a04c7dd8218484'],48129b4ee99f4e30843fd4395d4815c0,539,2,3,5
PROMPT STR,SUMMARIZE_DESCRIPTIONS,1.0,"The prompt str setting is used in the summarize_descriptions process, specifying the prompt file to guide the summarization",['9cbd4e21339eeed5e22a638e52a094cb'],6de4c00e48b3480883e696e24df9fda4,540,3,6,9
PROMPT STR,CLAIM_EXTRACTION,1.0,"The prompt str setting is used in the claim_extraction process, specifying the prompt file to guide the claim extraction",['9cbd4e21339eeed5e22a638e52a094cb'],4b3d236101de4904ab348e3e3b11b4be,541,3,5,8
PROMPT STR,COMMUNITY_REPORTS,1.0,"The prompt str setting is used in the community_reports process, specifying the prompt file to guide the report generation",['9cbd4e21339eeed5e22a638e52a094cb'],5be2ce9957ba404f939b6c8175015619,542,3,6,9
SUMMARIZE_DESCRIPTIONS,MAX_LENGTH,1.0,"The max_length setting is used in the summarize_descriptions process, controlling the length of the generated summaries",['9cbd4e21339eeed5e22a638e52a094cb'],fe77344850214c1cac923094de81098c,543,6,1,7
COMMUNITY_REPORTS,STRATEGY DICT,1.0,"The community_reports section can be fully customized by the strategy dict, allowing for the override of default settings and strategies for community reports",['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14'],798f739abfc14a13bf3911d0a9cfb63b,544,6,4,10
STRATEGY DICT,CLUSTER_GRAPH,1.0,"The cluster_graph section can be fully customized by the strategy dict, allowing for the override of default settings and strategies for cluster graphs",['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14'],3105de8188fd41d88d0dbf0a5d48e443,545,4,1,5
STRATEGY DICT,EMBED_GRAPH,1.0,"The embed_graph section can be fully customized by the strategy dict, allowing for the override of default settings and strategies for graph embeddings",['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14'],8108dde0e62a48008a270138a690a0b9,546,4,1,5
STRATEGY DICT,NODE2VEC RANDOM SEED,1.0,The node2vec random seed is related to the strategy dict as it can be a parameter within the strategy dict that influences the node2vec algorithm's behavior and results,['b70cb2eda62c6afad9e8d22daafe61cc'],d07207b853c14504a44eea1d4778f902,547,4,1,5
ENABLED BOOL,UMAP,1.0,The UMAP is related to the enabled bool as the enabled bool determines whether UMAP layouts are enabled or disabled in the system,['b70cb2eda62c6afad9e8d22daafe61cc'],406822a1a01a4140baf9bbf1d479f07e,548,1,1,2
SNAPSHOTS,GRAPHML BOOL,1.0,The snapshots are related to the graphml bool as the graphml bool is a sub-property of snapshots that controls the emission of graphml snapshots,['b70cb2eda62c6afad9e8d22daafe61cc'],fe47ba3762ae4feda39904d59cbb4160,549,3,1,4
SNAPSHOTS,RAW_ENTITIES BOOL,1.0,The snapshots are related to the raw_entities bool as the raw_entities bool is a sub-property of snapshots that determines if raw entity snapshots are emitted,['b70cb2eda62c6afad9e8d22daafe61cc'],53032c2afcb5474a88446ad7c5506980,550,3,1,4
SNAPSHOTS,TOP_LEVEL_NODES BOOL,1.0,The snapshots are related to the top_level_nodes bool as the top_level_nodes bool is a sub-property of snapshots that specifies whether top-level-node snapshots are emitted,['b70cb2eda62c6afad9e8d22daafe61cc'],5c66a88612a245cb91fbba9c094f12fc,551,3,1,4
EXTENDS,ROOT_DIR,1.0,"extends can influence the root_dir configuration by inheriting settings from base configurations, which may include the root directory path for the pipeline",['e01c546120a27319dcbdf7a6b89bab26'],b4c54fb7ce0b4b77afd5fbe5a8a2527f,552,1,2,3
RUN.PY,PYTHONPATH,1.0,run.py requires the PYTHONPATH environment variable to be set to the project's root directory in order to find and import the necessary modules and scripts when executing the script,['e01c546120a27319dcbdf7a6b89bab26'],c8b60cdb74104667b5d2b4b70d74d039,553,2,1,3
RUN.PY,POETRY SHELL,1.0,"poetry shell is used to activate the virtual environment with the required dependencies before running run.py, ensuring that the correct environment is set up for the execution of the script",['e01c546120a27319dcbdf7a6b89bab26'],333e294d7cc34df4abc47ad9ced3d186,554,2,1,3
REPORTING TYPE,BASE DIRECTORY,1.0,"The Reporting Type property is related to the Base Directory property, as the base directory is only relevant when the reporting type is set to file",['a3e5bacdf64bcaf080a04c7dd8218484'],15e66e10d12f4520abca20985d2cb39c,555,3,1,4
WORKFLOW NAME,STEPS,1.0,"The Workflow Name property is related to the Steps property, as steps are part of a specific workflow and can establish dependencies on other workflows through the input property",['a3e5bacdf64bcaf080a04c7dd8218484'],2a271d9b5d7b46fea4046d5590eed1d7,556,2,1,3
INPUT TYPE,FILE TYPE,1.0,"The Input Type property is related to the File Type property, as the file type is only relevant when the input type is set to file",['a3e5bacdf64bcaf080a04c7dd8218484'],99e372089bed4a0394af57175679f8e4,557,1,1,2
WORKFLOW2,WORKFLOW1,1.0,"workflow2 has a dependency on workflow1, as indicated in the derive step's input source",['76d9dcb9a27c2caea1f46bb5050851c6'],62afe93767684ea38f861d20fb05ff71,558,5,1,6
WORKFLOW2,DERIVE,1.0,"The derive step is a part of the workflow2 process, used to process data from col1 and col2 with a dependency on workflow1",['76d9dcb9a27c2caea1f46bb5050851c6'],8fc1fbff7e6c459c93ce2c2f5a62226e,559,5,1,6
TIMESTAMP_COLUMN,TIMESTAMP_FORMAT,1.0,The timestamp_column is related to the timestamp_format as the timestamp_format specifies how the timestamps in the timestamp_column are structured and should be interpreted,['3900b87693f02c43b4294e38647eb7cd'],04b3ae04020349a9bc568f26d17eab14,560,1,1,2
AUTHOR,MESSAGE,1.0,The Author is related to the Message as the author is the creator or originator of the message. The relationship is established through the 'author' column in the CSV file that links the author to the message,['6839baed839d7a5e837af1da93e462e5'],bbc4d367c60f41ad8a279c12e5cc7da6,561,1,2,3
MESSAGE,DATE,1.0,The Message is related to the Date as the date indicates when the message was created or recorded. The relationship is established through the 'date(yyyyMMddHHmmss)' column in the CSV file that provides the timestamp for the message,['6839baed839d7a5e837af1da93e462e5'],9a1aff251eda416ea6270e6158e663fc,562,2,1,3
POST PROCESS,FILE FILTER,1.0,"The File Filter is related to the Post Process as the filtered files are then processed by the post processing steps, which can include further filtering based on specific columns and values",['765d8a78606fe81a03a0da4f7ff231fa'],7a9e50846c274338ab09e7313b540edb,563,2,2,4
CSV FILE PATTERN,FILE FILTER,1.0,The CSV File Pattern is related to the File Filter as the filter uses the named groups from the pattern to apply additional filtering criteria to the files,['765d8a78606fe81a03a0da4f7ff231fa'],b268cc3ef860434ba663dd46af633cc5,564,1,2,3
GRAPHRAG_API_BASE,GRAPHRAG_API_VERSION,1.0,GRAPHRAG_API_BASE and GRAPHRAG_API_VERSION are related because the API base URL and the API version together determine the endpoint for making API requests. The API version is crucial for ensuring compatibility with the API base. The strength of this relationship is high because both settings are required for successful API interaction.,['3da10b454f926a257b9fdf5d2487c0a5'],1c9f67904a4c4fcc8cdac6a605900248,565,2,3,5
GRAPHRAG_INPUT_TYPE,GRAPHRAG_INPUT_FILE_TYPE,1.0,"GRAPHRAG_INPUT_TYPE and GRAPHRAG_INPUT_FILE_TYPE are related because GRAPHRAG_INPUT_TYPE specifies the type of input data, and GRAPHRAG_INPUT_FILE_TYPE specifies the type of files to be processed. When GRAPHRAG_INPUT_TYPE is set to ""file"", GRAPHRAG_INPUT_FILE_TYPE becomes relevant as it determines the format of the input files that the system will handle.",['8ac79ce92be1254dfda9a10eb54ab703'],e00c403d1dc84ba6a37ee193596e320f,566,4,1,5
GRAPHRAG_INPUT_TYPE,GRAPHRAG_INPUT_FILE_PATTERN,1.0,"GRAPHRAG_INPUT_TYPE and GRAPHRAG_INPUT_FILE_PATTERN are related because GRAPHRAG_INPUT_TYPE specifies the type of input data, and GRAPHRAG_INPUT_FILE_PATTERN specifies the pattern for matching input files. When GRAPHRAG_INPUT_TYPE is set to ""file"", GRAPHRAG_INPUT_FILE_PATTERN becomes relevant as it determines which files will be selected for processing based on their names.",['8ac79ce92be1254dfda9a10eb54ab703'],3f2e726c3b624fe7bf11de9be2c0457e,567,4,1,5
GRAPHRAG_INPUT_TYPE,GRAPHRAG_INPUT_SOURCE_COLUMN,1.0,"GRAPHRAG_INPUT_TYPE and GRAPHRAG_INPUT_SOURCE_COLUMN are related because GRAPHRAG_INPUT_TYPE specifies the type of input data, and GRAPHRAG_INPUT_SOURCE_COLUMN specifies the column name in the input data that contains the source information. When GRAPHRAG_INPUT_TYPE is set to ""file"", GRAPHRAG_INPUT_SOURCE_COLUMN becomes relevant as it determines which column in the input data should be used for source information.",['8ac79ce92be1254dfda9a10eb54ab703'],f71dc0c394f04771af7e2ed37f85647e,568,4,1,5
GRAPHRAG_EMBEDDING_TPM,GRAPHRAG_EMBEDDING_RPM,1.0,"The GRAPHRAG_EMBEDDING_TPM setting is related to the GRAPHRAG_EMBEDDING_RPM as both represent rate limits for embedding operations, with TPM focusing on transactions and RPM on requests",['2b777e3d591ce1511a03abd1a6d8dc73'],2fea9c1856e54a91b79a9ce85755fbf5,569,1,1,2
GRAPHRAG_STORAGE_TYPE,GRAPHRAG_STORAGE_CONNECTION_STRING,1.0,"The GRAPHRAG_STORAGE_TYPE property is related to the GRAPHRAG_STORAGE_CONNECTION_STRING property, as the type of storage system dictates the format and requirements of the connection string",['cde833db73c46ca28f08e35195134441'],7823b4c5b3364c5f890d05f33a46bdde,570,3,1,4
GRAPHRAG_STORAGE_TYPE,GRAPHRAG_STORAGE_CONTAINER_NAME,1.0,"The GRAPHRAG_STORAGE_TYPE property is related to the GRAPHRAG_STORAGE_CONTAINER_NAME property, as the type of storage system may require a specific container name for organization and identification",['cde833db73c46ca28f08e35195134441'],183f3a0b73ff41c5bb4a19fd7adf0c1d,571,3,1,4
GRAPHRAG_STORAGE_TYPE,GRAPHRAG_STORAGE_BASE_DIR,1.0,"The GRAPHRAG_STORAGE_TYPE property is related to the GRAPHRAG_STORAGE_BASE_DIR property, as the type of storage system determines the base directory structure for storing data",['cde833db73c46ca28f08e35195134441'],392e06f17d724484a9cfb85fe69aac50,572,3,1,4
GRAPHRAG_CACHE_TYPE,GRAPHRAG_CACHE_CONNECTION_STRING,1.0,"The GRAPHRAG_CACHE_TYPE property is related to the GRAPHRAG_CACHE_CONNECTION_STRING property, as the type of cache system dictates the format and requirements of the connection string",['cde833db73c46ca28f08e35195134441'],6f49e00cdac04a358173ecd40351ee00,573,3,1,4
GRAPHRAG_CACHE_TYPE,GRAPHRAG_CACHE_CONTAINER_NAME,1.0,"The GRAPHRAG_CACHE_TYPE property is related to the GRAPHRAG_CACHE_CONTAINER_NAME property, as the type of cache system may require a specific container name for organization and identification",['cde833db73c46ca28f08e35195134441'],3fef96af4ec343da8c34f8b09518de8a,574,3,1,4
GRAPHRAG_CACHE_TYPE,GRAPHRAG_CACHE_BASE_DIR,1.0,"The GRAPHRAG_CACHE_TYPE property is related to the GRAPHRAG_CACHE_BASE_DIR property, as the type of cache system determines the base directory structure for storing cached data",['cde833db73c46ca28f08e35195134441'],bd403eff654e42c997e5656a2b1c1a20,575,3,1,4
GRAPHRAG_REPORTING_TYPE,GRAPHRAG_REPORTING_CONNECTION_STRING,1.0,"The GRAPHRAG_REPORTING_TYPE property is related to the GRAPHRAG_REPORTING_CONNECTION_STRING property, as the type of reporting system dictates the format and requirements of the connection string",['cde833db73c46ca28f08e35195134441'],5763d829837144f199fac2b490b38110,576,3,1,4
GRAPHRAG_REPORTING_TYPE,GRAPHRAG_REPORTING_CONTAINER_NAME,1.0,"The GRAPHRAG_REPORTING_TYPE property is related to the GRAPHRAG_REPORTING_CONTAINER_NAME property, as the type of reporting system may require a specific container name for organization and identification",['cde833db73c46ca28f08e35195134441'],234c6f1859f0405ab607f0be53e7b06c,577,3,1,4
GRAPHRAG_REPORTING_TYPE,GRAPHRAG_REPORTING_BASE_DIR,1.0,"The GRAPHRAG_REPORTING_TYPE property is related to the GRAPHRAG_REPORTING_BASE_DIR property, as the type of reporting system determines the base directory structure for storing reports",['cde833db73c46ca28f08e35195134441'],21800eab85b94d4880bcada7a60763e5,578,3,1,4
GRAPHRAG_ENCODING_MODEL,GRAPHRAG_MAX_CLUSTER_SIZE,1.0,GRAPHRAG_ENCODING_MODEL and GRAPHRAG_MAX_CLUSTER_SIZE are related as they both influence the structure and efficiency of the graph representation,['1b24101de07b1c195448240237b84b37'],b8bb28a7a9624b6d805be89adfe29eb5,579,1,2,3
DOCUMENT,TEXTUNIT,2.0,"Documents, in the context of data processing and analysis, are often divided into smaller, more manageable components known as TextUnits. This division facilitates a detailed examination of the document's content, allowing for a more nuanced understanding of the information contained within. The relationship between Documents and TextUnits can be characterized as one-to-many or many-to-many, depending on the nature of the documents and the specific requirements of the analysis. This flexibility in dividing documents into multiple TextUnits enables a thorough exploration of the document's structure and content, enhancing the effectiveness of data processing and analysis tasks. The configuration settings determine the extent of division, creating a 1-to-many relationship between the original documents and the resulting TextUnits, thereby optimizing the analysis process for efficiency and accuracy.",['81f57cf867ea246ad9a6e794ed613375' '85e50a4d70697a2c4420e7a9fc82f22d'],61f26f8850504d56a6b7cd764c33299d,580,1,3,4
TEXTUNIT,ENTITY,1.0,"Entities are extracted from TextUnits, representing people, places, events, or other entity-models",['85e50a4d70697a2c4420e7a9fc82f22d'],d4456fac0ada4b6fbe3cfee873403d00,581,3,6,9
TEXTUNIT,GRAPH EXTRACTION,2.0,"During the Graph Extraction phase, TextUnits are meticulously processed to pinpoint and extract key components, including Entities, Relationships, and Claims. This process is fundamental in constructing the graph structure that underpins the analysis. Each TextUnit undergoes a detailed examination by the Graph Extraction process, which adeptly identifies and delineates entities and relationships embedded within the text. This results in the creation of a unique subgraph for every TextUnit, enabling a comprehensive mapping of the information landscape. The Graph Extraction phase plays a pivotal role in transforming raw text into a structured graph format, facilitating a deeper understanding of the relationships and claims within the Motor Control and Drive Systems domain.",['10d01d36390b307a63fd5bc97d8682c0' '81f57cf867ea246ad9a6e794ed613375'],f8fd3fcf650b47b2b1692506ebe77762,582,3,6,9
ENTITY,RELATIONSHIP,1.0,"Relationships are generated between entities based on the covariates, indicating connections between different entities",['85e50a4d70697a2c4420e7a9fc82f22d'],d95acc24180c47caa34114627d501592,583,6,2,8
ENTITY,COVARIATE,1.0,"Covariates contain statements about entities, which may be time-bound, providing context for the entities",['85e50a4d70697a2c4420e7a9fc82f22d'],f4753ab09adc42a9a52754e95440d4b9,584,6,2,8
ENTITY,COMMUNITY REPORT,1.0,"Community Reports are generated by performing hierarchical community detection on entities, providing insights into the structure of the data",['85e50a4d70697a2c4420e7a9fc82f22d'],12f5a7c56b454a3d8aae97f65908f96b,585,6,3,9
ENTITY,GRAPH EXTRACTION,1.0,"During the Graph Extraction phase, Entities are extracted from the text within each TextUnit, contributing to the graph being built",['81f57cf867ea246ad9a6e794ed613375'],95f79ff0b8a34080ae2ac8448ce561f1,586,6,6,12
RELATIONSHIP,GRAPH EXTRACTION,1.0,"During the Graph Extraction phase, Relationships are extracted from the text within each TextUnit, contributing to the graph being built",['81f57cf867ea246ad9a6e794ed613375'],8733d4602c084e1cab1384dde0306abf,587,2,6,8
COVARIATE,COMMUNITY REPORT,1.0,"Covariates are used in the generation of Community Reports, as they provide context and details about entities which are summarized in the reports",['493f38f41b89e767fc23d84e1fa5ba20'],ded3a49efdf6479a991cad53d0758cf4,588,2,3,5
DEFAULT CONFIGURATION WORKFLOW,NETWORK VISUALIZATION,1.0,"The Default Configuration Workflow includes Network Visualization as one of its phases, where the network of entities and their relationships are visualized",['493f38f41b89e767fc23d84e1fa5ba20'],816fceb7e1ca4b5d9277368f78e6ed80,589,7,1,8
DEFAULT CONFIGURATION WORKFLOW,DOCUMENT PROCESSING,1.0,"The Default Configuration Workflow includes Document Processing as one of its phases, where documents are processed for further analysis and transformation",['493f38f41b89e767fc23d84e1fa5ba20'],50539d4503a4495097f49a8ed83e2462,590,7,7,14
DEFAULT CONFIGURATION WORKFLOW,COMMUNITY SUMMARIZATION,1.0,"The Default Configuration Workflow includes Community Summarization as one of its phases, where communities are summarized to provide insights and reports",['493f38f41b89e767fc23d84e1fa5ba20'],d6f67aa7ef0e4a19bf5830e777aafea5,591,7,5,12
DEFAULT CONFIGURATION WORKFLOW,GRAPH AUGMENTATION,1.0,"The Default Configuration Workflow includes Graph Augmentation as one of its phases, where the graph is enhanced with additional information and relationships",['493f38f41b89e767fc23d84e1fa5ba20'],bbf61f9cd3e14f46a010d704e86be008,592,7,1,8
DEFAULT CONFIGURATION WORKFLOW,GRAPH EXTRACTION,1.0,"The Default Configuration Workflow includes Graph Extraction as one of its phases, where entities and relationships are extracted from the text to form a graph",['493f38f41b89e767fc23d84e1fa5ba20'],5d34e587bd2f41dba285e9178f179577,593,7,6,13
DEFAULT CONFIGURATION WORKFLOW,COMPOSE TEXTUNITS,1.0,"The Default Configuration Workflow includes Compose TextUnits as one of its phases, where input documents are transformed into TextUnits for graph analysis",['493f38f41b89e767fc23d84e1fa5ba20'],901b491be7344401b4544ff05e591a0e,594,7,1,8
DOCUMENT PROCESSING,COMMUNITY EMBEDDING,1.0,"Community Embedding is a part of the Document Processing phase, where vector representations of communities are created and used in the processing of documents",['3e292d936b7efa377ba9530456cfd888'],ecacbf62b81d485396a56e1730e75a04,595,7,4,11
DOCUMENT PROCESSING,COMMUNITY TABLES EMISSION,1.0,"Community Tables Emission is a process within the Document Processing phase, where the Communities and CommunityReports tables are generated and emitted",['3e292d936b7efa377ba9530456cfd888'],ba0ad1bcf02b4928a1b7ff7b23acdd6f,596,7,1,8
DOCUMENT PROCESSING,DOCUMENTS,1.0,"The Documents table is created during the Document Processing phase, which involves various steps such as Augment, Link to TextUnits, and Avg. Embedding.",['827fd80da359cf05b091c24e465dd05d'],0e3c66c25d7e43a7960c37d28315e5d8,597,7,4,11
DOCUMENT PROCESSING,LINK TO TEXTUNITS,1.0,"Link to TextUnits is a step within the Document Processing phase that connects documents to text-units, establishing the relationship between these entities.",['827fd80da359cf05b091c24e465dd05d'],a0e0d5b7db9f4efcb5277856db799775,598,7,2,9
DOCUMENT PROCESSING,PHASE 6: NETWORK VISUALIZATION,1.0,The Document Processing phase is related to Phase 6: Network Visualization as the processed documents are used to support network visualization of high-dimensional vector spaces within existing graphs.,['827fd80da359cf05b091c24e465dd05d'],3f85dab93736440f9776020b6410aa9b,599,7,7,14
COMMUNITY SUMMARIZATION,COMMUNITY EMBEDDING,1.0,"Community Summarization is related to Community Embedding, as the summarization of communities is based on the mapping of communities into a lower-dimensional space for visualization and analysis",['493f38f41b89e767fc23d84e1fa5ba20'],710ed70c346342ff81ccf205e30271bb,600,5,4,9
COMMUNITY SUMMARIZATION,GRAPH TABLES EMISSION,1.0,"Community Summarization builds upon the data from Graph Tables Emission, generating reports and summaries for communities at different levels of granularity to provide a high-level understanding of the graph",['5b2968b8f1c891d47ecbe641c3391663'],b3d3e8ba2ede4574a0498f082f0c15ae,601,5,3,8
COMMUNITY SUMMARIZATION,NODE2VEC ALGORITHM,1.0,Community Summarization utilizes the vector representations generated by the Node2Vec algorithm to summarize communities and understand the graph at various levels of granularity,['5b2968b8f1c891d47ecbe641c3391663'],8686013390614eca9116ccbab27431d7,602,5,2,7
GRAPH EXTRACTION,CLAIM,1.0,"During the Graph Extraction phase, Claims are extracted from the text within each TextUnit, contributing to the graph being built",['81f57cf867ea246ad9a6e794ed613375'],fd8c8b7e3b9248abb1d8cb8958ab86d3,603,6,1,7
GRAPH EXTRACTION,GRAPH SUMMARIZATION,1.0,"The output of Graph Extraction, which are subgraphs for each TextUnit, are combined and processed by Graph Summarization to create a single graph with merged entities and relationships.",['10d01d36390b307a63fd5bc97d8682c0'],039594428123415f95deb246f5097169,604,6,2,8
UMAP DOCUMENTS,DOCUMENT EMBEDDING,1.0,"Umap Documents is related to Document Embedding, as it maps documents into a lower-dimensional space for visualization and analysis, which is a part of the embedding process",['493f38f41b89e767fc23d84e1fa5ba20'],d78ce7696ff14234a544de945ffe40d6,605,2,3,5
UMAP DOCUMENTS,PHASE 6: NETWORK VISUALIZATION,1.0,"Umap Documents is a part of Phase 6: Network Visualization, as it is a process that generates a 2D representation of the document space for visualization.",['56506e2d064c0732efa3cf418057edfd'],59b21508be904875af22b5c1cfdcd211,606,2,7,9
UMAP ENTITIES,ENTITY & RELATIONSHIP EXTRACTION,1.0,"Umap Entities is related to Entity & Relationship Extraction, as it maps entities into a lower-dimensional space for visualization and analysis, which is based on the entities and relationships identified in the text",['493f38f41b89e767fc23d84e1fa5ba20'],e9c7a1d505b14229afbbef7c0d04751e,607,2,3,5
UMAP ENTITIES,PHASE 6: NETWORK VISUALIZATION,1.0,"Umap Entities is a part of Phase 6: Network Visualization, as it is a process that generates a 2D representation of the entity space for visualization.",['56506e2d064c0732efa3cf418057edfd'],4b0efcd54efc40e8a884ac6c31deada2,608,2,7,9
NODES TABLE,LINK TO TEXTUNITS,1.0,"The Nodes Table is related to the Link to TextUnits, as it contains information about the nodes in the graph, including their layout and relationships, which are connected to the corresponding TextUnits",['493f38f41b89e767fc23d84e1fa5ba20'],0970f08f3d1a4d638d44e2ccb9237382,609,1,2,3
DOCUMENT EMBEDDING,DOCUMENT GRAPH CREATION,1.0,"Document Embedding is related to Document Graph Creation, as the embedding process converts documents into numerical vectors for analysis and comparison, which is used in the creation of the document graph",['493f38f41b89e767fc23d84e1fa5ba20'],8f10c11ecb5142029869025521c73431,610,3,2,5
DOCUMENT EMBEDDING,AVG. EMBEDDING,1.0,"Avg. Embedding is a part of the Document Embedding process, which generates a vector representation of documents using an average of embeddings of document slices.",['827fd80da359cf05b091c24e465dd05d'],e36a0e3901864a7eaa5f5ad4280a6471,611,3,1,4
DOCUMENT GRAPH CREATION,DOCUMENT TABLES,1.0,"Document Graph Creation is related to Document Tables, as the creation of the document graph is based on the information about the documents, including metadata and analysis results, which are stored in the Document Tables",['493f38f41b89e767fc23d84e1fa5ba20'],6fce354faa104fe58ba8a565eb3c43f2,612,2,1,3
COMMUNITY EMBEDDING,COMMUNITY TABLES,1.0,"Community Embedding is related to Community Tables, as the mapping of communities into a lower-dimensional space for visualization and analysis is based on the information about the communities, including their members and properties, which are stored in the Community Tables",['493f38f41b89e767fc23d84e1fa5ba20'],20585e9a43c04375aa334e946e2dd144,613,4,2,6
COMMUNITY EMBEDDING,GRAPH EMBEDDING,1.0,"Community Embedding is related to Graph Embedding as both involve the representation of network structures in a vector space, with Community Embedding focusing specifically on community structures",['6f92ce3fcd05dd5697ded83586f7bc08'],32e343c0ae454660bdfcd1d3133baf0a,614,4,6,10
GRAPH EMBEDDING,AUGMENTED GRAPH TABLES,1.0,"Graph Embedding is related to Augmented Graph Tables, as the conversion of the graph into a numerical representation for analysis and visualization is based on the information about the graph after augmentation, including additional entities and relationships, which are stored in the Augmented Graph Tables",['493f38f41b89e767fc23d84e1fa5ba20'],505ab840f6cc4fa6a839ebfe82d255ed,615,6,1,7
GRAPH EMBEDDING,GRAPH TABLES,1.0,"Graph Tables are related to Graph Embedding as they are often used to store and organize the results of graph embedding techniques, including details about nodes, edges, and attributes",['6f92ce3fcd05dd5697ded83586f7bc08'],e38eb1698900424bb7392a74ff0f3351,616,6,2,8
GRAPH EMBEDDING,PHASE 3: GRAPH AUGMENTATION,1.0,"Graph Embedding is a subprocess of Phase 3: Graph Augmentation, aimed at understanding the implicit structure of the graph",['a6bcb4514cb6de67e3d74ad0ea62452d'],855c57eecf2a45c7aab02ff1ac36938d,617,6,3,9
GRAPH EMBEDDING,NODE2VEC ALGORITHM,1.0,"Graph Embedding uses the Node2Vec algorithm to generate vector representations of the graph, which is essential for understanding the graph's structure and searching for related concepts",['5b2968b8f1c891d47ecbe641c3391663'],6ee77949c94d4906bd98c24341fdfa03,618,6,2,8
GRAPH EMBEDDING,GRAPH TABLES EMISSION,1.0,"Graph Tables Emission follows the Graph Embedding step, where the final Entities and Relationships tables are emitted after text embedding, providing a structured representation of the graph data",['5b2968b8f1c891d47ecbe641c3391663'],d06f506604b249feb423915db282ed75,619,6,3,9
ENTITY & RELATIONSHIP EXTRACTION,ENTITY & RELATIONSHIP SUMMARIZATION,2.0,"Entity & Relationship Extraction and Entity & Relationship Summarization are closely intertwined processes within the domain of text analysis. Entity & Relationship Extraction involves the identification of entities and their relationships from the text, which serves as a foundational step for Entity & Relationship Summarization. The summarization process, in turn, relies on the results of the extraction to provide a concise overview of the identified entities and relationships, highlighting key connections and patterns within the data. This synergy between the two processes enables a comprehensive understanding of the structure and dynamics of the information, facilitating the identification of collaboration opportunities and knowledge gaps in specialized professional networks.",['493f38f41b89e767fc23d84e1fa5ba20' '6f92ce3fcd05dd5697ded83586f7bc08'],0f642f63d4af4fc38298822bfc952719,620,3,2,5
ENTITY & RELATIONSHIP EXTRACTION,TEXT UNITS,1.0,Entity & Relationship Extraction is related to Text Units as the process often operates on Text Units to identify entities and relationships within the text,['6f92ce3fcd05dd5697ded83586f7bc08'],e017ad1f09b049a7ad41d5a11dc1e3d9,621,3,3,6
ENTITY & RELATIONSHIP SUMMARIZATION,ENTITY RESOLUTION,1.0,"Entity & Relationship Summarization is related to Entity Resolution, as the summarization of the entities and relationships identified in the text is used in the resolution of entities that refer to the same real-world object or concept",['493f38f41b89e767fc23d84e1fa5ba20'],5cbced0ba7044b7490f520a436261c57,622,2,6,8
ENTITY RESOLUTION,DOCUMENTS,1.0,Entity Resolution is related to Documents as the process often operates on data from documents to identify and merge duplicate or similar entities,['6f92ce3fcd05dd5697ded83586f7bc08'],d45dea925f8d4e7e93d0e17317001eec,623,6,4,10
ENTITY RESOLUTION,GRAPH SUMMARIZATION,1.0,The graph produced by Graph Summarization is further processed by Entity Resolution to identify and merge entities that represent the same real-world entity but have different names.,['10d01d36390b307a63fd5bc97d8682c0'],8123eee04a3a4c779f03bdb85de99f9f,624,6,2,8
ENTITY RESOLUTION,COVARIATES,1.0,"Entity Resolution does not directly produce Covariates, but the resolved entities and their relationships can be part of the context for Claim Extraction, which emits Covariates.",['d44248ff7b7bfd969a7208eb3d6e2a78'],6129d90c83194bcfaede9ff00a011297,625,6,3,9
DOCUMENTS,TEXT UNITS,1.0,"Text Units are related to Documents as Text Units are derived from documents and used as the basis for further analysis or extraction, with a strict 1-to-many relationship by default",['6f92ce3fcd05dd5697ded83586f7bc08'],6ef76e963a564dbe9c9feff4f8ce1683,626,4,3,7
COVARIATES,CLAIM EXTRACTION & EMISSION,1.0,"Covariates are the primary artifacts emitted from the Claim Extraction & Emission process, representing claims that are positive factual statements with an evaluated status and time-bounds",['a6bcb4514cb6de67e3d74ad0ea62452d'],1c8bad73fda646f8b3f413e432f0e351,627,3,1,4
PHASE 3: GRAPH AUGMENTATION,GRAPH TABLES EMISSION,1.0,"Graph Tables Emission is a subprocess of Phase 3: Graph Augmentation, involving emitting the final entities and relationships in a tabular format",['a6bcb4514cb6de67e3d74ad0ea62452d'],7e75749d13d24321b8b10c5be0138805,628,3,3,6
AUGMENT,AUGMENT WITH COLUMNS (CSV ONLY),1.0,The Augment process is related to Augment with Columns (CSV Only) as it allows for the addition of extra fields to the Documents output when processing CSV data.,['827fd80da359cf05b091c24e465dd05d'],05bfaf60aa304a288e6789443bd6fd6c,629,1,1,2
DOCUMENT TABLE EMISSION,DOCUMENTS TABLE EMISSION,1.0,"Document Table Emission is the process of emitting the Documents table into the knowledge model, which is a part of the Documents Table Emission function.",['827fd80da359cf05b091c24e465dd05d'],6097e047a74d41ca996a0b7949ef6f0e,630,1,2,3
DOCUMENTS TABLE EMISSION,PHASE 6: NETWORK VISUALIZATION,1.0,"The Documents Table Emission is a prerequisite for Phase 6: Network Visualization, as it provides the data necessary for network visualization and understanding the relationships between documents.",['56506e2d064c0732efa3cf418057edfd'],e257439ce5be47a88faaeb0fe01bc4a1,631,2,7,9
PHASE 6: NETWORK VISUALIZATION,ENTITY-RELATIONSHIP GRAPH,1.0,"Phase 6: Network Visualization involves the Entity-Relationship graph, as it is one of the logical graphs that are visualized to understand the relationships between entities and their attributes.",['56506e2d064c0732efa3cf418057edfd'],067b9486d59f45d2963235220f723a41,632,7,1,8
PHASE 6: NETWORK VISUALIZATION,DOCUMENT GRAPH,1.0,"Phase 6: Network Visualization involves the Document graph, as it is one of the logical graphs that are visualized to understand the relationships between documents.",['56506e2d064c0732efa3cf418057edfd'],87c46c7ead5447bc8309ab116a316959,633,7,1,8
PHASE 6: NETWORK VISUALIZATION,NODES TABLE EMISSION,1.0,"Nodes Table Emission is a part of Phase 6: Network Visualization, as it is a process that emits a table of nodes for visualization, including information about whether the node is a document or an entity and the UMAP coordinates.",['56506e2d064c0732efa3cf418057edfd'],f607d795f00347109cab3b2370c414f7,634,7,1,8
DISCRIMINATOR,UMAP COORDINATES,1.0,The Discriminator and UMAP Coordinates are related in that the Discriminator can help in interpreting the UMAP Coordinates by providing context on whether the coordinates represent a document or an entity in the data structure,['2011f03f21e526cf9277c27bf3e68242'],8f0610c89e9f42e9b8c3d8a947fa2852,635,1,1,2
GRAPHRAG INDEXER CLI,CLI ARGUMENTS,1.0,"The GraphRAG Indexer CLI utilizes CLI Arguments to customize its functionality and behavior, allowing users to configure various aspects of the indexing process.",['f239de6498e0f471bf418974c00f1e36'],75ef3591790a49748154ddbba20e9cdf,636,1,8,9
CLI ARGUMENTS,VERBOSE,1.0,The verbose argument is a CLI Argument that can be used to increase the logging level during the execution of the GraphRAG Indexer CLI.,['f239de6498e0f471bf418974c00f1e36'],58b7f26cb17b4b2283d3cacbaed15cfc,637,8,1,9
CLI ARGUMENTS,INIT,1.0,"The init argument is a CLI Argument that initializes the data project directory for the GraphRAG Indexer CLI, setting up the necessary configuration and overrides.",['f239de6498e0f471bf418974c00f1e36'],277cdf13617e47ca883b949f495bc243,638,8,1,9
CLI ARGUMENTS,RESUME,1.0,"The resume argument is a CLI Argument that enables the GraphRAG Indexer CLI to resume a previous run, loading parquet files as inputs and skipping certain workflows.",['f239de6498e0f471bf418974c00f1e36'],26080c121c9645b2bb258e4d61d47672,639,8,1,9
CLI ARGUMENTS,CONFIG,1.0,"The config argument is a CLI Argument that allows the GraphRAG Indexer CLI to execute a custom configuration, overriding the default settings.",['f239de6498e0f471bf418974c00f1e36'],ee91a06f13b4495f95c800a0c7329ef7,640,8,1,9
CLI ARGUMENTS,REPORTER,1.0,The reporter argument is a CLI Argument that specifies the progress reporting mechanism for the GraphRAG Indexer CLI.,['f239de6498e0f471bf418974c00f1e36'],6ed8b67be79242e98aa1b9283431d5df,641,8,1,9
CLI ARGUMENTS,EMIT,1.0,The emit argument is a CLI Argument that determines the output formats for the tables generated by the GraphRAG Indexer CLI.,['f239de6498e0f471bf418974c00f1e36'],40c2425cb1c34c1591f7cb89f9f5e0bf,642,8,1,9
