id,name,type,description,human_readable_id,graph_embedding,text_unit_ids,description_embedding
b45241d70f0e43fca764df95b2b81f77,PYTHON 3.10-3.12,"SOFTWARE, VERSION","The Python programming language versions 3.10 to 3.12 are the supported and required versions for running and developing the GraphRAG system. These versions serve as the foundation for executing the library and its associated scripts, ensuring compatibility and optimal performance of the GraphRAG system.",0,,['4cf772ca8a1ffad729902e9b630e1ec0' '84d24b5db902baca7217b5e3bb6ec462'],"[ 0.05387061  0.00079517 -0.01745062 ... -0.00887034 -0.03218541
  0.02785086]"
4119fd06010c494caa07f439b333f4c5,POETRY,"SOFTWARE, TOOL","Poetry, a versatile package manager for Python projects, plays a crucial role in managing dependencies and virtual environments. It enables users to run the command-line interface (CLI) smoothly by setting up the required environment and installing necessary dependencies. This tool is indispensable for GraphRAG, as it facilitates the installation and management of dependencies, ensuring the project's seamless execution.",1,,['4cf772ca8a1ffad729902e9b630e1ec0' 'b0505e11596cadd9890fef049c29473c'],"[ 0.03598293  0.0058315  -0.01374399 ... -0.00311136 -0.00045949
  0.01299622]"
d3835bf3dda84ead99deadbeac5d0d7d,AZURITE,"SOFTWARE, EMULATOR","Azurite is an emulator for Azure resources, used in unit and smoke tests to simulate Azure environments for testing purposes.",2,,['4cf772ca8a1ffad729902e9b630e1ec0'],"[ 0.00274721  0.0070368  -0.00861453 ... -0.01325784 -0.00820657
  0.03066722]"
077d2820ae1845bcbb1803379a3d1eae,INDEXING ENGINE,"SOFTWARE, ENGINE",The Indexing Engine is a component of GraphRAG that can be executed using Poetry to process and index data for the graph database.,3,,['4cf772ca8a1ffad729902e9b630e1ec0'],"[-0.02380327 -0.00200924 -0.01421209 ... -0.02415464  0.02539852
 -0.00215737]"
3671ea0dd4e84c1a9b02c5ab2c8f4bac,QUERY ENGINE,"SOFTWARE, ENGINE","The Query Engine is a pivotal component of the GraphRAG system, serving as the retrieval module within the Graph RAG Library. It operates in tandem with the Indexing Pipeline, forming one of the two main components of the library. The Engine is designed to facilitate the querying of the graph database, enabling users to ask questions and retrieve information from the indexed data through various methods. It supports Global search for high-level questions, which is resource-intensive but provides comprehensive responses by understanding the dataset as a whole, and Local search for more specific inquiries, which is suitable for questions requiring an understanding of specific entities mentioned in the documents. The Engine combines relevant data from the AI-extracted knowledge-graph with text chunks of the raw documents and searches over all AI-generated community reports in a map-reduce fashion to generate answers. Additionally, it features question generation functionality, which is beneficial for creating follow-up questions in a conversation or for generating a list of questions to help investigators delve deeper into the dataset. The Query Engine can be executed using Poetry, enhancing its usability and flexibility in querying the graph database.",4,,"['4cf772ca8a1ffad729902e9b630e1ec0' '7c1bad237a1ef86cb41b6c5dbad4ffc3'
 'f8cf53ce98a8bc52581f7907ad98ef70']","[ 0.00931099  0.02480169 -0.00626694 ... -0.04054927 -0.01123014
  0.02734928]"
19a7f254a5d64566ab5cc15472df02de,LIFECYCLE SCRIPTS,"SOFTWARE, SCRIPTS","Lifecycle Scripts are a set of scripts managed by Poetry and poethepoet, used for various tasks such as building, testing, and executing the GraphRAG package.",5,,['4cf772ca8a1ffad729902e9b630e1ec0'],"[ 0.01815265 -0.01357458 -0.00472059 ... -0.01955523  0.03126961
  0.0109931 ]"
e7ffaee9d31d4d3c96e04f911d0a8f9e,UNIT AND SMOKE TESTS,,,6,,['4cf772ca8a1ffad729902e9b630e1ec0'],"[ 0.03679015 -0.01040786 -0.00705258 ...  0.03909829  0.02631698
  0.01682895]"
f7e11b0e297a44a896dc67928368f600,CLI,"COMMAND, TOOL","CLI, or Command Line Interface, is a versatile tool enabling users to interact with software by inputting text commands. Specifically, in the context provided, CLI serves as the interface for executing tasks using the poetry tool. This tool facilitates the operation of a pipeline by allowing users to provide commands and arguments. It can be seamlessly integrated with a Config File, either in default or custom config mode, to enhance its functionality. Depending on the user's environment, the CLI can be accessed through either Poetry or Node, offering flexibility in usage.",7,,['563caa38fe33c495449888d62950b959' 'b0505e11596cadd9890fef049c29473c'],"[-0.00189303 -0.01444735  0.01549449 ... -0.00637752  0.00621518
  0.00154714]"
1fd3fa8bb5a2408790042ab9573779ee,POETRY RUN POE QUERY,"COMMAND, TOOL","poetry run poe query is a command used to run the Query CLI, which allows for executing queries through the command line interface.",8,,['563caa38fe33c495449888d62950b959'],"[ 0.0154725  -0.01258719 -0.00351024 ... -0.01584766  0.01006138
 -0.00675125]"
27f9fbe6ad8c4a8b9acee0d3596ed57c,POETRY BUILD,"COMMAND, TOOL","poetry build is a command that invokes the build process, creating a wheel file and other distributable artifacts for the package.",9,,['563caa38fe33c495449888d62950b959'],"[-0.00078879 -0.00915426 -0.0455677  ... -0.02824374  0.02638447
  0.01357066]"
e1fd0e904a53409aada44442f23a51cb,POETRY RUN POE TEST,"COMMAND, TOOL","poetry run poe test is a command that executes all tests for the package, ensuring its functionality and integrity.",10,,['563caa38fe33c495449888d62950b959'],"[ 0.01390883 -0.00721496 -0.01120682 ... -0.00608813  0.02774766
  0.00364074]"
de988724cfdf45cebfba3b13c43ceede,POETRY RUN POE TEST_UNIT,"COMMAND, TOOL","poetry run poe test_unit is a command that specifically executes unit tests, which are tests that verify the correctness of individual units of code.",11,,['563caa38fe33c495449888d62950b959'],"[ 0.01667821 -0.00810335 -0.01326549 ...  0.03134498  0.03157637
  0.0029704 ]"
96aad7cb4b7d40e9b7e13b94a67af206,POETRY RUN POE TEST_INTEGRATION,"COMMAND, TOOL","poetry run poe test_integration is a command that executes integration tests, which are tests that verify the interaction between different parts of the system.",12,,['563caa38fe33c495449888d62950b959'],"[-0.00294341 -0.00703554 -0.00641368 ...  0.00052264  0.01944592
 -0.01392747]"
c9632a35146940c2a86167c7726d35e9,POETRY RUN POE TEST_SMOKE,"COMMAND, TOOL","poetry run poe test_smoke is a command that executes smoke tests, which are a preliminary set of tests to ensure that the system is in a stable state before more extensive testing.",13,,['563caa38fe33c495449888d62950b959'],"[ 0.02566768 -0.0088948   0.00046035 ...  0.03196016  0.02071824
  0.00991177]"
9646481f66ce4fd2b08c2eddda42fc82,POETRY RUN POE CHECK,"COMMAND, TOOL","poe check is a command that performs a suite of static checks across the package, including formatting, documentation formatting, linting, security patterns, and type-checking.",14,,['563caa38fe33c495449888d62950b959'],"[ 0.02191271 -0.02804939  0.0116406  ... -0.00818111  0.04510696
 -0.00926971]"
d91a266f766b4737a06b0fda588ba40b,POETRY RUN POE FIX,"COMMAND, TOOL","poetry run poe fix is a command that applies any available auto-fixes to the package, typically limited to formatting fixes.",15,,['563caa38fe33c495449888d62950b959'],"[ 0.00047398 -0.02235238  0.02275948 ... -0.00095179  0.03101803
 -0.00462697]"
bc0e3f075a4c4ebbb7c7b152b65a5625,POETRY RUN POE FIX_UNSAFE,"COMMAND, TOOL","poetry run poe fix_unsafe is a command that applies any available auto-fixes to the package, including those that may be unsafe, potentially altering the code in ways that could affect its functionality.",16,,['563caa38fe33c495449888d62950b959'],"[-0.01566155 -0.00351695  0.01823715 ...  0.03200512  0.02915998
 -0.01473395]"
254770028d7a4fa9877da4ba0ad5ad21,POETRY RUN POE FORMAT,"COMMAND, TOOL","poetry run poe format is a command that explicitly runs the formatter across the package, ensuring consistent code style and formatting.",17,,['563caa38fe33c495449888d62950b959'],"[ 0.01859432 -0.00570302 -0.00691578 ... -0.00042143  0.03213897
 -0.01022494]"
4a67211867e5464ba45126315a122a8a,TROUBLESHOOTING,"SECTION, DOCUMENT",Troubleshooting is a section that provides solutions to common problems encountered when using the software or executing commands. It includes specific steps to resolve issues such as missing dependencies or configuration errors.,18,,['563caa38fe33c495449888d62950b959'],"[-0.00074178 -0.05208278 -0.01349145 ... -0.00159159  0.01143478
  0.01284645]"
04dbbb2283b845baaeac0eaf0c34c9da,RUNTIMEERROR,"ERROR, SOFTWARE_ISSUE","A RuntimeError occurred when executing the command 'poetry install', indicating that 'llvm-config' failed to execute. The error suggests that the user should point the LLVM_CONFIG environment variable to the path for llvm-config. This issue is related to the LLVM configuration and is a common software error encountered during the installation process.",19,,['0dc1f5e4f8fb5903f12acf8e141fb205'],"[-0.00231169  0.00039691 -0.01318261 ...  0.02004192 -0.01885981
 -0.02007212]"
1943f245ee4243bdbfbd2fd619ae824a,LLVM_CONFIG,"ENVIRONMENT_VARIABLE, CONFIGURATION",LLVM_CONFIG is an environment variable that needs to be set to the path of the llvm-config executable. This variable is crucial for the proper functioning of LLVM-related tools and components in the software development environment.,20,,['0dc1f5e4f8fb5903f12acf8e141fb205'],"[ 0.02127778  0.01080136  0.00414336 ... -0.01269126 -0.0514576
  0.04291604]"
273daeec8cad41e6b3e450447db58ee7,LLVM-9,"SOFTWARE, DEVELOPMENT_TOOL","llvm-9 is a version of the LLVM compiler infrastructure, which is a collection of modular and reusable compiler and toolchain technologies. It is required for the installation process to proceed without errors related to the 'llvm-config' executable.",21,,['0dc1f5e4f8fb5903f12acf8e141fb205'],"[ 0.01338959  0.01886567 -0.01650851 ...  0.02144708 -0.05054867
  0.02751447]"
e69dc259edb944ea9ea41264b9fcfe59,LLVM-9-DEV,"SOFTWARE, DEVELOPMENT_TOOL","llvm-9-dev is a development package for the LLVM compiler infrastructure version 9. It contains headers and libraries necessary for building software that uses LLVM, and is required for the installation process to proceed without errors related to the 'llvm-config' executable.",22,,['0dc1f5e4f8fb5903f12acf8e141fb205'],"[ 0.01065756  0.00987969  0.0113801  ...  0.02262068 -0.04862509
  0.00313632]"
e2f5735c7d714423a2c4f61ca2644626,POETRY INSTALL,"COMMAND, INSTALLATION_PROCESS",poetry install is a command used in the poetry package manager to install all dependencies for a project as specified in the pyproject.toml file. This command is essential for setting up the development environment for a Python project.,23,,['0dc1f5e4f8fb5903f12acf8e141fb205'],"[ 0.01721992  0.00490774 -0.01833928 ... -0.01264532  0.03533192
 -0.01271921]"
deece7e64b2a4628850d4bb6e394a9c3,PYTHON.H,"FILE, HEADER_FILE","Python.h is a header file that provides the definitions and declarations for the Python C API. It is required for building C extensions for Python and is missing when the error ""numba/_pymodule.h:6:10: fatal error: Python.h: No such file or directory"" occurs during the 'poetry install' process.",24,,['0dc1f5e4f8fb5903f12acf8e141fb205'],"[ 0.01077783  0.00110121  0.00250873 ...  0.02691118  0.02089267
 -0.01913596]"
e657b5121ff8456b9a610cfaead8e0cb,PYTHON3.10-DEV,"SOFTWARE, DEVELOPMENT_TOOL","python3.10-dev is a development package for Python version 3.10. It contains headers, libraries, and other resources necessary for building Python extensions and applications. It is required to resolve the error related to the missing Python.h file during the 'poetry install' process.",25,,['0dc1f5e4f8fb5903f12acf8e141fb205'],"[ 0.00846249 -0.00060164 -0.01380815 ...  0.01938593  0.00993687
 -0.01609161]"
bf4e255cdac94ccc83a56435a5e4b075,GRAPHRAG_LLM_THREAD_COUNT,"ENVIRONMENT_VARIABLE, CONFIGURATION","GRAPHRAG_LLM_THREAD_COUNT is a configuration property and environment variable within the GraphRAG system, specifically impacting the Large Language Model (LLM) component. This variable determines the number of threads allocated for processing requests in the Human-in-the-Loop Request Augmentation Gateway (HRAG). By default, GRAPHRAG_LLM_THREAD_COUNT is set to 50, enabling high concurrency. However, this default setting may lead to potential performance issues due to the high number of threads. Modifying GRAPHRAG_LLM_THREAD_COUNT can help in reducing concurrency and enhancing system stability.",26,,['0dc1f5e4f8fb5903f12acf8e141fb205' '9aff9243c57cabca574b35438bf31a50'],"[ 0.03271159  0.01949904 -0.0138933  ... -0.0341273  -0.02751046
  0.02617218]"
3b040bcc19f14e04880ae52881a89c1c,GRAPHRAG_EMBEDDING_THREAD_COUNT,"ENVIRONMENT_VARIABLE, CONFIGURATION","GRAPHRAG_EMBEDDING_THREAD_COUNT is an environment variable pivotal in the Motor Control and Drive Systems domain, specifically within the context of the GraphRAG system. This variable dictates the number of threads allocated to the embedding component, a crucial aspect of the system's performance and efficiency. By default, GRAPHRAG_EMBEDDING_THREAD_COUNT is set to 50, which, while promoting high concurrency, may inadvertently trigger performance issues due to excessive thread usage. Adjusting this variable can significantly mitigate concurrency-related problems, thereby enhancing the stability and overall performance of the GraphRAG system. This understanding is essential for professionals in the Motor Control and Drive Systems domain looking to optimize their systems and avoid potential bottlenecks.",27,,['0dc1f5e4f8fb5903f12acf8e141fb205' '2b777e3d591ce1511a03abd1a6d8dc73'],"[ 0.0116748   0.03142565 -0.01624197 ... -0.03390775 -0.03220916
 -0.02576124]"
3d6b216c14354332b1bf1927ba168986,GRAPHRAG,"PRODUCT, TECHNOLOGY","GraphRAG (Graph Retrieval-Augmented Generation) is a sophisticated software tool developed by Microsoft Research, designed to enhance the capabilities of Large Language Models (LLMs) in reasoning about complex information, particularly within private datasets. It operates by extracting a knowledge graph from the input corpus, which is then augmented with community summaries and graph machine learning outputs to improve query responses. GraphRAG demonstrates a significant enhancement in answering intricate questions compared to other approaches.

The process involves indexing and slicing the input corpus into TextUnits, followed by entity and relationship extraction. Hierarchical clustering using the Leiden technique is applied to identify themes and semantic clusters, enabling a more effective global search. Summaries of each community are generated to provide a holistic understanding of the dataset, facilitating the summarization of themes in response to user queries.

GraphRAG is a structured, hierarchical approach to Retrieval Augmented Generation (RAG) that leverages the natural modularity of graphs to partition data for global summarization. It is distinct from other graph-based RAG systems by its ability to create domain adaptive templates for the generation of knowledge graphs. This feature improves the results of an Index Run by adapting to specific domains through the use of templates.

The tool requires an initialized workspace with the graphrag.index --init command to function properly. The initialization process creates necessary configuration files and default prompts. Users can customize the template generation algorithm by tweaking various parameters, allowing for greater flexibility and adaptability to different domains.

GraphRAG is a system for managing and processing graph-based data, offering features such as indexing, querying, and adapting prompts for better data handling. It is a software product that enhances the question-and-answer performance of Language Models (LMs) by using knowledge graphs, aiming to provide better insights and understanding compared to Baseline RAG. GraphRAG is a tool that enables the analysis of LLM-generated knowledge graphs, providing insights into the structure and themes of datasets.",28,,"['12294feb07a1d202b27241eaaf64718b' '32603b739bed06b4695b0cc3915b2c4b'
 '369b39fdfd649d6df32a5d7b4cc559b7' '3e143a60e2aeb57eb418a68d1484bbb3'
 '812b3414c467da0b62f7932d2adcbad4' '849698743b07680402ff8572b1c6c469'
 '9b364093aeecfc789c70fc5bd9503487' 'd0f7c236538005bc3056b7daed2401d8'
 'd441b136505c273cf3577b6867e872e4' 'e015335cdcae20e6546fe7cbdef56c1a'
 'e6fa3bdaf65c92df6b3430f02804321a']","[ 0.03192798  0.0029551  -0.02123717 ... -0.0067685  -0.01572336
  0.04018514]"
1c109cfdc370463eb6d537e5b7b382fb,GPT-4 TURBO,"PRODUCT, TECHNOLOGY","GPT-4 Turbo is a version of the GPT-4 model that is used to generate knowledge graphs from text data. It is capable of creating detailed and structured representations of information, which can be used in various applications including GraphRAG.",29,,['e6fa3bdaf65c92df6b3430f02804321a'],"[ 0.04422943 -0.02396359  0.01973582 ...  0.00576751  0.00381952
 -0.01833563]"
3d0dcbc8971b415ea18065edc4d8c8ef,MICROSOFT RESEARCH BLOG POST,ONLINE_RESOURCE,The Microsoft Research Blog Post is an online resource that provides information about GraphRAG and how it can be used to enhance the ability of Large Language Models (LLMs) to reason about private data. It offers insights into the GraphRAG system and its applications.,30,,['e6fa3bdaf65c92df6b3430f02804321a'],"[ 0.02823504  0.01516174 -0.02106258 ...  0.02029049 -0.04670781
  0.04743102]"
68105770b523412388424d984e711917,GITHUB REPOSITORY,ONLINE_RESOURCE,"The GitHub Repository is an online resource where the source code and documentation for GraphRAG can be found. It is a platform for developers to access, contribute to, and collaborate on the GraphRAG project.",31,,['e6fa3bdaf65c92df6b3430f02804321a'],"[ 0.01204341  0.0212788  -0.01416511 ... -0.02347205  0.01786183
 -0.01050931]"
85c79fd84f5e4f918471c386852204c5,GRAPHRAG ARXIV,ONLINE_RESOURCE,"GraphRAG Arxiv is an online resource that contains research papers and documentation related to GraphRAG. It is a repository for academic and technical papers that discuss the theory, implementation, and applications of GraphRAG.",32,,['e6fa3bdaf65c92df6b3430f02804321a'],"[ 0.02132612  0.01793148 -0.00309032 ... -0.01484746 -0.00255113
 -0.01938851]"
eae4259b19a741ab9f9f6af18c4a0470,SOLUTION ACCELERATOR,"PRODUCT, TECHNOLOGY",The Solution Accelerator is a package that provides a user-friendly end-to-end experience with Azure resources for quickstarting the GraphRAG system. It is recommended for users who want to start using GraphRAG with ease.,33,,['e6fa3bdaf65c92df6b3430f02804321a'],"[ 0.0028679   0.0280288  -0.02645066 ... -0.02471621 -0.00904732
  0.02096158]"
3138f39f2bcd43a69e0697cd3b05bc4d,GET STARTED GUIDE,ONLINE_RESOURCE,"The ""GET STARTED GUIDE"" is a comprehensive resource designed to assist new users in effectively utilizing the GraphRAG software. Available both as a document and an online resource, it offers clear instructions and information to help users understand the basic functionalities and setup process of the system. The guide provides a step-by-step approach, making it easy for beginners to navigate through the initial stages of using GraphRAG.",34,,['32603b739bed06b4695b0cc3915b2c4b' 'e6fa3bdaf65c92df6b3430f02804321a'],"[ 0.02576707  0.00559134 -0.02945534 ... -0.02937737  0.00635886
  0.02401094]"
dde131ab575d44dbb55289a6972be18f,INDEXER,"PRODUCT, TECHNOLOGY","The Indexer is a sophisticated software tool and a critical sub-system of GraphRAG, designed to process, organize, and prepare data for efficient search, analysis, and retrieval. It excels in handling and processing large datasets by extracting information from raw text, indexing it, and building a structured knowledge graph represented in .parquet output files. These files contain structured data that is accessible for both Local and Global search methods, ensuring that the data is ready for querying and analysis. The Indexer's role is pivotal in the GraphRAG process, as it creates a structured representation of information, enabling the software to manage and process extensive data sets effectively.",35,,"['32603b739bed06b4695b0cc3915b2c4b' '8c70a7321fb0e945054d226a8c69abee'
 'ae6e91a8cc5773dbd4789773c9ef5a30' 'e6fa3bdaf65c92df6b3430f02804321a']","[ 0.01353317 -0.00178407 -0.04319632 ... -0.00494313 -0.01169442
  0.01400428]"
de9e343f2e334d88a8ac7f8813a915e5,QUERY PACKAGE,"PRODUCT, TECHNOLOGY","The Query package, a crucial sub-system of GraphRAG, serves as a powerful tool for users seeking to explore and extract information from the knowledge graph. It facilitates the search process within the indexed data, allowing users to interact effectively with the graph and retrieve pertinent results. This subsystem ensures that users can efficiently query the knowledge graph, making it an essential component for anyone aiming to harness the full potential of GraphRAG's data resources.",36,,['32603b739bed06b4695b0cc3915b2c4b' 'e6fa3bdaf65c92df6b3430f02804321a'],"[ 0.02977812 -0.00145355 -0.026257   ... -0.0460513  -0.01353162
  0.02569106]"
e2bf260115514fb3b252fd879fb3e7be,SOLUTION ACCELERATOR PACKAGE,"PRODUCT, SOFTWARE","The Solution Accelerator package is a software product designed to offer a user-friendly experience in managing and utilizing Azure resources, streamlining the process for end-users.",37,,['32603b739bed06b4695b0cc3915b2c4b'],"[-0.02636567  0.02656752 -0.02280916 ... -0.01667903 -0.01866167
  0.02848459]"
b462b94ce47a4b8c8fffa33f7242acec,BASELINE RAG,"PRODUCT, SOFTWARE","Baseline RAG (Retrieval-Augmented Generation) is a foundational technology in LLM-based tools that enhances the outputs of Language Models (LMs) by incorporating real-world information through a vector search method. This technique identifies semantically similar text content within a dataset, aiming to solve problems in communications by connecting disparate pieces of information. However, Baseline RAG has limitations in handling complex information and reasoning about private datasets. It struggles with queries that require aggregation of information across the dataset, as it relies on finding text that is semantically similar to the query, rather than traversing through shared attributes for new insights. Additionally, Baseline RAG performs poorly in understanding summarized semantic concepts over large data collections or singular large documents. Despite these challenges, Baseline RAG remains a crucial approach in leveraging vector similarity to augment language model outputs.",38,,"['32603b739bed06b4695b0cc3915b2c4b' '3e143a60e2aeb57eb418a68d1484bbb3'
 'd441b136505c273cf3577b6867e872e4']","[ 0.01401414  0.02271356  0.00639585 ...  0.05172024 -0.01968571
  0.04691074]"
17ed1d92075643579a712cc6c29e8ddb,LLMS,"TECHNOLOGY, ARTIFICIAL INTELLIGENCE","LLMS, also known as Large Language Models (LLMs), are sophisticated AI models designed to process and generate text that closely mimics human language. These models are widely utilized in research studies and various applications due to their ability to understand complex linguistic patterns. In the context of GraphRAG, LLMs play a pivotal role in constructing a knowledge graph from an input corpus. They excel in tasks such as entity and relationship extraction, as well as hierarchical clustering, making them indispensable tools for analyzing and structuring large volumes of textual data.",39,,"['40f2d6a0270e54743e7ace239369da96' '53455f8552b0787cb13c5a03eb550842'
 '6dace8e490674ac8e031aed987a63789' 'd441b136505c273cf3577b6867e872e4']","[ 0.05993932  0.02003021 -0.00636358 ...  0.02656004 -0.0547429
  0.03957954]"
3ce7c210a21b4deebad7cc9308148d86,LEIDEN TECHNIQUE,"METHOD, ALGORITHM","The Leiden Technique is a sophisticated algorithm employed in the GraphRAG process for hierarchical clustering of graphs. This method, a refined version of the Louvain method, is instrumental in visually representing the clustering of entities and relationships within the graph. In the visual representation, entities are depicted as circles, where the size of the circle corresponds to the degree of the entity, and the color signifies its community, providing a comprehensive and intuitive understanding of the graph's structure and dynamics.",40,,['369b39fdfd649d6df32a5d7b4cc559b7' 'd441b136505c273cf3577b6867e872e4'],"[ 0.01776054  0.00157537  0.03120119 ... -0.01538379 -0.00719793
  0.04267764]"
d64ed762ea924caa95c8d06f072a9a96,TEXTUNITS,DATA UNIT,"TextUnits are the analyzable units created by slicing up the input corpus in the GraphRAG process. They serve as the basis for entity, relationship, and key claim extraction and provide fine-grained references into the outputs.",41,,['369b39fdfd649d6df32a5d7b4cc559b7'],"[ 0.01711229 -0.00938693  0.00505242 ...  0.01319462  0.03364523
  0.00559151]"
adf4ee3fbe9b4d0381044838c4f889c8,LLM,"TECHNOLOGY, TOOL","LLM, or Language Learning Model, is a pivotal technology in the domain of text analysis, serving multiple functions such as summarization, entity resolution, and claim extraction. It is employed to capture unique information from various descriptions, reconcile entities that denote the same real-world entity but are known by different names, and distill claims from source TextUnits. LLM acts as a configuration property in entity extraction, where it specifies the language model to be utilized for analyzing text. This technology is integral to the GraphRAG process, aiding in the identification of entities, relationships, and key claims within TextUnits. The 'llm' configuration setting is critical, as it determines the AI or machine learning model that will process the text in various processes such as entity extraction, summarization, and claim extraction. Additionally, 'llm' is a configuration field within community_reports, referring to the top-level LLM configuration. This setting encompasses parameters that define the operational aspects of the language model and its application within the system.",42,,"['1a4bca0786d529c91073997b63412adc' '369b39fdfd649d6df32a5d7b4cc559b7'
 '3e143a60e2aeb57eb418a68d1484bbb3' '53f1b5ad1d2f4ee5dfb53a8f1ff3ec14'
 '9cbd4e21339eeed5e22a638e52a094cb' 'abac77a5673e907cf8d65161c2612784'
 'd27237468a1b9e89110eeeca8080f63c' 'd44248ff7b7bfd969a7208eb3d6e2a78']","[ 0.02605454  0.00751888 -0.02844662 ...  0.0064631  -0.06743792
  0.07708047]"
32ee140946e5461f9275db664dc541a5,COMMUNITY SUMMARIES,"DATA, OUTPUT","Community Summaries are a pivotal component within the GraphRAG framework, serving as a kind of self-memory for generation-augmented retrieval that facilitates future generation cycles. These summaries are pre-generated for groups of closely-related entities identified in the entity knowledge graph, designed to scale to very large datasets and independently useful for understanding the global structure and semantics of the dataset. They are created for each community in the Leiden hierarchy, allowing for answering questions at different hierarchical levels, which may offer varying balances of detail and scope for general sensemaking questions. The summaries are categorized into different levels (C0-C3), with C0 being the root-level summary and C3 the low-level summary, providing a more concise representation of the original content.

The summaries are prepared by shuffling and dividing them into chunks of pre-specified token size to ensure even distribution of relevant information. They are ranked based on the number of tokens they contain, and shorter summaries may replace longer ones to fit within the context window. The summaries are used to generate community answers, which are then combined into a global answer. The global answer is generated by mapping community answers, generating intermediate answers for each chunk, and reducing them to a single global answer. The intermediate answers are scored by an LLM on a scale of 0-100 based on their helpfulness in answering the target question, with answers scoring 0 being filtered out. The global answer is the final result of this process, making the community summaries a crucial element in the generation of a comprehensive and contextually relevant response to user queries.

For leaf-level communities, element summaries are added to the LLM context window until the token limit is reached. For higher-level communities, if all element summaries fit within the token limit, they are summarized as is; otherwise, sub-community summaries are substituted for their associated element summaries to fit within the context window. Community summaries are condensed versions of information or data, often created by or for a community, which can be used to provide an overview or key insights from a larger set of data or documents. They are generated for leaf-level and higher-level communities to provide an overview of the elements (nodes, edges, covariates) within a corpus, prioritized based on the prominence of the elements, and used to make sense of a corpus or to answer global queries.",43,,"['369b39fdfd649d6df32a5d7b4cc559b7' '7040ba36a7c09899a355d14a30d65375'
 '71f14506a6b15dfabd93fd1606a67b73' '7da3d8d244b67f09425a4a7783e4bb55'
 '849698743b07680402ff8572b1c6c469' '93d4d4effbf989e6ef1c4c3b4f42494e'
 '9b52298451f8936974ab08a129b0b92e' 'a660289d2bf43f25d3524d35cd2d9a96'
 'b149708d0b4ac3ff417565739ea6b03b' 'd08fc91bbfe9749abab38a99a1a88dc6'
 'f76c18c7582167c3626f8741c2c9374f']","[ 0.06163266  0.00447385 -0.02342983 ... -0.03188805 -0.00943854
  0.0460614 ]"
c160b9cb27d6408ba6ab20214a2f3f81,GLOBAL SEARCH,"FUNCTION, QUERY MODE","Global Search is a comprehensive query method designed to answer complex, high-level questions about a dataset by aggregating information across the entire dataset. This method leverages the structure of an LLM-generated knowledge graph to identify themes and semantic clusters, enabling the summarization of these themes in response to user queries. Global Search is particularly useful after the Indexer has processed the data, as it allows for the exploration of the dataset's overall content and structure. In the context of the GraphRAG process, Global Search serves as a query mode that facilitates reasoning about holistic questions concerning the corpus by utilizing community summaries. The Query Engine employs Global Search to generate answers by searching over all AI-generated community reports in a map-reduce fashion, which, although resource-intensive, often yields high-quality responses for questions that require an understanding of the dataset as a whole.",44,,"['369b39fdfd649d6df32a5d7b4cc559b7' '3e143a60e2aeb57eb418a68d1484bbb3'
 'ae6e91a8cc5773dbd4789773c9ef5a30' 'f8cf53ce98a8bc52581f7907ad98ef70']","[ 0.02916778  0.02550031 -0.0547419  ... -0.0287048  -0.04299146
  0.04123661]"
23527cd679ff4d5a988d52e7cd056078,LOCAL SEARCH,"FUNCTION, QUERY MODE","Local Search is a sophisticated method employed in the GraphRAG process and the Query Engine, designed to answer specific questions about particular aspects or entities within a dataset. This technique combines structured data from the knowledge graph with unstructured data from input documents to augment the context of a language model with relevant entity information at query time. It is particularly adept at providing detailed information about specific characters, themes, or relationships within the data, offering a more targeted approach to data exploration.

Local Search enables reasoning about specific entities by exploring their immediate neighbors and associated concepts in a graph or network. It uses a context builder class to generate context for the search and can be enhanced with various parameters such as llm_params and context_builder_params. This method is suitable for questions that require an understanding of specific entities mentioned in the documents, as it can extract and prioritize relevant structured and unstructured data, including entities, relationships, and other data records, which are then used to generate context for question generation.

However, Local Search is limited in its ability to aggregate information across the entire dataset, focusing instead on finding information that is semantically similar to a query within a specific context. By fanning out to the neighbors and associated concepts of a particular entity, Local Search offers a powerful tool for data exploration and question answering in specialized professional networks and beyond.",45,,"['1415949832ba3fee570ea961998a8ac4' '364624242a84e1859e758069d914d8c8'
 '369b39fdfd649d6df32a5d7b4cc559b7' '3e143a60e2aeb57eb418a68d1484bbb3'
 '849698743b07680402ff8572b1c6c469' 'ae6e91a8cc5773dbd4789773c9ef5a30'
 'f8cf53ce98a8bc52581f7907ad98ef70']","[ 0.05030566  0.02945241 -0.02895395 ... -0.01047921 -0.04997007
  0.03152579]"
f1c6eed066f24cbdb376b910fce29ed4,PROMPT TUNING,"FUNCTION, TECHNIQUE","Prompt Tuning is a pivotal feature of the GraphRAG indexing engine, designed to optimize and customize the prompts used in the generation of knowledge graphs. This technique is highly recommended for enhancing the performance of GraphRAG with specific datasets, as it allows for the creation of domain-adaptive templates that can significantly improve the outcomes of Index Runs. The process entails loading inputs, dividing them into text units, and executing a series of Large Language Model (LLM) invocations and template substitutions to generate refined prompts. Users are provided with default values by the system for ease of use, but the real power of Prompt Tuning lies in its ability to fine-tune these prompts according to the guidelines detailed in the GraphRAG documentation. By specifying a custom prompt file in plaintext and employing token replacements, users can tailor the prompts to their specific use cases, thereby boosting the effectiveness of knowledge discovery and natural language processing tasks. This customization ensures that the models perform optimally in the context of graph-based reasoning, making Prompt Tuning an essential tool for achieving the best possible results in knowledge graph creation.",46,,"['369b39fdfd649d6df32a5d7b4cc559b7' '4f37c0e9c3c9bac4e5c1c6821eea442e'
 '6a7157695d90d434b2625c3f05420916' '849698743b07680402ff8572b1c6c469'
 'bdb8f9e797229f596744d9636ab857b0']","[ 0.03003082 -0.000299   -0.0274499  ... -0.01475671 -0.03815292
  0.02113666]"
83a6cb03df6b41d8ad6ee5f6fef5f024,CORPUS,"DOCUMENT, DATA","The corpus refers to a collection of documents or data that is being analyzed or processed, often used in natural language processing tasks to train models or extract information.",47,,['849698743b07680402ff8572b1c6c469'],"[-0.00486921 -0.01272626  0.01049907 ...  0.01207374 -0.00793141
  0.04151285]"
147c038aef3e4422acbbc5f7938c4ab8,INDEXING PIPELINE,"SOFTWARE, MODULE","The Indexing Pipeline is a crucial system component within the Graph RAG library, designed to index data for efficient searchability and accessibility. It operates alongside the Query Engine, the other primary component of the library. The Indexing Pipeline prepares data by creating an index, enabling the Query Engine to perform searches and generate answers. This process can be initiated after setting up the workspace and adapting prompts. It involves executing a Python script with parameters such as the root directory and model configuration to structure the data for subsequent querying. As one of the two main components of the Graph RAG library, the Indexing Pipeline plays a pivotal role in making data searchable and ready for various operations and analyses.",48,,"['32e96c66a531ecd0a8edc7414aec0803' '7c1bad237a1ef86cb41b6c5dbad4ffc3'
 'd0f7c236538005bc3056b7daed2401d8' 'f8cf53ce98a8bc52581f7907ad98ef70']","[-0.00828238  0.01422682  0.00206589 ... -0.02751759  0.01431841
  0.04029059]"
b7702b90c7f24190b864e8c6e64612a5,QUESTION GENERATION,"FUNCTION, PROCESS","Question Generation is a sophisticated feature of the Query Engine designed to enhance data exploration and conversation flow. This functionality takes a list of user queries and generates the next set of candidate questions, combining structured data from a knowledge graph with unstructured data from input documents. It is particularly useful for creating follow-up questions that represent important or urgent information content or themes in the data, enabling investigators to explore a dataset more thoroughly and dive deeper into its nuances. Detailed information on how this feature works can be found at the Question Generation documentation page.",49,,"['1415949832ba3fee570ea961998a8ac4' '364624242a84e1859e758069d914d8c8'
 'f8cf53ce98a8bc52581f7907ad98ef70']","[ 0.03879185  0.00335084 -0.04743904 ... -0.01998548 -0.00787726
  0.01097764]"
de6fa24480894518ab3cbcb66f739266,GLOBAL SEARCH DOCUMENTATION,"DOCUMENT, REFERENCE","The Global Search documentation provides detailed information about the Global Search functionality, which is a tool for searching and retrieving information across various sources. It is referenced as a source for more information about the topic discussed in the text.",50,,['364624242a84e1859e758069d914d8c8'],"[ 0.00587881 -0.02959868 -0.03767684 ... -0.02977955  0.01146482
  0.01564214]"
6fae5ee1a831468aa585a1ea09095998,ENTITY-BASED REASONING,"CONCEPT, APPROACH",Entity-based Reasoning is an approach used in the local search method. It involves the use of entities and their relationships to reason about information in the context of a user query. This approach is effective for answering questions that require knowledge about specific entities and their properties.,51,,['364624242a84e1859e758069d914d8c8'],"[ 0.00972479  0.02144418 -0.03262778 ... -0.00284784 -0.04521257
  0.0243754 ]"
ef32c4b208d041cc856f6837915dc1b0,EMBEDDING,"PROPERTY, TECHNIQUE",Embedding is a technique used in the local search method to represent entities and text in a numerical format that can be processed by machine learning models. It is a key component in the Entity-Text Unit Mapping process.,52,,['364624242a84e1859e758069d914d8c8'],"[ 8.26995296e-04  2.25343909e-02 -2.37465799e-02 ... -1.85007229e-03
 -4.91924509e-02  7.86358505e-05]"
07b2425216bd4f0aa4e079827cb48ef5,ENTITY-TEXT UNIT MAPPING,"PROPERTY, TECHNIQUE",Entity-Text Unit Mapping is a process in the local search method that associates entities with relevant text units. This mapping is used to identify and prioritize text units that are relevant to a user query.,53,,['364624242a84e1859e758069d914d8c8'],"[ 0.01188195  0.03285125 -0.0340352  ... -0.01522883 -0.03848728
  0.00523186]"
2670deebfa3f4d69bb82c28ab250a209,RANKING + FILTERING,"PROPERTY, TECHNIQUE","Ranking + Filtering is a technique used in the local search method to prioritize and select the most relevant entities, text units, community reports, relationships, and covariates based on their relevance to a user query.",54,,['364624242a84e1859e758069d914d8c8'],"[ 0.02932572  0.01405956 -0.02588637 ...  0.01950563 -0.00470163
  0.02681634]"
404309e89a5241d6bff42c05a45df206,ENTITY-REPORT MAPPING,"PROPERTY, TECHNIQUE",Entity-Report Mapping is a process in the local search method that associates entities with relevant community reports. This mapping is used to identify and prioritize community reports that are relevant to a user query.,55,,['364624242a84e1859e758069d914d8c8'],"[-0.01052406  0.05573114 -0.06723902 ... -0.01424479 -0.04304938
  0.01041998]"
b785a9025069417f94950ad231bb1441,ENTITY-ENTITY RELATIONSHIPS,"PROPERTY, CONCEPT",Entity-Entity Relationships are connections between entities that are identified and prioritized in the local search method. These relationships are used to understand the connections between entities and to answer questions that require knowledge about these connections.,56,,['364624242a84e1859e758069d914d8c8'],"[ 0.02576567  0.05646011 -0.03447862 ...  0.00982271 -0.03030518
  0.00640629]"
3b6cd96a27304614850709aba1c9598b,ENTITY-COVARIATE MAPPINGS,"PROPERTY, TECHNIQUE",Entity-Covariate Mappings is a process in the local search method that associates entities with relevant covariates. This mapping is used to identify and prioritize covariates that are relevant to a user query.,57,,['364624242a84e1859e758069d914d8c8'],"[ 0.0395127   0.0577594  -0.02185163 ... -0.04588192 -0.04726489
  0.00235077]"
d54956b79dd147f894b67a8b97dcbef0,USER QUERY,"INPUT, QUERY","A User Query represents a specific question, request, or command initiated by a user, serving as the catalyst for information retrieval and navigation within the GraphRAG system and community summaries. This query can be directed towards seeking answers based on the dataset and its themes, and it often includes conversation history to provide additional context for a more refined search. As the starting point for entity and relationship extraction, the User Query plays a pivotal role in initiating the local search process within the knowledge graph, enabling the exploration of the corpus and identification of relevant information.",58,,"['3a0742c280217fe600b9af2d06b58eea' '812b3414c467da0b62f7932d2adcbad4'
 '93d4d4effbf989e6ef1c4c3b4f42494e']","[ 0.053922    0.01113427 -0.03654145 ... -0.03150476 -0.01704401
  0.03799714]"
958beecdb5bb4060948415ffd75d2b03,CONVERSATION HISTORY,"INPUT, CONTEXT","Conversation History is a comprehensive record of all previous interactions or queries made by the user to the system. This data serves as a critical context for the current user query, enabling the system to generate more informed and relevant responses. By leveraging the conversation history, GraphRAG can better understand the user's needs and preferences, leading to enhanced search and response generation processes. This historical data is essential for maintaining continuity in conversations and ensuring that the system's responses are tailored to the user's specific requirements.",59,,['3a0742c280217fe600b9af2d06b58eea' '812b3414c467da0b62f7932d2adcbad4'],"[ 0.04005963 -0.00377371 -0.00430082 ... -0.01457095  0.00377641
  0.01763498]"
b999ed77e19e4f85b7f1ae79af5c002a,LOCAL SEARCH DATAFLOW,"PROCESS, ALGORITHM","Local Search Dataflow is the method used to identify and prioritize entities, relationships, and covariates from the knowledge graph based on the user query and conversation history. It extracts relevant details and text chunks from the input documents and prioritizes them for fitting within a single context window.",60,,['3a0742c280217fe600b9af2d06b58eea'],"[ 0.04483688  0.05041772 -0.03114293 ... -0.00824862 -0.03909709
  0.06411631]"
48c0c4d72da74ff5bb926fa0c856d1a7,KNOWLEDGE GRAPH,"DATABASE, INFORMATION","The KNOWLEDGE GRAPH is a sophisticated database that leverages graph theory to organize data into a network of entities and their relationships. This structure enables the storage and representation of structured data in a highly accessible and analyzable format, making it an indispensable resource for AI applications such as question generation. The KNOWLEDGE GRAPH acts as the central information hub for the local search method, supplying the necessary context and details to formulate a response to user queries. Its richly interconnected data model facilitates efficient querying and analysis, enhancing the capabilities of AI systems that rely on it.",61,,['1415949832ba3fee570ea961998a8ac4' '3a0742c280217fe600b9af2d06b58eea'],"[ 0.03224266  0.00949429 -0.02349422 ...  0.03413921 -0.02507951
  0.02802739]"
4f3c97517f794ebfb49c4c6315f9cf23,PRIORITIZED TEXT UNITS,"OUTPUT, INFORMATION",Prioritized Text Units are the relevant text chunks extracted from the raw input documents and prioritized by the local search method. They are associated with the identified entities and are used to generate a response to the user query.,62,,['3a0742c280217fe600b9af2d06b58eea'],"[ 0.02715048  0.01606275 -0.01683276 ...  0.03211705  0.00264192
  0.03633242]"
1745a2485a9443bab76587ad650e9be0,PRIORITIZED COMMUNITY REPORTS,"OUTPUT, INFORMATION",Prioritized Community Reports are the relevant reports extracted from the knowledge graph and prioritized by the local search method. They are associated with the identified entities and are used to generate a response to the user query.,63,,['3a0742c280217fe600b9af2d06b58eea'],"[ 0.02082807  0.03773894 -0.06314147 ...  0.03126365 -0.00719255
  0.05483764]"
32e6ccab20d94029811127dbbe424c64,PRIORITIZED ENTITIES,"OUTPUT, INFORMATION",Prioritized Entities are the entities identified from the knowledge graph and prioritized by the local search method. They serve as access points into the knowledge graph and are used to extract further relevant details.,64,,['3a0742c280217fe600b9af2d06b58eea'],"[ 0.03824478  0.0511844  -0.02897308 ...  0.03269864 -0.025904
  0.05461996]"
94a964c6992945ebb3833dfdfdc8d655,PRIORITIZED RELATIONSHIPS,"OUTPUT, INFORMATION",Prioritized Relationships are the relationships identified from the knowledge graph and prioritized by the local search method. They provide context and details about the connections between entities.,65,,['3a0742c280217fe600b9af2d06b58eea'],"[ 0.03593541  0.03974072 -0.04704343 ...  0.03717596 -0.00286519
  0.05414467]"
1eb829d0ace042089f0746f78729696c,PRIORITIZED COVARIATES,"OUTPUT, INFORMATION",Prioritized Covariates are the covariates identified from the knowledge graph and prioritized by the local search method. They provide additional details about the entities and their attributes.,66,,['3a0742c280217fe600b9af2d06b58eea'],"[ 0.05964211  0.03029242 -0.02265155 ...  0.00660584 -0.01273487
  0.04408074]"
015e7b58d1a14b44beab3bbc9f912c18,LOCALSEARCH CLASS,"CLASS, INFORMATION_RETRIEVAL","The LocalSearch class is a component designed for searching and retrieving information from a collection of knowledge model objects. It prioritizes and filters candidate data sources to fit within a single context window of a pre-defined size, which is then used to generate a response to a user query. Key parameters include the OpenAI model object (llm), context builder object (context_builder), system prompt, response type, llm_params, context_builder_params, and callbacks for handling LLM's completion streaming events.",67,,['25797740f434cc2bf16365fc498791f6'],"[ 0.00736979  0.01408374 -0.04523056 ...  0.00304245 -0.03080648
  0.04441084]"
26f88ab3e2e04c33a459ad6270ade565,QUESTION GENERATION METHOD,"METHOD, INFORMATION_EXTRACTION",The Question Generation method is a process that combines structured data from the knowledge graph with unstructured data from input documents to generate candidate questions related to specific entities. This method uses the same context-building approach as the LocalSearch class to extract and prioritize relevant structured and unstructured information.,68,,['25797740f434cc2bf16365fc498791f6'],"[ 0.02650192  0.00975988 -0.03918218 ... -0.00314927 -0.0322825
  0.02895908]"
babe97e1d9784cffa1c85abc1e588126,CONFIGURATION PARAMETERS,"PROPERTY, CONFIGURATION","Configuration parameters for the LocalSearch class include llm (the OpenAI model object), context_builder (the context builder object), system_prompt (the prompt template for generating search responses), response_type (the desired format of the response), llm_params (additional parameters for the LLM call), context_builder_params (additional parameters for the context_builder), and callbacks (optional functions for handling LLM's completion streaming events).",69,,['25797740f434cc2bf16365fc498791f6'],"[ 0.02208653  0.01982805 -0.0257004  ... -0.03698976 -0.01566378
  0.03185809]"
1033a18c45aa4584b2aef6ab96890351,LLM COMPLETION STREAMING EVENTS,"CONCEPT, TECHNOLOGY",LLM Completion Streaming Events refer to the real-time updates or responses generated by Large Language Models (LLM) during the completion of tasks or queries. These events can be handled by custom event handlers to process or react to the information as it is being generated.,70,,['1415949832ba3fee570ea961998a8ac4'],"[ 0.0093744   0.01077937 -0.02572732 ... -0.00610794 -0.02776372
  0.05893958]"
c9b8ce91fc2945b4907fe35519339cac,ENTITY-BASED QUESTION GENERATION,"CONCEPT, TECHNOLOGY",Entity-based Question Generation is a specific approach within the question generation method that focuses on generating questions related to specific entities. It utilizes both structured and unstructured data to create context and generate relevant questions.,71,,['1415949832ba3fee570ea961998a8ac4'],"[ 0.02631802  0.00829025 -0.03127868 ...  0.01523564 -0.02544036
  0.00487505]"
fa3c4204421c48609e52c8de2da4c654,STRUCTURED DATA,"DATA, INFORMATION","Structured Data refers to the organized and formatted data that is typically stored in databases or knowledge graphs. This data is well-organized and can be easily searched and analyzed, making it useful for various applications including question generation.",72,,['1415949832ba3fee570ea961998a8ac4'],"[ 0.03505977 -0.02437458  0.00980955 ...  0.03720228  0.01248795
  0.0416623 ]"
53af055f068244d0ac861b2e89376495,UNSTRUCTURED DATA,"DATA, INFORMATION","Unstructured Data refers to the data that does not have a predefined format or organization. It includes text documents, images, and other forms of data that are not easily searchable or analyzed without prior processing. Unstructured data is often used in conjunction with structured data to provide a more comprehensive context for question generation.",73,,['1415949832ba3fee570ea961998a8ac4'],"[-0.01505997 -0.02451949  0.00601243 ...  0.05671435  0.00534224
  0.0183624 ]"
c03ab3ce8cb74ad2a03b94723bfab3c7,OPENAI MODEL,"CONCEPT, TECHNOLOGY","An OpenAI Model is a type of artificial intelligence model developed by OpenAI. It can be used for various tasks, including response generation in the context of question generation.",74,,['1415949832ba3fee570ea961998a8ac4'],"[-0.0086569   0.01842521 -0.03311398 ...  0.00087372  0.00578798
 -0.00035036]"
ed6d2eee9d7b4f5db466b1f6404d31cc,CONTEXT BUILDER,"CONCEPT, TECHNOLOGY","The Context Builder, a crucial component in the GlobalSearch class, serves a dual purpose in the realm of question generation and data analysis. Primarily, it prepares context data by meticulously extracting and prioritizing relevant information from collections of knowledge model objects, akin to the context-building approach employed in local search. Additionally, the Context Builder plays a significant role in the map-reduce process by processing community reports, ensuring that the data is optimized for further analysis and question generation. This versatile component is pivotal in bridging the gap between raw data and actionable insights, facilitating a more efficient and targeted exploration of knowledge within specialized professional networks.",75,,['1415949832ba3fee570ea961998a8ac4' '1a4bca0786d529c91073997b63412adc'],"[ 0.00668447  0.00141577 -0.06893525 ... -0.0179385  -0.02896036
  0.03350699]"
fc01e9baa80e417c9206f941bb279407,SYSTEM PROMPT,"CONCEPT, TECHNOLOGY",A System Prompt is a template used to generate candidate questions in the question generation process. It can be customized to fit specific needs and is used as a starting point for the LLM to generate follow-up questions.,76,,['1415949832ba3fee570ea961998a8ac4'],"[ 0.04326201 -0.01806383 -0.00438529 ... -0.02174918 -0.01397705
  0.01238643]"
56d0e5ebe79e4814bd1463cf6ca21394,LLM PARAMETERS,"CONCEPT, TECHNOLOGY","LLM Parameters are additional parameters that can be passed to the LLM call during the question generation process. These parameters can include settings such as temperature and max_tokens, which affect the behavior and output of the LLM.",77,,['1415949832ba3fee570ea961998a8ac4'],"[ 0.08425232  0.02159845 -0.02315154 ... -0.01270615 -0.04034646
  0.05856479]"
7c49f2710e8b4d3b8dc9310834406ea5,CONTEXT BUILDER PARAMETERS,"CONCEPT, TECHNOLOGY",Context Builder Parameters are additional parameters that can be passed to the Context Builder object when building context for the question generation prompt. These parameters can be used to customize the context-building process to better fit specific needs.,78,,['1415949832ba3fee570ea961998a8ac4'],"[ 0.05306542 -0.02479801 -0.04175138 ... -0.02203381 -0.02659756
  0.02733967]"
c6d1e4f56c2843e89cf0b91c10bb6de2,CALLBACKS,"CONCEPT, TECHNOLOGY","Callbacks are optional functions designed to handle custom events, specifically focusing on completion streaming events from the LLM (Language Model). These callbacks enable real-time processing, logging, and custom reactions to the information generated by the LLM during task completion or query responses. They provide a mechanism for monitoring, intervention, and custom processing during the various processing stages, enhancing the flexibility and control over the LLM's operations.",79,,"['1415949832ba3fee570ea961998a8ac4' 'e0cc1cf05b92456e09100790815186fe'
 'e442fbb7a67e97ebc4de131b25c639e1']","[-0.02140964  0.02367408 -0.03174636 ... -0.01942918 -0.00623768
  0.07023969]"
0adb2d9941f34ef7b2f7743cc6225844,LLM (LANGUAGE MODEL),"TOOL, TECHNOLOGY","LLM, or Large Language Model, is a sophisticated AI tool designed to generate human-like text based on given prompts. This model is widely utilized in various applications, including entity extraction, relationship detection, and abstractive summarization. LLM can create meaningful summaries of concepts that may be implied but not explicitly stated in the source texts, making it an invaluable asset in understanding the information contained within different communities from both high-level and low-level perspectives. In the context of the GlobalSearch class and data sensemaking tasks, LLM is employed for response generation, identifying users and tasks, and automating the generation of summarization queries to evaluate RAG systems. Its capabilities extend to generating text and questions, facilitating its use in Local Search and Global Search processes to produce context and responses.",80,,"['1a4bca0786d529c91073997b63412adc' '3e143a60e2aeb57eb418a68d1484bbb3'
 '5b2968b8f1c891d47ecbe641c3391663' '805a07a8f9c2ed5da2d9a61356aafa77'
 '8e69f04648f5fc24c299591365f1aa68' 'a739018eb63cbb6c26b779bd37afc233']","[ 0.04050933  0.01847726 -0.01851713 ...  0.02316942 -0.04598552
  0.04655053]"
6b02373137fd438ba96af28f735cdbdb,QUESTION GENERATION FUNCTION,"FUNCTION, ACTIVITY","The Question Generation Function is a process that generates candidate questions based on a given context. It can be customized with parameters such as system_prompt, llm_params, and context_builder_params, and can use callback functions for custom event handling.>",81,,['3e143a60e2aeb57eb418a68d1484bbb3'],"[ 0.0394786   0.00191499 -0.03897012 ... -0.01944638 -0.03761591
  0.01622979]"
36a4fcd8efc144e6b8af9a1c7ab8b2ce,LLM-GENERATED KNOWLEDGE GRAPH,DATA STRUCTURE,The LLM-generated knowledge graph is a data structure that represents the relationships and themes within a dataset. It is used by GraphRAG to organize data into semantic clusters and summarize information.,82,,['812b3414c467da0b62f7932d2adcbad4'],"[ 0.02367793  0.01912475 -0.01513061 ...  0.02089503 -0.04481012
  0.06559087]"
fbeef791d19b413a9c93c6608286ab63,SEMANTIC CLUSTERS,DATA ORGANIZATION,"Semantic clusters are groups of related data within the LLM-generated knowledge graph. They are organized by GraphRAG to provide a structured representation of the dataset, allowing for the summarization of themes and meaningful responses to user queries.",83,,['812b3414c467da0b62f7932d2adcbad4'],"[ 0.01347966  0.0230986  -0.0259728  ...  0.01424629 -0.02157213
  0.04748359]"
d2b629c0396f4180a03e16ddf3818589,GLOBAL SEARCH METHOD,"METHOD, PROCEDURE","The global search method is a process used by GraphRAG to generate responses to user queries. It involves using a collection of LLM-generated community reports as context data, segmenting them into text chunks, and producing intermediate responses. The most important points from these intermediate responses are then aggregated to generate the final response.",84,,['812b3414c467da0b62f7932d2adcbad4'],"[ 0.02567243  0.02106506 -0.05144066 ... -0.0482786  -0.04650431
  0.03861413]"
6102fc6619ed422ebc42588bfa97355d,AGGREGATED INTERMEDIATE RESPONSES,"OUTPUT, RESULT","Aggregated intermediate responses are the combined results of the intermediate responses generated during the global search method. They are formed by filtering and selecting the most important points from the intermediate responses, which are then used to generate the final response.",85,,['812b3414c467da0b62f7932d2adcbad4'],"[-0.0032239  -0.00524611 -0.05511645 ... -0.02990908  0.01217761
  0.00906247]"
8d141c0b80f74b79a05eed7fe161fe49,GRAPH'S COMMUNITY HIERARCHY,"CONCEPT, HIERARCHY","The Graph's Community Hierarchy is a structured organization of communities within a graph, which can be used as context data for generating responses in a map-reduce manner. Different levels of the hierarchy provide varying degrees of detail in community reports.>",86,,['1a4bca0786d529c91073997b63412adc'],"[ 0.01018505 -0.01230404 -0.03101899 ... -0.00909141  0.0074695
  0.00783737]"
e22d1d1cd8d14f12b81828d940f40d70,MAP-REDUCE PROCESS,"CONCEPT, PROCESS","The Map-Reduce Process is a computational paradigm used to process large data sets. In the context of generating responses, it involves segmenting community reports into text chunks, producing intermediate responses with points rated for importance, and aggregating the most important points to generate the final response.>",87,,['1a4bca0786d529c91073997b63412adc'],"[-0.01998134  0.02532377 -0.03603275 ... -0.02498863 -0.03161422
  0.00834521]"
9ab48505fb1b487babd0d1f6d3a3f980,COMMUNITY REPORTS,"DATA, DOCUMENT","Community Reports are comprehensive summaries generated by the GraphRAG system, tailored to the needs of specific communities or user groups. These reports offer insights and data from a community or a particular context, segmented into text chunks during the map step of the map-reduce process. They include tables of entities and relationships extracted from the input text, providing a structured overview of the information. Community Reports are created using the LLM, offering an overview of the distinct information within each community, including key entities, relationships, and claims. They provide a scoped understanding of the graph, from high-level to low-level perspectives, depending on the community's level in the hierarchy. Overall, Community Reports serve as a valuable tool for understanding the dynamics and structure of specialized professional networks, enabling the identification of collaboration opportunities and knowledge gaps in the field.",88,,"['1a4bca0786d529c91073997b63412adc' '21cdf11c58927ae505d3d375d1b75c82'
 '3e292d936b7efa377ba9530456cfd888' '5b2968b8f1c891d47ecbe641c3391663'
 'bdb8f9e797229f596744d9636ab857b0']","[ 0.01863246  0.02646268 -0.05109202 ... -0.01879313 -0.024474
  0.03594843]"
148fffeb994541b2b4b6dcefda7001a8,INTERMEDIATE RESPONSE,"DATA, DOCUMENT","An Intermediate Response is a document containing a list of points, each accompanied by a numerical rating indicating the importance of the point. These responses are produced during the map step of the map-reduce process and are used as input for the reduce step.>",89,,['1a4bca0786d529c91073997b63412adc'],"[-0.01099652  0.00530894 -0.03808086 ... -0.0491282   0.02383405
  0.00420733]"
89c08e793298442686292454a1abff31,FINAL RESPONSE,"DATA, DOCUMENT","The Final Response is the aggregated output of the map-reduce process, containing a filtered set of the most important points from the intermediate responses. It is generated using the context provided by the community reports and the map-reduce process.>",90,,['1a4bca0786d529c91073997b63412adc'],"[-0.02739325 -0.00581697 -0.03287189 ... -0.01879958  0.02500878
  0.01403741]"
0467928aa65e4a4fba62bdb1467e3a54,GLOBALSEARCH CLASS,"CONCEPT, CLASS","The GlobalSearch Class is a software class that implements the map-reduce process for generating responses. It includes key parameters such as the LLM model, context builder, map and reduce system prompts, response type, and settings for including general knowledge.>",91,,['1a4bca0786d529c91073997b63412adc'],"[-0.00245735  0.03394857 -0.04462488 ... -0.00992673 -0.02488844
  0.03195266]"
43c3390303c6476cb65f584e37c3e81c,MAP SYSTEM PROMPT,"CONCEPT, TEMPLATE",The Map System Prompt is a template used in the map stage of the map-reduce process. It provides instructions for processing community reports and generating intermediate responses.>,92,,['1a4bca0786d529c91073997b63412adc'],"[-0.00810759 -0.0060352  -0.03615489 ... -0.03942713 -0.00117349
  0.00090133]"
fa14b16c17e3417dba5a4b473ea5b18d,REDUCE SYSTEM PROMPT,"CONCEPT, TEMPLATE",The Reduce System Prompt is a template used in the reduce stage of the map-reduce process. It provides instructions for aggregating intermediate responses and generating the final response.>,93,,['1a4bca0786d529c91073997b63412adc'],"[-0.02057811 -0.01774572 -0.01937694 ... -0.0285026   0.01132677
 -0.00597181]"
7cc3356d38de4328a51a5cbcb187dac3,RESPONSE TYPE,"CONCEPT, FORMAT","The Response Type is a parameter of the GlobalSearch class that describes the desired format of the final response, such as multiple paragraphs or a multi-page report.>",94,,['1a4bca0786d529c91073997b63412adc'],"[ 0.01006415 -0.00406599 -0.00876921 ... -0.04796977  0.00517989
 -0.0012138 ]"
bef16fb5fd7344cca5e295b13ef3e0cd,ALLOW GENERAL KNOWLEDGE,"CONCEPT, SETTING","Allow General Knowledge is a setting in the GlobalSearch class that, when enabled, includes additional instructions in the reduce_system_prompt to prompt the LLM to include general knowledge in the final response.>",95,,['1a4bca0786d529c91073997b63412adc'],"[ 0.02388767  0.00984172 -0.02996112 ... -0.00637477 -0.04381637
  0.03254998]"
bb9e01bc171d4326a29afda59ece8d17,MAP_SYSTEM_PROMPT,"PROPERTY, TEMPLATE","The map_system_prompt is a template used in the map stage of data processing. It serves as a guideline for the initial processing of data, with a default template available for use.",96,,['e442fbb7a67e97ebc4de131b25c639e1'],"[-0.00538254 -0.02735407  0.00492855 ... -0.04070967 -0.01164225
 -0.0002846 ]"
3c063eea52e94164b70c99431ea30bae,REDUCE_SYSTEM_PROMPT,"PROPERTY, TEMPLATE","The reduce_system_prompt is a template used in the reduce stage of data processing. It guides the consolidation and analysis of data, with a default template available for use.",97,,['e442fbb7a67e97ebc4de131b25c639e1'],"[-0.02735221 -0.03518227  0.01891587 ... -0.00537117  0.00102582
 -0.00141293]"
252cc8452bfc4c2aa58cab68d8b61879,RESPONSE_TYPE,"PROPERTY, FORMAT","The response_type is a versatile parameter that specifies the desired format and structure of the final response or output. It serves as a free-form text field to describe the format and type of response expected from the query. The response_type can be tailored to various formats, including multiple paragraphs, a single paragraph, a single sentence, a list of 3-7 points, a single page, or a multi-page report. By default, the response_type is set to multiple paragraphs, providing flexibility to adapt the response to the specific needs of the request. This parameter enables customization of the output format, ensuring that the information is presented in a manner that best suits the context and requirements of the query.",98,,"['8c70a7321fb0e945054d226a8c69abee' 'e0cc1cf05b92456e09100790815186fe'
 'e442fbb7a67e97ebc4de131b25c639e1']","[-0.00608599 -0.02380937 -0.00677868 ... -0.049157    0.01559753
 -0.01430222]"
7e2c84548fb94ee395ba8588d8f2a006,ALLOW_GENERAL_KNOWLEDGE,"PROPERTY, SETTING","The allow_general_knowledge is a setting that, when enabled, allows the reduce stage to incorporate real-world knowledge outside of the dataset. This can enhance the response but may increase the risk of hallucinations.",99,,['e442fbb7a67e97ebc4de131b25c639e1'],"[ 0.01426669 -0.00435688 -0.01460831 ...  0.0085443  -0.02277014
  0.02360933]"
f034618dde7948beb6dab30176d0fc87,GENERAL_KNOWLEDGE_INCLUSION_PROMPT,"PROPERTY, INSTRUCTION",The general_knowledge_inclusion_prompt is an instruction added to the reduce_system_prompt when allow_general_knowledge is set to True. It guides the LLM to include relevant real-world knowledge in the response.,100,,['e442fbb7a67e97ebc4de131b25c639e1'],"[ 0.03593881 -0.00269507 -0.02350656 ... -0.00978228 -0.03094396
  0.02217492]"
5c41f96be13e49dba649454297834546,MAX_DATA_TOKENS,"PROPERTY, LIMIT",The max_data_tokens is a token budget that limits the amount of context data that can be used in the processing stages.,101,,['e442fbb7a67e97ebc4de131b25c639e1'],"[ 0.02587593 -0.01993504 -0.01580628 ...  0.00303585 -0.01405731
  0.02054289]"
7ea4afbf8a264f29af29950ce98105ba,MAP_LLM_PARAMS,"PROPERTY, PARAMETERS","The map_llm_params is a set of additional parameters for the LLM call during the map stage, such as temperature and max_tokens, to customize the behavior of the LLM.",102,,['e442fbb7a67e97ebc4de131b25c639e1'],"[ 0.07520291  0.03783375 -0.01639226 ... -0.00497047 -0.0292451
  0.05012045]"
91ff849d12b24574b0691dbddf44968b,REDUCE_LLM_PARAMS,"PROPERTY, PARAMETERS","The ""REDUCE_LLM_PARAMS"" is a dictionary designed to enhance the customization and fine-tuning of the LLM (Language Model) during the reduce stage. This set of additional parameters, which includes attributes like temperature and max_tokens, allows for a more precise control over the model's behavior, enabling users to adjust the output to better suit their specific needs and preferences. By passing these parameters to the LLM call, one can effectively influence aspects such as the randomness of the generated text (through temperature) and the length of the output (via max_tokens), thereby optimizing the performance of the model in various applications.",103,,['e0cc1cf05b92456e09100790815186fe' 'e442fbb7a67e97ebc4de131b25c639e1'],"[ 0.04823022 -0.00273373 -0.00690653 ...  0.02622325 -0.03751395
  0.04610712]"
d73c1f2fb3094d8dace42ad2a76e9a52,CONTEXT_BUILDER_PARAMS,"PROPERTY, PARAMETERS","The context_builder_params is a pivotal set of additional parameters designed for the context_builder object. This dictionary of parameters is utilized to customize the construction of the context window during the map stage, thereby playing a crucial role in how the model interprets the context of the input data. By tweaking these parameters, users can fine-tune the model's understanding of the input data's context, enhancing its performance and accuracy in various applications.",104,,['e0cc1cf05b92456e09100790815186fe' 'e442fbb7a67e97ebc4de131b25c639e1'],"[ 0.05248009 -0.02611799 -0.04463061 ... -0.00158697 -0.00650417
  0.0438428 ]"
cdc8901e668749889bd49bebdc4ff1f6,CONCURRENT_COROUTINES,"PROPERTY, SETTING","The ""CONCURRENT_COROUTINES"" is a parameter or setting that plays a crucial role in managing the degree of parallelism within the map stage of a computational process. This entity determines the number of tasks that can be processed or executed concurrently, thereby influencing the efficiency and performance of parallel computing operations. By adjusting the value of CONCURRENT_COROUTINES, users can optimize the system's ability to handle multiple tasks simultaneously, ensuring that resources are utilized effectively and that the processing speed is maximized. This setting is particularly important in environments where tasks can be divided and processed in parallel, such as in data processing, machine learning, and other high-performance computing scenarios.",105,,['e0cc1cf05b92456e09100790815186fe' 'e442fbb7a67e97ebc4de131b25c639e1'],"[ 0.01731675  0.01383425 -0.01862928 ... -0.00775846 -0.03992917
 -0.00784861]"
36084a9fab53433493f079e97e68bf65,LLM CALL,"PROCESS, ACTION","LLM call refers to the invocation of a Large Language Model, typically at the map stage of a data processing pipeline, to perform tasks such as text generation or analysis.",106,,['e0cc1cf05b92456e09100790815186fe'],"[ 0.01600744  0.01399797 -0.03739085 ...  0.00294765 -0.04817322
  0.04778765]"
eebcc7ec8e3e4df7aea83659bbdc2199,GRAPHRAG QUERY CLI,"TOOL, INTERFACE","The GraphRAG query CLI is a command-line interface that enables no-code usage of the GraphRAG Query engine, allowing users to perform searches and generate responses based on the data indexed by the system.",107,,['e0cc1cf05b92456e09100790815186fe'],"[ 0.01290592  0.00979169  0.0088738  ... -0.04301785  0.00489814
  0.00467361]"
ceadf262ef834e9ab146b20650912cae,DATA,"DATA, INPUT","data refers to the input data, typically stored in .parquet files, that are used as the basis for queries and responses in the GraphRAG system.",108,,['e0cc1cf05b92456e09100790815186fe'],"[ 0.01412838 -0.00357081  0.0207215  ... -0.01367992  0.00179522
  0.00416329]"
7f65feab75424b53b24470d305ba331a,COMMUNITY_LEVEL,"PROPERTY, CONFIGURATION","The parameter ""community_level"" is a crucial element in the context of the Leiden community hierarchy. It determines the level from which community reports are loaded, with higher values signifying smaller, more specialized communities. This parameter enables users to delve into the intricacies of the hierarchy, allowing for a detailed exploration of various community sizes. The default setting for ""community_level"" is 2, providing a balanced view of the community structure. By adjusting this parameter, users can tailor their analysis to focus on broader or more niche communities, facilitating a comprehensive understanding of the network's dynamics and facilitating the identification of collaboration opportunities and knowledge gaps within the Motor Control and Drive Systems domain.",109,,['8c70a7321fb0e945054d226a8c69abee' 'e0cc1cf05b92456e09100790815186fe'],"[ 0.04504855 -0.00451927 -0.0042408  ... -0.01780669 -0.04257771
 -0.01068216]"
fd9cb733b28d420cb5cef01e545a132c,METHOD,"PROPERTY, PARAMETER","METHOD is a versatile command-line option and parameter that plays a crucial role in various functionalities within the software. Primarily, it determines the method to select documents, with options including ""all,"" ""random,"" or ""top,"" and the default being ""random."" This feature is particularly significant for the auto-templating feature, where it serves as an optional property to specify the document selection method for template generation. Additionally, the method parameter influences the approach used to answer a query, which can be either ""local"" or ""global."" For a detailed understanding of its application, one should refer to the Overview section. The method property is also utilized in the configuration of the graphrag.prompt_tune command, further highlighting its importance in controlling the selection of text units for template generation.",110,,"['8c70a7321fb0e945054d226a8c69abee' '9243633f55cccd0885ba553e14fa5e3f'
 'ce9cc3ed2e5f890d02e867ed0b0f8ff9']","[ 0.02804628 -0.00965539  0.00857979 ... -0.0193442  -0.03098657
  0.03238383]"
0fbcca3f17c649a08aea64b5a7d9ef36,GRAPHRAG_API_KEY,"PROPERTY, ENV_VARIABLE","GRAPHRAG_API_KEY is a critical configuration property and environment variable that serves as the API key for accessing both the LLM (Language Model) service and the GraphRAG service. It is a security measure that enables authentication and authorization for the system to interact with these services. The placeholder value ""your_api_key"" indicates where the actual API key should be inserted, which must be a valid key provided by the service provider. In the context of the GraphRAG pipeline, GRAPHRAG_API_KEY is defined in the .env file and is essential for authenticating requests made to the OpenAI API or Azure OpenAI endpoint. If GRAPHRAG_API_KEY is not provided, the system will fall back to using the OPENAI_API_KEY for authentication purposes. This setting is indispensable for any interaction with the GraphRAG API and ensures secure and authorized access to the required services.",111,,"['3da10b454f926a257b9fdf5d2487c0a5' '5aaa26fbe97dc7573cd1a56d6fb11213'
 '8ac79ce92be1254dfda9a10eb54ab703' '8c70a7321fb0e945054d226a8c69abee']","[ 0.03322462  0.0465912  -0.03061676 ... -0.02881266 -0.04559287
  0.03607772]"
482027a59f32484c9c44fd700615c1b6,GRAPHRAG_LLM_MODEL,"PROPERTY, ENV_VARIABLE","GRAPHRAG_LLM_MODEL is a configuration property, also recognized as an environment variable, that determines the model to be utilized for the Large Language Model (LLM) in the Human-in-the-Loop Request Augmentation Gateway (HRAG) system. Specifically, it is set to gpt-4-turbo-preview, which signifies that the GPT-4 Turbo Preview model has been chosen for Chat Completions within the HRAG framework. This selection enables advanced language processing capabilities, enhancing the system's performance in augmenting human requests with machine intelligence.",112,,['8c70a7321fb0e945054d226a8c69abee' '9aff9243c57cabca574b35438bf31a50'],"[ 0.04081521  0.00796799  0.00207705 ... -0.02322532 -0.00900005
  0.01969182]"
de837ff3d626451282ff6ac77a82216d,GRAPHRAG_EMBEDDING_MODEL,"PROPERTY, ENV_VARIABLE",GRAPHRAG_EMBEDDING_MODEL is an environment variable that determines the model to use for Embeddings.,113,,['8c70a7321fb0e945054d226a8c69abee'],"[ 0.00478136  0.00907981 -0.0085314  ... -0.01889356 -0.03823029
 -0.01047183]"
460295fed3ae4cd39f9f274cec9c2506,GRAPHRAG_LLM_API_BASE,"PROPERTY, ENV_VARIABLE","GRAPHRAG_LLM_API_BASE is a configuration property and an optional environment variable that plays a crucial role in specifying the base URL for the Azure OpenAI service API for LLM (Language Model) operations. By default, it is set to ""http://<domain>.openai.azure.com"", where ""<domain>"" is a placeholder for the actual domain name provided by Azure. However, it is also mentioned that the default value can be None, indicating that no specific base URL is predetermined. This flexibility allows users to customize the base URL according to their specific Azure OpenAI service setup.",114,,"['1ef6439b7c457ba43993467ff734eedf' '7b45dafa74553d3899e2291a3c9fb86e'
 '8c70a7321fb0e945054d226a8c69abee']","[-0.01148415  0.04168336  0.0102984  ... -0.03293581 -0.045305
  0.03701964]"
553b285bba60460ab1ed8341ae61282b,GRAPHRAG_LLM_TYPE,"PROPERTY, ENV_VARIABLE","GRAPHRAG_LLM_TYPE is an environment variable and configuration setting that plays a pivotal role in specifying the type of language model to be utilized for text generation tasks. It can be configured to either 'azure_openai_chat' or 'openai_chat', with 'openai_chat' being the default setting. This setting ensures that the chosen model, be it Azure's version of OpenAI's chat model or OpenAI's chat model directly, is employed for generating text based on the input data. The default value of GRAPHRAG_LLM_TYPE is set to 'openai_chat', signifying that OpenAI's chat model is the standard choice for LLM operations unless explicitly overridden.",115,,"['1ef6439b7c457ba43993467ff734eedf' '3da10b454f926a257b9fdf5d2487c0a5'
 '8c70a7321fb0e945054d226a8c69abee']","[ 3.13567361e-05  3.77559960e-02  1.91230830e-02 ... -2.11651959e-02
 -2.73293983e-02  2.03561876e-02]"
cec95bf17e7e4c939b56c9c6f402a29f,GRAPHRAG_LLM_MAX_RETRIES,"PROPERTY, ENV_VARIABLE","GRAPHRAG_LLM_MAX_RETRIES is a critical configuration property utilized in the Human-in-the-Loop Request Augmentation Gateway (HRAG) system. It serves as an environment variable that determines the maximum number of retries for a request to the Large Language Model (LLM) API in case of failure. Initially, it was mentioned that GRAPHRAG_LLM_MAX_RETRIES is set to 10, allowing for up to 10 retries. However, the default value provided for this variable is 20, indicating that the system is designed to retry a failed request up to 20 times before ceasing further attempts. This robust retry mechanism ensures that the HRAG system maintains a high level of reliability and resilience in its interactions with the LLM, optimizing the chances of successful request processing amidst potential transient errors.",116,,"['1ef6439b7c457ba43993467ff734eedf' '8c70a7321fb0e945054d226a8c69abee'
 '9aff9243c57cabca574b35438bf31a50']","[ 0.02999806  0.01931744 -0.00745756 ... -0.01811473  0.00476092
  0.01929822]"
599164aead034bc19446efacc77554d2,GRAPHRAG_EMBEDDING_API_BASE,"ENVIRONMENT_VARIABLE, API_CONFIGURATION","GRAPHRAG_EMBEDDING_API_BASE is a pivotal configuration property utilized in the Human-in-the-Loop Request Augmentation Gateway (HRAG). This variable is specifically designed to define the base URL for the embedding service, which is crucial for Azure OpenAI users. It is set to ""http://<domain>.openai.azure.com"", providing a dedicated endpoint for embedding API requests. This setting is particularly relevant when GRAPHRAG_API_BASE is not configured, as it serves as the fallback base URL for embedding operations. By default, GRAPHRAG_EMBEDDING_API_BASE has a value of None, signifying that no predefined base URL is established for embedding tasks until explicitly set. This configuration ensures seamless integration and operation of embedding services within the HRAG framework for Azure OpenAI users.",117,,"['1ef6439b7c457ba43993467ff734eedf' '485c17007ccb3102887eaa47d6a6100f'
 '9aff9243c57cabca574b35438bf31a50']","[-0.00941355  0.01670025 -0.00429225 ... -0.03099136 -0.00406864
  0.01465521]"
bbf148ae4d48422f8fdef754cfa2b9e4,GRAPHRAG_EMBEDDING_TYPE,"ENVIRONMENT_VARIABLE, API_CONFIGURATION","GRAPHRAG_EMBEDDING_TYPE is a pivotal configuration setting, functioning as an environment variable that specifies the type of embedding model to be utilized for text embedding tasks. This setting can be configured to either 'azure_openai_embedding' or 'openai_embedding', based on the preferred model. By default, GRAPHRAG_EMBEDDING_TYPE is set to 'openai_embedding', signifying that OpenAI's embedding model is the standard choice for generating embeddings from input data. This setting is critical for determining the model that will be employed for embedding operations, ensuring flexibility and adaptability in text processing workflows.",118,,['1ef6439b7c457ba43993467ff734eedf' '3da10b454f926a257b9fdf5d2487c0a5'],"[-0.02450337  0.00982988  0.01408033 ... -0.03094213 -0.00068733
 -0.00677591]"
de61b2670999433f807a6a1dc2b81e43,GRAPHRAG_EMBEDDING_MAX_RETRIES,"ENVIRONMENT_VARIABLE, API_CONFIGURATION","GRAPHRAG_EMBEDDING_MAX_RETRIES is a critical configuration setting in the system, serving as an environment variable that determines the maximum number of retries for embedding operations. There seems to be a discrepancy in the default values mentioned; one source indicates it is set to 10, implying that the system will attempt up to 10 retries when a request to the embedding API fails. However, another source suggests a default value of 20, which would mean the system is configured to retry up to 20 times before abandoning a failed request. This setting is crucial for managing the resilience and reliability of embedding operations within the system.",119,,['1ef6439b7c457ba43993467ff734eedf' '2b777e3d591ce1511a03abd1a6d8dc73'],"[ 0.00435085  0.0144894  -0.01430978 ... -0.01676065 -0.00045754
 -0.01304691]"
3e95dacfe57b4d57b5da4310ef2e157f,GRAPHRAG_LOCAL_SEARCH_TEXT_UNIT_PROP,"ENVIRONMENT_VARIABLE, SEARCH_CONFIGURATION","GRAPHRAG_LOCAL_SEARCH_TEXT_UNIT_PROP is an environment variable that sets the proportion of the context window dedicated to related text units. The default value is 0.5, indicating that half of the context window is reserved for related text units.",120,,['1ef6439b7c457ba43993467ff734eedf'],"[ 0.01360536 -0.01116578 -0.01157713 ...  0.00042936 -0.01072783
 -0.01639782]"
1f1545308e9347af91fd03b94aadc21f,GRAPHRAG_LOCAL_SEARCH_COMMUNITY_PROP,"ENVIRONMENT_VARIABLE, SEARCH_CONFIGURATION","GRAPHRAG_LOCAL_SEARCH_COMMUNITY_PROP is a configuration property, also functioning as an environment variable, that specifies the proportion of the context window allocated to community reports within the Motor Control and Drive Systems domain. This property is crucial for Social Network Analysis as it influences the visibility of community reports, enabling a better understanding of the structure and dynamics of specialized professional networks. With a default value of 0.1, it indicates that 10% of the context window is reserved for community reports, facilitating the identification of key influencers and collaboration opportunities within the field. This setting ensures that a significant portion of the interface is dedicated to showcasing community insights, which is essential for mapping complex relationships and identifying knowledge gaps in the Motor Control and Drive Systems domain.",121,,['1ef6439b7c457ba43993467ff734eedf' '2efb1fec56fe3b0543d395dd541295c3'],"[ 0.01559283  0.01157102 -0.02242474 ... -0.02019589 -0.01520735
  0.00344089]"
6ea81acaf232485e94fff638e03336e1,GRAPHRAG_LOCAL_SEARCH_CONVERSATION_HISTORY_MAX_TURNS,"ENVIRONMENT_VARIABLE, SEARCH_CONFIGURATION","GRAPHRAG_LOCAL_SEARCH_CONVERSATION_HISTORY_MAX_TURNS is a configuration property, also functioning as an environment variable, that determines the maximum number of turns to be included in the conversation history for local search operations. This setting ensures that the system can reference up to 5 previous turns in the dialogue, aiding in context retention and more informed responses. The default value for GRAPHRAG_LOCAL_SEARCH_CONVERSATION_HISTORY_MAX_TURNS is set to 5, providing a balance between historical context and computational efficiency.",122,,['1ef6439b7c457ba43993467ff734eedf' '2efb1fec56fe3b0543d395dd541295c3'],"[ 0.04971915  0.0132887  -0.00839538 ... -0.00878876 -0.00326956
  0.00987675]"
d136b08d586d488f9e4188b524c85a29,GRAPHRAG_LOCAL_SEARCH_TOP_K_ENTITIES,"ENVIRONMENT_VARIABLE, SEARCH_CONFIGURATION","GRAPHRAG_LOCAL_SEARCH_TOP_K_ENTITIES is a configuration property, also functioning as an environment variable, that specifies the number of related entities to be fetched from the entity description embedding store. This setting has a default value of 10, implying that the system is configured to retrieve the top 10 related entities by default. This feature is crucial for optimizing the retrieval of relevant information and enhancing the efficiency of data processing within the system.",123,,['1ef6439b7c457ba43993467ff734eedf' '2efb1fec56fe3b0543d395dd541295c3'],"[ 0.00891071  0.02030342  0.00035035 ... -0.02520843 -0.01599145
  0.00975782]"
cccfa151fedc4b218a8d96adc7dceabe,GRAPHRAG_LOCAL_SEARCH_TOP_K_RELATIONSHIPS,"PROPERTY, CONFIGURATION",GRAPHRAG_LOCAL_SEARCH_TOP_K_RELATIONSHIPS is a configuration property that controls the number of out-of-network relationships to pull into the context window. It has a default value of 10.,124,,['2efb1fec56fe3b0543d395dd541295c3'],"[ 0.01760812 -0.00027671 -0.02219565 ... -0.01993101  0.00780118
  0.01199911]"
ce54725672a74ebcabe6127577dacb2b,GRAPHRAG_LOCAL_SEARCH_MAX_TOKENS,"PROPERTY, CONFIGURATION",GRAPHRAG_LOCAL_SEARCH_MAX_TOKENS is a configuration property that can be changed based on the token limit of the model being used. It has a default value of 12000.,125,,['2efb1fec56fe3b0543d395dd541295c3'],"[ 0.02318467  0.00956054 -0.00084464 ... -0.00730271 -0.00838828
 -0.00987371]"
ea2b28ca1a974ffab4517811dc1d1e5c,GRAPHRAG_LOCAL_SEARCH_LLM_MAX_TOKENS,"PROPERTY, CONFIGURATION",GRAPHRAG_LOCAL_SEARCH_LLM_MAX_TOKENS is a configuration property that can be changed based on the token limit of the model being used. It has a default value of 2000.,126,,['2efb1fec56fe3b0543d395dd541295c3'],"[ 0.0338672   0.01982273  0.0047648  ... -0.00810933 -0.02747236
  0.01228243]"
aff21f1da1654e7babdcf3fb0e4a75fc,GRAPHRAG_GLOBAL_SEARCH_MAX_TOKENS,"PROPERTY, CONFIGURATION","GRAPHRAG_GLOBAL_SEARCH_MAX_TOKENS is a configuration property that determines the maximum number of tokens for global search. It can be adjusted based on the token limit of the model being used, ensuring optimal performance. For instance, with an 8k limit model, a suitable setting could be 5000 tokens. The property has a default value of 12000 tokens, which serves as a baseline for models with higher token capacities.",127,,['2049798d3000849f8bec3e88c0006807' '2efb1fec56fe3b0543d395dd541295c3'],"[ 0.02803783  0.00856524 -0.00971719 ... -0.00754172 -0.03156515
  0.00050825]"
dc2cc9016e3f49dbac7232f05cce794d,GRAPHRAG_GLOBAL_SEARCH_DATA_MAX_TOKENS,"PROPERTY, CONFIGURATION","GRAPHRAG_GLOBAL_SEARCH_DATA_MAX_TOKENS is a pivotal configuration property that governs the maximum number of tokens for data in global search. This setting is adaptable and should be fine-tuned in accordance with the token limit of the model being utilized. For instance, with an 8k limit model, a recommended setting is 5000 tokens. It is noteworthy that the default value for GRAPHRAG_GLOBAL_SEARCH_DATA_MAX_TOKENS is set at 12000 tokens, providing a baseline for users to adjust based on their specific model requirements.",128,,['2049798d3000849f8bec3e88c0006807' '2efb1fec56fe3b0543d395dd541295c3'],"[ 0.01902692 -0.00047034 -0.00220802 ... -0.01391263 -0.02999084
  0.00705754]"
6ea0cef05f694dcea455478f40674e45,GRAPHRAG_GLOBAL_SEARCH_MAP_MAX_TOKENS,"PROPERTY, CONFIGURATION",GRAPHRAG_GLOBAL_SEARCH_MAP_MAX_TOKENS is a configuration property that determines the maximum number of tokens for mapping in global search. The default value is 500.,129,,['2049798d3000849f8bec3e88c0006807'],"[ 0.02058037  0.01847344 -0.01164858 ... -0.01404442 -0.02977982
 -0.01179396]"
7ab5d53a872f4dfc98f3d386879f3c75,GRAPHRAG_GLOBAL_SEARCH_REDUCE_MAX_TOKENS,"PROPERTY, CONFIGURATION","GRAPHRAG_GLOBAL_SEARCH_REDUCE_MAX_TOKENS is a configuration property that determines the maximum number of tokens for reduction in global search. It should be adjusted based on the token limit of the model being used. For an 8k limit model, a good setting could be 1000-1500. The default value is 2000.",130,,['2049798d3000849f8bec3e88c0006807'],"[ 0.02134923  0.00292415  0.00352658 ...  0.00573563 -0.03185005
  0.00016736]"
af1d0fec22114a3398b8016f5225f9ed,GRAPHRAG_GLOBAL_SEARCH_CONCURRENCY,"PROPERTY, CONFIGURATION","GRAPHRAG_GLOBAL_SEARCH_CONCURRENCY is a pivotal configuration property within the GraphRag system, specifically designed to govern the degree of concurrency for global search operations. This property plays a crucial role in optimizing the performance of search functionalities, enabling adjustments based on the available system resources and specific requirements. By default, GRAPHRAG_GLOBAL_SEARCH_CONCURRENCY is set to a value of 32, providing a baseline for the system's search concurrency that can be fine-tuned for enhanced efficiency.",131,,['2049798d3000849f8bec3e88c0006807' '60df16c009594c15c4ead6125e1453ce'],"[ 0.00639379  0.0043976  -0.01799847 ... -0.01420975 -0.03577374
  0.00935559]"
b07a7f088364459098cd8511ff27a4c8,GRAPHRAG KNOWLEDGE MODEL,"CONCEPT, DATA MODEL","The GraphRAG Knowledge Model is a conceptual model designed to abstract over the underlying data storage technology, providing a common interface for the GraphRAG system to interact with. It is aligned with the outputs of the indexing engine in the Default Configuration Mode and is used to load data into a database system for the GraphRAG's Query Engine to interact with.",132,,['25e04f0e9a961dcdc3f6eae6df7807b2'],"[-0.00282884 -0.011786    0.00791166 ... -0.00065618 -0.04654118
  0.03874727]"
8870cf2b5df64d2cab5820f67e29b9f1,GRAPHRAG INDEXER,"SOFTWARE, DATA PROCESSING","The GraphRAG Indexer, a pivotal component of the GraphRAG system, specializes in indexing data for efficient retrieval and analysis. In its default configuration mode, the Indexer aligns its outputs with the GraphRAG Knowledge Model, preparing the data for seamless integration into a database system. This data is then readily accessible for further processing by the Query Engine, facilitating advanced querying capabilities. Moreover, the GraphRAG Indexer is equipped with a set of default prompts designed for knowledge discovery from text data. To enhance its adaptability across diverse contexts, the Indexer supports customization through a custom prompt file, enabling users to tailor its functionality to specific requirements. This feature makes the GraphRAG Indexer a versatile tool for knowledge discovery and data indexing in various professional networks and domains.",133,,['25e04f0e9a961dcdc3f6eae6df7807b2' '6a7157695d90d434b2625c3f05420916'],"[-0.01466918 -0.01265738 -0.02543996 ... -0.00633213 -0.01234691
  0.01959458]"
cd130938a2844050be991af70baf5ee0,GRAPHRAG QUERY ENGINE,"SOFTWARE, QUERY PROCESSING",The GraphRAG Query Engine is a component of the GraphRAG system that interacts with the database system using the knowledge model data-store types. It processes queries based on the data indexed by the GraphRAG Indexer and stored in the database.,134,,['25e04f0e9a961dcdc3f6eae6df7807b2'],"[-0.01477842 -0.0113516  -0.0151059  ... -0.0350144  -0.01594068
  0.0142265 ]"
43544b99c3b04b059546198a0ae6366d,DATASHAPER,"SOFTWARE, DATA PROCESSING","DataShaper is a versatile, open-source software tool and library that specializes in data transformation and manipulation through the use of workflows, known as verbs. These verbs represent relational concepts and are capable of modifying input data tables, which can then be passed through a pipeline for additional processing. Users can declaratively define data pipelines, schemas, and associated assets using well-established schemas. With implementations in both JavaScript and Python, DataShaper is designed to be extensible to other programming languages, making it a valuable resource for data processing across various platforms.",135,,['25e04f0e9a961dcdc3f6eae6df7807b2' '81031e23c0b000ee60cd9b06950f96cd'],"[-0.02962387  0.00367859 -0.0344691  ... -0.02140018  0.00766893
  0.04893215]"
a671bf7fea2f4514b6e96ba99127fafd,WORKFLOW,"CONCEPT, DATA PROCESSING","In the context of DataShaper, a Workflow is a pivotal resource type characterized by a series of steps, known as verbs, which collectively transform data. Each step within a Workflow is defined by a verb name and a configuration object, enabling the modeling of relational operations such as SELECT, DROP, JOIN, and more. Workflows in DataShaper are instrumental in processing data tables by passing them through a pipeline for successive transformations, ensuring that each verb modifies the input data table before it is handed over to the next step in the sequence. This structured approach facilitates efficient data manipulation and analysis within the DataShaper environment.",136,,['25e04f0e9a961dcdc3f6eae6df7807b2' '81031e23c0b000ee60cd9b06950f96cd'],"[-0.01259111  0.00301478 -0.02469196 ... -0.05216462 -0.00704119
  0.05411176]"
525f41ea20274a05af4e52b625b473f3,GRAPHRAG INDEXING PIPELINE,"SOFTWARE, DATA PROCESSING","The GraphRAG Indexing Pipeline is an integral component of the GraphRAG system, designed to facilitate the scheduling and processing of data indexing tasks. This sophisticated system enables workflows to establish dependencies on one another, forming a directed acyclic graph (DAG) that streamlines the data indexing process. Built upon the robust foundation of DataShaper, the GraphRAG Indexing Pipeline guides data through a sequence of steps or verbs, ensuring that it is appropriately indexed for the GraphRAG Knowledge Model. This pipeline plays a crucial role in maintaining the integrity and accessibility of data within the GraphRAG ecosystem.",137,,['25e04f0e9a961dcdc3f6eae6df7807b2' 'd19a57bca2c14fc9c2bf5058958380fd'],"[-0.02185591 -0.00337417 -0.0154011  ... -0.05794024  0.00935274
  0.03240551]"
071a416efbec4f0886c19ac68f6d43cb,VERB,"CONCEPT, PROCESS","A Verb in DataShaper is a step within a workflow that models a specific data transformation action. Verbs can represent relational concepts like SELECT, JOIN, and BINARIZE, and each verb has a name and a configuration object that defines how it operates on an input data table.",138,,['81031e23c0b000ee60cd9b06950f96cd'],"[-0.02270124 -0.011858   -0.01754373 ... -0.0453766  -0.01773601
  0.03271455]"
6d8473ef3b1042bf87178a611e3dbcc6,INPUT TABLE,"DATA, STRUCTURE",An Input Table is the data structure that is fed into a verb within a DataShaper workflow. It is the starting point for data transformations and is passed through a series of verbs for processing.,139,,['81031e23c0b000ee60cd9b06950f96cd'],"[-0.02487716 -0.01173393  0.01076229 ... -0.01553238 -0.01470459
  0.02425765]"
30c9641543c24773938bd8ec57ea98ab,OUTPUT TABLE,"DATA, STRUCTURE",An Output Table is the result of a verb's processing in a DataShaper workflow. It is the transformed data structure that is passed down the pipeline for further processing by subsequent verbs.,140,,['81031e23c0b000ee60cd9b06950f96cd'],"[-0.04463929 -0.01700139  0.00191205 ... -0.03979636  0.02264449
  0.03122346]"
18b839da898e4026b81727d759d95c6a,GRAPHRAG'S INDEXING PIPELINE,"SOFTWARE, TOOL","GraphRAG's Indexing Pipeline is a custom extension of DataShaper that implements additional verbs on top of the standard relational verbs. It is designed to augment text documents with rich, structured data using the power of LLMs like GPT-4, and it can be used to extract entities, relationships, claims, community structures, and community reports and summaries.",141,,['81031e23c0b000ee60cd9b06950f96cd'],"[-0.0103752   0.00827387 -0.00836026 ... -0.05315766  0.01709277
  0.04094349]"
eeef6ae5c464400c8755900b4f1ac37a,LLM-BASED WORKFLOW STEPS,"CONCEPT, PROCESS",LLM-based Workflow Steps are custom verbs in GraphRAG's Indexing Pipeline that utilize Large Language Models (LLMs) to perform data enrichment and extraction tasks. These steps can be customized and extended to support various AI-based data processing tasks.,142,,['81031e23c0b000ee60cd9b06950f96cd'],"[ 0.04622561  0.02673033 -0.02476089 ... -0.03983261 -0.05708592
  0.08050137]"
422433aa45804c7ebb973b2fafce5da6,WORKFLOW GRAPHS,"CONCEPT, STRUCTURE","Workflow Graphs, a crucial component of GraphRAG's Indexing Pipeline, serve to illustrate the intricate web of interdependencies that exist between various workflows. These graphs take the form of a directed acyclic graph (DAG), which is instrumental in scheduling processing tasks and managing the dependencies between different steps in the workflow. By representing data indexing tasks as a series of interconnected workflows, Workflow Graphs enable a comprehensive understanding of the complexity involved in data pipelines. This structure allows for the definition of dependencies among workflows, ensuring that the processing is carried out in an organized and efficient manner.",143,,['81031e23c0b000ee60cd9b06950f96cd' 'd19a57bca2c14fc9c2bf5058958380fd'],"[ 0.00923996  0.00859826 -0.00917238 ... -0.04481603  0.00975039
  0.01987043]"
86505bca739d4bccaaa1a8e0f3baffdc,DAG (DIRECTED ACYCLIC GRAPH),"CONCEPT, STRUCTURE","A Directed Acyclic Graph (DAG) is a structure used in GraphRAG's Indexing Pipeline to represent the dependencies between workflows. It is a graph that is directed (edges have a direction) and acyclic (no cycles exist), which allows for the scheduling and processing of workflows in a defined order.",144,,['81031e23c0b000ee60cd9b06950f96cd'],"[-0.00419153 -0.00552937 -0.00789529 ... -0.03723647  0.04113389
  0.03011259]"
1af9faf341e14a5bbf4ddc9080e8dc0b,PREPARE,"VERB, PROCESS","""PREPARE is a pivotal workflow step within the GraphRAG Indexing Pipeline, serving as a preparatory phase for data that is destined for further processing. This phase encompasses a range of tasks, including but not limited to, initial data cleaning, formatting, and setting up the data environment to optimize it for subsequent verbs in the pipeline. PREPARE ensures that the data is in an appropriate state, thereby facilitating smoother and more efficient processing downstream.""",145,,['81031e23c0b000ee60cd9b06950f96cd' 'd19a57bca2c14fc9c2bf5058958380fd'],"[ 0.021051    0.01591978 -0.02604416 ... -0.07001996 -0.00707909
  0.03735223]"
353d91abc68648639d65a549e59b5cf3,CHUNK,"VERB, PROCESS","Chunk is a critical workflow step within the GraphRAG Indexing Pipeline, serving as a verb that signifies the division of data into smaller, more manageable pieces. This process is pivotal for handling large datasets by enabling more efficient and potentially parallel processing. Chunk refers to a segment of text or data that is processed as a discrete unit, a practice commonly employed in text analysis and information extraction workflows. By breaking down data into chunks, the system facilitates enhanced processing capabilities and optimizes resource utilization.",146,,"['493f38f41b89e767fc23d84e1fa5ba20' '6f92ce3fcd05dd5697ded83586f7bc08'
 '81031e23c0b000ee60cd9b06950f96cd' 'd19a57bca2c14fc9c2bf5058958380fd']","[ 0.01335709  0.00031011 -0.01157829 ... -0.03573998 -0.00796626
  0.03412781]"
7ce637e4f35b42e3a9f8272cab69cd22,EXTRACTGRAPH,"VERB, PROCESS","ExtractGraph is a pivotal workflow step within the GraphRAG Indexing Pipeline, serving as a verb that signifies the process of extracting graph structures from data. This process entails meticulously identifying relationships, entities, and patterns within the data to construct a comprehensive graph representation. Through ExtractGraph, the pipeline is able to uncover and map the intricate connections and structures inherent in the data, facilitating a deeper understanding and analysis of the information at hand.",147,,['81031e23c0b000ee60cd9b06950f96cd' 'd19a57bca2c14fc9c2bf5058958380fd'],"[ 1.81221589e-03  5.52326534e-03 -5.06018810e-02 ... -5.98469526e-02
 -3.14483259e-05  6.86881170e-02]"
4d999d7744b04a998475f8f8531589f0,EMBEDDOCUMENTS,"VERB, PROCESS","EmbedDocuments is a critical workflow step within the GraphRAG Indexing Pipeline, serving as a verb that signifies the process of embedding documents into a vector space. This step is pivotal for converting documents into numerical representations, a transformation that facilitates advanced tasks such as document similarity analysis and information retrieval. By embedding documents, the system enables more sophisticated machine learning applications and enhances the efficiency of information retrieval processes.",148,,['81031e23c0b000ee60cd9b06950f96cd' 'd19a57bca2c14fc9c2bf5058958380fd'],"[-0.0055661  -0.01078598  0.00906082 ... -0.01337014 -0.02236582
  0.02472123]"
9a6f414210e14841a5b0e661aedc898d,GENERATEREPORTS,"VERB, PROCESS","GenerateReports is a pivotal workflow step within the GraphRAG Indexing Pipeline, serving as a verb that encapsulates the process of generating comprehensive reports based on the processed data. This critical phase involves a multifaceted approach to data analysis, encompassing the summarization of data, the identification of trends, and the provision of insightful observations. The reports created during the GenerateReports step are designed to consolidate findings, offer analytical insights, and meticulously document the outcomes of various data processing tasks, thereby facilitating a deeper understanding of the data's implications and enabling informed decision-making.",149,,['81031e23c0b000ee60cd9b06950f96cd' 'd19a57bca2c14fc9c2bf5058958380fd'],"[-0.01626803  0.01011514 -0.0133646  ... -0.03382793  0.01602604
  0.00061895]"
db541b7260974db8bac94e953009f60e,EMBEDGRAPH,"VERB, PROCESS","EmbedGraph is a critical workflow step within the GraphRAG Indexing Pipeline, serving as a verb that signifies the process of embedding graph structures into a vector space. This transformation is pivotal for converting graph data into numerical representations, thereby facilitating the application of machine learning algorithms to graph-based information. The ability to embed graphs in a vector space enhances the potential for tasks such as graph similarity analysis and graph-based information retrieval, making EmbedGraph a versatile and essential component in the processing and analysis of graph data.",150,,['81031e23c0b000ee60cd9b06950f96cd' 'd19a57bca2c14fc9c2bf5058958380fd'],"[ 0.00178599  0.00868711 -0.00759598 ... -0.01246623  0.01016343
  0.00625237]"
f2ff8044718648e18acef16dd9a65436,ENTITYRESOLUTION,"VERB, PROCESS","EntityResolution is a critical workflow step within the GraphRAG Indexing Pipeline, designed to enhance data integrity and coherence. This process involves meticulously identifying and merging duplicate entities, ensuring that each unique entity is accurately represented within the system. Additionally, EntityResolution addresses ambiguities in data by disambiguating entities with similar names, thereby facilitating more precise and effective data analysis. Through these operations, EntityResolution plays a pivotal role in streamlining the indexing process and optimizing the overall performance of the GraphRAG system.",151,,['81031e23c0b000ee60cd9b06950f96cd' 'd19a57bca2c14fc9c2bf5058958380fd'],"[-0.02157078  0.01644404  0.00821703 ... -0.00900084 -0.00357424
  0.02210246]"
00d785e7d76b47ec81b508e768d40584,SAMPLE WORKFLOW DAG,"CONCEPT, DIAGRAM",Sample Workflow DAG is a visual representation of a directed acyclic graph (DAG) that shows the dependencies between different workflows in the GraphRAG Indexing Pipeline.,152,,['d19a57bca2c14fc9c2bf5058958380fd'],"[-0.00101017  0.01403495  0.01589909 ... -0.03747886  0.04218943
  0.03503307]"
87915637da3e474c9349bd0ae604bd95,DATAFRAME MESSAGE FORMAT,"CONCEPT, FORMAT","Dataframe Message Format is the primary unit of communication between workflows and workflow steps in the GraphRAG Indexing Pipeline. It is an instance of pandas.DataFrame, which facilitates data-centric and table-centric data processing.",153,,['d19a57bca2c14fc9c2bf5058958380fd'],"[ 0.02156643 -0.00124161  0.00864622 ... -0.0087313  -0.0028859
  0.03918099]"
8f1eba29f39e411188200bf0d14628ec,LLM CACHING,"CONCEPT, TECHNIQUE","LLM Caching is a technique used in the GraphRAG library to improve the resilience of the indexer to network issues. It involves caching the results of Large Language Model (LLM) interactions to avoid reprocessing the same input set, thus saving resources and improving efficiency.",154,,['d19a57bca2c14fc9c2bf5058958380fd'],"[ 0.03416723  0.04093343 -0.02442959 ...  0.00535014 -0.04278222
  0.07478616]"
7282c73622b8408e97289d959faff483,GRAPHRAG LIBRARY,"SOFTWARE, TOOL","The GraphRAG library is a software tool designed specifically for Large Language Model (LLM) interactions. It is equipped with features to handle common issues encountered when working with LLM APIs, such as network latency and throttling errors. The library includes a caching mechanism to improve the efficiency and reliability of LLM interactions.",155,,['6335601c6ec22bd6f15c8b69c26f854b'],"[ 0.04113775  0.02477548 -0.02470827 ...  0.02108976 -0.04505522
  0.03643138]"
3deb220d31f74103aa44870a36a63220,LLM INTERACTIONS,"PROCESS, COMMUNICATION","LLM interactions refer to the communication and data exchange between a system and Large Language Models (LLMs). These interactions can be affected by network latency, throttling, and other errors, which can lead to decreased performance and reliability. Caching is used to mitigate these issues and improve the efficiency of the interactions.",156,,['6335601c6ec22bd6f15c8b69c26f854b'],"[ 0.01716517  0.03763517 -0.0116014  ...  0.02002803 -0.0479426
  0.04886822]"
af7a1584dd15492cb9a4940e285f57fc,CACHING,"TECHNIQUE, STRATEGY","Caching is a technique used in the GraphRAG library to store and reuse results from LLM interactions. When a completion request is made with the same input set (prompt and tuning parameters), the library checks if a cached result exists and returns it if available. This strategy enhances the system's resilience to network issues, ensures idempotency, and provides a more efficient end-user experience.",157,,['6335601c6ec22bd6f15c8b69c26f854b'],"[ 0.0334032   0.01825484 -0.01691001 ... -0.01563356 -0.01333282
  0.04054397]"
6e8d9029ce4e4ea182367173ab2c7bbf,LOCAL TO GLOBAL GRAPH RAG APPROACH,"METHOD, APPROACH","The Local to Global Graph RAG (Retrieval-Augmented Generation) Approach is a method designed for query-focused summarization tasks. It enables large language models to answer questions over private and/or previously unseen document collections by retrieving relevant information. The approach is particularly suited for global questions that require summarization of an entire text corpus, such as identifying main themes in a dataset. It combines the strengths of retrieval tasks and query-focused summarization methods, scaling to handle both the generality of user questions and the quantity of source text to be indexed.",158,,['f76c18c7582167c3626f8741c2c9374f'],"[ 0.02706639  0.02827951 -0.01183265 ... -0.01139855 -0.01106002
  0.04012558]"
cbf232211e7d4eb6abdbe182f71c2cf0,RETRIEVAL-AUGMENTED GENERATION (RAG),"TECHNIQUE, TOOL","Retrieval-Augmented Generation (RAG) is a sophisticated technique designed to empower large language models with the ability to answer questions by accessing and retrieving pertinent information from an external knowledge source. This method is particularly effective in addressing queries over private or previously unseen document collections, making it a valuable tool for information retrieval in specialized domains. RAG operates by identifying local regions of text within the dataset that are relevant to the question at hand, providing the necessary context for generating accurate responses. However, it is important to note that RAG may face challenges when confronted with global questions that demand a comprehensive summary of an entire text corpus, as these tasks are inherently query-focused and require a broader scope of analysis. Despite this limitation, RAG remains a well-established approach for answering user questions over extensive datasets by skillfully retrieving and leveraging the most pertinent information.",159,,['c7669e6a1add9a2829b09196256b1492' 'f76c18c7582167c3626f8741c2c9374f'],"[ 0.00150714  0.01432533 -0.00992352 ...  0.00799023  0.00978377
  0.02642541]"
bb0cff774a4440b289cc6f3b929fe13c,QUERY-FOCUSED SUMMARIZATION (QFS),"TECHNIQUE, TOOL","Query-Focused Summarization (QFS) is a specialized summarization task introduced by Dang in 2006, designed to generate natural language summaries in direct response to user queries. Unlike generic summarization methods, QFS focuses on producing abstractive summaries that go beyond simple concatenations of text excerpts, aiming to provide relevant information tailored to specific queries. This technique is particularly useful for summarization tasks that require a comprehensive understanding of an entire text corpus, such as identifying main themes. However, QFS methods can struggle with scalability when dealing with the vast quantities of text indexed by typical Retrieval-Augmented Generation (RAG) systems. Despite this challenge, QFS remains a valuable tool for generating concise, query-specific summaries that enhance information retrieval and comprehension.",160,,"['85eff07c379a9dc24db0edb983acf3c9' 'c7669e6a1add9a2829b09196256b1492'
 'f76c18c7582167c3626f8741c2c9374f']","[ 0.02336246 -0.00148982  0.0121104  ... -0.00506819  0.00675076
  0.0510082 ]"
ce55841ebfdd47008bab8c258f10372e,ENTITY KNOWLEDGE GRAPH,"DATA STRUCTURE, CONCEPT","The ENTITY KNOWLEDGE GRAPH is a sophisticated data structure that encapsulates entities and their interconnections, extracted from source documents. This graph is a fundamental component in the initial phase of both the Graph RAG approach and the graph-based text indexing process. Its primary function is to facilitate the identification of closely-related entities, enabling the creation of comprehensive community summaries for clusters of these entities. Through this structure, insights into the relationships and dynamics within specialized professional networks, such as those in the Motor Control and Drive Systems domain, can be gleaned, aiding in the discovery of collaboration opportunities and knowledge gaps.",161,,['b149708d0b4ac3ff417565739ea6b03b' 'f76c18c7582167c3626f8741c2c9374f'],"[ 0.01812324  0.03987738  0.004342   ...  0.01958984 -0.04939616
  0.03552104]"
6090e736374d45fd84f0e4610a314f8f,GRAPH-BASED TEXT INDEX,"METHOD, TECHNOLOGY",A graph-based text index is a method for organizing and querying text data that involves creating an entity knowledge graph from source documents and generating community summaries for groups of closely-related entities to improve the comprehensiveness and diversity of generated answers to questions. This method is particularly effective for global sensemaking questions over datasets in the 1 million token range.,162,,['b149708d0b4ac3ff417565739ea6b03b'],"[ 0.02323037  0.00584847  0.00429243 ... -0.01471974 -0.01179018
  0.00952839]"
0e8d921ccd8d4a8594b65b7fd19f7120,GLOBAL SENSEMAKING QUESTIONS,"QUERY, INFORMATION NEED","Global sensemaking questions are a class of questions that require understanding connections among people, places, and events in order to anticipate their trajectories and act effectively. They are typically asked over datasets in the 1 million token range and are used to test the effectiveness of the graph-based text index method.",163,,['b149708d0b4ac3ff417565739ea6b03b'],"[ 0.03408881  0.03288962 -0.04434066 ... -0.00906944 -0.03771987
  0.00933553]"
59c726a8792d443e84ab052cb7942b4a,GRAPH RAG,"METHOD, TECHNOLOGY","Graph RAG (Retrieval-Augmented Generation) is a sophisticated AI model designed to enhance the generation of responses or summaries by leveraging a graph-based text index. This method significantly improves the comprehensiveness and diversity of answers to global sensemaking questions, outperforming a naive RAG baseline in both global and local approaches. Graph RAG's unique capability to use a self-generated graph index enables advanced retrieval and analysis of information, making it particularly effective for summarization tasks. It offers scalability advantages over traditional source text summarization, requiring fewer context tokens for low-level community summaries (C3) and root-level community summaries (C0). This efficiency is further demonstrated in iterative question answering, where Graph RAG boasts high win rates in terms of comprehensiveness and diversity. The model can be finely tuned to retain more details in the index, ensuring that the generated responses are rich in information. Graph RAG's graph-based approach to retrieval and generation allows for the handling of more complex and interconnected data, incorporating multiple concepts related to other systems. It is renowned for providing superior improvements in answer comprehensiveness and diversity when compared to source texts, especially in the context of community summaries.",164,,"['40f2d6a0270e54743e7ace239369da96' '7040ba36a7c09899a355d14a30d65375'
 '71f14506a6b15dfabd93fd1606a67b73' '7da3d8d244b67f09425a4a7783e4bb55'
 'b149708d0b4ac3ff417565739ea6b03b' 'ed433e2f5d5387b47376eb0e45ca1c99']","[ 0.0368632   0.01827417 -0.00474769 ...  0.00082737  0.00652049
  0.02305558]"
4f2c665decf242b0bfcaf7350b0e02ed,LARGE LANGUAGE MODELS (LLMS),"TECHNOLOGY, ARTIFICIAL INTELLIGENCE",Large language models (LLMs) are artificial intelligence systems that are capable of processing and generating human-like language. They are used to automate human-like sensemaking in complex domains like scientific discovery and intelligence analysis.,165,,['b149708d0b4ac3ff417565739ea6b03b'],"[ 0.04845711  0.01635873 -0.00427247 ...  0.04674974 -0.0498545
  0.02595657]"
66cdf168f36d4a57a505028c97dc06e0,SCIENTIFIC DISCOVERY,"DOMAIN, ACTIVITY",Scientific discovery is a domain of human endeavor that involves the process of making new and significant contributions to scientific knowledge. It is an area where large language models are being used to automate human-like sensemaking.,166,,['b149708d0b4ac3ff417565739ea6b03b'],"[-0.02337834  0.0266347  -0.02998806 ...  0.02312837 -0.01740571
  0.05321974]"
38f51478f41f48db9bee570859b6f43e,INTELLIGENCE ANALYSIS,"DOMAIN, ACTIVITY","Intelligence analysis is a domain of human endeavor that involves the process of gathering, processing, and analyzing information to support decision-making. It is an area where large language models are being used to automate human-like sensemaking.",167,,['b149708d0b4ac3ff417565739ea6b03b'],"[-0.01658715  0.03476232 -0.01479628 ... -0.00496248 -0.03996143
  0.027784  ]"
896d2a51e8de47de85ba8ced108c3d53,AUTOMATED SENSEMAKING,"CONCEPT, TECHNOLOGY","Automated sensemaking refers to the application of artificial intelligence and machine learning techniques to understand complex domains, such as scientific discovery and intelligence analysis, by identifying connections among people, places, and events to anticipate their trajectories and act effectively.",168,,['c7669e6a1add9a2829b09196256b1492'],"[-0.01044456  0.04177004 -0.04491924 ...  0.02316214 -0.0017688
  0.01551803]"
14555b518e954637b83aa762dc03164e,HUMAN-LED SENSEMAKING,"CONCEPT, PROCESS","Human-led sensemaking is a process where humans apply and refine their mental model of data by asking questions of a global nature to understand connections among people, places, and events in order to anticipate their trajectories and act effectively.",169,,['c7669e6a1add9a2829b09196256b1492'],"[-0.03108992  0.01533021 -0.0484332  ...  0.02034446  0.00042388
  0.04332461]"
b1f6164116d44fe8b8f135d7f65b9e58,ABSTRACTIVE SUMMARIZATION,"CONCEPT, TECHNOLOGY","Abstractive Summarization is a sophisticated technique within the domain of text summarization. Unlike extractive summarization, which merely selects and concatenates existing sentences from the source material, Abstractive Summarization generates entirely new sentences to convey the essence and meaning of the original text. This process involves creating a summary that is not a direct copy of the source but rather a novel representation of its content, allowing for a more concise and rephrased version of the information. By generating new sentences, Abstractive Summarization offers a more flexible and comprehensive way to encapsulate the core ideas of a text, making it an essential tool in the field of information processing and analysis.",170,,['85eff07c379a9dc24db0edb983acf3c9' 'c7669e6a1add9a2829b09196256b1492'],"[-0.00021336 -0.00347806  0.00969851 ... -0.01714933 -0.01591468
  0.05455662]"
c8b2408617804483b620e1a6691ac90d,EXTRACTIVE SUMMARIZATION,"CONCEPT, TECHNOLOGY","Extractive Summarization is a technique within the field of text processing and natural language generation, where the system selects and concatenates existing sentences or phrases from the source text to create a concise summary. This method does not involve the generation of new sentences but focuses on extracting the most significant and relevant parts of the original text, ensuring that the summary retains the core information and meaning of the source material. By reordering and combining these selected sentences, Extractive Summarization provides a succinct representation of the text, making it easier for readers to grasp the essential points without having to read the entire document.",171,,['85eff07c379a9dc24db0edb983acf3c9' 'c7669e6a1add9a2829b09196256b1492'],"[ 0.00027328 -0.00080047 -0.02217562 ... -0.00803278  0.00610265
  0.05003632]"
a5e0d1644eb547ba9a5c3211aac4631a,TRANSFORMER ARCHITECTURE,"CONCEPT, TECHNOLOGY","The Transformer Architecture is a deep learning model introduced by Vaswani et al. in 2017, which has revolutionized natural language processing tasks, including summarization. It is based on the mechanism of self-attention, allowing the model to weigh the importance of different parts of the input data.",172,,['85eff07c379a9dc24db0edb983acf3c9'],"[ 0.0119144  -0.00834057 -0.06244994 ...  0.04658088 -0.01967608
  0.03359128]"
5a28b94bc63b44edb30c54748fd14f15,LLMS (LARGE LANGUAGE MODELS),"CONCEPT, TECHNOLOGY","LLMS, or Large Language Models (LLMs), are sophisticated AI models renowned for their ability to process and generate human-like text. These advanced AI systems excel in understanding and responding to complex queries, performing various language tasks, and have demonstrated their prowess in summarization tasks by leveraging in-context learning to condense content within their context window. LLMs are particularly adept at recognizing the common entity behind multiple name variations, making them invaluable in processing entity graphs and handling rich descriptive text in potentially noisy graph structures.

Moreover, LLMs are at the forefront of natural language generation, achieving state-of-the-art or competitive results compared to human judgments. They can generate reference-based metrics when gold standard answers are available and measure the qualities of generated texts in a reference-free style. LLMs also facilitate head-to-head comparisons of competing outputs and can evaluate the performance of conventional Retrieval-Augmented Generation (RAG) systems, assessing critical qualities such as context relevance, faithfulness, and answer relevance. In essence, LLMs are versatile tools that enhance the understanding and generation of natural language, making them essential in various applications within the AI domain.",173,,"['53455f8552b0787cb13c5a03eb550842' '6dace8e490674ac8e031aed987a63789'
 '85eff07c379a9dc24db0edb983acf3c9']","[ 0.05234293  0.02610267  0.00593688 ...  0.02990197 -0.0339027
  0.03605084]"
f97011b2a99d44648e18d517e1eae15c,GPT (GENERATIVE PRE-TRAINED TRANSFORMER),"CONCEPT, TECHNOLOGY","GPT (Generative Pre-trained Transformer) is a series of large language models developed by OpenAI. It is based on the transformer architecture and is known for its ability to generate coherent and contextually relevant text, making it highly effective for various natural language processing tasks, including summarization.",174,,['85eff07c379a9dc24db0edb983acf3c9'],"[ 0.01075151 -0.00269604  0.00346259 ...  0.03916588  0.01852871
  0.0054547 ]"
35489ca6a63b47d6a8913cf333818bc1,LLAMA,"CONCEPT, TECHNOLOGY","Llama is a large language model developed by Facebook AI Research (FAIR). It is designed to handle complex language tasks and can generate human-like text, making it suitable for summarization and other NLP tasks.",175,,['85eff07c379a9dc24db0edb983acf3c9'],"[ 0.03435512  0.02083752 -0.00739031 ...  0.01573865  0.00867734
  0.02353634]"
5d3344f45e654d2c808481672f2f08dd,GEMINI,"CONCEPT, TECHNOLOGY","Gemini is a large language model developed by Alibaba Cloud. It is capable of understanding and generating text, making it useful for various NLP tasks, including summarization.",176,,['85eff07c379a9dc24db0edb983acf3c9'],"[ 0.01616224  0.00032476 -0.01579288 ...  0.02643683 -0.00869442
 -0.0129506 ]"
6fb57f83baec45c9b30490ee991f433f,"BROWN ET AL., 2020","REFERENCE, ACADEMIC PAPER","Brown et al., 2020, is an academic paper that discusses the use of in-context learning for summarizing content within the context window of large language models (LLMs).",177,,['3fc3718256cb7f614fcde622af2ed912'],"[ 0.01674485 -0.01164285 -0.01676512 ...  0.03277248 -0.03367819
  0.01921312]"
68762e6f0d1c41cd857c6b964a8e76c3,"LLAMA (TOUVRON ET AL., 2023)","REFERENCE, ACADEMIC PAPER","Llama (Touvron et al., 2023) is an academic paper that explores the application of in-context learning for summarization tasks, focusing on the Llama series which can summarize content within the context window of LLMs.",178,,['3fc3718256cb7f614fcde622af2ed912'],"[ 0.05529594  0.00862488 -0.02030509 ... -0.00047987 -0.0252999
  0.04578034]"
70634e10a5e845aa8c6a32fe7e8eb2b2,"GEMINI (ANIL ET AL., 2023)","REFERENCE, ACADEMIC PAPER","Gemini (Anil et al., 2023) is an academic paper that discusses the Gemini series, which utilizes in-context learning to summarize content within the context window of LLMs.",179,,['3fc3718256cb7f614fcde622af2ed912'],"[ 0.04452173  0.02437828 -0.01151689 ...  0.01390875 -0.01680905
  0.00693383]"
04085f7cf46544b79597fc49286ff84d,IN-CONTEXT LEARNING,"CONCEPT, TECHNIQUE","In-context learning is a technique used by LLMs to adapt their responses based on the context provided in their input, enabling them to summarize content within their context window.",180,,['3fc3718256cb7f614fcde622af2ed912'],"[ 0.02828253  0.0046554  -0.06075655 ...  0.00018007 -0.03782472
  0.06105152]"
d203efdbfb2f4b2a899abfb31cf72e82,QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION,"CONCEPT, TECHNIQUE","Query-focused abstractive summarization is a technique that aims to generate a summary of a corpus in response to a specific query, focusing on the most relevant information.",181,,['3fc3718256cb7f614fcde622af2ed912'],"[ 0.02216075  0.00866778  0.01765569 ... -0.00868338 -0.03034194
  0.04153566]"
6731a665561840c2898ce8c9788e4c88,LLM CONTEXT WINDOW LIMITS,"PROPERTY, CONSTRAINT","LLM context window limits refer to the maximum amount of context that a large language model can process at once, which can be a constraint for summarizing entire corpora.",182,,['3fc3718256cb7f614fcde622af2ed912'],"[ 0.03923976 -0.00859577 -0.00802026 ...  0.0250541  -0.02718702
  0.03923487]"
4026806fa92f4e849a59a7f5c9a45c79,INFORMATION LOSS IN LONGER CONTEXTS,"PROPERTY, CONSTRAINT","Information loss in longer contexts is a phenomenon where information can be overlooked or lost when processing very long texts, as the middle part of the context may not receive adequate attention.",183,,['3fc3718256cb7f614fcde622af2ed912'],"[ 0.01016853 -0.03597438 -0.00879955 ...  0.03567198 -0.01014788
  0.01607379]"
68e0c60d2e8845d89d9d0ad397833648,NAIVE RAG (RETRIEVAL-AUGMENTED GENERATION),"CONCEPT, TECHNIQUE","Naive RAG (Retrieval-Augmented Generation) is a foundational technique in the domain of text generation and response creation. It operates by retrieving and augmenting information from a dataset to produce text, serving as a basic benchmark for evaluating the efficacy of more advanced methods. Naive RAG directly extracts text segments for summarization purposes; however, its capabilities might be limited when applied to query-focused summarization tasks across extensive document collections. This straightforward approach is often utilized to establish a baseline against which more sophisticated text generation models can be compared, highlighting its role in the initial stages of algorithm development and testing.",184,,['3fc3718256cb7f614fcde622af2ed912' 'e31d2d134cf501c93f9445914d7350f9'],"[-0.0129423   0.01484513  0.00197601 ...  0.00455584  0.03003862
  0.03243749]"
101572f552b54e529fe7765c05168981,GRAPH RAG APPROACH,"CONCEPT, TECHNIQUE","The Graph RAG (Retrieval-Augmented Generation) approach is a sophisticated technique that integrates knowledge graph generation, retrieval-augmented generation, and query-focused summarization to support human sensemaking across extensive text corpora. This method enhances the process of generating text by leveraging a graph index to retrieve and augment information, specifically focusing on the modularity of graphs and the effectiveness of community detection algorithms in partitioning graphs into closely-related nodes. Designed to improve comprehensiveness, diversity, and token efficiency in summarization tasks, the Graph RAG approach refines and adapts current methodologies by operating in a more localized manner. It achieves this through embedding-based matching of user queries and graph annotations, and by implementing hybrid RAG schemes that combine embedding-based matching against community reports before employing map-reduce summarization mechanisms. This approach is particularly adept at processing text chunks extracted from source documents, making it a valuable tool for navigating and summarizing large volumes of information.",185,,"['3fc3718256cb7f614fcde622af2ed912' '5e2933c9646c751e6a60c9de12a255f2'
 'd2399fd0aae5bd200639806ca87184f8']","[ 0.01541131  0.01661093  0.00454047 ...  0.0090565  -0.00447685
  0.04659375]"
60c58026b2764b40adffca6eaa31d6d9,STRUCTURED RETRIEVAL AND TRAVERSAL,"CONCEPT, TECHNIQUE","Structured retrieval and traversal is a sophisticated technique that capitalizes on the inherent structure of graph indexes to facilitate efficient information retrieval and navigation. This method is specifically designed to access and traverse through structured data, such as graph indexes, enabling the precise location and extraction of specific information. By leveraging the organized nature of the data, structured retrieval and traversal ensures a streamlined and expedient process for finding and retrieving relevant details.",186,,['3fc3718256cb7f614fcde622af2ed912' 'd39abd5380fb3fe0468ea1e122512091'],[0.01806877 0.01056089 0.01053613 ... 0.00929277 0.03175947 0.02101289]
ad1595a78935472999444c9330e7730e,GRAPH MODULARITY,"PROPERTY, CONCEPT","Graph modularity is a property of graphs that refers to their inherent structure, allowing them to be partitioned into modular communities of closely-related nodes.",187,,['3fc3718256cb7f614fcde622af2ed912'],"[ 0.01916454 -0.00261382 -0.01574583 ...  0.02588512  0.02552712
  0.05558028]"
735d19aea0744b2295556841c5c4c3fd,COMMUNITY DETECTION ALGORITHMS,"CONCEPT, TECHNIQUE","Community Detection Algorithms are sophisticated computational methods employed to partition a graph into communities of nodes that exhibit stronger connections among themselves than with other nodes in the graph. These algorithms are pivotal in identifying the structure and semantics of large datasets by grouping similar nodes together, thereby aiding in the summarization of the entity graph into coherent communities. They operate by optimizing for modularity or other criteria that define the quality of the partitioning, aiming to identify groups of closely-related nodes within the graph. Essential for understanding the connectivity patterns in complex networks, Community Detection Algorithms facilitate the identification of collaboration opportunities and knowledge gaps in specialized professional networks, making them a valuable tool in the analysis of Motor Control and Drive Systems domain and beyond.",188,,"['3fc3718256cb7f614fcde622af2ed912' '6dace8e490674ac8e031aed987a63789'
 'a660289d2bf43f25d3524d35cd2d9a96' 'd39abd5380fb3fe0468ea1e122512091']","[ 0.0091099   0.02498673 -0.02243262 ... -0.00081221 -0.02282441
  0.03141282]"
c725babdb14a485582f8fbdf95429030,LLM-DERIVED KNOWLEDGE GRAPH,"CONCEPT, INFORMATION STRUCTURE","An LLM-derived knowledge graph is a structured representation of information, typically in the form of a graph, where nodes represent entities and edges represent relationships between those entities. This graph is used to store and retrieve knowledge in a more human-like manner, facilitating the understanding and analysis of complex information. The graph is characterized by its inherent modularity and the ability to be partitioned into modular communities of closely-related nodes using community detection algorithms.>",189,,['d39abd5380fb3fe0468ea1e122512091'],"[ 0.02264474  0.01097943  0.00322419 ...  0.02879609 -0.04797731
  0.05699426]"
a0047221896d418d849847d422fa4bb8,MODULARITY,"PROPERTY, CONCEPT","Modularity is a property of graphs that describes the degree to which the graph can be partitioned into distinct subgraphs or communities. It is a measure of the inherent structure of the graph and its ability to be divided into meaningful, self-contained parts.>",190,,['d39abd5380fb3fe0468ea1e122512091'],"[ 0.02779227  0.00259968 -0.01172563 ...  0.01565863  0.02045524
  0.04408983]"
98fc2ee593184c5a839454db4eec7013,LOUVAIN,"CONCEPT, ALGORITHM",Louvain is a community detection algorithm that aims to optimize the modularity of a graph partition. It is an iterative process that starts by assigning each node to its own community and then iteratively merges the most similar communities until no further improvement in modularity can be achieved.>,191,,['d39abd5380fb3fe0468ea1e122512091'],"[ 0.02938339  0.00758269 -0.01652866 ...  0.00215561 -0.00309399
  0.06050635]"
80020a1da63042459e00266b2a605452,LEIDEN,"CONCEPT, ALGORITHM",Leiden is an extension of the Louvain algorithm for community detection. It aims to improve the resolution of the Louvain algorithm by adding a refinement step that allows for the detection of smaller communities. Leiden is designed to be more efficient and to produce more stable and reproducible results.>,192,,['d39abd5380fb3fe0468ea1e122512091'],"[ 0.03021444  0.0088207   0.00211994 ...  0.00847994 -0.01024123
  0.04579986]"
31a7e680c4d54101afe4c8d52d246913,QUERY-FOCUSED SUMMARIZATION,"CONCEPT, INFORMATION PROCESSING",Query-focused summarization is a technique used to generate summaries that are specifically tailored to answer a particular query. It involves analyzing a corpus of documents or a graph index to extract information relevant to the query and then summarizing that information in a concise and coherent manner.>,193,,['d39abd5380fb3fe0468ea1e122512091'],"[ 0.03997526  0.02364482  0.0190415  ... -0.02241874 -0.01453035
  0.04414621]"
351abba16e5c448994c6daf48121b14d,MAP-REDUCE APPROACH,"CONCEPT, INFORMATION PROCESSING","The map-reduce approach is a programming model for processing large data sets. It involves two main steps: the map step, where the data is divided into smaller chunks and processed independently, and the reduce step, where the results of the map step are combined to produce the final output. This approach is particularly useful for parallel and distributed processing of large datasets.>",194,,['d39abd5380fb3fe0468ea1e122512091'],"[-0.02138313  0.0325883  -0.02667904 ... -0.00454843 -0.01016541
  0.02252429]"
50ea7d3b69614bcdbfbff7ddbfbf3d34,ACTIVITY-CENTERED SENSEMAKING QUESTIONS,"CONCEPT, INFORMATION QUERY",Activity-centered sensemaking questions are questions that are designed to help users understand complex information by focusing on specific activities or processes. These questions are often derived from short descriptions of datasets and are intended to guide the user in making sense of the underlying data and its implications.>,195,,['d39abd5380fb3fe0468ea1e122512091'],"[ 0.01645394  0.01851535 -0.03745036 ...  0.01045548 -0.04489262
  0.01416782]"
004f40a5aeca48a1879db728eb12bcba,PODCAST TRANSCRIPTS,"CONCEPT, INFORMATION TYPE","The dataset known as Podcast Transcripts is a comprehensive collection of written records derived from podcast conversations, featuring discussions between Kevin Scott, the CTO of Microsoft, and other influential figures in the technology sector. This dataset is a significant component of the Behind the Tech series by Scott (2024), offering a rich resource for understanding the viewpoints of tech leaders on policy, regulation, and industry trends. The transcripts are meticulously structured, comprising 1669 segments of 600 tokens each, with 100-token overlaps between segments, aggregating to roughly 1 million tokens in total. This format facilitates in-depth analysis and is particularly valuable for tech journalists seeking insights and patterns within the tech community. Moreover, the transcripts enhance accessibility and searchability, making them a versatile tool for various analytical purposes.",196,,"['5d04129d46662571f635a4e63cb4d6b7' 'aed2ea39de8a027cc818c7f4557f0514'
 'd39abd5380fb3fe0468ea1e122512091']","[ 0.00244609 -0.03289125 -0.01204546 ...  0.01624161 -0.01892621
  0.02975147]"
4465efb7f6ed4dedad72a658184addd2,NEWS ARTICLES,"CONCEPT, INFORMATION TYPE","The News Articles dataset is a comprehensive benchmark collection that spans from September 2013 to December 2023, featuring a diverse range of categories such as entertainment, business, sports, technology, health, and science. This dataset, which is part of MultiHop-RAG (Tang and Yang, 2024), consists of 3197 text chunks, each containing 600 tokens, with 100-token overlaps between chunks, amounting to approximately 1.7 million tokens in total. News articles, as written pieces, serve to report on current events, issues, and trends, providing valuable information and insights on a multitude of topics. They are not only a source of information for the general public but also a valuable educational tool, particularly in the context of health and wellness, where educators incorporate current affairs into their curricula to enhance learning experiences. Typically published in newspapers, magazines, or online news platforms, these articles play a crucial role in informing and engaging the public on important events and developments across various domains.",197,,"['5a5a94f85dfc4d119ebb87f3037fd1cc' '5d04129d46662571f635a4e63cb4d6b7'
 'aed2ea39de8a027cc818c7f4557f0514' 'd39abd5380fb3fe0468ea1e122512091']","[ 0.03373146  0.01065103 -0.00631555 ...  0.02430791 -0.03774211
  0.02692412]"
b0dd60e11dad4ff782623acf039b3948,DIVERSE ACTIVITY-CENTERED SENSE-MAKING QUESTIONS,"CONCEPT, INFORMATION","Diverse activity-centered sense-making questions are generated from short descriptions of real-world datasets, specifically podcast transcripts and news articles, to foster understanding of broad issues and themes. These questions aim to empower and provide comprehensive and diverse insights. The development of these questions involves exploring the impact of varying hierarchical levels of community summaries used to answer queries and comparing them to naive RAG and global map-reduce summarization of source texts.",198,,['d2399fd0aae5bd200639806ca87184f8'],"[ 0.0289711   0.03239146 -0.0657578  ... -0.01988388 -0.03136001
  0.01542191]"
db8c43fa4df947b09e5754d3b1393ead,REAL-WORLD DATASETS,"DATA, INFORMATION","Real-world datasets, including podcast transcripts and news articles, serve as the source material for generating diverse activity-centered sense-making questions. These datasets are used to develop understanding of broad issues and themes through the creation of questions that aim to be comprehensive, diverse, and empowering.",199,,['d2399fd0aae5bd200639806ca87184f8'],"[ 0.03090267  0.02531112 -0.03742723 ...  0.00601474 -0.02343682
  0.04275665]"
5dabc4cd05da425cb194a04482bf0c29,"COMPREHENSIVENESS, DIVERSITY, EMPOWERMENT","CONCEPT, CRITERIA","Comprehensiveness, diversity, and empowerment are the target qualities that guide the development of sense-making questions. These qualities are designed to foster a deeper understanding of broad issues and themes by ensuring that the questions cover a wide range of topics, offer varied perspectives, and empower the user to engage with the material in a meaningful way.",200,,['d2399fd0aae5bd200639806ca87184f8'],"[ 0.0212655   0.00563382 -0.03440572 ... -0.02858463 -0.00978261
  0.00130944]"
9d08f285a7be4c79b8f359c51d51db37,HIERARCHICAL LEVEL OF COMMUNITY SUMMARIES,"CONCEPT, INFORMATION",The hierarchical level of community summaries refers to the varying degrees of detail and abstraction in summarizing information from source texts. These summaries are used to answer queries and are compared to naive RAG and global map-reduce summarization techniques to assess their effectiveness in terms of comprehensiveness and diversity.,201,,['d2399fd0aae5bd200639806ca87184f8'],"[ 0.03462034 -0.00232992 -0.00564186 ... -0.01850988 -0.00699908
  0.00835873]"
adffed660d154b519c1817e514e83096,NAIVE RAG,"CONCEPT, TECHNIQUE","Naive RAG, standing for Retrieval-Augmented Generation, is a foundational technique in the domain of text generation and summarization. This method simplifies the process by converting documents into text, dividing it into manageable segments, and embedding these segments into a vector space where proximity indicates semantic similarity. This embedded information serves as a context for queries, enabling Naive RAG to produce direct and succinct responses. In the context of question answering and summarization, Naive RAG is noted for its straightforwardness and efficiency in generating responses. It is contrasted with more complex global approaches and hierarchical community summaries, which evaluate comprehensiveness and diversity. While Naive RAG is less effective in providing specific examples, quotes, and citations that aid in informed understanding, it stands out for its simplicity and directness, making it a valuable tool in the arsenal of text generation techniques. Comparisons with Graph RAG and other global approaches highlight its role in the empowerment of text summarization methods.",202,,"['38feec52b8bfbd3fd8e03635acdaec97' '71f14506a6b15dfabd93fd1606a67b73'
 'd2399fd0aae5bd200639806ca87184f8' 'ed433e2f5d5387b47376eb0e45ca1c99']",[0.00073617 0.01617535 0.0013394  ... 0.00288314 0.0267436  0.0185473 ]
b7e9c9ef572c445a9574ca571e41fb96,GLOBAL MAP-REDUCE SUMMARIZATION,"CONCEPT, TECHNIQUE",Global map-reduce summarization is a technique that aggregates information from source texts to create summaries. It is compared to naive RAG and hierarchical community summaries to assess its effectiveness in providing comprehensive and diverse insights.,203,,['d2399fd0aae5bd200639806ca87184f8'],"[ 0.01211959  0.01707866 -0.02671024 ... -0.02260749 -0.03161841
  0.03657109]"
dcb9f281cd6248c699e0ebb285a42a5e,TEXT CHUNKS,"DATA, INFORMATION","Text Chunks are pivotal components in the process of information extraction and graph index creation within the context of Large Language Model (LLM) prompts. These chunks are derived by dividing source documents into smaller, more manageable segments, which are then processed by LLMs. The size and granularity of these text chunks play a critical role in the efficiency and effectiveness of information extraction, impacting both the number of LLM calls needed for data extraction and the quality of the extracted information. Text Chunks serve as the fundamental units that enable the identification and extraction of graph nodes and edges, making them essential for meeting the baseline requirement of recognizing entities and their relationships within the text.",204,,"['d2399fd0aae5bd200639806ca87184f8' 'e50740c4332fdedb8739773592e2a402'
 'e7caf4256ddea71533af1c4c50444146']","[ 0.03316883 -0.00403789  0.00317011 ... -0.01317219 -0.03698234
  0.04144192]"
072cdee531b74513984f49d99a8d64a0,SOURCE DOCUMENTS,"DOCUMENT, INFORMATION",Source Documents are the original texts or files from which information is extracted for processing. They serve as the primary input for the design and implementation of a graph index system.,205,,['e7caf4256ddea71533af1c4c50444146'],"[ 0.0068703  -0.02349112  0.0466045  ... -0.03764172  0.013793
  0.0416049 ]"
5ae335d9210a45fda3f92a9a028d6d9b,LLM PROMPTS,"PROCEDURE, TOOL","LLM (Language Model) Prompts are designed to extract various elements of a graph index from the Text Chunks. They are used to identify and extract instances of graph nodes and edges, as well as entities and their relationships, from each chunk of source text.",206,,['e7caf4256ddea71533af1c4c50444146'],"[ 0.03808507  0.0020843  -0.01965283 ... -0.00944732 -0.02594333
  0.06000777]"
5ac60a941a5b4934bdc43d2f87de601c,GRAPH INDEX,"DATA_STRUCTURE, INDEX","The Graph Index is a sophisticated data structure that plays a pivotal role in the Graph RAG approach, designed for efficient querying and analysis of relationships between entities. It organizes information in a graph format, where nodes and edges represent entities and their relationships, respectively. The Graph Index is tailored for information retrieval and is specifically engineered to support conditions C0-C3. Its design and implementation are influenced by the granularity of text chunks and the effectiveness of LLM prompts. The indexing process involves the use of generic prompts for entity and relationship extraction, with entity types and few-shot examples customized to the domain of the data. For the Podcast dataset, a context window size of 600 tokens with 1 gleaning is utilized, while the News dataset employs 0 gleanings. This versatile data structure is crucial for understanding and navigating the complex relationships within specialized professional networks, enabling the identification of collaboration opportunities and knowledge gaps in various fields.",207,,"['53455f8552b0787cb13c5a03eb550842' '7040ba36a7c09899a355d14a30d65375'
 'e7caf4256ddea71533af1c4c50444146']",[0.0169848  0.02268877 0.00044377 ... 0.0093856  0.00340419 0.06811331]
d405c3154d0e48ce96fad4c28fe20590,ENTITY REFERENCES,"REFERENCE, INFORMATION","Entity References are mentions or instances of entities found within the Text Chunks. The number of entity references extracted is influenced by the size of the text chunks, with smaller chunks generally leading to higher recall but potentially lower precision.",208,,['e7caf4256ddea71533af1c4c50444146'],"[ 0.0177674   0.00934079  0.0081828  ...  0.03183626 -0.00691451
  0.01603311]"
7923d8521c744bd9aab131c1aea91ffd,GRAPH NODES,"CONCEPT, INFORMATION",Graph Nodes represent entities or concepts that are identified within the text chunks. These nodes are the building blocks for constructing a graph representation of the information contained in the text.,209,,['e50740c4332fdedb8739773592e2a402'],"[ 0.02656565 -0.02278812  0.00968607 ...  0.03179199  0.01441315
  0.02521815]"
5bd156c87ec44e19ae6f8f62e6e50b9d,GRAPH EDGES,"CONCEPT, INFORMATION","Graph Edges represent the relationships between graph nodes. They are identified and extracted from the text chunks to connect nodes in a graph, illustrating how entities are related to each other.",210,,['e50740c4332fdedb8739773592e2a402'],"[ 0.01133193  0.00756201 -0.004317   ...  0.00604841  0.01724136
  0.02250916]"
c1a146d7fb16429ea6d0aa2a55ee597f,LLM PROMPT,"CONCEPT, TOOL","LLM (Language Model) Prompt is a multipart instruction used to guide the language model in identifying entities and relationships within the text chunks. It includes few-shot examples for in-context learning, tailored to the domain of the document corpus.",211,,['e50740c4332fdedb8739773592e2a402'],"[ 0.05089451 -0.00060186 -0.0229699  ... -0.00673754 -0.03515163
  0.06034501]"
ede9350632084da5b0b577ff799ab14b,FEW-SHOT EXAMPLES,"CONCEPT, TOOL","Few-Shot Examples are crucial data points utilized for in-context learning, enabling the Large Language Model (LLM) to grasp domain-specific entities and relationships. These specialized instances are pivotal in enhancing the model's proficiency in recognizing and extracting information accurately. Particularly in niche fields such as science, medicine, and law, few-shot examples equip the LLM with the capability to understand and execute tasks effectively, even when the available data is limited. By providing these targeted samples, the model can be swiftly adapted to perform with precision in various specialized professional networks, facilitating a deeper understanding of the structure and dynamics within these domains.",212,,['805a07a8f9c2ed5da2d9a61356aafa77' 'e50740c4332fdedb8739773592e2a402'],"[ 0.04107466  0.00084132  0.00657475 ...  0.06184364 -0.00941462
  0.03897667]"
ed559fb4ebde45518849ec803b350fa3,NAMED ENTITIES,"CONCEPT, INFORMATION","Named Entities are specific types of entities like people, places, and organizations that are generally applicable across various domains. They are identified by the default LLM prompt.",213,,['e50740c4332fdedb8739773592e2a402'],"[ 0.0090153   0.00201479 -0.00625175 ...  0.0045264  -0.0194626
  0.0409839 ]"
f422035f8b78417f98e4d116971cf9f3,SPECIALIZED KNOWLEDGE,"CONCEPT, INFORMATION","Specialized Knowledge refers to domain-specific information that is relevant in fields such as science, medicine, and law. Few-shot examples specialized to these domains can improve the accuracy of entity and relationship extraction.",214,,['e50740c4332fdedb8739773592e2a402'],"[ 0.03851631  0.02348585 -0.01262455 ...  0.01129653 -0.03967635
  0.06523436]"
c79d686eba044c5586c706cdc096817d,COVARIATE PROMPT<||COVARIATE PROMPT,"CONCEPT, TOOL","Covariate Prompt is a secondary extraction prompt used to associate additional attributes or covariates with the detected node instances. It aims to extract claims linked to entities, including details such as the subject, object, type, description, source text span, and start and end dates.",215,,['e50740c4332fdedb8739773592e2a402'],"[ 0.0482004  -0.01634584 -0.00312901 ... -0.05654761 -0.00582985
  0.02446498]"
0f70db1e598d463fbbcdd1e288bd9490,COVARIATE PROMPT,,,216,,['e50740c4332fdedb8739773592e2a402'],"[ 0.05009422 -0.00600283 -0.00837827 ... -0.0290137  -0.00884457
 -0.00967354]"
b35c3d1a7daa4924b6bdb58bc69c354d,SECONDARY EXTRACTION PROMPT,"METHOD, PROCESS","The secondary extraction prompt is a technique used to gather additional information or covariates associated with the extracted node instances. It aims to extract claims linked to detected entities, including details such as the subject, object, type, description, source text span, and start and end dates.",217,,['805a07a8f9c2ed5da2d9a61356aafa77'],"[ 0.03704289 -0.01142973 -0.02228678 ... -0.05628687 -0.00997145
  0.02948681]"
a97e2ecd870944cfbe71c79bc0fcc752,GLEANING PROCESS,"METHOD, PROCESS","The gleaning process is a multi-stage method used to ensure that all entities are detected by the LLM. It involves multiple rounds of extraction, up to a specified maximum, to encourage the LLM to find any additional entities it may have missed in prior rounds. This process balances efficiency and quality by using larger chunk sizes without a drop in quality or the introduction of noise.",218,,['805a07a8f9c2ed5da2d9a61356aafa77'],"[ 0.00646332  0.03418654 -0.03835922 ... -0.0330679  -0.01101661
  0.09133026]"
3e1b063bbfa9423d84e50311296d2f3c,ELEMENT SUMMARIES,"OUTPUT, DATA","Element Summaries are comprehensive, condensed representations of information distilled from source texts by a Large Language Model (LLM). These summaries serve as a crucial component for each graph element within the network, encompassing entity nodes, relationship edges, and claim covariates. They are instrumental in transforming instance-level details into cohesive, descriptive blocks of text. Element summaries are characterized by their abstractive nature, enabling the LLM to generate independently meaningful synopses of concepts that might be implied but not explicitly stated in the original texts. This process facilitates a deeper understanding of the relationships and dynamics within the network, enhancing the ability to identify key influencers and collaboration opportunities in specialized professional communities such as Motor Control and Drive Systems.",219,,['805a07a8f9c2ed5da2d9a61356aafa77' 'a73d3e7b661743b7583d8a0fd412b6a7'],"[ 0.03554717  0.00575387 -0.00264621 ... -0.00115932 -0.00723914
  0.02983294]"
9a8ce816ee954bdabd01ea2081538009,LLM (LARGE LANGUAGE MODEL),"TECHNOLOGY, TOOL","LLM, or Large Language Model, is a sophisticated tool used for generating summaries and extracting information from source texts. It is capable of creating meaningful summaries of concepts that may be implied but not explicitly stated in the text, including entities, relationships, and claims. The LLM can handle variations in entity references and maintain consistency across multiple instances. It is also used to summarize groups of instances into single blocks of descriptive text for each graph element, such as entity nodes, relationship edges, and claim covariates.",220,,['a73d3e7b661743b7583d8a0fd412b6a7'],"[ 0.04805677  0.01047944 -0.00694738 ...  0.00756267 -0.03659957
  0.05892606]"
09f18f81442d4d6d93a90f0fac683f9b,ELEMENT INSTANCES,"PROPERTY, INPUT","Element Instances refer to the specific occurrences or representations of entities, relationships, and claims within source texts. These instances are the raw data that an LLM processes to generate element summaries.",221,,['a73d3e7b661743b7583d8a0fd412b6a7'],"[ 0.01460351  0.01838888  0.022914   ...  0.04097562 -0.00209109
  0.02930588]"
e02be3e37ca0454883a4c1fd859c24bb,GRAPH ELEMENTS,"CONCEPT, STRUCTURE","Graph Elements are the components of a graph structure used to represent information extracted from texts. These elements include entity nodes, relationship edges, and claim covariates, which are summarized and described using rich descriptive text generated by an LLM.",222,,['a73d3e7b661743b7583d8a0fd412b6a7'],"[ 0.01079022  0.00337417 -0.00472471 ...  0.01982734  0.02580291
  0.0263817 ]"
6e0c81bef5364c988b21bf9b709d9861,ENTITY GRAPH,"CONCEPT, DATA STRUCTURE","The Entity Graph is a representation of entities and their relationships, where entities are nodes and relationships are edges. It is used to detect closely-related communities of entities and summarize their connections. The graph is potentially noisy and includes homogeneous nodes with rich descriptive text, which is beneficial for LLMs and global, query-focused summarization.",223,,['6dace8e490674ac8e031aed987a63789'],"[ 0.02218121  0.02536975 -0.02388761 ...  0.01202109 -0.00405179
  0.02768745]"
1dbc51475cb04dafa4a8833a8378635e,CONNECTIVITY,"PROPERTY, CONCEPT","Connectivity refers to the links between entities in the entity graph. It is crucial for the resilience of the overall approach to variations in entity names, as long as there is sufficient connectivity from all variations to a shared set of closely-related entities.",224,,['6dace8e490674ac8e031aed987a63789'],"[ 0.00670879  0.02755575 -0.01723531 ...  0.01304829  0.01557123
  0.02084539]"
c12b9ebd8b4e42b7896822a32e3fa6eb,RICH DESCRIPTIVE TEXT,"PROPERTY, CONCEPT","Rich Descriptive Text is detailed information associated with homogeneous nodes in the entity graph. It aligns with the capabilities of LLMs and is essential for global, query-focused summarization.",225,,['6dace8e490674ac8e031aed987a63789'],"[ 0.03183788 -0.00650623  0.00253531 ... -0.00288654  0.01512945
  0.02201274]"
27505f6ade4b4e5f9316ffe9c34821f7,KNOWLEDGE GRAPHS,"CONCEPT, DATA STRUCTURE","Knowledge Graphs are structured representations of information, typically relying on concise and consistent knowledge triples (subject, predicate, object) for downstream reasoning tasks. They are contrasted with the entity graph, which uses rich descriptive text.",226,,['6dace8e490674ac8e031aed987a63789'],"[ 0.02729741 -0.01088157 -0.00764425 ...  0.0419115  -0.00731649
  0.01195777]"
0ee7db2c6bea4630ba9f0c25e8a967ad,LEIDEN ALGORITHM,"CONCEPT, ALGORITHM","The Leiden Algorithm is a sophisticated community detection algorithm renowned for its efficiency in uncovering the hierarchical community structure within large-scale graphs. This algorithm is specifically chosen for its capability to manage extensive datasets, offering a hierarchy of community partitions that cover the nodes of the graph in a mutually-exclusive and collectively-exhaustive manner. The Leiden Algorithm's inclusion in the pipeline highlights its effectiveness in processing and analyzing complex networks, making it an indispensable tool in the field of social network analysis and beyond.",227,,['6dace8e490674ac8e031aed987a63789' 'a660289d2bf43f25d3524d35cd2d9a96'],"[ 0.02261951  0.00499192  0.00010964 ...  0.01303698 -0.01590404
  0.04257828]"
5a6c1d15424149f69052cd8d91fbff75,GRAPHCOMMUNITIES,"DATA STRUCTURE, CONCEPT",GraphCommunities refers to the communities of nodes identified within a graph by community detection algorithms. These communities are groups of nodes that have stronger connections to each other than to the rest of the nodes in the graph.,228,,['a660289d2bf43f25d3524d35cd2d9a96'],"[ 0.02083614  0.00672375 -0.0138064  ...  0.00366419  0.01132696
  0.02710916]"
d005bf75c31d4848ad7041f39651e59c,GLOBAL QUERIES,"CONCEPT, INFORMATION","Global queries are questions that seek to understand the overall themes or information within a corpus. They can be answered using community summaries, which provide a structured way to access and interpret the information contained in the corpus.",229,,['93d4d4effbf989e6ef1c4c3b4f42494e'],"[ 0.03116965  0.00463279 -0.04136457 ... -0.04167822 -0.02289481
 -0.00359678]"
9b3eef8f3a3a45e6873838db95295b8a,CHUNKS OF PRE-SPECIFIED TOKEN SIZE,"PROPERTY, PROCESS","Chunks of pre-specified token size are created to ensure that relevant information is distributed across multiple chunks, preventing concentration and potential loss of information in a single context window. This process is essential for handling large datasets or documents effectively.",230,,['aed2ea39de8a027cc818c7f4557f0514'],"[ 0.01962781 -0.01596616  0.01823685 ...  0.00346949 -0.02769342
  0.03550852]"
fdc954b454744820804d7798f3e0b5de,INTERMEDIATE ANSWERS,"PROPERTY, PROCESS","Intermediate answers are generated in parallel, one for each chunk, by mapping community answers. The Large Language Model (LLM) also generates a score between 0-100 for each answer, indicating its helpfulness in answering the target question. Answers with a score of 0 are filtered out.",231,,['aed2ea39de8a027cc818c7f4557f0514'],"[ 0.02371258  0.02891248 -0.03016496 ... -0.02698274 -0.01798368
  0.00478114]"
49c1383836934ec495c3b35769100a73,GLOBAL ANSWER,"PROPERTY, PROCESS",Global answers are created by sorting intermediate community answers in descending order of helpfulness score and iteratively adding them into a new context window until the token limit is reached. This final context is used to generate the global answer that is returned to the user.,232,,['aed2ea39de8a027cc818c7f4557f0514'],"[ 0.02718012  0.00058937 -0.03912608 ... -0.06304996 -0.01395278
  0.01266035]"
859dedcc3736439a8a563419f16cb3d8,DATASET,"PROPERTY, DATA","The ""DATASET"" is a comprehensive collection of data designed to be processed through a pipeline, typically represented as a DataFrame in the Python API. This dataset is versatile, serving multiple purposes such as facilitating the understanding of tech leaders' perspectives on policy and regulation, and providing educational content on health and wellness. It can encompass diverse data sources, including podcast transcripts and news articles. Specifically, the dataset is structured as a pandas DataFrame, featuring columns named col1 and col2, both populated with numerical values, making it a valuable resource for data analysis and processing tasks.",233,,"['aed2ea39de8a027cc818c7f4557f0514' 'b0505e11596cadd9890fef049c29473c'
 'f3a07680cbe8ab1f6055369da05f4f38']","[ 0.02825095 -0.01850204  0.00634105 ...  0.04129772  0.01318083
  0.04323249]"
6078b9980a6c4dcd9198d151b833ead7,TECH JOURNALIST,"PERSON, ROLE",A tech journalist is a person who looks for insights and trends in the tech industry. They use podcast transcripts to understand how tech leaders view the role of policy and regulation.,234,,['aed2ea39de8a027cc818c7f4557f0514'],"[ 0.02538393 -0.01356549 -0.02728703 ...  0.00524247 -0.02153984
  0.00674112]"
f93cd6b8213e46dda67af7e5382e1bd2,EDUCATOR,"PERSON, ROLE","An EDUCATOR is a dedicated professional who specializes in teaching and facilitating learning. They play a crucial role in the educational landscape by integrating current affairs and news articles into their curricula, particularly in the context of health education. This approach enables EDUCATORS to provide students with a comprehensive understanding of health and wellness, ensuring that they are well-informed about the latest developments and issues in the field. By incorporating real-world events and information, EDUCATORS enhance the relevance and impact of their lessons, making them more engaging and meaningful for students. This method of teaching not only broadens students' knowledge but also fosters critical thinking and encourages them to apply what they have learned to their own lives. As a result, EDUCATORS are instrumental in promoting health literacy and empowering the next generation to make informed decisions about their well-being.",235,,['5a5a94f85dfc4d119ebb87f3037fd1cc' 'aed2ea39de8a027cc818c7f4557f0514'],"[-0.00027078 -0.00743537 -0.06040476 ...  0.01165642 -0.00459594
  0.01326388]"
496f17c2f74244c681db1b23c7a39c0c,PRIVACY LAWS,"LEGAL, REGULATION","Privacy laws are government regulations that govern the collection, use, and protection of personal data. They impact technology development by setting boundaries for data usage and influencing how tech companies design and implement their products and services.",236,,['5a5a94f85dfc4d119ebb87f3037fd1cc'],"[-0.01901554 -0.03085805  0.03931782 ... -0.00522633 -0.02873621
  0.01739509]"
da1684437ab04f23adac28ff70bd8429,TECHNOLOGY DEVELOPMENT,"INDUSTRY, INNOVATION","Technology development refers to the process of creating new technologies or improving existing ones. It is influenced by various factors, including legal frameworks, market demands, and ethical considerations.",237,,['5a5a94f85dfc4d119ebb87f3037fd1cc'],"[-0.00366275  0.00456328  0.00337917 ... -0.01882398 -0.03054543
  0.01440655]"
4517768fc4e24bd2a790be0e08a7856e,ETHICAL CONSIDERATIONS,"PHILOSOPHY, ETHICS","Ethical considerations involve the principles and values that guide behavior and decision-making. In the context of technology, they ensure that innovations are developed and used responsibly, considering the impact on individuals and society.",238,,['5a5a94f85dfc4d119ebb87f3037fd1cc'],"[ 0.01492465  0.00246139 -0.01350982 ...  0.01529069 -0.03480728
  0.0209463 ]"
545edff337344e518f68d1301d745455,CURRENT POLICIES,"LEGAL, REGULATION","Current policies refer to the existing laws, regulations, and guidelines that govern various aspects of society, including technology, health, and education. They are subject to change based on new insights, societal needs, and technological advancements.",239,,['5a5a94f85dfc4d119ebb87f3037fd1cc'],"[-0.01249994 -0.01315298 -0.00797913 ...  0.02070868 -0.01348856
  0.03828794]"
9376ce8940e647a99e5e087514b88fa4,COLLABORATIONS,"RELATIONSHIP, PARTNERSHIP","Collaborations refer to cooperative efforts between different entities, such as tech companies and governments. They can lead to the development of new technologies, policies, or solutions that benefit society.",240,,['5a5a94f85dfc4d119ebb87f3037fd1cc'],"[ 0.02193396  0.01808785 -0.01465082 ... -0.00908725 -0.0176335
  0.01755995]"
b38a636e86984600bb4b57c2e2df9747,HEALTH EDUCATION CURRICULA,"EDUCATION, CURRICULUM",Health education curricula are structured programs of study that focus on teaching students about health and wellness. They can be enriched by integrating current topics and news articles to provide real-world relevance.,241,,['5a5a94f85dfc4d119ebb87f3037fd1cc'],"[ 0.01868485 -0.01412563 -0.0062228  ... -0.00037651  0.0313806
  0.02339952]"
4bc7440b8f4b4e4cae65a5c49defa923,PREVENTIVE MEDICINE,"MEDICINE, HEALTH","Preventive medicine is a branch of medicine that focuses on preventing diseases and promoting health. It includes practices such as vaccinations, screenings, and lifestyle modifications.",242,,['5a5a94f85dfc4d119ebb87f3037fd1cc'],"[ 0.00633269  0.03512251  0.00011632 ... -0.00251693 -0.00379881
  0.03439522]"
5d1b038ce8be4533b54dd79d6496de9b,WELLNESS,"HEALTH, LIFESTYLE","Wellness refers to a state of being in good health, both physically and mentally. It encompasses a holistic approach to health, including nutrition, exercise, and mental well-being.",243,,['5a5a94f85dfc4d119ebb87f3037fd1cc'],"[ 0.01710802 -0.01064865 -0.01865136 ... -0.01414204  0.00605894
 -0.01470713]"
ac6e5a44e0c04a4fa93589376fde4c34,HEALTH ARTICLES,"MEDIA, INFORMATION","Health articles are written pieces that focus on health-related topics. They can provide insights into public health priorities, contradicting views on health issues, and the importance of health literacy.",244,,['5a5a94f85dfc4d119ebb87f3037fd1cc'],"[ 0.01748438 -0.00745184 -0.00144426 ...  0.01093749  0.01136553
 -0.0071713 ]"
40e4ef7dbc98473ba311bd837859a62a,PUBLIC HEALTH PRIORITIES,"HEALTH, POLICY","Public health priorities are the areas of focus for public health agencies and policymakers. They are determined by the prevalence of health issues, available resources, and societal needs.",245,,['5a5a94f85dfc4d119ebb87f3037fd1cc'],"[ 0.01253686 -0.00643885 -0.00346441 ...  0.00771147 -0.0128274
  0.01530105]"
222f0ea8a5684123a7045986640ec844,HEALTH LITERACY,"EDUCATION, HEALTH",Health literacy is the ability to understand and use health information to make informed decisions. It is crucial for individuals to navigate the healthcare system and maintain their health.,246,,['5a5a94f85dfc4d119ebb87f3037fd1cc'],"[ 0.01455791 -0.02063356 -0.02304585 ...  0.01880994  0.00375691
 -0.01316505]"
668cf1fdfd644d39acc6350b86117ea2,TECH COMPANIES,,,247,,['5a5a94f85dfc4d119ebb87f3037fd1cc'],"[ 0.0200076  -0.01111623 -0.00730718 ... -0.00611211  0.00223094
  0.0145563 ]"
478e4c72d8fb46dd8cc9f0691c9878fd,HOTPOTQA,DATASET,"HotPotQA, introduced by Yang et al. in 2018, is a benchmark dataset designed for open-domain question answering. It emphasizes explicit fact retrieval over summarization, aiming to facilitate data sensemaking by enabling systems to accurately retrieve specific pieces of information rather than providing broad overviews. This dataset serves as a valuable resource for researchers and developers in the field of natural language processing, helping them to evaluate and improve the capabilities of question answering systems in handling complex, open-domain queries.",248,,['5d04129d46662571f635a4e63cb4d6b7' '8e69f04648f5fc24c299591365f1aa68'],"[ 0.03261458 -0.00765825 -0.02658871 ... -0.0013913   0.00627428
  0.03795214]"
82b0446e7c9d4fc793f7b97f890e9049,MULTIHOP-RAG,DATASET,"MultiHop-RAG, introduced by Tang and Yang in 2024, is a benchmark dataset specifically designed for open-domain question answering. This dataset emphasizes explicit fact retrieval over summarization, making it an invaluable tool for data sensemaking in complex information environments. By focusing on the retrieval of explicit facts, MultiHop-RAG facilitates a deeper understanding of the underlying data, enabling more accurate and comprehensive answers to open-domain questions.",249,,['5d04129d46662571f635a4e63cb4d6b7' '8e69f04648f5fc24c299591365f1aa68'],"[ 0.03416166  0.00371763 -0.01019386 ... -0.00326431 -0.03313434
  0.03231111]"
8169efeea3ce473d9fd2f1c688126a1c,MT-BENCH,DATASET,"MT-BENCH, also known as MT-Bench, is a benchmark dataset specifically designed for open-domain question answering. Introduced by Zheng et al. in 2024, this dataset emphasizes explicit fact retrieval over summarization, aiming to facilitate data sensemaking in a comprehensive manner. MT-BENCH serves as a valuable resource for researchers and practitioners in the field of information retrieval and natural language processing, enabling them to evaluate and improve their models' performance in answering questions that require the retrieval of specific facts from large, unstructured datasets.",250,,['5d04129d46662571f635a4e63cb4d6b7' '8e69f04648f5fc24c299591365f1aa68'],"[ 0.02349158 -0.0266152  -0.01545043 ... -0.00029235 -0.03931106
  0.01698796]"
c2d48b75af6a4d7989ccf9eceabd934e,DATA SENSEMAKING,"CONCEPT, PROCESS","Data sensemaking is the process through which people inspect, engage with, and contextualize data within the broader scope of real-world activities. It involves summarization for understanding data rather than explicit fact retrieval. Koesten et al. (2021) discuss this concept.",251,,['8e69f04648f5fc24c299591365f1aa68'],"[ 0.00179216  0.01473945 -0.04805919 ... -0.00291184 -0.01127173
  0.03829172]"
5f1fc373a8f34050a5f7dbd8ac852c1b,SUMMARIZATION QUERIES,"PROPERTY, QUERY","Summarization queries are questions or queries that aim to extract a high-level understanding of dataset contents, rather than details of specific texts. They are used for data sensemaking and global understanding of the corpus.",252,,['8e69f04648f5fc24c299591365f1aa68'],"[ 0.05015439 -0.00290987 -0.01250528 ... -0.00708954  0.00928856
  0.00564403]"
0c010fa3aeac4b28b2fbb8c2339c2521,RAG (RETRIEVAL-AUGMENTED GENERATION) SYSTEMS,"SYSTEM, TECHNOLOGY",RAG systems are retrieval-augmented generation systems that combine information retrieval with text generation to answer questions. They are evaluated for their effectiveness in global sensemaking tasks using summarization queries.,253,,['8e69f04648f5fc24c299591365f1aa68'],"[-0.01633906  0.01427236 -0.00669768 ...  0.0258984   0.01971359
  0.02121416]"
c2999bdca08a478b84b10219875b285e,ACTIVITY-CENTERED APPROACH,"METHOD, APPROACH","The Activity-Centered Approach is a methodology used for automating the generation of questions. It involves identifying potential users and tasks per user, and then generating questions that require an understanding of the entire corpus for each (user, task) combination.",254,,['a739018eb63cbb6c26b779bd37afc233'],"[ 0.00295276  0.02830801 -0.03038638 ...  0.00242153 -0.03704919
  0.03040734]"
263d07354a1b4336b462024288f9bcd3,EVALUATION DATASETS,"DATA, INFORMATION",Evaluation Datasets are collections of data used for testing and evaluating the effectiveness of the LLM in generating questions. Each dataset results in 125 test questions when N = 5.,255,,['a739018eb63cbb6c26b779bd37afc233'],"[ 0.02328396  0.01492162 -0.00257844 ...  0.00568475 -0.01434901
  0.05302811]"
f9005e5c01b44bb489f7112322fd1162,GRAPH RAG (RETRIEVAL-AUGMENTED GENERATION),"METHOD, APPROACH","Graph RAG is a method that uses graph communities at different levels (C0, C1, C2, C3) to answer user queries. It leverages summaries from these communities to provide responses.",256,,['a739018eb63cbb6c26b779bd37afc233'],"[ 0.01762855  0.01951428  0.01717005 ... -0.00093767  0.01392674
  0.04874354]"
d9ef017549724f4fbc4ff4ba6701dac0,TEXT SUMMARIZATION METHOD,"METHOD, APPROACH",The Text Summarization Method is an approach that applies a map-reduce technique directly to source texts (TS) to generate summaries. It is used as a condition for comparison in the evaluation.,257,,['a739018eb63cbb6c26b779bd37afc233'],"[ 0.01176475 -0.00224346  0.02304706 ... -0.01004387 -0.0166309
  0.00939997]"
33b9e826af3f43838c07c847b6349497,NAIVE SEMANTIC SEARCH RAG APPROACH,"METHOD, APPROACH",The Naive Semantic Search RAG Approach (SS) is a simple method for answering queries by searching for semantic matches in the text. It is used as a baseline for comparison in the evaluation.,258,,['a739018eb63cbb6c26b779bd37afc233'],"[-0.0183474   0.02909941  0.00982017 ...  0.03454725  0.0065064
  0.04305759]"
dbe9063124d047dc8d6fcaeadcda038f,C0 (ROOT-LEVEL COMMUNITY SUMMARIES),"DATA, INFORMATION","C0 refers to the root-level community summaries, which are the fewest in number. They are used in the Graph RAG approach to answer user queries.",259,,['a739018eb63cbb6c26b779bd37afc233'],"[ 0.04439812 -0.00181793  0.00137925 ...  0.01119305 -0.00510871
  0.02776582]"
c885166d0c454a748376b56279f96408,C1 (HIGH-LEVEL COMMUNITY SUMMARIES),"DATA, INFORMATION","C1 represents high-level community summaries, which are sub-communities of C0 if present, or C0 communities projected down. They are used in the Graph RAG approach to answer queries.",260,,['a739018eb63cbb6c26b779bd37afc233'],"[ 0.03430057  0.00199253  0.02374137 ... -0.00470031  0.01799783
  0.0089822 ]"
586bccefb1e344289c1ee984e165de9c,C2 (INTERMEDIATE-LEVEL COMMUNITY SUMMARIES),"DATA, INFORMATION","C2 consists of intermediate-level community summaries, which are sub-communities of C1 if present, or C1 communities projected down. They are used in the Graph RAG approach to answer queries.",261,,['a739018eb63cbb6c26b779bd37afc233'],"[ 0.02724056  0.01436132  0.02159026 ... -0.02402166 -0.00198633
  0.01542419]"
a2201b8753ba4847ab0b22054e27d2c0,C3 (LOW-LEVEL COMMUNITY SUMMARIES),"DATA, INFORMATION","C3 includes low-level community summaries, which are the greatest in number. They are sub-communities of C2 if present, or otherwise used directly in the Graph RAG approach to answer queries.",262,,['a739018eb63cbb6c26b779bd37afc233'],"[ 0.06292725  0.00362028  0.02215911 ...  0.00117888 -0.00348395
  0.01897518]"
b5ecd0553dd742f5813c9b855d548a41,C1,"COMMUNITY, INFORMATION SYSTEM","C1 refers to a level of community summaries that are used to answer queries. These summaries are sub-communities of C0 if C0 is present, or C0 communities projected down if C0 is not present. C1 communities are at a higher level of detail than C0.",263,,['88847c4d3e6c5a64a5b44d9d99d06237'],"[ 0.02431938  0.0048026  -0.00127875 ... -0.03277846  0.01161409
  0.01347564]"
89b2003e97804961805ea1886d078ebd,C2,"COMMUNITY, INFORMATION SYSTEM","C2 refers to a level of community summaries that are used to answer queries. These summaries are sub-communities of C1 if C1 is present, or C1 communities projected down if C1 is not present. C2 communities are at a higher level of detail than C1.",264,,['88847c4d3e6c5a64a5b44d9d99d06237'],"[ 0.01408419  0.012598    0.01485987 ... -0.04052425  0.0024147
  0.00580802]"
6dd7f5f6b4544271a97f6a136f82fc3d,C3,"COMMUNITY, INFORMATION SYSTEM","C3 refers to a level of community summaries that are used to answer queries. These summaries are sub-communities of C2 if C2 is present, or C2 communities projected down if C2 is not present. C3 communities are the low-level community summaries, greatest in number, and are at a higher level of detail than C2.",265,,['88847c4d3e6c5a64a5b44d9d99d06237'],"[ 0.03570454  0.0044152   0.00323822 ... -0.03431987 -0.00224362
  0.02340856]"
eb01db8435554f2cbafe39a50f62f20a,TS,"INFORMATION PROCESSING, SUMMARIZATION TECHNIQUE","TS is a method that uses the same approach as described in subsection 2.6, with the exception that source texts are shuffled and chunked for the map-reduce summarization stages instead of using community summaries.",266,,['88847c4d3e6c5a64a5b44d9d99d06237'],"[ 0.0018214   0.02628224  0.0008235  ... -0.01028415 -0.01305737
 -0.00122278]"
3d175ad1f0014cd4871eff4e86db9f88,SS,"INFORMATION PROCESSING, SUMMARIZATION TECHNIQUE",SS is an implementation of a naive RAG (Retrieval-Augmented Generation) method in which text chunks are retrieved and added to the available context window until the specified token limit is reached.,267,,['88847c4d3e6c5a64a5b44d9d99d06237'],"[-0.00477826  0.02809143  0.02745993 ... -0.00099997  0.01869473
  0.0288378 ]"
c8e706fbdc90420d952deed03c4f04b4,C0,,,268,,['88847c4d3e6c5a64a5b44d9d99d06237'],"[-0.00295514 -0.00567687  0.02087512 ... -0.02468129  0.00156812
 -0.00710676]"
cf6115e69d6649cc99ef2bd11854ccfb,RAGAS (RETRIEVAL-AUGMENTED GENERATION ASSESSMENT SYSTEM),"TECHNOLOGY, INFORMATION RETRIEVAL","RAGAS, or Retrieval-Augmented Generation Assessment System, is a system that uses LLMs to evaluate the performance of conventional RAG systems. It automatically assesses qualities such as context relevance, faithfulness, and answer relevance.",269,,['53455f8552b0787cb13c5a03eb550842'],"[-0.00337865  0.02052234 -0.0004868  ...  0.03607888 -0.00434528
  0.00860315]"
9ed7e3d187b94ab0a90830b17d66615e,PODCAST DATASET,DATA SET,"The Podcast Dataset is a comprehensive collection of audio content, typically featuring episodes or segments, utilized in various research contexts such as summarization, question answering, and language model performance evaluation. This dataset plays a pivotal role in the indexing process, culminating in a graph structure comprising 8564 nodes and 20691 edges. It serves as a critical resource for assessing language models under different context window sizes, with a specific focus on a context window of 600 tokens for gleaning insights. The Podcast Dataset's multifaceted use underscores its significance in advancing research methodologies and understanding in the field of language processing and analysis.",270,,"['3900d15a5f3ace358fc06038c34cdf79' '53455f8552b0787cb13c5a03eb550842'
 '71f14506a6b15dfabd93fd1606a67b73' 'd08fc91bbfe9749abab38a99a1a88dc6']","[ 0.03389677  0.00717662 -0.03283599 ...  0.04803311 -0.0178251
  0.05972562]"
b4c7432f712849d7aba9dccbb77471ef,NEWS DATASET,DATA SET,"The News Dataset is a comprehensive collection of data, primarily comprising news articles and reports, utilized in the indexing process and subsequent research. This dataset plays a pivotal role in evaluating the performance of language models across different context window sizes. With a total of 15,754 nodes and 19,520 edges, it forms a larger graph compared to the Podcast Dataset. The News Dataset is specifically employed in summarization and question answering experiments, offering a context window size of 600 tokens, albeit with 0 gleanings, indicating a potential absence of additional insights or summaries derived from the dataset.",271,,"['3900d15a5f3ace358fc06038c34cdf79' '53455f8552b0787cb13c5a03eb550842'
 '71f14506a6b15dfabd93fd1606a67b73' 'd08fc91bbfe9749abab38a99a1a88dc6']","[ 0.03562402  0.00759362 -0.0117779  ...  0.02933836 -0.01312367
  0.05170261]"
434e752b992c4e6a812557529315c5b9,RAGAS,,,272,,['53455f8552b0787cb13c5a03eb550842'],"[-0.03091858  0.03413439  0.01982942 ...  0.02999638 -0.02793673
 -0.02579044]"
df79a27b9a4f42fd839c90bb8a79ad91,"WANG ET AL., 2023A","AUTHOR, PUBLICATION","Wang et al., 2023a, are authors of a publication that is referenced in the context of head-to-head comparison of competing outputs in the field of LLMs (Large Language Models).",273,,['cbfd4a09b266218f64dc6e6d80f8a77e'],"[ 0.02912821  0.01585852  0.00439241 ...  0.01965217 -0.04930326
 -0.01860759]"
8f140fd7126f47b6b00307b0181509f9,"LLM AS-A-JUDGE, ZHENG ET AL., 2024","AUTHOR, PUBLICATION","LLM as-a-judge, Zheng et al., 2024, are authors of a publication that discusses the use of LLMs as evaluators in head-to-head comparisons of competing outputs.",274,,['cbfd4a09b266218f64dc6e6d80f8a77e'],"[ 0.00103879 -0.00854706 -0.01123088 ... -0.00754281 -0.02901337
 -0.01190913]"
40450f2c91944a81944621b94f190b49,"RAGAS, ES ET AL., 2023","AUTHOR, PUBLICATION","RAGAS, Es et al., 2023, are authors of a publication that focuses on the evaluation of RAG (Retrieval-Augmented Generation) systems, specifically looking at qualities like context relevance, faithfulness, and answer relevance.",275,,['cbfd4a09b266218f64dc6e6d80f8a77e'],"[-0.01390035  0.0117299  -0.00436039 ...  0.01215827 -0.01407186
 -0.02119397]"
5b9fa6a959294dc29c8420b2d7d3096f,GRAPH RAG MECHANISM,"METHOD, TECHNIQUE","The Graph RAG mechanism is a multi-stage method used for sensemaking activities, which involves the retrieval and integration of information from various sources to answer complex questions.",276,,['cbfd4a09b266218f64dc6e6d80f8a77e'],"[ 0.01011256  0.01235811  0.01272238 ... -0.00532073 -0.00482038
  0.0383005 ]"
b84d71ed9c3b45819eb3205fd28e13a0,HEAD-TO-HEAD COMPARISON APPROACH,"METHOD, TECHNIQUE","The head-to-head comparison approach is a method used to evaluate and compare different outputs or methods by directly contrasting them against each other, often using an LLM evaluator.",277,,['cbfd4a09b266218f64dc6e6d80f8a77e'],"[ 0.00798533  0.02155969 -0.00676737 ... -0.00092597  0.01652013
  0.02783677]"
b0b464bc92a541e48547fe9738378dab,LLM EVALUATOR,"TOOL, TECHNOLOGY","The LLM Evaluator is a sophisticated Large Language Model designed to serve as a critical tool in the evaluation of various methods and outputs, particularly within the realm of sensemaking activities and the assessment of RAG (Relevance, Accuracy, and Grading) systems. This tool is instrumental in gauging the quality of answers by applying a set of predefined metrics. It meticulously compares answers to a given question, judiciously determining which answer is superior based on the established criteria. The LLM Evaluator not only selects the better answer but also provides a detailed rationale for its decision, offering valuable insights into the evaluation process.",278,,['2a5e1212b351d63d059ba1a1dec2811f' 'cbfd4a09b266218f64dc6e6d80f8a77e'],"[ 0.00734289 -0.00100358 -0.0409822  ...  0.02029409 -0.02938111
  0.03920579]"
44c65dda6fb7472dae36f6eea720ab47,TARGET METRICS,"PROPERTY, MEASUREMENT","Target metrics are specific measures used to evaluate the performance of methods or outputs in sensemaking activities, focusing on qualities such as comprehensiveness, diversity, empowerment, and directness.",279,,['cbfd4a09b266218f64dc6e6d80f8a77e'],"[-0.01793834  0.03411209 -0.01805643 ... -0.01397066 -0.00958496
  0.0278687 ]"
5d97ff82691c4482973d73d1860e4757,CONTROL METRIC (DIRECTNESS),"PROPERTY, MEASUREMENT","The control metric, directness, is a measure used to indicate the validity of the evaluation, specifically assessing how specifically and clearly an answer addresses a question. It is often used as a baseline for comparison.",280,,['cbfd4a09b266218f64dc6e6d80f8a77e'],"[ 0.02200846  0.01503449  0.01131947 ... -0.02648675  0.00810263
  0.01063799]"
2567445079794d1e84f17abc48776002,COMPREHENSIVENESS,"PROPERTY, MEASUREMENT","Comprehensiveness is a critical metric utilized in evaluating the quality of answers or responses, particularly those generated by language models. It serves as a measure of how much detail a response provides to cover all aspects and nuances of a question or topic, assessing the thoroughness of the answer in addressing the question's requirements. A higher comprehensiveness score indicates that the response more effectively covers the content of the datasets or the topic at hand, ensuring that all relevant details are included and considered. This metric is essential for determining the level of detail and completeness in responses, enabling a more accurate assessment of their quality and relevance.",281,,"['2a5e1212b351d63d059ba1a1dec2811f' '3900d15a5f3ace358fc06038c34cdf79'
 'cbfd4a09b266218f64dc6e6d80f8a77e' 'd08fc91bbfe9749abab38a99a1a88dc6']","[ 0.0414378  -0.01675032 -0.00329438 ... -0.01610956  0.01005773
  0.00293117]"
392be891f8b649fabdc20e7bf549f669,DIVERSITY,"PROPERTY, MEASUREMENT","Diversity is a comprehensive metric utilized to evaluate the richness and variety of responses or answers in various contexts. It gauges the range of viewpoints, the depth of information, and the uniqueness of content presented, making it a crucial tool for assessing the breadth and quality of insights provided. In the context of language models, Diversity measures the range and uniqueness of generated content, with a higher score indicating greater diversity. Additionally, it is employed to measure the variety of approaches in handling different aspects of datasets, further emphasizing its versatility as a metric in evaluating multifaceted responses.",282,,"['2a5e1212b351d63d059ba1a1dec2811f' '3900d15a5f3ace358fc06038c34cdf79'
 'cbfd4a09b266218f64dc6e6d80f8a77e' 'd08fc91bbfe9749abab38a99a1a88dc6']","[ 0.01695423  0.00883324 -0.03548893 ...  0.00548214 -0.0009787
  0.00610564]"
0111777c4e9e4260ab2e5ddea7cbcf58,EMPOWERMENT,"PROPERTY, MEASUREMENT","Empowerment is a multifaceted concept that serves as a metric in evaluating the effectiveness of methods, systems, and language models in providing users with the necessary information to reach an informed understanding and make educated decisions about a topic. It measures the ability of an answer or generated content to facilitate clarity, understanding, and decision-making, enabling the reader to form educated opinions and take action. Comparisons have shown mixed results when assessing global approaches versus naive RAG and Graph RAG approaches against source text summarization, indicating that the concept of Empowerment can yield varying outcomes depending on the context and methodology employed. The metric of Empowerment is crucial in gauging the empowering potential of answers and content, with a higher win rate suggesting greater empowerment.",283,,"['2a5e1212b351d63d059ba1a1dec2811f' '3900d15a5f3ace358fc06038c34cdf79'
 'cbfd4a09b266218f64dc6e6d80f8a77e' 'ed433e2f5d5387b47376eb0e45ca1c99']","[ 0.01074825 -0.01420383 -0.06059696 ...  0.00691877 -0.02792755
  0.02104731]"
785f7f32471c439e89601ab81c828d1d,DIRECTNESS,"PROPERTY, MEASUREMENT","Directness, in the context of evaluating responses or answers, is a multifaceted validity test and measure. It assesses the degree to which an answer addresses the question in a clear, specific, and straightforward manner. This measure is crucial for determining the relevance and clarity of the response in relation to the query, ensuring that the information provided is not only accurate but also directly pertinent to the topic at hand. By quantifying directness, one can identify how well approaches or responses align with the intended subject, facilitating a more precise and effective communication process.",284,,['2a5e1212b351d63d059ba1a1dec2811f' 'd08fc91bbfe9749abab38a99a1a88dc6'],"[ 0.01989096  0.02587628  0.00259761 ... -0.02292483 -0.0053849
  0.01863376]"
6768339b54084020aec27adcef8994ff,COMPARISON METHOD,"PROCEDURE, EVALUATION METHOD","The Comparison Method involves providing the LLM with a question, a target metric, and a pair of answers. The LLM then assesses which answer is better according to the metric and returns the winner, or a tie if the answers are fundamentally similar.",285,,['2a5e1212b351d63d059ba1a1dec2811f'],"[ 3.16425934e-02  3.46551985e-02 -2.78225821e-02 ... -2.86317244e-02
  3.94789022e-05  2.15301234e-02]"
f09f381c319f4251847d1a4bb8cdcac1,STOCHASTICITY,"PROPERTY, BEHAVIOR","Stochasticity refers to the inherent randomness or variability in the LLM's responses. To account for this, each comparison is run five times and mean scores are used to determine the outcome.",286,,['2a5e1212b351d63d059ba1a1dec2811f'],"[ 0.03017224  0.04993118  0.00771268 ...  0.03640976 -0.00363861
  0.01591225]"
eec11f567e7f4943b157c3a657eb9a46,TABLE 2,"DATA, EXAMPLE","Table 2 is an example of LLM-generated assessment, showing the results of the head-to-head comparisons based on the metrics and conditions evaluated.",287,,['2a5e1212b351d63d059ba1a1dec2811f'],"[-0.01195723  0.00182522  0.02037664 ... -0.0112256   0.02598315
  0.00246169]"
efef117839b64ce9adf614a461d41ba6,FIGURE 4,"DATA, VISUALIZATION","Figure 4 is a visual representation of head-to-head win rate percentages across two datasets, four metrics, and 125 questions per comparison. It shows the performance of different conditions in relation to the metrics.",288,,['2a5e1212b351d63d059ba1a1dec2811f'],"[ 0.06005048 -0.0359454   0.0014939  ... -0.01875582  0.03979834
 -0.03890482]"
2171091ada0942d8ae7944df11659f6e,HEADWINRATEPERCENTAGES,"PROPERTY, MEASUREMENT","Headwin rate percentages represent the success rates of different conditions (row and column conditions) across two datasets, four metrics, and 125 questions per comparison. Each comparison is repeated five times and averaged. The overall winner per dataset and metric is shown in bold. Self-win rates were not computed but are shown as the expected 50% for reference.",289,,['b83d819b03401fb8332316960610e5d6'],"[ 0.03909017 -0.01451218 -0.00770564 ... -0.01015433  0.01416739
 -0.04862012]"
bcfdc48e5f044e1d84c5d217c1992d4b,GRAPHRAGCONDITIONS,"PROPERTY, TECHNIQUE",GraphRAG conditions refer to the conditions under which GraphRAG (a graph-based retrieval-augmented generation model) is applied. These conditions outperformed naive RAG (a retrieval-augmented generation model without a graph index) on comprehensiveness and diversity. Conditions C1-C3 also showed slight improvements in answer comprehensiveness and diversity over TS (global text summarization without a graph index).,290,,['b83d819b03401fb8332316960610e5d6'],"[ 0.00932371 -0.00577353  0.01811628 ... -0.01817291  0.01717507
  0.00245989]"
b232fb0f2ac14790b931d1e7fcddd8ad,CONTEXTWINDOWSIZE,"PROPERTY, PARAMETER","Context window size is a parameter that affects the performance of tasks, especially for models like GPT-4 Turbo, which have a large context size of 128k tokens. The effect of context window size on any particular task is unclear, especially for models with a large context size. The potential for information to be “lost in the middle” of longer contexts is a concern. The optimum context size for the baseline condition (SS) was determined and then used uniformly for all query-time LLM (large language model) use.",291,,['b83d819b03401fb8332316960610e5d6'],"[ 0.04639085 -0.02551581  0.01188733 ...  0.01963229 -0.0453198
  0.00353137]"
1c16b22e18d3483b8d41b284754274e2,VARYING CONTEXT WINDOW SIZE,"PROPERTY, RESEARCH","Varying the context window size is a research variable that was explored to understand its effects on combinations of datasets, questions, and metrics in the context of language model (LLM) use. The goal was to determine the optimum context size for the baseline condition (SS) and apply it uniformly for all query-time LLM use.",292,,['3900d15a5f3ace358fc06038c34cdf79'],"[ 0.03662026 -0.00248316  0.00066878 ...  0.0079798  -0.04555146
  0.0219619 ]"
0080f96708cd4054a5f0986ca86889f4,OPTIMUM CONTEXT SIZE,"PROPERTY, RESEARCH","The optimum context size is the ideal size of the context window that provides the best performance for a given set of conditions, such as datasets, questions, and metrics. In this case, the optimum context size was determined to be 8k tokens for the baseline condition (SS) and was used uniformly for all query-time LLM use.",293,,['3900d15a5f3ace358fc06038c34cdf79'],"[ 0.04631317 -0.00635544  0.01992654 ...  0.01076772 -0.06070857
  0.03225349]"
e683130322ac47708a852a5e51abb7c5,WINDOWSIZE,"PROPERTY, MEASUREMENT","The windowsize refers to the size of the window used in the indexing process for the final evaluation, in this case, it is 8k tokens.",294,,['d08fc91bbfe9749abab38a99a1a88dc6'],"[ 0.02186458 -0.00552603  0.02568008 ...  0.00876111 -0.03098323
 -0.00606716]"
71a0a8c1beb64da08124205e9a803d98,GLOBAL APPROACHES,"METHOD, APPROACH",Global Approaches refer to the methods used in the evaluation that consistently outperformed the naive RAG (SS) approach in both comprehensiveness and diversity metrics across datasets.,295,,['d08fc91bbfe9749abab38a99a1a88dc6'],"[-0.00055083  0.04715556 -0.02692409 ... -0.0016291   0.00254229
  0.04878939]"
f84314943bee4c859c9a62f268c9c216,NAIVE RAG (SS) APPROACH,"METHOD, APPROACH",The Naive RAG (SS) Approach is a method used in the evaluation that was outperformed by global approaches in terms of comprehensiveness and diversity metrics.,296,,['d08fc91bbfe9749abab38a99a1a88dc6'],"[-0.0118011   0.04382671  0.00694662 ...  0.0086048   0.00133808
  0.05595479]"
ba481175ee1d4329bf07757a30abd3a1,MAP-REDUCE SUMMARIZATION,"METHOD, ALGORITHM","Map-Reduce Summarization is a computationally demanding technique utilized in the Graph RAG approach for summarizing extensive text corpora. This method, known for its resource-intensive nature, stands out due to its requirement for the highest number of context tokens among the discussed summarization methods, highlighting its significant computational demands. The process involves two primary stages: the data is first broken down into smaller, manageable parts (map) and then the results from these parts are combined (reduce) to generate a comprehensive summary. Map-Reduce Summarization is often employed in conjunction with other techniques to facilitate human sensemaking over large datasets, making it a crucial tool in the analysis of vast text collections.",297,,['5e2933c9646c751e6a60c9de12a255f2' '71f14506a6b15dfabd93fd1606a67b73'],"[ 0.01278742  0.01148861  0.00630584 ...  0.00472026 -0.02273664
  0.03046957]"
8d8da35190bf43c5878fa38f3eb4f3d2,SOURCE TEXTS,"DOCUMENT, ORIGINAL",Source Texts are the original documents or data from which summaries are derived. They are the primary material that undergoes summarization or analysis.>,298,,['71f14506a6b15dfabd93fd1606a67b73'],"[ 0.00355248 -0.04267675  0.0554099  ... -0.03189006  0.01192742
  0.01872435]"
2fb7e14a3f124526bd7b24867fc18e81,SOURCE TEXT SUMMARIZATION,"METHOD, TECHNOLOGY",Source Text Summarization is a method for creating summaries directly from the original text. It is compared to Graph RAG in terms of context tokens required and comprehensiveness and diversity of the summaries.,299,,['ed433e2f5d5387b47376eb0e45ca1c99'],"[ 0.03314462 -0.01983501  0.02840955 ... -0.02902902  0.00578469
  0.03138274]"
5c13c7d61e6c4bfe839f21e7ad3530a7,LOW-LEVEL COMMUNITY SUMMARIES (C3),"PROPERTY, CATEGORY",Low-level Community Summaries (C3) are a category of summaries that are part of the analysis. Graph RAG requires 26-33% fewer context tokens for these summaries compared to source text summarization.,300,,['ed433e2f5d5387b47376eb0e45ca1c99'],"[ 0.04810062 -0.00505693  0.02518007 ... -0.00439664 -0.00722479
  0.03510071]"
a621663edba64d99b7e50f1e53f32ee7,ROOT-LEVEL COMMUNITY SUMMARIES (C0),"PROPERTY, CATEGORY",Root-level Community Summaries (C0) are a category of summaries that are part of the analysis. Graph RAG requires over 97% fewer context tokens for these summaries compared to source text summarization.,301,,['ed433e2f5d5387b47376eb0e45ca1c99'],"[ 0.03291493 -0.00159383 -0.00332483 ...  0.00393461 -0.00737628
  0.02580259]"
42be4e140061482ea509dd3e26189480,INFORMED UNDERSTANDING,"CONCEPT, INFORMATION PROCESSING","Informed Understanding refers to the process by which users reach a comprehensive and knowledgeable comprehension of a subject, often facilitated by specific examples, quotes, and citations.",302,,['38feec52b8bfbd3fd8e03635acdaec97'],"[-0.01617866  0.01075077 -0.03095368 ... -0.00665653  0.00353158
  0.00850146]"
4da4ef951ff340f1a3dd679de4be3341,GRAPH RAG INDEX,"PROPERTY, INFORMATION SYSTEM","Graph RAG Index is a component of a system designed to enhance the retrieval of relevant information by indexing and organizing data in a graph structure, potentially improving the efficiency and effectiveness of information retrieval.",303,,['38feec52b8bfbd3fd8e03635acdaec97'],"[-0.00840482  0.00831829  0.01497332 ...  0.02532952  0.01001194
  0.04295549]"
2f05fcce857e4a499ca4e89a3cefbcb3,TUNING ELEMENT EXTRACTION PROMPTS,"PROPERTY, INFORMATION RETRIEVAL","Tuning Element Extraction Prompts involves refining the prompts used to extract information from documents, which can help in retaining more details in the Graph RAG index, potentially improving the quality of information retrieval.",304,,['38feec52b8bfbd3fd8e03635acdaec97'],"[ 0.02145233 -0.00343193 -0.01383003 ... -0.01096394 -0.00130184
  0.02475139]"
b3aeb7ae009a4f52ae3ae4586e32fe11,RAG APPROACHES,"CONCEPT, INFORMATION RETRIEVAL","RAG Approaches refer to the methods and systems used to retrieve relevant information from external data sources to augment the context window of Large Language Models (LLMs), aiding in answering queries with more comprehensive information.",305,,['38feec52b8bfbd3fd8e03635acdaec97'],"[ 0.00742587  0.00519493 -0.02363024 ...  0.02883239 -0.02368347
  0.06544576]"
089b9b9841714b8da043777e2cda3767,ADVANCED RAG<||ADVANCED RAG,"CONCEPT, INFORMATION RETRIEVAL","Advanced RAG encompasses more sophisticated variations of Retrieval-Augmented Generation (RAG) systems that include pre-retrieval, retrieval, and post-retrieval strategies designed to overcome the limitations of Naive RAG, often incorporating iterative and dynamic cycles of retrieval and generation.",306,,['38feec52b8bfbd3fd8e03635acdaec97'],"[ 0.00023616  0.02011226 -0.00166599 ... -0.00653499  0.03181376
  0.03916859]"
38f1e44579d0437dac1203c34678d3c3,MODULAR RAG,"PROPERTY, INFORMATION RETRIEVAL","Modular RAG is a type of RAG system that includes patterns for iterative and dynamic cycles of interleaved retrieval and generation, designed to enhance the flexibility and adaptability of information retrieval processes.",307,,['38feec52b8bfbd3fd8e03635acdaec97'],"[-0.00449712 -0.00215094  0.01067193 ...  0.0261448   0.02168532
  0.05232214]"
1ca24718a96b47f3a8855550506c4b41,ADVANCED RAG,,"Advanced RAG (Retrieval-Augmented Generation) is a cutting-edge technology and research area where the index is a knowledge graph, as detailed by Gao et al. in 2023. This innovative approach leverages knowledge graphs to enhance the generation of text and facilitate advanced retrieval and analysis of information. By integrating a knowledge graph as the indexing mechanism, Advanced RAG enables more sophisticated and contextually rich text generation, making it a significant advancement in the field of information retrieval and natural language processing.",308,,"['38feec52b8bfbd3fd8e03635acdaec97' '40f2d6a0270e54743e7ace239369da96'
 '7383c69e93bb8c8648181f5355d2c9a7']","[ 0.00620973  0.0211447  -0.00167817 ... -0.00588813 -0.00479416
  0.03926799]"
9c980dfe3cab44b7a83408405edab0b6,LLM’S CONTEXT WINDOW,"CONCEPT, TECHNIQUE","LLM’s context window refers to the limitation of a large language model in processing and understanding text, where the model can only consider a fixed amount of text at a time, typically a few thousand tokens. This context window can affect the model's ability to understand and generate text that is longer than the window size.>",309,,['7da3d8d244b67f09425a4a7783e4bb55'],"[ 0.04074272 -0.02068091 -0.01984933 ...  0.03238794 -0.03491375
  0.02673189]"
f23484b1b45d44c3b7847e1906dddd37,ADVANCED RAG SYSTEMS,"CONCEPT, TECHNIQUE","Advanced RAG systems are retrieval-augmented generation systems that include pre-retrieval, retrieval, and post-retrieval strategies designed to overcome the drawbacks of Naive RAG. These systems are more sophisticated and can handle complex tasks by incorporating various strategies for retrieval and generation.>",310,,['7da3d8d244b67f09425a4a7783e4bb55'],"[-0.00609954  0.01807854  0.00541112 ... -0.00450364  0.02941039
  0.03145956]"
929f30875e1744b49e7b416eaf5a790c,MODULAR RAG SYSTEMS,"CONCEPT, TECHNIQUE",Modular RAG systems are retrieval-augmented generation systems that include patterns for iterative and dynamic cycles of interleaved retrieval and generation. These systems are designed to be flexible and can adapt to different retrieval and generation requirements.>,311,,['7da3d8d244b67f09425a4a7783e4bb55'],[0.00014739 0.00635463 0.00778776 ... 0.01702288 0.03817048 0.03835838]
4920fda031804ce8a1073ace8e061ed6,PARALLEL GENERATION OF COMMUNITY ANSWERS,"CONCEPT, TECHNIQUE",Parallel generation of community answers is a technique where community answers are generated simultaneously from community summaries. This approach can improve the efficiency and effectiveness of retrieval and generation by leveraging the power of parallel processing.>,312,,['7da3d8d244b67f09425a4a7783e4bb55'],"[ 0.00362559  0.02134811 -0.04361875 ... -0.03349927  0.00818897
 -0.01437683]"
4b8aa4587c7344adac2cbfa69d5e40fa,ITERATIVE RETRIEVAL-GENERATION STRATEGY,"CONCEPT, TECHNIQUE",Iterative retrieval-generation strategy is a method where retrieval and generation are performed in a series of iterative cycles. This strategy allows for continuous refinement and improvement of the retrieval and generation process.>,313,,['7da3d8d244b67f09425a4a7783e4bb55'],"[-0.01706718 -0.00381606  0.01225497 ... -0.01395707  0.04773645
  0.02837929]"
52701d941dfb45359693baae8f267056,FEDERATED RETRIEVAL-GENERATION STRATEGY,"CONCEPT, TECHNIQUE",Federated retrieval-generation strategy is a method where retrieval and generation are performed in a distributed and collaborative manner. This strategy allows for the sharing of resources and information across multiple systems or nodes.>,314,,['7da3d8d244b67f09425a4a7783e4bb55'],"[-0.03891794 -0.01185628 -0.03675006 ... -0.01351896  0.04727554
  0.02313369]"
31499ee6277a4d71b19cb5b6be554c69,MULTI-DOCUMENT SUMMARIZATION,"CONCEPT, TECHNIQUE","Multi-document summarization is a technique for creating a concise and coherent summary of multiple documents. This technique is used to provide a high-level overview of the content of multiple documents, which can be useful for information retrieval and analysis.>",315,,['7da3d8d244b67f09425a4a7783e4bb55'],"[ 0.04513585  0.01282136  0.01340846 ... -0.03300624  0.01134288
  0.06059413]"
d99eabad5dfd47278692569d2a9395b1,MULTI-HOP QUESTION ANSWERING,"CONCEPT, TECHNIQUE",Multi-hop question answering is a technique for answering questions that require reasoning over multiple pieces of information or documents. This technique is used to handle complex questions that cannot be answered by a single piece of information or document.>,316,,['7da3d8d244b67f09425a4a7783e4bb55'],"[ 0.06348132 -0.00250399 -0.06147335 ... -0.05102759 -0.04457656
  0.00420576]"
d53f15cb7f7845de91cc44ad44ff9f6e,HIERARCHICAL INDEX,"CONCEPT, TECHNIQUE",Hierarchical index is a data structure that organizes information in a hierarchical manner. This index is used to improve the efficiency and effectiveness of information retrieval by allowing for faster and more accurate search and retrieval of information.>,317,,['7da3d8d244b67f09425a4a7783e4bb55'],"[-0.02397686 -0.01306845 -0.00539679 ...  0.00359902  0.04006268
 -0.01468431]"
23becf8c6fca4f47a53ec4883d4bf63f,SUMMARIZATION,"CONCEPT, TECHNIQUE","Summarization is a technique for creating a concise and coherent summary of a document or set of documents. This technique is used to provide a high-level overview of the content of a document or set of documents, which can be useful for information retrieval and analysis.>",318,,['7da3d8d244b67f09425a4a7783e4bb55'],"[ 0.02970448 -0.00929338  0.0237009  ... -0.01531808  0.00109108
  0.048739  ]"
d0ffa3bcd1234258953ff4956d19f561,CAIRE-COVID,RESEARCH STUDY,"CAiRE-COVID is a research study conducted by Su et al. in 2020, focusing on the impact of COVID-19 on various aspects of society and health.",319,,['40f2d6a0270e54743e7ace239369da96'],"[-0.01177122  0.00030522 -0.02887597 ... -0.01267201 -0.00649687
 -0.01988114]"
ac41b77ba33c4c84877eb425aba03aa1,ITRG,RESEARCH STUDY,"ITRG is a research study that involves multi-hop question answering, as described by Feng et al. in 2023.",320,,['40f2d6a0270e54743e7ace239369da96'],"[ 0.00529302 -0.003108   -0.06951348 ... -0.00454898 -0.0136214
  0.00148483]"
5d3184dabfd647a5a7e565f72c60ff24,IR-COT,RESEARCH STUDY,"IR-CoT is a research study that deals with multi-hop question answering, as described by Trivedi et al. in 2022.",321,,['40f2d6a0270e54743e7ace239369da96'],"[ 0.02057449 -0.00966542 -0.02491361 ... -0.00708742  0.0007102
 -0.01646503]"
0ec262c2cfef4dd581f3655e5e496e31,DSP,RESEARCH STUDY,"DSP is a research study that involves multi-hop question answering, as described by Khattab et al. in 2022.",322,,['40f2d6a0270e54743e7ace239369da96'],"[ 0.02273092  0.00465016 -0.04592443 ... -0.04342288 -0.04937138
  0.02699632]"
100c2fccd7f74d9281707082f062ba72,RAPTOR,RESEARCH STUDY,"RAPTOR is a research study that involves generating a hierarchical index of text chunks by clustering the vectors of text embeddings, as described by Sarthi et al. in 2024.",323,,['40f2d6a0270e54743e7ace239369da96'],"[ 0.00099066  0.00290945 -0.02019756 ...  0.00314033  0.03933865
  0.0031368 ]"
378fc7636eeb4aabbfd40995a6960c64,TREE OF CLARIFICATIONS,RESEARCH STUDY,"Tree of Clarifications is a research study that involves generating a “tree of clarifications” to answer multiple interpretations of ambiguous questions, as described by Kim et al. in 2023.",324,,['40f2d6a0270e54743e7ace239369da96'],"[ 0.01939877 -0.00355001 -0.03316722 ...  0.01479742  0.0019229
  0.02224724]"
80a04aa18cd649d584292f23b10c0727,KNOWLEDGE GRAPH CREATION,RESEARCH STUDY,"Knowledge Graph Creation is a research area that involves using LLMs to create knowledge graphs, as described by Trajanoska et al. in 2023.",325,,['40f2d6a0270e54743e7ace239369da96'],"[ 0.02499536  0.01326481 -0.0338569  ... -0.00593325 -0.04954418
  0.05749451]"
4e9ca18ccc1d4527a3bc035d07f5e162,KNOWLEDGE GRAPH COMPLETION,RESEARCH STUDY,"Knowledge Graph Completion is a research area that involves using LLMs to complete knowledge graphs, as described by Yao et al. in 2023.",326,,['40f2d6a0270e54743e7ace239369da96'],"[ 0.01927051  0.00324799 -0.01414189 ...  0.01095926 -0.05642781
  0.032307  ]"
5564257e89f1428486a64fcf52f49490,CAUSAL GRAPH EXTRACTION,RESEARCH STUDY,"Causal Graph Extraction is a research area that involves using LLMs to extract causal graphs from source texts, as described by Ban et al. in 2023 and Zhang et al. in 2024.",327,,['40f2d6a0270e54743e7ace239369da96'],"[-0.01090042  0.01892219 -0.03435066 ... -0.01494118 -0.02189182
  0.04705315]"
83c76fbd2a004d90a5b0a6736ffed61d,KAPING,RESEARCH STUDY,"KAPING, a pioneering research study introduced by Baek et al. in 2023, delves into the realm of advanced RAG (Retrieval-Augmented Generation) techniques. Central to KAPING's methodology is the utilization of a knowledge graph as the index, a concept detailed by Baek et al. in their work. This system uniquely focuses on subsets of the graph structure as the primary objects of enquiry, enabling researchers to query specific parts of the knowledge graph for detailed information. Through this approach, KAPING aims to enhance understanding and facilitate the retrieval of intricate data within specialized professional networks, thereby identifying collaboration opportunities and knowledge gaps in the field.",328,,['40f2d6a0270e54743e7ace239369da96' '7383c69e93bb8c8648181f5355d2c9a7'],"[ 2.72271521e-02  1.88374501e-02 -5.65229682e-03 ... -3.55963675e-05
  1.00290552e-02  3.49191912e-02]"
d9779c41e3c74fe0b26e23822a4b995b,LLMS FOR KNOWLEDGE GRAPH CREATION,"TECHNOLOGY, APPLICATION","LLMs (Large Language Models) are used for the creation of knowledge graphs, as demonstrated by the work of Trajanoska et al. in 2023. This involves the automatic generation of structured knowledge graphs from unstructured text data.",329,,['7383c69e93bb8c8648181f5355d2c9a7'],"[ 0.05717922  0.0074481  -0.00535312 ...  0.03571255 -0.05755464
  0.03615416]"
9d7a563b3b2d405092c31f1fe08cff77,LLMS FOR KNOWLEDGE GRAPH COMPLETION,"TECHNOLOGY, APPLICATION","LLMs are also applied for the completion of knowledge graphs, as shown by the research of Yao et al. in 2023. This involves enhancing existing knowledge graphs by filling in missing information or relationships.",330,,['7383c69e93bb8c8648181f5355d2c9a7'],"[ 0.03759762  0.01510631 -0.00882632 ...  0.01541525 -0.06181611
  0.04932911]"
bd43f3d439a54781bd4b721a9a269b92,LLMS FOR CAUSAL GRAPH EXTRACTION,"TECHNOLOGY, APPLICATION","LLMs are used for the extraction of causal graphs from source texts, as evidenced by the work of Ban et al. in 2023 and Zhang et al. in 2024. This involves identifying causal relationships between entities in the text.",331,,['7383c69e93bb8c8648181f5355d2c9a7'],"[ 0.0158633   0.02870335 -0.00960857 ...  0.00265692 -0.0455786
  0.04517817]"
adc0f95733e74351a891c4dadf650a52,G-RETRIEVER,"TECHNOLOGY, APPLICATION","G-Retriever, introduced by He et al. in 2024, is a system that retrieves specific parts of a graph structure. This involves querying a graph for specific information or relationships.",332,,['7383c69e93bb8c8648181f5355d2c9a7'],"[ 0.03733843 -0.02124599 -0.02333998 ... -0.02023828 -0.00997202
  0.04564111]"
225105a7be14447cb03186bd40756059,GRAPHTOOLFORMER,"TECHNOLOGY, APPLICATION","GraphToolFormer, developed by Zhang in 2023, is a system that uses derived graph metrics as the objects of enquiry. This involves analyzing graph metrics to extract information.",333,,['7383c69e93bb8c8648181f5355d2c9a7'],"[ 0.01872157 -0.00018219 -0.01038411 ... -0.04243387 -0.00881965
  0.02089156]"
efce8a9d61254447a26aee99e53f0398,SURGE,"TECHNOLOGY, APPLICATION","SURGE, created by Kang et al. in 2023, is a system where narrative outputs are strongly grounded in the facts of retrieved subgraphs. This involves generating narratives based on the information retrieved from subgraphs.",334,,['7383c69e93bb8c8648181f5355d2c9a7'],"[ 0.04187965 -0.01227327 -0.01290176 ... -0.00790394  0.01184471
  0.00937673]"
4a75a9f0b18a48bea9c0601c0fc395c4,FABULA,"TECHNOLOGY, APPLICATION","FABULA, developed by Ranade and Joshi in 2023, is a system that serializes retrieved event-plot subgraphs using narrative templates. This involves creating narratives from event plots retrieved from graphs.",335,,['7383c69e93bb8c8648181f5355d2c9a7'],"[ 0.01539221 -0.0217191   0.00548598 ...  0.01274757  0.06363182
  0.01856588]"
e19287afe00a431f9a593a4827d1b448,SYSTEM FOR MULTI-HOP QUESTION ANSWERING,"TECHNOLOGY, APPLICATION","A system that supports both creation and traversal of text-relationship graphs for multi-hop question answering, as described by Wang et al. in 2023b. This involves answering complex questions that require understanding relationships across multiple pieces of text.",336,,['7383c69e93bb8c8648181f5355d2c9a7'],"[ 0.0493805  -0.01498753 -0.05003091 ... -0.03021199 -0.01367865
 -0.00462109]"
f2c06f3a0c704296bf3353b91ee8af47,LANGCHAIN,"TECHNOLOGY, APPLICATION","LangChain, as of 2024, is a versatile library that facilitates the creation and navigation of text-relationship graphs, specifically designed to enhance multi-hop question answering capabilities. It is compatible with a wide range of graph databases, making it an ideal choice for Retrieval-Augmented Generation (RAG) applications. LangChain offers a comprehensive suite of tools and interfaces for effectively managing and manipulating graph data, enabling users to leverage the power of graph databases in their projects.",337,,['7383c69e93bb8c8648181f5355d2c9a7' 'e015335cdcae20e6546fe7cbdef56c1a'],"[ 0.05028896  0.02919274 -0.0229018  ... -0.01534173 -0.01892977
  0.02439307]"
f512103ed4624accac6cbbf90d7d250a,LLAMAINDEX,"TECHNOLOGY, APPLICATION","LlamaIndex, as of 2024, is a sophisticated library designed to facilitate the creation and navigation of text-relationship graphs. This library is pivotal for multi-hop question answering, enabling complex queries that require understanding relationships between multiple pieces of information. It is notable for its compatibility with a wide range of graph databases, making it a versatile tool for Retrieval-Augmented Generation (RAG) applications. LlamaIndex offers a comprehensive suite of tools and interfaces for managing graph data, making it an essential resource for developers and researchers working in the field of graph-based information retrieval and analysis.",338,,['7383c69e93bb8c8648181f5355d2c9a7' 'e015335cdcae20e6546fe7cbdef56c1a'],"[ 0.02855473  0.0351394  -0.00505764 ...  0.00470348  0.01785269
  0.02742369]"
2325dafe50d1435cbee8ebcaa69688df,GRAPH-BASED RAG APPLICATIONS,"TECHNOLOGY, APPLICATION",A more general class of graph-based RAG (Retrieval-Augmented Generation) applications is emerging. This involves the use of graph data in various applications for retrieval and generation.,339,,['7383c69e93bb8c8648181f5355d2c9a7'],"[2.31254846e-02 1.35854846e-02 4.19504977e-05 ... 2.25919727e-02
 1.72589496e-02 1.67812575e-02]"
469aeef98cd1421fa123277b93d7b83a,NEO4J,"SOFTWARE, DATABASE","Neo4J is a graph database that can be used to create and reason over knowledge graphs, and is supported by LangChain and LlamaIndex libraries for RAG applications.",340,,['e015335cdcae20e6546fe7cbdef56c1a'],"[ 0.02953883  0.01844379 -0.0203276  ...  0.02216422 -0.01004841
  0.06275056]"
2fb66f9a0de6406d83b61742a3b52cd6,NEBULAGRAPH,"SOFTWARE, DATABASE","NebulaGraph is a graph database that can be used to create and reason over knowledge graphs, and is supported by LangChain and LlamaIndex libraries for RAG applications.",341,,['e015335cdcae20e6546fe7cbdef56c1a'],"[ 0.01253991  0.03859957 -0.01637177 ... -0.00016949 -0.00786153
 -0.00561514]"
b0e6cfd979ea48b997019b059999d3c2,EVALUATION APPROACH,"METHOD, PROCESS","The evaluation approach has limitations, as it has only examined a certain class of sensemaking questions for two corpora in the region of 1 million tokens. More work is needed to understand how performance varies across different ranges of question types, data types, and dataset sizes.",342,,['e015335cdcae20e6546fe7cbdef56c1a'],"[ 0.01091517  0.00804936 -0.03974429 ...  0.01415873 -0.01899691
  0.00389574]"
ef00ec3a324f4f5986141401002af3f6,SELFCHECKGPT,"SOFTWARE, APPLICATION","SelfCheckGPT, developed by Manakul et al. in 2023, is an advanced AI model designed to enhance the analysis of Graph RAG's performance. This innovative application specializes in comparing fabrication rates, offering a significant improvement over existing analysis methods. By leveraging the capabilities of SelfCheckGPT, users can gain deeper insights into the efficiency and effectiveness of fabrication processes, ultimately leading to optimized performance and better decision-making in the Motor Control and Drive Systems domain.",343,,['7040ba36a7c09899a355d14a30d65375' 'e015335cdcae20e6546fe7cbdef56c1a'],"[ 0.02429659 -0.01439186  0.02000067 ...  0.00122645 -0.00080216
 -0.01646157]"
a542fd7aed7341468028928937ea2983,1 MILLION TOKENS,"QUANTITY, DATA_SIZE","The region of 1 million tokens refers to a specific size of data or text, which is a significant amount for analyzing performance in various tasks and models.",344,,['7040ba36a7c09899a355d14a30d65375'],"[ 0.02233888 -0.00768819 -0.02120751 ...  0.01159138 -0.04185868
  0.00443287]"
1c5e296a5ac541c1b5cac4357537c22d,QUESTION TYPES,"PROPERTY, TASK","Question types represent the various categories or formats of questions that can be asked or generated, which can affect the performance of models or systems in different ways.",345,,['7040ba36a7c09899a355d14a30d65375'],"[ 0.03276112 -0.00657095 -0.01761762 ... -0.00224928  0.00090634
 -0.02049624]"
5ecf534a9ffe46e0b1c2144110c691c0,DATA TYPES,"PROPERTY, DATA_CLASSIFICATION","Data types refer to the classification or categories of data, such as numerical, textual, categorical, etc., which can influence the performance of models or systems depending on their specific capabilities.",346,,['7040ba36a7c09899a355d14a30d65375'],"[-0.00809663 -0.0226198   0.01822349 ...  0.02048103 -0.01073424
 -0.01253519]"
4d183e7007624fcd98af96b9d752c16d,DATASET SIZES,"QUANTITY, DATA_SIZE","Dataset sizes refer to the volume or scale of datasets used for training or evaluating models, which can impact the performance of models due to the amount of data they have to process.",347,,['7040ba36a7c09899a355d14a30d65375'],"[ 0.02378109 -0.01875557  0.02079271 ...  0.03992213 -0.03194995
  0.01657957]"
718c507cb8ac49e6a35c251ac951b5ca,END USERS,"PERSON, USER","End users are the individuals or groups who will ultimately use or benefit from the models, systems, or services, and their feedback is crucial for validating the effectiveness of the sensemaking questions and target metrics.",348,,['7040ba36a7c09899a355d14a30d65375'],"[-0.03439373  0.01008588 -0.0561641  ...  0.01036184  0.00018095
  0.00419557]"
b45ef27279c043269b23b894461d7d8c,GLOBAL SUMMARIZATION,"PROPERTY, TEXT_PROCESSING","Global summarization is a text processing technique that generates a concise summary of the entire source text, which can be used to provide an overview of the content and can be competitive with the graph index approach in some cases.",349,,['7040ba36a7c09899a355d14a30d65375'],"[ 0.031024    0.01149156 -0.00783351 ... -0.03232836 -0.01533245
  0.03768625]"
10983a248cc448c59c94df4d1d0898f0,COMPUTE BUDGET,"PROPERTY, COST","Compute budget refers to the financial resources allocated for computing tasks, which can influence the decision to invest in building a graph index due to the potential costs associated with its creation and maintenance.",350,,['7040ba36a7c09899a355d14a30d65375'],"[ 0.01235577 -0.02489509 -0.03860686 ... -0.02068096 -0.01004566
  0.01324702]"
e2ec7d3cdbeb4dd086ae6eb399332363,LIFETIME QUERIES,"PROPERTY, QUERY_FREQUENCY","Lifetime queries refer to the expected number of queries that will be made to a dataset over its lifetime, which can affect the decision to invest in building a graph index due to the potential benefits of faster querying.",351,,['7040ba36a7c09899a355d14a30d65375'],"[-0.00608773  0.02757208 -0.01094715 ... -0.0217811   0.01430772
 -0.00730249]"
67f10971666240ea930f3b875aabdc1a,GRAPH-RELATED RAG APPROACHES,"PROPERTY, AI_MODEL","Graph-related RAG approaches are variations of the Retrieval-Augmented Generation model that utilize graph structures for various tasks, such as summarization or question answering, and they can offer additional benefits beyond the basic graph index.",352,,['7040ba36a7c09899a355d14a30d65375'],"[ 0.00906603  0.00676646 -0.0171592  ...  0.00943641  0.02149282
  0.032588  ]"
8b95083939ad4771b57a97c2d5805f36,FUTURE WORK,"PROPERTY, RESEARCH","Future work refers to the potential research directions or improvements that can be pursued, which can include refining and adapting the current Graph RAG approach, as well as exploring hybrid RAG schemes that combine different techniques.",353,,['7040ba36a7c09899a355d14a30d65375'],"[ 0.01304931  0.01608269 -0.04659195 ... -0.02052019  0.00290081
  0.03099219]"
3c4062de44d64870a3cc5913d5769244,HIERARCHICAL COMMUNITY STRUCTURE,"CONCEPT, ORGANIZATION","Hierarchical community structure refers to the organization of communities within a graph or text corpus at different levels. This structure supports the refinement and adaptation of the Graph RAG approach by allowing for ""roll-up"" operations across multiple levels and ""drill down"" mechanisms that follow the information scent contained in higher-level community summaries.",354,,['5e2933c9646c751e6a60c9de12a255f2'],"[ 0.02113174 -0.01436206 -0.00807339 ... -0.0022082  -0.00098651
  0.01670771]"
24652fab20d84381b112b8491de2887e,EMBEDDING-BASED MATCHING,"METHOD, TECHNIQUE",Embedding-based matching is a technique used in the Graph RAG approach to match user queries and graph annotations in a more local manner. It involves converting textual information into numerical vectors (embeddings) to compare and find relevant information.,355,,['5e2933c9646c751e6a60c9de12a255f2'],"[ 0.01623273  0.01476165  0.00177027 ...  0.01167069  0.00142415
 -0.0158626 ]"
d4602d4a27b34358baa86814a3836d68,HYBRID RAG SCHEMES,"METHOD, TECHNIQUE","Hybrid RAG schemes are a combination of different methods in the Graph RAG approach, which include embedding-based matching against community reports before employing map-reduce summarization mechanisms. These schemes aim to improve the comprehensiveness and diversity of answers by integrating various techniques.",356,,['5e2933c9646c751e6a60c9de12a255f2'],"[-0.00825919  0.00905917 -0.00146136 ... -0.00166912  0.02781756
  0.02528927]"
36be44627ece444284f9e759b8cd25c6,ANSWER IIVENESS AND DIVERSITY,"PROPERTY, QUALITY",Answer Iiveness and Diversity refers to the richness and variety of responses or solutions generated by a system or method. It is a measure of the system's capability to produce a wide range of answers or solutions to a given problem or query.,357,,['e31d2d134cf501c93f9445914d7350f9'],"[ 0.01189357  0.03697221 -0.02749731 ... -0.02579956  0.00532635
  0.00034542]"
a64b4b17b07a44e4b1ac33580d811936,GLOBAL BUT GRAPH-FREE APPROACH,"METHOD, TECHNIQUE",The Global but Graph-free Approach is a method that uses map-reduce source text summarization techniques to process and summarize large datasets without relying on graph structures. It is a computational approach that can handle global queries over large datasets.,358,,['e31d2d134cf501c93f9445914d7350f9'],"[-0.00506615  0.03081495 -0.01398273 ... -0.02276178 -0.01915434
  0.00731143]"
423b72bbd56f4caa98f3328202c1c3c9,ENTITY-BASED GRAPH INDEX,"DATA STRUCTURE, INDEX","The Entity-based Graph Index is a data structure that organizes and indexes information based on entities and their relationships in a graph format. It provides a superior data index for root-level communities, offering better performance and efficiency compared to naive RAG (Retrieval-Augmented Generation) and other global methods.",359,,['e31d2d134cf501c93f9445914d7350f9'],"[-0.00092952  0.01717312 -0.01559858 ...  0.00972425 -0.00044743
  0.01703512]"
5c7ef01f46a94641bf1ae5cd25f8a538,ROOT-LEVEL COMMUNITIES,"GROUP, COMMUNITY","Root-level Communities are the fundamental or top-level groups within a dataset or graph structure. They represent the highest-level divisions or categories in the data, which can be further analyzed or queried for detailed information.",360,,['e31d2d134cf501c93f9445914d7350f9'],"[ 0.01632675 -0.01074942 -0.04641655 ...  0.03013373 -0.01030084
 -0.0007876 ]"
aefde1f7617f4c0e9aed31db77f6d862,GLOBAL METHODS,"METHOD, TECHNIQUE","Global Methods refer to computational techniques or algorithms that can handle global queries or operations over large datasets. These methods are designed to process and analyze data at a global scale, often requiring significant computational resources and token costs.",361,,['e31d2d134cf501c93f9445914d7350f9'],"[-0.00954269  0.03191654 -0.04123226 ... -0.01456429 -0.03708896
  0.05153333]"
ad52ba79a84748a49067e53b1d5095f9,TOKEN COST,"PROPERTY, COST",Token Cost is a measure of the computational or resource cost associated with processing or analyzing data in a graph or dataset. It represents the cost of operations or queries in terms of the number of tokens or computational units required.,362,,['e31d2d134cf501c93f9445914d7350f9'],"[-0.00035472  0.00247318 -0.0219408  ...  0.03187808 -0.01666456
  0.01786133]"
289616058bf4495887292003b27ba216,GRAPHRAG INDEXING,"SOFTWARE, TECHNOLOGY","GraphRAG Indexing is a sophisticated suite of data pipeline and transformation tools, designed to extract structured data from unstructured text by leveraging Large Language Models (LLMs). This system is highly configurable, offering both default and custom configuration modes to optimize the performance and integration of the Indexing Engine pipelines. GraphRAG Indexing includes workflows, standard and custom steps, prompt templates, and input/output adapters, enabling entity extraction, relationship detection, community detection, and data embedding into vector spaces. The suite supports configuration through the init command, environment variables, and JSON or YAML files for deeper control, ensuring flexibility and adaptability. Outputs from GraphRAG Indexing can be stored in JSON, Parquet, or accessed via the Python API, facilitating seamless integration into various data processing workflows.",363,,['251e8d332b451d900df961cbe215bca0' 'ccd2de9e2219521fbca779843c65af58'],"[ 0.0099667   0.01078495 -0.01421123 ... -0.02015328 -0.00719036
  0.04826494]"
7ffa3a064bce468082739c5a164df5a3,INDEXING PIPELINES,"PROCESS, TECHNOLOGY","Indexing Pipelines are configurable workflows within the GraphRAG indexing package. They consist of standard and custom steps, prompt templates, and input/output adapters. These pipelines are designed to extract entities, relationships, and claims from raw text, perform community detection, generate summaries and reports, and embed data into vector spaces. Outputs can be stored in various formats or accessed through the Python API.>",364,,['251e8d332b451d900df961cbe215bca0'],"[-0.01188401  0.0095214  -0.02051129 ... -0.05952785  0.04098883
  0.02960798]"
ce36d1d637cf4a4e93f5e37ffbc6bd76,ENTITY EXTRACTION,"FUNCTION, TECHNOLOGY","Entity Extraction is a pivotal function within the GraphRAG indexing suite, serving as a configuration section that specializes in settings for extracting entities from text. This process is essential for deciphering the components of unstructured text, acting as a cornerstone in the indexing pipeline. The section manages various parameters such as the Language Model (LLM), parallelization, async mode, prompt file, entity types, max gleanings, and strategy. The entities identified and extracted through Entity Extraction are further analyzed to uncover relationships and detect communities, contributing significantly to the structured data produced by the indexing process.",365,,['251e8d332b451d900df961cbe215bca0' 'abac77a5673e907cf8d65161c2612784'],"[-0.0111802   0.01195419 -0.04171039 ... -0.03895677 -0.02732978
  0.06055956]"
eeb9c02c0efa4131b9e95d33c31019fc,RELATIONSHIP DETECTION,"FUNCTION, TECHNOLOGY","Relationship Detection is a function within the GraphRAG indexing suite that identifies relationships between entities extracted from unstructured text. This process helps in understanding the context and connections within the text, contributing to the generation of structured data. The detected relationships are part of the outputs that can be stored in various formats or accessed through the Python API.>",366,,['251e8d332b451d900df961cbe215bca0'],"[ 0.002716    0.01127605 -0.033544   ...  0.03001621  0.02525989
  0.03203511]"
7b2472c5dd9949c58828413387b94659,COMMUNITY DETECTION,"FUNCTION, TECHNOLOGY","Community Detection is a sophisticated function embedded within the GraphRAG indexing suite, specifically operating as a subprocess during Phase 3: Graph Augmentation. This process leverages the Hierarchical Leiden Algorithm to meticulously identify and generate a hierarchy of entity communities, thereby facilitating a deeper understanding of the community structure within the graph. By analyzing the connectivity patterns of nodes, Community Detection effectively discerns groups or clusters of related entities, enabling the summarization and reporting of text data at various levels of granularity. The outcomes of this algorithmic process significantly enrich the structured data outputs of the indexing procedure, providing a valuable tool for navigating and summarizing the graph data in a more organized and insightful manner.",367,,"['251e8d332b451d900df961cbe215bca0' '493f38f41b89e767fc23d84e1fa5ba20'
 '6f92ce3fcd05dd5697ded83586f7bc08' 'a6bcb4514cb6de67e3d74ad0ea62452d']","[ 0.01564981  0.01233042 -0.01434811 ... -0.02070144 -0.01778535
  0.03579277]"
bdddcb17ba6c408599dd395ce64f960a,DATA EMBEDDING,"FUNCTION, TECHNOLOGY","Data Embedding is a function within the GraphRAG indexing suite that transforms extracted entities and text chunks into vector representations. This process is used to embed entities into a graph vector space and text chunks into a textual vector space, facilitating further analysis and storage of the structured data. Outputs can be stored in various formats or accessed through the Python API.>",368,,['251e8d332b451d900df961cbe215bca0'],"[-0.01066695  0.02052996 -0.0033389  ... -0.00970328 -0.02313545
  0.01657763]"
bc70fee2061541148833d19e86f225b3,OUTPUT FORMATS,"PROPERTY, TECHNOLOGY","Output Formats refer to the various ways in which the structured data generated by the GraphRAG indexing suite can be stored. These include JSON and Parquet formats, which are commonly used for data storage and analysis. Additionally, the outputs can be handled manually via the Python API, providing flexibility in how the data is accessed and used.>",369,,['251e8d332b451d900df961cbe215bca0'],"[-0.00280056 -0.00373582  0.01118621 ... -0.03245381  0.04898535
 -0.00030339]"
0fc15cc3b44c4142a770feb4c037a6f7,CONFIG FILE,"FILE, CONFIGURATION","A Config File is a pivotal document utilized in the setup and execution of software applications or systems, particularly the GraphRAG system. This file contains essential settings, parameters, and configurations that dictate how a pipeline should be executed, ensuring the system functions correctly. It can be utilized with the Command Line Interface (CLI) or the Python API, offering flexibility in specifying execution details. The Config File supports two modes of operation: Default Configuration mode and Custom Configuration mode. By default, it operates in Default Configuration mode, but users can opt out and execute a custom configuration by specifying the Config File using the --config flag, followed by the path to the configuration file. This feature is crucial for setting up the environment and pipeline for the GraphRAG system, as it allows for the precise specification of required environment variables and settings.",370,,"['919cb44d9688a14bf48fa7c98163ed81' '9f2cd3d789fd49f220d4cda6b9e8048c'
 'b0505e11596cadd9890fef049c29473c']","[ 0.02602848 -0.00630653  0.01011304 ... -0.01075292 -0.0036395
  0.03501515]"
a24e9df02e1b4b43bf6324b039e28285,PYTHON API,"PROGRAMMING INTERFACE, TOOL",The Python API is a programming interface that allows users to run the pipeline using Python code. It provides functions and methods for executing the pipeline and can be used to specify the workflow and parameters for the pipeline.>,371,,['b0505e11596cadd9890fef049c29473c'],"[ 0.03106133  0.01406877 -0.0457478  ... -0.01406253 -0.00186516
  0.03899541]"
ab3a5a6713244fd595a1ace978c3d960,NODE,"EXECUTION ENVIRONMENT, TOOL","NODE serves multiple roles within the system. Primarily, it contains layout information for rendered graph-views of the Entities and Documents, which have been embedded and clustered for effective visualization. This makes NODE an integral part of the table that organizes and presents data in a comprehensible format. Additionally, NODE functions as an execution environment, enabling users to run the Command Line Interface (CLI) in a JavaScript environment. This capability provides the necessary runtime and dependencies for executing pipeline commands, making NODE a versatile component that supports both data visualization and execution tasks within the system.",372,,"['493f38f41b89e767fc23d84e1fa5ba20' '85e50a4d70697a2c4420e7a9fc82f22d'
 'b0505e11596cadd9890fef049c29473c']","[-0.00513925 -0.03698811 -0.02777939 ... -0.03695548  0.00071122
 -0.00034397]"
02a88c0d128e4586b2f1f64329786d3c,PIPELINE WORKFLOW REFERENCE,"DATA STRUCTURE, CONFIGURATION","Pipeline Workflow Reference is a data structure used in the Python API to define the workflow of the pipeline. It contains a list of steps that specify the operations to be performed on the data. Each step can include a verb, arguments, and an optional input.>",373,,['b0505e11596cadd9890fef049c29473c'],"[ 0.03532578  0.0032996   0.0016326  ... -0.01461005 -0.00295164
  0.04603741]"
1ca41537c47c4752a17a44d1d7086d96,DERIVE VERB,"FUNCTION, CONFIGURATION","The Derive Verb is a built-in function used in the Pipeline Workflow Reference to perform operations on the data. It can be used to create new columns by applying an operator to existing columns. The Derive Verb requires arguments such as column names, the operator to be used, and the name of the new column.>",374,,['b0505e11596cadd9890fef049c29473c'],"[ 0.00070095  0.00404274 -0.01076211 ... -0.05809082 -0.04575175
  0.05911366]"
7e0d14ca308b4796bdc675a64bd3a36e,COL1,"PROPERTY, COLUMN","COL1 is a significant data column within the dataset, characterized by its numerical values. It plays a crucial role as an input in the operational workflow, specifically in the derive step of workflow2, demonstrating its importance in data processing activities. COL1's numerical nature and its utilization in workflow operations highlight its relevance and necessity in the analytical processes defined within the workflow framework.",375,,['76d9dcb9a27c2caea1f46bb5050851c6' 'f3a07680cbe8ab1f6055369da05f4f38'],"[ 0.05271704 -0.00404263  0.0024879  ...  0.02967527 -0.01419408
  0.03084414]"
8323efc8e539419e9ca3c98e758f6609,COL2,"PROPERTY, COLUMN","""COL2 is a significant data column within the dataset, characterized by its numerical values. It holds the position of the second input in the operational workflow, demonstrating its integral role in the data processing sequence. Specifically, COL2 is utilized as an input in the derive step of workflow2, highlighting its functional importance in generating new data attributes or modifying existing ones through the workflow's operations.""",376,,['76d9dcb9a27c2caea1f46bb5050851c6' 'f3a07680cbe8ab1f6055369da05f4f38'],"[ 0.0403741   0.00176021  0.02293648 ...  0.00658198 -0.03560227
  0.03513232]"
a80c7c98c0b647f8b9f6f8cc09168e44,COL_MULTIPLIED,"PROPERTY, COLUMN",col_multiplied is a new column in the dataset that is the result of multiplying the values of col1 and col2.,377,,['f3a07680cbe8ab1f6055369da05f4f38'],"[ 0.01109604 -0.02622437  0.00540968 ...  0.03998249 -0.0013671
  0.01921785]"
2d66a15939294d21b83b3e277f0a4e46,RUN_PIPELINE,"FUNCTION, PROCESS","run_pipeline is a function that takes a dataset and workflows as input, and asynchronously processes the data according to the workflows. It returns the result of the operations as outputs.",378,,['f3a07680cbe8ab1f6055369da05f4f38'],"[-0.00612626  0.01154234 -0.02278119 ... -0.00410812  0.0212935
  0.04835631]"
47f6d6573cf34e1096c95e36251dd60c,WORKFLOWS,"PROPERTY, PROCESS","The Workflows section is a critical component that meticulously outlines the Directed Acyclic Graph (DAG) for the data processing pipeline. This section encompasses an array of workflows, each detailing a series of operations to be executed on the dataset. Each operation within the workflows specifies the source columns, the target column, and the operator to be utilized, thereby defining the transformation steps and inter-dependencies between the workflows. This structured approach ensures a clear and systematic processing sequence, enabling efficient data manipulation and analysis.",379,,['a3e5bacdf64bcaf080a04c7dd8218484' 'f3a07680cbe8ab1f6055369da05f4f38'],"[ 0.01802731 -0.00057199 -0.00432251 ... -0.02418165 -0.00223051
  0.06180631]"
2fbd74d5ccca4be99c5257b3ac95cfba,OUTPUTS,"PROPERTY, DATA",outputs is a list that collects the results of the run_pipeline function. Each output is the result of processing the dataset according to the workflows.,380,,['f3a07680cbe8ab1f6055369da05f4f38'],"[-0.0338227   0.00159767  0.00735876 ... -0.02628856  0.06843924
  0.02754813]"
a2b1621a3e424ae29a6a73f00edbeca3,PIPELINE_RESULT,"PROPERTY, DATA","pipeline_result is the last element in the outputs list, representing the final result of the pipeline execution.",381,,['f3a07680cbe8ab1f6055369da05f4f38'],"[-0.00717475 -0.02040151 -0.01045501 ... -0.02178791  0.04785682
  0.00279805]"
ec45e1c400654c4f875046926486ded7,DEFAULT PROMPTS,"PROPERTY, CONFIGURATION","Default Prompts are the simplest way to start using the GraphRAG system. They are designed to work with minimal configuration and are suitable for out-of-the-box use. These prompts cover various aspects such as entity and relationship extraction, description summarization, claim extraction, and community reports.",382,,['bdb8f9e797229f596744d9636ab857b0'],"[-0.00109002 -0.00817817 -0.00928924 ... -0.02652858  0.00926552
  0.00880106]"
047cd93e9d704c7d8dadb6e79f9458df,ENTITY/RELATIONSHIP EXTRACTION,"PROPERTY, FUNCTION","Entity/Relationship Extraction, a crucial function within the GraphRAG system, specializes in identifying and extracting entities along with their relationships from input data. This process is pivotal for the construction of a knowledge graph. It operates by processing text data, using prompts and token-replacements to analyze the input text. The outcome is the generation of tuples, which accurately represent individual entities or the relationships between them. This procedure is foundational in the domain of Social Network Analysis, enabling a deeper understanding of complex relationships and facilitating the identification of key influencers within specialized professional networks such as Motor Control and Drive Systems. By leveraging Entity/Relationship Extraction, professionals can uncover collaboration opportunities and pinpoint knowledge gaps, enhancing their ability to navigate and contribute to the field.",383,,['6a7157695d90d434b2625c3f05420916' 'bdb8f9e797229f596744d9636ab857b0'],"[ 0.0055198   0.02330344 -0.03617044 ... -0.02703321 -0.02413291
  0.03578929]"
5b71ee73a5b6484495b2a0a75219426c,ENTITY/RELATIONSHIP DESCRIPTION SUMMARIZATION,"PROPERTY, FUNCTION",Entity/Relationship Description Summarization is a function that provides concise summaries of the descriptions of entities and their relationships. This can be useful for understanding the context and significance of the extracted information.,384,,['bdb8f9e797229f596744d9636ab857b0'],"[ 0.01270764  0.00862803  0.00388405 ...  0.00214036  0.01020506
 -0.00148358]"
e1f524d4b9754ce2b64a0a4c8f73b854,CLAIM EXTRACTION,"PROPERTY, FUNCTION","Claim Extraction is a critical function and process within the domain of text analysis and information retrieval. It specializes in identifying and extracting claims or assertions made within text data, focusing on the validity or truthfulness of statements. This process is particularly useful in scenarios where the accuracy of information is paramount. Claim Extraction uses prompts and token-replacements to process text and pinpoint claims based on the values provided by the extractor. It is a specific type of information extraction that zeroes in on identifying assertions or statements made within the text, often about entities and their attributes. The process is designed to identify positive factual statements with an evaluated status and time-bounds, emitting these claims as a primary artifact known as Covariates. This capability is essential in the pipeline of text analysis, enabling the extraction of meaningful and accurate information from large volumes of textual data.",385,,"['10d01d36390b307a63fd5bc97d8682c0' '493f38f41b89e767fc23d84e1fa5ba20'
 '6a7157695d90d434b2625c3f05420916' '6f92ce3fcd05dd5697ded83586f7bc08'
 'bdb8f9e797229f596744d9636ab857b0' 'd44248ff7b7bfd969a7208eb3d6e2a78']","[-0.01027799 -0.00680933 -0.01794849 ... -0.02946827  0.01016495
  0.02684768]"
ae1fe1c014c54ec4bcdf10dbdaed5068,AUTO TEMPLATING,"PROPERTY, CONFIGURATION",Auto Templating is a feature that leverages input data and LLM interactions to create domain adaptive templates for the generation of the knowledge graph. It is highly recommended for better results in an Index Run. The process involves analyzing the input data and automatically generating templates that are tailored to the specific domain or use case.,386,,['bdb8f9e797229f596744d9636ab857b0'],"[-0.00147583 -0.010476    0.02499967 ...  0.00114847  0.00024109
  0.01848209]"
92646910ee624bd7909fac2b5c0232e3,MANUAL CONFIGURATION,"PROPERTY, CONFIGURATION",Manual Configuration is an advanced use-case feature of the GraphRAG system. It allows users to customize the prompts and templates used in the generation of the knowledge graph manually. This is typically used when the Auto Templating feature does not meet specific requirements or when more control over the process is desired.,387,,['bdb8f9e797229f596744d9636ab857b0'],"[ 0.02175036 -0.02748797 -0.00177398 ... -0.02298534  0.00183254
  0.02500151]"
05913bee89a94bca88449249e35ba74d,TEMPLATE GENERATION ALGORITHM,"ALGORITHM, PROCESS","The Template Generation Algorithm is a process within GraphRAG that is responsible for creating domain adaptive templates for knowledge graph generation. It involves loading inputs, splitting them into chunks (text units), and then running a series of LLM invocations and template substitutions to generate the final prompts. The algorithm can be customized by adjusting various parameters such as the method, limit, language, max tokens, and chunk size. The default values provided by the script are suggested for use, but users can explore and tweak the algorithm for better results. The algorithm is executed as part of the automatic template generation process, which is optional but highly recommended for better Index Run results.",388,,['9b364093aeecfc789c70fc5bd9503487'],"[ 0.00225158 -0.00360271  0.00522842 ... -0.01416345 -0.01410709
  0.00847686]"
57b8930790c34dcba4a32c6be703ed78,INITIALIZATION PROCESS,"PROCESS, TASK","The Initialization Process is a task that must be completed before running the automatic template generation in GraphRAG. It involves using the graphrag.index --init command to create the necessary configuration files and default prompts. This process is crucial for setting up the workspace and ensuring that the tool can function properly. For more detailed information about the initialization process, refer to the Init Documentation.",389,,['9b364093aeecfc789c70fc5bd9503487'],"[ 4.18246305e-03  4.15808754e-05  1.74046438e-02 ... -3.51373963e-02
 -5.79266762e-03  2.18205508e-02]"
838c4498bc3c437f8d65428b580766a2,ROOT,"COMMAND, OPTION","ROOT is a pivotal command-line option that designates the base directory or starting point for all relative paths and configurations within the data project. This directory is essential as it houses the config files in formats such as YML, JSON, or .env, an input directory containing the input data, and an .env file with environment variables. ROOT defaults to the current directory if not explicitly specified. It is a required property utilized in the configuration of commands like graphrag.prompt_tune, serving as a guide to locate the input data and other resources necessary for prompt generation. The presence of ROOT ensures that the system can accurately identify and access the project's critical components, making it a fundamental aspect of the project's setup and operation.",390,,"['9243633f55cccd0885ba553e14fa5e3f' 'abac77a5673e907cf8d65161c2612784'
 'ce9cc3ed2e5f890d02e867ed0b0f8ff9' 'f239de6498e0f471bf418974c00f1e36']","[ 0.02681613 -0.00510503 -0.03705935 ... -0.01097219 -0.03201352
  0.01717855]"
1b893f24eb98477aad6ce49c0f26737e,DOMAIN,"COMMAND, OPTION","The ""DOMAIN"" is a versatile command-line option and an optional property that plays a crucial role in specifying the subject area or topic of the input data. It enables users to explicitly define the domain related to the data, such as 'space science', 'microbiology', or 'environmental news', which is particularly useful in the configuration of the graphrag.prompt_tune command. This command is designed to customize the prompt generation process to better suit a specific field of interest. If the ""DOMAIN"" is left unspecified, it intelligently infers the domain from the input data, ensuring that the analysis and processing are contextually accurate and relevant. This feature is pivotal in enhancing the precision and effectiveness of data processing and analysis within specialized professional networks.",391,,['9243633f55cccd0885ba553e14fa5e3f' 'ce9cc3ed2e5f890d02e867ed0b0f8ff9'],"[ 0.00530753 -0.00930663 -0.04004769 ... -0.01921163 -0.02002938
  0.03666115]"
6573bc2af4f94596a3f4452a602d6fc4,LIMIT,"COMMAND, OPTION","LIMIT is a versatile command-line option and optional property utilized in the context of text unit selection. It serves a dual purpose: first, as a command-line parameter, it establishes the maximum number of text units to load when employing random or top selection methods, with a default setting of 15. Second, within the configuration of the graphrag.prompt_tune command, LIMIT acts as a property to regulate the sample size for prompt generation, thereby influencing the template creation process. This feature provides users with the flexibility to control the scope and scale of text data used in various operations, ensuring optimal outcomes in text analysis and processing tasks.",392,,['9243633f55cccd0885ba553e14fa5e3f' 'ce9cc3ed2e5f890d02e867ed0b0f8ff9'],"[ 0.03621211 -0.00968981  0.02861299 ... -0.0261095  -0.0029721
 -0.01269199]"
0dddcca0e5df4b16bc03a51a2d2d8e16,LANGUAGE,"COMMAND, OPTION","The entity ""LANGUAGE"" serves a dual purpose within the context of input processing and command configuration. Firstly, as a command-line option, LANGUAGE designates the language to be used for input processing. If the specified language differs from that of the inputs, the Language Model (LLM) facilitates translation. By default, if no language is explicitly set, the system automatically detects the language from the inputs. Secondly, ""language"" is also an optional property utilized in the configuration of the graphrag.prompt_tune command. This property ensures that the prompt generation process is customized to match the language of the input documents, thereby enhancing the accuracy and relevance of the generated prompts.",393,,['9243633f55cccd0885ba553e14fa5e3f' 'ce9cc3ed2e5f890d02e867ed0b0f8ff9'],"[ 0.0118207  -0.00543663 -0.03038049 ... -0.02989274 -0.07123584
  0.02043241]"
df40ad480a3c47299a6c8fad05349304,MAX_TOKENS,"COMMAND, OPTION","MAX_TOKENS is a crucial command-line option utilized in the context of Language Models (LLM). It serves the dual purpose of setting the maximum token count for prompt generation as well as determining the maximum number of tokens allowed in the output of the LLM. By default, MAX_TOKENS is set to 2000, providing a limit to the length of the generated text to ensure efficient and manageable responses. This parameter is integral for controlling the verbosity and scope of the model's output, making it a key attribute for users to adjust according to their specific needs and constraints.",394,,['647be47c939b4d72f1c0b29a2e0d2cb2' '9243633f55cccd0885ba553e14fa5e3f'],"[ 0.04341898 -0.01567579  0.01524171 ...  0.00408843 -0.01232427
  0.00439507]"
fe98fb197d294b0b837aee8d5a98dfb1,CHUNK_SIZE,"COMMAND, OPTION",CHUNK_SIZE is a command-line option that determines the size in tokens to use for generating text units from input documents. The default is 200.,395,,['9243633f55cccd0885ba553e14fa5e3f'],"[ 0.0243658  -0.03045701  0.03246034 ... -0.00732087 -0.03050704
 -0.01972355]"
feb9ddd0ac2949178f26a36949aa5422,NO_ENTITY_TYPES,"COMMAND, OPTION",NO_ENTITY_TYPES is a command-line option that enables untyped entity extraction generation. It is recommended for data covering a lot of topics or highly randomized data.,396,,['9243633f55cccd0885ba553e14fa5e3f'],"[-0.02015452  0.0186187  -0.01592426 ... -0.00625132  0.01427873
  0.00436341]"
b4e4fa2e3dfc46e68d532d659b18d17d,OUTPUT,"COMMAND, OPTION","OUTPUT is a command-line option and an optional property used in the configuration of the graphrag.prompt_tune command. It specifies the folder where the generated prompts will be saved, with the default location being ""prompts"". This feature enables users to customize the storage location for output files, enhancing flexibility and organization within their projects.",397,,['9243633f55cccd0885ba553e14fa5e3f' 'ce9cc3ed2e5f890d02e867ed0b0f8ff9'],"[-0.00490255 -0.01337955 -0.00330579 ... -0.05038702  0.02213321
 -0.00531667]"
f58813d090b947a48c1b4614b92c3ec3,MAX-TOKENS,"PROPERTY, CONFIGURATION",max-tokens is an optional property that specifies the maximum token count for prompt generation. The default value is 2000. It is used in the configuration of the graphrag.prompt_tune command to control the size of the generated prompts.,398,,['ce9cc3ed2e5f890d02e867ed0b0f8ff9'],"[ 0.0299369  -0.00353104  0.00356234 ... -0.00758164 -0.00091235
 -0.01656019]"
30a251bc3d04430d82b5a1a98c7b8c75,CHUNK-SIZE,"PROPERTY, CONFIGURATION",chunk-size is an optional property that defines the size in tokens to use for generating text units from input documents. The default value is 200. It is used in the configuration of the graphrag.prompt_tune command to determine how input documents are segmented for processing.,399,,['ce9cc3ed2e5f890d02e867ed0b0f8ff9'],"[ 0.02650714 -0.00238603  0.02761005 ... -0.02025741 -0.04095872
 -0.01367177]"
93e1d19f9bfa4c6b8962d56d10ea9483,NO-ENTITY-TYPES,"PROPERTY, CONFIGURATION","no-entity-types is an optional property that, when used, enables untyped entity extraction generation. It is recommended for data that covers a wide range of topics or is highly randomized. It is used in the configuration of the graphrag.prompt_tune command to control the type of entity extraction.",400,,['ce9cc3ed2e5f890d02e867ed0b0f8ff9'],"[-0.011587    0.03256374 -0.01715293 ... -0.01650179  0.00997674
  0.01031796]"
8046335ba70b434aa3188392a746fd78,CHUNK SIZE PARAMETER,"PROPERTY, PARAMETER",The Chunk Size Parameter determines the size of text units into which the input data is divided for processing in template generation. It is a crucial setting for managing the granularity of text analysis.,401,,['4f37c0e9c3c9bac4e5c1c6821eea442e'],"[ 0.02868316 -0.03019593  0.04329267 ... -0.01110862 -0.0531209
 -0.02105753]"
5c02b1ab32064c64a0f8b27b219e358a,RANDOM SELECTION METHOD,"PROPERTY, STRATEGY","The Random Selection Method is a strategy used in template generation to select text units randomly. It is the default and recommended option for most use cases, ensuring a diverse and unbiased sample of text units.",402,,['4f37c0e9c3c9bac4e5c1c6821eea442e'],"[-0.02111041  0.01510926  0.03128387 ...  0.03488738  0.00758135
 -0.01267438]"
c5f77ba0c261408780db3d50346f16b7,TOP SELECTION METHOD,"PROPERTY, STRATEGY",The Top Selection Method is a strategy used in template generation to select the head n text units. This method is useful for focusing on the most significant or relevant parts of the input data.,403,,['4f37c0e9c3c9bac4e5c1c6821eea442e'],"[ 0.00361282 -0.00363825  0.03380528 ...  0.02055263  0.00206715
  0.00376748]"
453ecf5476f64f4a8d5020b95baf1314,ALL SELECTION METHOD,"PROPERTY, STRATEGY","The All Selection Method is a strategy used in template generation to use all text units for the generation. It is recommended for small datasets where comprehensive analysis is desired, but not usually recommended for larger datasets due to computational constraints.",404,,['4f37c0e9c3c9bac4e5c1c6821eea442e'],"[ 0.00855289  0.02042865  0.01971094 ...  0.010077    0.0167823
 -0.00057147]"
6a1d83c9ce2b483dbd7de5ab3ae2487d,GRAPHRAG_ENTITY_EXTRACTION_PROMPT_FILE,"PROPERTY, CONFIGURATION","GRAPHRAG_ENTITY_EXTRACTION_PROMPT_FILE serves as both a configuration setting and an environment variable, playing a crucial role in the entity extraction process. This entity is responsible for specifying the file used for entity extraction prompts during the index run. When set to None, it indicates the absence of a designated file for this purpose. However, GRAPHRAG_ENTITY_EXTRACTION_PROMPT_FILE defaults to the path ""prompts/entity_extraction.txt"" when a specific file is not defined, ensuring that the entity extraction process has a fallback resource to rely on.",405,,['2b777e3d591ce1511a03abd1a6d8dc73' '4f37c0e9c3c9bac4e5c1c6821eea442e'],"[ 0.00278335  0.01751808 -0.01024613 ... -0.05084185 -0.01949515
  0.0190733 ]"
66c3dffb7d7a4fa8bb6b48a22ca917a6,GRAPHRAG_COMMUNITY_REPORT_PROMPT_FILE,"PROPERTY, CONFIGURATION","The GRAPHRAG_COMMUNITY_REPORT_PROMPT_FILE is a configuration property, also serving as an environment variable, that designates the file to be utilized for generating community report prompts. This dual-purpose entity is pivotal for the index run, as it specifies the path to the prompt file. Currently, it is set to None, but its default path is ""prompts/community_report.txt"" when not explicitly defined. This file plays a crucial role in the Motor Control and Drive Systems domain by facilitating the creation of detailed reports that help in understanding the structure and dynamics of specialized professional networks, identifying key influencers, and mapping complex relationships within the community.",406,,['4f37c0e9c3c9bac4e5c1c6821eea442e' 'cde833db73c46ca28f08e35195134441'],"[ 0.01469623  0.01461211 -0.01481485 ... -0.04196827 -0.00708432
 -0.00472474]"
6f3dd1fd6d7f4df4af0656ed0525c92e,GRAPHRAG_SUMMARIZE_DESCRIPTIONS_PROMPT_FILE,"PROPERTY, CONFIGURATION","GRAPHRAG_SUMMARIZE_DESCRIPTIONS_PROMPT_FILE is a configuration setting, represented as an environment variable, that designates the file to be utilized for summarizing descriptions during the index run. Currently, it is set to None, which signifies the absence of a specified file for this purpose. The default path for this file, when set, is ""prompts/summarize_descriptions.txt"". This configuration property plays a crucial role in the process of consolidating and streamlining descriptions within the system.",407,,"['2b777e3d591ce1511a03abd1a6d8dc73' '4f37c0e9c3c9bac4e5c1c6821eea442e'
 'cde833db73c46ca28f08e35195134441']","[ 0.03565139 -0.01710771  0.009467   ... -0.0445624   0.00890789
 -0.00159005]"
711eb39432794b0a91110358dd536517,CUSTOM PROMPT FILE,"CONCEPT, DOCUMENT","A Custom Prompt File is a plaintext document that can be created to override the default prompts used by the GraphRAG indexer. It enables users to specify their own prompts, using token-replacements, to better align with their specific use cases in knowledge discovery.",408,,['6a7157695d90d434b2625c3f05420916'],"[ 0.01240551 -0.02241645  0.0162021  ... -0.02389088 -0.01761427
  0.02584203]"
0e00585b08044954a254116665400463,TOKEN-REPLACEMENTS,"CONCEPT, TECHNIQUE","Token-Replacements is a technique used in customizing prompts for the GraphRAG indexer. It involves replacing placeholders in the form of {token_name} with actual values provided by the extractor, such as input text, entity types, and delimiters, to tailor the prompts to specific needs.",409,,['6a7157695d90d434b2625c3f05420916'],"[ 2.52298210e-02 -2.28201076e-02 -8.59783177e-05 ... -3.79668139e-02
 -1.51828993e-02 -1.74441002e-02]"
db0147eff2204a20b5e5e6bec7a8bae5,SUMMARIZE ENTITY/RELATIONSHIP DESCRIPTIONS,"CONCEPT, PROCEDURE",Summarize Entity/Relationship Descriptions is a procedure that involves summarizing the descriptions of entities or relationships. It uses prompts and token-replacements to process a list of descriptions for an entity or relationship.,410,,['6a7157695d90d434b2625c3f05420916'],"[ 0.02535307 -0.01956107  0.00368373 ... -0.01411861  0.00837527
  0.01189944]"
67bb4f4678284819add02ba04f3b1103,RECORD_DELIMITER,"PROPERTY, DELIMITER",The record_delimiter is a special character or string used to separate different tuple instances in a text. It helps in identifying the boundaries of individual records or entities within a larger text or data stream.,411,,['853bfe9a74a916130a20f81506bcaf09'],"[ 0.00753135 -0.01418328  0.00978738 ...  0.01813123 -0.04557088
  0.01157023]"
2033ec0487f04240abb3bdbe77b39087,COMPLETION_DELIMITER,"PROPERTY, DELIMITER","The completion_delimiter is a marker or indicator used to signal the end of a series of generated data or text. It is particularly useful in scenarios where data is generated in a stream or sequence, and there is a need to determine when the generation process has been completed.",412,,['853bfe9a74a916130a20f81506bcaf09'],"[-0.00406205 -0.03655393  0.01568022 ...  0.00533574 -0.01604457
  0.01172731]"
f026fab8fec948ae9e7baa2ad715e6ef,ENTITY_NAME,"PROPERTY, IDENTIFIER",The entity_name is a unique identifier or label given to an entity or object in a data set or text. It is used to distinguish one entity from another and is crucial for referencing and linking entities in the context of relationships and descriptions.,413,,['853bfe9a74a916130a20f81506bcaf09'],"[-0.02229085  0.00843264 -0.01102051 ...  0.01485665  0.00472877
  0.01453819]"
d0d7ed36d6f54b5d986dfd854096b728,DESCRIPTION_LIST,"PROPERTY, LIST","The description_list is a collection of descriptions or attributes associated with an entity or relationship. It provides detailed information about the entity's characteristics, functions, or the nature of the relationship between entities.",414,,['853bfe9a74a916130a20f81506bcaf09'],"[-0.00608266 -0.00758599 -0.00831334 ...  0.02187782  0.03800519
  0.002134  ]"
bf6a4c18f44042799eb7456a6b85b54a,INPUT_TEXT,"PROPERTY, TEXT","The input_text is the text or data provided as input for processing. It can contain information about entities, relationships, or other data points that need to be analyzed, summarized, or extracted.",415,,['853bfe9a74a916130a20f81506bcaf09'],"[-0.00342195 -0.0188005   0.01288748 ...  0.01005756 -0.01133034
 -0.00759082]"
fac4a59c2278498d83f9f1b4231ad62e,TUPLE_DELIMITER,"PROPERTY, DELIMITER",The tuple_delimiter is a character or string used to separate values within a single tuple. A tuple is a collection of related values that represent an individual entity or a relationship between entities.,416,,['853bfe9a74a916130a20f81506bcaf09'],"[ 0.00451354 -0.00369306  0.01051227 ...  0.00947784 -0.02052664
 -0.00300685]"
d6d2b5862ddc4c4d87deee3423506817,CONFIGURATION DOCUMENTATION,"DOCUMENT, INSTRUCTION","The Configuration Documentation is a comprehensive guide designed to assist users in understanding and modifying the settings of GraphRAG, a tool for information discovery and processing. It offers detailed instructions on various configuration aspects, including the use of the init command, .env files, and config files, as well as other configuration-related commands. This documentation serves as a valuable resource for users looking to optimize their information extraction and processing capabilities by customizing GraphRAG's settings.",417,,"['12294feb07a1d202b27241eaaf64718b' '21cdf11c58927ae505d3d375d1b75c82'
 '32e96c66a531ecd0a8edc7414aec0803' 'd0f7c236538005bc3056b7daed2401d8']","[ 0.0294557  -0.01859911 -0.0181009  ... -0.0349278   0.01331981
  0.03193901]"
47d588d26e2b4cccb68fe2af4c147c8f,PROMPT SOURCE,"SOURCE, DATA","Prompt Source refers to the origin or provider of the input text used to generate the report. It could be a database, a file, or any other data source that contains the information needed for the report generation.>",418,,['21cdf11c58927ae505d3d375d1b75c82'],"[-0.01098276 -0.03372936 -0.00325619 ... -0.05778526 -0.00246527
  0.00507539]"
c0f2dc03d8df400db4997c1a0babd6ad,TOKENS,"PROPERTY, DATA","Tokens represent values provided by the extractor, such as the input text. They are key components in the process of generating reports, as they contain the actual data that will be analyzed and presented in the report.>",419,,['21cdf11c58927ae505d3d375d1b75c82'],"[ 0.00560892 -0.02283921 -0.00582301 ...  0.00191732 -0.01306709
  0.00883052]"
0211d61aae834229a3a1e004ff5cc658,GRAPHRAG SYSTEM,"SOFTWARE, SYSTEM","The GraphRAG system is a software solution designed for indexing and querying text data. It offers various ways to get started, including using the GraphRAG Accelerator solution, installing from PyPI, or using it from source. The system is compatible with Python versions 3.10 to 3.12.",420,,['84d24b5db902baca7217b5e3bb6ec462'],"[ 0.03034496 -0.00020634 -0.01197504 ... -0.00546105  0.00757213
  0.01799645]"
ccbbbcc055c34709abcf103208c2c299,GRAPHRAG ACCELERATOR SOLUTION,"SOFTWARE, SOLUTION",The GraphRAG Accelerator solution is a user-friendly package that provides an end-to-end experience with Azure resources for getting started with the GraphRAG system. It is recommended for a quick and easy setup.,421,,['84d24b5db902baca7217b5e3bb6ec462'],"[ 0.00899615  0.02866087 -0.02277567 ... -0.02645684  0.00897204
  0.01815261]"
989add81cf874018a569239b68d17ff2,INDEXING PIPELINE OVERVIEW,"PROCESS, SYSTEM COMPONENT","The Indexing Pipeline Overview is a component of the GraphRAG system that describes the process of indexing text data. It involves setting up a data project, initial configuration, and using the system to index text for later querying.",422,,['84d24b5db902baca7217b5e3bb6ec462'],"[-0.01089867 -0.00621313 -0.01100922 ... -0.04265469  0.01926175
  0.01146551]"
fd7d94fbab084bc380480abeef6bfade,QUERY ENGINE OVERVIEW,"PROCESS, SYSTEM COMPONENT",The Query Engine Overview is a component of the GraphRAG system that describes the process of querying indexed data. It allows users to ask questions about the documents that have been indexed using the system.,423,,['84d24b5db902baca7217b5e3bb6ec462'],"[-0.0160788   0.0004728  -0.00557982 ... -0.03230455 -0.0032087
  0.01391297]"
cfb915c95caf41c6a25e99a9f37f03a2,ENVIRONMENT VARIABLES,"PROPERTY, CONFIGURATION","Environment variables are variables that are set in the operating system's environment and can be accessed by any program running on the system. They are used to configure the behavior of software applications and systems. In the context of the GraphRAG system, environment variables are necessary for setting up the workspace and specifying the API key for the OpenAI API or Azure OpenAI endpoint.>",424,,['9f2cd3d789fd49f220d4cda6b9e8048c'],"[ 1.28262537e-02  2.22756062e-02  3.18565981e-05 ... -5.03522158e-02
 -3.44367921e-02  2.86768600e-02]"
8815ed80f9b741dbb458d902024f34a4,SAMPLE DATASET,"DATA, FILE","A sample dataset is a collection of data used for testing and demonstration purposes. In this case, the sample dataset is a copy of ""A Christmas Carol"" by Charles Dickens, obtained from a trusted source and saved as a text file named book.txt in the ./ragtest/input directory.>",425,,['9f2cd3d789fd49f220d4cda6b9e8048c'],"[-0.00859852 -0.01144556  0.06799245 ...  0.03883991  0.03700972
  0.02562685]"
dddb831546354e088d29aebd154e3a31,A CHRISTMAS CAROL,"LITERATURE, BOOK","""A Christmas Carol"" is a novella by Charles Dickens, first published in 1843. It is a classic Christmas story that tells the tale of Ebenezer Scrooge, an elderly miser who is visited by the ghost of his former business partner Jacob Marley and the Ghosts of Christmas Past, Present, and Yet to Come. The story has been adapted into numerous films, plays, and other media.>",426,,['9f2cd3d789fd49f220d4cda6b9e8048c'],"[ 0.00027524 -0.04786557  0.03280238 ...  0.02241777  0.01660503
 -0.01133935]"
005d2154da754b21adcd90ac921bd5f7,GRAPHRAG PIPELINE,"SOFTWARE, PROCESS","The GraphRAG Pipeline is a sophisticated software tool specifically engineered for the efficient indexing and processing of graph data, as well as large text datasets. This dual-purpose capability makes it a versatile solution for a wide range of data management needs. The pipeline supports seamless integration with OpenAI and Azure OpenAI APIs, enhancing its functionality by enabling advanced features and services. To ensure secure and authorized access, the GraphRAG Pipeline necessitates an API key for authentication. Configuration of the pipeline is facilitated through the settings.yaml file, where users can customize various parameters to suit their specific requirements.

The pipeline's workflow includes setting up a workspace, configuring essential environment variables, and executing the indexing command. Once the indexing process is complete, the system generates a comprehensive index of the text dataset. This index serves as a powerful resource for answering complex questions and retrieving pertinent information, making the GraphRAG Pipeline an indispensable tool for data analysis and retrieval tasks.",427,,['5aaa26fbe97dc7573cd1a56d6fb11213' '9f2cd3d789fd49f220d4cda6b9e8048c'],"[ 0.01720028  0.02314643 -0.00097982 ... -0.03913383  0.00801991
  0.03876109]"
711ba818354546cea69f1532b92a2f26,OPENAI API,"API, SERVICE","The OpenAI API, a service offered by OpenAI, provides developers with access to a range of AI capabilities, including language models, embeddings, text generation, translation, and summarization. To utilize these features, an API key is required for authentication. The OpenAI API can be seamlessly integrated with the GraphRAG pipeline, enhancing its functionality. Developers can activate OpenAI mode by updating the value of the GRAPHRAG_API_KEY environment variable, enabling them to leverage the full potential of the OpenAI models through the API.",428,,['5aaa26fbe97dc7573cd1a56d6fb11213' '9f2cd3d789fd49f220d4cda6b9e8048c'],"[ 0.01079421  0.0352459  -0.0402333  ... -0.01806416 -0.01537222
  0.01448825]"
5c4d8a8f9c104176b87d2bfdf04ae0bd,AZURE OPENAI,"API, SERVICE","Azure OpenAI, a service offered by Microsoft Azure, is a platform designed for enterprise and business use cases, providing access to OpenAI's models and services. It enables users to customize and deploy AI models in a secure and scalable environment, supporting various API versions and requiring an API key for authentication. Azure OpenAI can be integrated with the GraphRAG pipeline by configuring specific settings in the settings.yaml file, including the API base URL, API version, and deployment name. As an alternative to the OpenAI API, Azure OpenAI can be utilized by updating the value of the GRAPHRAG_API_KEY environment variable, offering similar AI capabilities.",429,,"['5aaa26fbe97dc7573cd1a56d6fb11213' '7b45dafa74553d3899e2291a3c9fb86e'
 '9f2cd3d789fd49f220d4cda6b9e8048c']","[-0.01512303  0.04431321 -0.01626274 ... -0.0159236  -0.00054526
  0.03372374]"
5a781604f1fb4719b730f43f534627f6,SETTINGS.YAML,"FILE, CONFIGURATION","The settings.yaml file is a pivotal configuration settings file for the GraphRAG system, created by the init command. This file is central to the operation and customization of the GraphRAG pipeline, as it contains essential configuration settings. It references environment variables defined in the .env file, enabling the setup of the GraphRAG system. The settings.yaml file includes adjustable parameters that can be modified to tailor the pipeline's behavior according to specific needs. Notably, it features settings for Azure OpenAI users, such as the API key, facilitating integration and additional functionalities for those utilizing Azure's services.",430,,"['12294feb07a1d202b27241eaaf64718b' '32e96c66a531ecd0a8edc7414aec0803'
 '5aaa26fbe97dc7573cd1a56d6fb11213']","[ 0.03948604  0.01989728  0.01360595 ... -0.04755417 -0.00969155
  0.03417327]"
ecdc1020b10e49ca869d399825e16fa3,API_BASE,"PROPERTY, CONFIGURATION","The API_BASE is a crucial configuration property utilized in the context of accessing Azure OpenAI API services. It serves as a string attribute that designates the base URL for the API, specifically for the Language Model (LLM) service. This property is mandatory for initiating API calls to the designated Azure instance. To ensure proper functionality, the placeholder URL within API_BASE should be substituted with the accurate instance name of the Azure service. This configuration enables seamless interaction with the Azure OpenAI API, facilitating the use of advanced language model capabilities.",431,,['647be47c939b4d72f1c0b29a2e0d2cb2' '7c1bad237a1ef86cb41b6c5dbad4ffc3'],"[-0.00124658  0.0278008  -0.00503015 ... -0.00199288 -0.03630727
  0.02663582]"
0d8fde01d7234726a00d7e73e2e01d66,API_VERSION,"PROPERTY, CONFIGURATION","The API_VERSION is a crucial configuration property utilized in the Azure OpenAI API, serving as a string attribute that specifies the particular version of the API to be employed by the LLM (Language Model) service. This feature enables users to customize their applications for different API versions, facilitating compatibility and optimization. An example of a version that might be used is ""2024-02-15-preview"", highlighting the ability to work with preview versions for early access to new features and improvements.",432,,['647be47c939b4d72f1c0b29a2e0d2cb2' '7c1bad237a1ef86cb41b6c5dbad4ffc3'],"[ 0.01469469  0.02326771 -0.01210344 ...  0.00037746 -0.02490828
  0.03485699]"
9c4bd60958fd4e09a6d5b9e2ab163b5a,DEPLOYMENT_NAME,"PROPERTY, CONFIGURATION","The deployment_name is a crucial string attribute within the configuration properties of Azure's cognitive services, specifically designed to identify and access the desired model deployment. This parameter is essential for utilizing Azure-based Language Model (LLM) services, as it specifies the exact name of the deployment to be used, enabling seamless interaction with the particular model instance hosted on Azure.",433,,"['3c66b7e86b3675fce14fe0047ae731aa' '647be47c939b4d72f1c0b29a2e0d2cb2'
 '7c1bad237a1ef86cb41b6c5dbad4ffc3']","[ 0.02459951 -0.01725899 -0.02674237 ...  0.02830126 -0.01608233
  0.04569831]"
39d31f770cf740e78d526a2e1101a1db,GRAPHRAG CONFIGURATION DOCUMENTATION,DOCUMENTATION,"The GraphRAG configuration documentation provides detailed information about how to configure GraphRAG, including settings for the API base, version, and deployment name.>",434,,['7c1bad237a1ef86cb41b6c5dbad4ffc3'],"[ 0.01706397 -0.00846766 -0.02775445 ... -0.02154744  0.00508253
  0.01344385]"
9d282b2250f7408888504f1f93c202a8,INITIALIZATION DOCUMENTATION,DOCUMENTATION,"The Initialization documentation offers guidance on how to initialize GraphRAG, which is necessary for setting up the environment and preparing for data indexing and querying.>",435,,['7c1bad237a1ef86cb41b6c5dbad4ffc3'],"[ 0.00939216 -0.01263719  0.01505592 ... -0.02866848  0.01352769
  0.03136934]"
c063484895794a0eaae1b0ff070ad4c9,CLI DOCUMENTATION,DOCUMENTATION,"The CLI documentation explains how to use the command-line interface (CLI) for GraphRAG, including commands for indexing data and running the query engine.>",436,,['7c1bad237a1ef86cb41b6c5dbad4ffc3'],"[ 0.01880267 -0.00034412  0.0080047  ... -0.04707264  0.01827162
  0.02051093]"
e8868920e21b4431aad16e86db977ecb,QUERY ENGINE DOCS,"DOCUMENTATION, REFERENCE MATERIAL",Query Engine Docs are reference materials that provide detailed information on how to use the Local and Global search mechanisms effectively. They offer guidance on leveraging these search methods to extract meaningful insights from data after the Indexer has completed its processing.,437,,['ae6e91a8cc5773dbd4789773c9ef5a30'],"[ 0.00254343  0.00791576  0.00520851 ... -0.04575047 -0.00925511
  0.04473298]"
aea3378bfff842e5b3f4b7a4b55b3879,SCROOGE,"CHARACTER, PERSON",Scrooge is a character within the dataset. Specific questions can be asked about Scrooge to understand his main relationships and characteristics within the context of the story or data being analyzed.,438,,['ae6e91a8cc5773dbd4789773c9ef5a30'],"[ 0.05714172 -0.00157424  0.00036951 ...  0.03987546  0.01224023
  0.03624823]"
d562223c17d948bf98e34b4d97dde932,DEFAULT CONFIGURATION MODE,CONFIGURATION MODE,"Default Configuration Mode is the simplest way to start using the GraphRAG system. It is designed to work with minimal configuration and is suitable for most users. The mode supports configuration through the init command, environment variables, and JSON or YAML files for more control. It creates a .env and settings.yaml files with necessary configuration settings when initialized.",439,,['ccd2de9e2219521fbca779843c65af58'],"[-0.00830142  0.01944679 -0.00255996 ... -0.02350251  0.00405356
  0.02139732]"
cde2d75c51d245879265b79d14b8699b,CUSTOM CONFIGURATION MODE,CONFIGURATION MODE,"Custom Configuration Mode is an advanced feature designed for experienced users of the GraphRAG system, enabling them to exert deeper control over the system's configuration. This mode is particularly useful for those who need to fine-tune the system for specific needs, as it allows users to define their own configuration for the Indexing Engine pipelines, rather than relying on the default settings. Custom Configuration Mode supports configuration through JSON or YAML files, providing flexibility in how users can input their custom settings. Detailed guidance on how to utilize this mode can be found in the Custom Configuration Mode documentation, making it accessible to those with the requisite expertise. It is important to note that this mode is not recommended for most users due to its complexity and the level of technical knowledge required to effectively utilize it.",440,,['b70cb2eda62c6afad9e8d22daafe61cc' 'ccd2de9e2219521fbca779843c65af58'],"[-0.00350948 -0.00651483  0.00150627 ... -0.03647304 -0.00968652
  0.04284357]"
44594467054849d4a1fadb46ddd51641,INIT COMMAND,COMMAND,"The INIT COMMAND is a pivotal tool designed to streamline the setup process for the GraphRAG system. It facilitates the initialization of the system in the Default Configuration Mode, making it the go-to option for the majority of users looking to quickly and efficiently get started with GraphRAG. Upon execution, the INIT COMMAND adeptly generates the essential configuration files, namely .env and settings.yaml, within the specified directory. Additionally, it outputs the default LLM (Language Model) prompts that are integral to the operation of GraphRAG, ensuring that users have all the necessary components to begin utilizing the system with ease.",441,,['ccd2de9e2219521fbca779843c65af58' 'd0f7c236538005bc3056b7daed2401d8'],"[ 0.03032489  0.01682814  0.00646377 ... -0.03438092 -0.01468636
  0.04178954]"
2918130221f94f4387da049b647bfe6a,.ENV,"FILE, CONFIGURATION","The .env file, a crucial component in the configuration process of GraphRAG, serves as the environment variables file. It is automatically generated by the init command of GraphRAG and contains settings that are referenced in the settings.yaml file. These variables play a significant role in the configuration document, as they can be used for token replacements using the ${ENV_VAR} syntax. This enables dynamic and flexible configuration of GraphRAG, allowing for the customization and adaptation of settings based on the specific environment in which it is being used.",442,,['12294feb07a1d202b27241eaaf64718b' '32e96c66a531ecd0a8edc7414aec0803'],"[ 0.01432435  0.01673661  0.00172827 ... -0.05395173 -0.02029955
  0.00578679]"
fd139ac75b0e4777ab67b7423eaaa37f,PROMPTS/,"DIRECTORY, CONFIGURATION","The ""prompts/"" directory is a crucial component within the GraphRAG system, serving as the repository for default Language Model (LLM) prompts. These prompts are instrumental in facilitating the system's functionality. Users have the flexibility to customize these prompts to better suit their specific data requirements. Additionally, the Auto Prompt Tuning command offers an advanced feature, enabling the generation of new prompts that are finely tuned to the nuances of the user's data, ensuring optimal performance and adaptability within the Motor Control and Drive Systems domain or any other specialized professional networks being analyzed.",443,,['12294feb07a1d202b27241eaaf64718b' '32e96c66a531ecd0a8edc7414aec0803'],"[ 0.02717741  0.00093473 -0.02565419 ... -0.02982057 -0.03087138
  0.01316949]"
a701c349eb7142d48ba7efad89caf9d2,PYTHON -M GRAPHRAG.INDEX,"COMMAND, INITIALIZATION",The python -m graphrag.index command is used to initialize GraphRAG in a specified directory. It can create necessary configuration files and output default prompts used by GraphRAG.,444,,['12294feb07a1d202b27241eaaf64718b'],"[ 0.01776166  0.00745785  0.00167317 ... -0.0303162   0.01222256
  0.0250512 ]"
e5d40a1b17f74b1db5d18279caedb04a,PROMPT TUNING COMMAND,"COMMAND, ACTIVITY","The Prompt Tuning command is a valuable feature designed to enable users to customize and optimize the default prompts according to their specific data requirements. This command plays a crucial role in enhancing the performance of GraphRAG by fine-tuning the language model to better suit the user's unique data set and use case, thereby improving the accuracy and relevance of the generated insights.",445,,['32e96c66a531ecd0a8edc7414aec0803' 'd0f7c236538005bc3056b7daed2401d8'],"[ 0.03653046 -0.00071201 -0.02615687 ... -0.03122761 -0.03275846
  0.01203998]"
de25d06733d04385825ee082792f5e52,.ENV FILE,"FILE, CONFIGURATION","The .env file contains environment variables referenced in the settings.yaml file, providing configuration settings for GraphRAG.",446,,['d0f7c236538005bc3056b7daed2401d8'],"[ 0.02897553  0.01235676  0.00413972 ... -0.0298878  -0.00701041
  0.01246753]"
32f6f11a7845416b8c6eb9fb0b382140,SETTINGS.YAML FILE,"FILE, CONFIGURATION","The settings.yaml file contains configuration settings for GraphRAG, including parameters for indexing and other system operations.",447,,['d0f7c236538005bc3056b7daed2401d8'],"[ 0.03655034  0.00144829  0.02544724 ... -0.02906015 -0.0088992
  0.02333324]"
91407be8c3e54e23918d3a7183d962db,PROMPTS FOLDER,"DIRECTORY, FILE","The prompts folder contains the default prompts used by GraphRAG, which can be modified or adapted through the Auto Prompt Tuning command.",448,,['d0f7c236538005bc3056b7daed2401d8'],"[ 0.01693769 -0.01384363  0.00213589 ... -0.03586073 -0.01213661
  0.01172524]"
3831134696584d83bbf676a6b3bfa8f9,CONFIG.JSON,"FILE, CONFIGURATION","Config.json is a versatile JSON configuration file that serves dual purposes within the technological framework. Primarily, it functions as a settings file for the LLM (Language Model) service, detailing operational parameters such as input type, file encoding, and API key within its structured JSON object. Additionally, Config.json is utilized for configuring GraphRAG, setting up the default configuration mode and facilitating token replacements through environment variables when used in conjunction with .env files. This dual role underscores the file's adaptability and importance in managing settings for distinct yet interconnected services.",449,,['32e96c66a531ecd0a8edc7414aec0803' 'f135654a3c057c66b9e5f97a960d302f'],"[ 0.02977814  0.00662918 -0.01276532 ... -0.02072479 -0.04095248
  0.01975466]"
50e512a5dbe941f5af68bfdf74b1c3c0,CONFIG.YML,"FILE, CONFIGURATION",config.yml is a YAML configuration file used to set up the default configuration mode for GraphRAG. It can be used alongside .env for environment variable token replacements.,450,,['32e96c66a531ecd0a8edc7414aec0803'],"[ 0.04362652  0.00309663 -0.00113534 ... -0.03974388  0.01027347
  0.02917154]"
edc717747e904728b57185f5013461f9,API_KEY,"PROPERTY, CONFIGURATION","The entity known as API_KEY is an environment variable that holds a string attribute, specifically the OpenAI API key. This key is essential for authentication purposes when utilizing services provided by OpenAI. The API_KEY is defined in the .env file and is referenced in the configuration files, such as config.json or config.yml, to ensure secure and proper access to the Language Model (LLM) configuration.",451,,['32e96c66a531ecd0a8edc7414aec0803' '647be47c939b4d72f1c0b29a2e0d2cb2'],"[ 0.01682949  0.04164679 -0.03121884 ... -0.01204504 -0.03798671
  0.01570736]"
8fba1fea719d49d380ac2d9c310d68b3,INPUT,"SECTION, CONFIGURATION","The ""input"" entity refers to the data or file that is being read and processed within the workflow2 context. It is configured as a 'file' type with a specific 'file_type' of 'csv'. The base directory for these CSV files is set at '../data/csv'. A sophisticated file pattern, utilizing a regex, is employed to match the CSV files, extracting critical metadata such as the source, year, month, day, and author from the file names. This input section in the configuration file not only specifies the type and file type but also includes details on encoding and the file pattern, ensuring a seamless data input process for GraphRAG. The input property comprehensively describes the configuration for reading data, integrating all necessary parameters for efficient data processing.",452,,"['32e96c66a531ecd0a8edc7414aec0803' '3900b87693f02c43b4294e38647eb7cd'
 '6839baed839d7a5e837af1da93e462e5' '76d9dcb9a27c2caea1f46bb5050851c6']","[ 0.01434129  0.03515555  0.02789168 ... -0.03649938 -0.02632314
  0.01895201]"
532da08f04f645708e747c57e9c4ee05,TYPE,"PROPERTY, CONFIGURATION","The ""type"" entity serves multiple roles within various contexts. Primarily, it is a string attribute that designates the type of Language Model (LLM) to be utilized, with options such as openai_chat, azure_openai_chat, openai_embedding, and azure_openai_embedding. Additionally, ""type"" is a configuration property that determines the storage or reporting mechanism to be employed, with choices including file, memory, or blob storage. In the context of data input, ""type"" is a property that defines the input method for loading data, with file being the default option. Furthermore, ""type"" acts as a setting that specifies the cache or storage type to be used, which influences how data is stored and accessed, again with options such as file, memory, or blob.",453,,"['32e96c66a531ecd0a8edc7414aec0803' '647be47c939b4d72f1c0b29a2e0d2cb2'
 'abac77a5673e907cf8d65161c2612784' 'd27237468a1b9e89110eeeca8080f63c']","[-0.021559    0.00372134 -0.00403367 ... -0.00918754 -0.02509556
  0.02058925]"
3cf0ab4cf14e47ddabd49d500a3dc488,FILE_TYPE,"PROPERTY, CONFIGURATION","The file_type is a property situated under the input section, primarily serving to designate the kind of input data to be loaded. By default, the file_type is set to ""text,"" however, it can be explicitly defined as ""csv"" when dealing with comma-separated values files. This attribute is crucial for ensuring that the system correctly interprets and processes the incoming data format.",454,,['32e96c66a531ecd0a8edc7414aec0803' '3900b87693f02c43b4294e38647eb7cd'],"[-0.00361573 -0.00521919  0.05109439 ...  0.00503517 -0.01184684
 -0.0027253 ]"
a39b72f8921f43ef8ef295c7cc8f7294,FILE_ENCODING,"PROPERTY, CONFIGURATION",file_encoding is a property under the input section that sets the encoding of the input file. The default is utf-8.,455,,['32e96c66a531ecd0a8edc7414aec0803'],"[-0.00930786  0.03052433  0.01218107 ...  0.00654928 -0.03109036
 -0.00672681]"
9f5adbeb6cf04f089abe78d86cfa6aba,FILE_PATTERN,"PROPERTY, CONFIGURATION","The ""file_pattern"" is a crucial property situated under the input section, designed to contain a regex pattern. This pattern is specifically utilized to match CSV files within the system. The detailed pattern is expressed as '.*[\\/](?P<source>[^\\/]+)[\\/](?P<year>\\d{4})-(?P<month>\\d{2})-(?P<day>\\d{2})_(?P<author>[^_]+)_\\d+\\.csv$'. This intricate regex formulation allows for the identification and matching of files based on their source, date (year, month, day), author, and a numerical identifier, all encapsulated within the filename. Although a default pattern is not explicitly mentioned, the provided pattern serves as a comprehensive guide for matching input files in the system.",456,,['32e96c66a531ecd0a8edc7414aec0803' '3900b87693f02c43b4294e38647eb7cd'],"[ 0.02240297  0.01999279  0.04120993 ...  0.03436097 -0.00042236
  0.01395978]"
efb6350e65964659bc20396c0166b296,API KEY,"PROPERTY, CONFIGURATION","The API Key is a configuration property used to authenticate and access the LLM (Language Model) service, specifically the OpenAI API. It is stored in the config.json file under the llm section. The value of the API Key is represented by the placeholder ${API_KEY}.",457,,['f135654a3c057c66b9e5f97a960d302f'],"[ 0.02293137  0.0390036  -0.03049834 ... -0.01161455 -0.05326903
  0.02233888]"
e095cc36da784300b27c6f8c60a96440,INPUT CONFIGURATION,"SECTION, CONFIGURATION","The Input Configuration is a section within the config.json file that specifies how input data should be handled. It includes fields for input type, file type, file encoding, file pattern, and additional parameters specific to CSV mode, such as source column, timestamp column, timestamp format, text column, title column, and document attribute columns. It also includes settings for file input from Azure Storage, such as connection string, container name, base directory, and storage account blob URL.",458,,['f135654a3c057c66b9e5f97a960d302f'],"[-0.00609198  0.02821103  0.01453593 ... -0.02300715 -0.0052689
  0.01041753]"
c68893ca39d74ba08c6eb138f24441e1,LLM CONFIGURATION,"SECTION, CONFIGURATION","The LLM Configuration is a section within the config.json file that specifies settings for the LLM (Language Model) service. It includes the API Key field, which is used to authenticate and access the service. Other steps in the system may override this base configuration with their own LLM configuration.",459,,['f135654a3c057c66b9e5f97a960d302f'],"[ 0.02731198  0.0197344  -0.0384884  ...  0.00621884 -0.06932218
  0.04894371]"
472b23bb92834173b4118d101040c726,CONNECTION_STRING,"PROPERTY, CONFIGURATION","The CONNECTION_STRING is a crucial string attribute designed for Azure Blob storage, enabling access to the storage service by supplying essential connection details. This connection_string setting is pivotal for utilizing blob storage for various purposes, including caching and storage, as it furnishes the Azure Storage connection string required for these functionalities.",460,,['647be47c939b4d72f1c0b29a2e0d2cb2' 'd27237468a1b9e89110eeeca8080f63c'],"[ 0.00121864 -0.00975193  0.00863037 ... -0.01505818  0.00084719
  0.04310709]"
81869985b45a4fefbbbb23ea118a3de4,CONTAINER_NAME,"PROPERTY, CONFIGURATION","The CONTAINER_NAME is a string attribute pivotal in the context of Azure Blob storage. It specifically denotes the name of the container within Azure Storage where data is housed. This setting is crucial for organizing and accessing data in blob storage, enabling efficient management and retrieval of information. The CONTAINER_NAME plays a significant role in structuring data within Azure's cloud storage environment, facilitating streamlined operations and enhanced data accessibility.",461,,['647be47c939b4d72f1c0b29a2e0d2cb2' 'd27237468a1b9e89110eeeca8080f63c'],"[ 0.00411906 -0.02155838  0.01651326 ...  0.01937672  0.01965015
  0.02600051]"
42b8584c5a874eb08fbd61f0c18f3ca0,BASE_DIR,"PROPERTY, CONFIGURATION","The base_dir, a string attribute in the configuration, plays a multifaceted role in managing the file structure for storage. It primarily specifies the base directory for accessing CSV files, with the default being ""../data/csv"", relative to the config file. Additionally, this setting is utilized to determine the base directory from which input data should be read, again relative to the root directory of the storage. Furthermore, base_dir is also employed to define the base directory for writing cache or reports to, facilitating efficient storage management by maintaining a clear and organized file structure. This setting is crucial for ensuring that data, cache, and reports are correctly located and accessed within the storage system.",462,,"['3900b87693f02c43b4294e38647eb7cd' '647be47c939b4d72f1c0b29a2e0d2cb2'
 'd27237468a1b9e89110eeeca8080f63c']","[-0.01376476 -0.02538024  0.02942779 ...  0.00544601 -0.03075697
  0.00638229]"
824d93d9840a4b7c8b1f31bc6816b497,STORAGE_ACCOUNT_BLOB_URL,"PROPERTY, CONFIGURATION","The STORAGE_ACCOUNT_BLOB_URL is a string attribute that plays a crucial role in accessing and managing data within Azure's blob storage service. This setting specifically provides the URL for the Azure storage account blob, enabling direct access to the storage service. It is essential for various operations involving blob storage, ensuring seamless interaction with the data stored.",463,,['647be47c939b4d72f1c0b29a2e0d2cb2' 'd27237468a1b9e89110eeeca8080f63c'],"[-0.01356009  0.00587893  0.01183268 ... -0.02941099 -0.01007139
  0.0437378 ]"
f209a808f1f04a5699601e672f4abd06,MODEL,"PROPERTY, CONFIGURATION",The model is a string attribute that identifies the name of the model to be used for the LLM (Language Model) configuration.,464,,['647be47c939b4d72f1c0b29a2e0d2cb2'],"[ 0.00124616 -0.01907421 -0.02453339 ...  0.03341405 -0.03796828
  0.03871197]"
ccb335166f6c4564ac1c61549d8ded50,REQUEST_TIMEOUT,"PROPERTY, CONFIGURATION",The request_timeout is a float attribute that defines the timeout duration for each request made to the LLM (Language Model) service.,465,,['647be47c939b4d72f1c0b29a2e0d2cb2'],"[ 0.01810583  0.01648053 -0.03633759 ...  0.00210154 -0.02308399
  0.01636126]"
cbe1a41a82aa4f268e8264568b25938f,ORGANIZATION,"PROPERTY, CONFIGURATION",The organization is a string attribute that identifies the client organization using the LLM (Language Model) service.,466,,['647be47c939b4d72f1c0b29a2e0d2cb2'],"[-0.02043856 -0.03374303 -0.06015198 ... -0.0036164  -0.07317321
  0.07851578]"
28e7639f55ce464c8a080cbb2c745fa2,PROXY,"PROPERTY, CONFIGURATION",The proxy is a string attribute that specifies the URL of the proxy server to be used when making requests to the LLM (Language Model) service.,467,,['647be47c939b4d72f1c0b29a2e0d2cb2'],"[-0.00368485 -0.00540868 -0.02383641 ... -0.00723065 -0.04002735
  0.05894923]"
3f3a2d7aa1294116814f0b4d89baa23d,COGNITIVE_SERVICES_ENDPOINT,"PROPERTY, CONFIGURATION","The cognitive_services_endpoint is a string attribute that provides the URL endpoint for cognitive services, used for accessing additional AI services.",468,,['647be47c939b4d72f1c0b29a2e0d2cb2'],"[-0.04118128 -0.02715978 -0.02318642 ... -0.00295284 -0.04073187
  0.0428229 ]"
3073b33926bd4f33807ffa3befacefaf,MODEL_SUPPORTS_JSON,"PROPERTY, CONFIGURATION","The MODEL_SUPPORTS_JSON is a boolean attribute serving as a configuration parameter for the Language Model (LLM). This flag determines whether the model is capable of generating responses in JSON format. When enabled, it facilitates JSON-mode output, accommodating structured data requirements for various applications and integrations.",469,,['3c66b7e86b3675fce14fe0047ae731aa' '647be47c939b4d72f1c0b29a2e0d2cb2'],"[ 0.02702724 -0.01858971 -0.03420987 ...  0.02024733 -0.03485585
 -0.00962751]"
2b916117691c4872a9c4e4888d4fe4ab,TOKENS_PER_MINUTE,"PROPERTY, CONFIGURATION","The ""tokens_per_minute"" is an integral configuration parameter that governs the rate at which tokens can be consumed by the LLM (Language Model) service. It acts as a leaky-bucket throttle, setting a limit on the number of tokens processed per minute, thereby controlling the pace of token usage in requests. This attribute is crucial for managing the service's token consumption rate, ensuring efficient and controlled processing.",470,,['3c66b7e86b3675fce14fe0047ae731aa' '647be47c939b4d72f1c0b29a2e0d2cb2'],"[ 0.03057152  0.02148064 -0.01803569 ... -0.02032958 -0.08886328
  0.03105587]"
1f7b02bf486e4f42b23e9cb1a63207f3,REQUESTS_PER_MINUTE,"PROPERTY, CONFIGURATION","The requests_per_minute is an integer attribute that serves as a critical configuration parameter for managing the rate of incoming requests to the LLM (Language Model) service. It sets a throttle limit, implementing a leaky-bucket algorithm to control the number of requests processed per minute. This mechanism ensures that the service can handle requests at a sustainable rate, preventing overload and maintaining optimal performance.",471,,['3c66b7e86b3675fce14fe0047ae731aa' '647be47c939b4d72f1c0b29a2e0d2cb2'],"[ 0.03281311  0.02307128 -0.03274801 ... -0.0149659  -0.07434469
  0.03855121]"
e744c118ae7f4638a01d060bbaedd6e9,MAX_RETRIES,"PROPERTY, CONFIGURATION","The ""MAX_RETRIES"" is an integer attribute that plays a crucial role in the configuration of request handling in the LLM (Language Model) service. It specifies the maximum number of retries to be attempted when a request fails, ensuring that the system has multiple opportunities to successfully process the request before giving up. This parameter is essential for managing the reliability and resilience of the service, as it determines how persistent the system will be in the face of temporary failures or network issues. By setting the ""MAX_RETRIES"" value, users can balance between the need for robustness and the risk of wasting resources on repeatedly attempting doomed requests.",472,,['3c66b7e86b3675fce14fe0047ae731aa' '647be47c939b4d72f1c0b29a2e0d2cb2'],"[ 0.0203999   0.00183309 -0.03523413 ...  0.01484055 -0.01520978
  0.02264661]"
e1c1080c717d437996def1a41772d179,MAX_RETRY_WAIT,"PROPERTY, CONFIGURATION","The ""MAX_RETRY_WAIT"" is a float attribute that plays a crucial role in the configuration of retry mechanisms for failed requests to the LLM (Language Model) service. It specifies the maximum backoff time before a failed request is retried, effectively determining the upper limit for the wait time before initiating a retry. This parameter is essential for managing the retry strategy in the context of service requests, ensuring that there is an optimal balance between persistence and resource management.",473,,['3c66b7e86b3675fce14fe0047ae731aa' '647be47c939b4d72f1c0b29a2e0d2cb2'],"[ 0.02932112  0.00595296 -0.03548898 ...  0.00262334 -0.0166657
 -0.00210511]"
63fba9a7c47a4f14ac0bee6bc90d0fea,SLEEP_ON_RATE_LIMIT_RECOMMENDATION,"PROPERTY, CONFIGURATION","The sleep_on_rate_limit_recommendation is a boolean configuration parameter that governs the system's behavior when encountering rate limit recommendations from the LLM (Language Model) service. When set to true, the system will pause and adhere to sleep recommendations upon reaching rate limits, ensuring compliance with service limitations and optimizing resource usage. This flag enables control over how the system responds to rate limit encounters, providing a mechanism to manage system performance and service adherence.",474,,['3c66b7e86b3675fce14fe0047ae731aa' '647be47c939b4d72f1c0b29a2e0d2cb2'],"[ 0.04409671  0.01119701 -0.00729163 ...  0.03617842 -0.04970383
  0.0244173 ]"
6bfc2395b4f54a528a1ebac94a43acb8,URL ENDPOINT,"PROPERTY, CONFIGURATION","The url endpoint is the specific address used to access cognitive services, such as Azure's deployment for machine learning models. It is a configuration parameter that determines where requests are sent.>",475,,['3c66b7e86b3675fce14fe0047ae731aa'],"[-0.02107596  0.01388343 -0.03098031 ... -0.01960436 -0.01392893
  0.04961936]"
1cce5cebf437428eb1a60dffbdfa603f,CONCURRENT_REQUESTS,"PROPERTY, CONFIGURATION",The concurrent_requests is an integer that specifies the number of open requests to allow at once. It is a configuration parameter that manages the concurrency of requests.>,476,,['3c66b7e86b3675fce14fe0047ae731aa'],"[ 0.020103    0.00957779 -0.03583643 ... -0.00536759 -0.00085472
  0.00974446]"
dc94039d6643460ca3c66150b9087129,TEMPERATURE,"PROPERTY, CONFIGURATION",The temperature is a float that specifies the temperature to use in generating completions. It is a configuration parameter that influences the randomness of model outputs.>,477,,['3c66b7e86b3675fce14fe0047ae731aa'],"[ 0.0366479  -0.01265387 -0.00338845 ... -0.00443415 -0.00145196
 -0.01261995]"
f197d75f159943f8a3ff441199790bc7,TOP_P,"PROPERTY, CONFIGURATION",The top_p is a float that specifies the top-p value to use in generating completions. It is a configuration parameter that influences the diversity of model outputs.>,478,,['3c66b7e86b3675fce14fe0047ae731aa'],"[ 0.03449285 -0.01121287  0.03362268 ... -0.01432148  0.01698378
 -0.03429038]"
4d8890c699684c9381105b03b0b41b03,N,"PROPERTY, CONFIGURATION",The n is an integer that specifies the number of completions to generate. It is a configuration parameter that determines the quantity of completions returned by the model.>,479,,['3c66b7e86b3675fce14fe0047ae731aa'],"[ 0.0328221  -0.03530309 -0.00390422 ... -0.00475405  0.00178178
  0.0163121 ]"
b1658adfa43847eabad1437db235e858,STAGGER,"PROPERTY, CONFIGURATION",The stagger is a float that specifies the threading stagger value for parallelization. It is a configuration parameter that influences the scheduling of threads.>,480,,['3c66b7e86b3675fce14fe0047ae731aa'],"[ 0.03127109  0.01107538 -0.01677722 ... -0.02197505 -0.00431922
 -0.02927675]"
a1773cac7d4c4939aec965660e5015fe,NUM_THREADS,"PROPERTY, CONFIGURATION",The num_threads is an integer that specifies the maximum number of work threads for parallelization. It is a configuration parameter that determines the number of threads used for processing.>,481,,['3c66b7e86b3675fce14fe0047ae731aa'],"[ 0.04900082 -0.00498711 -0.02900175 ... -0.01438836 -0.03402749
  0.00391834]"
6a054cb59fb44cf494b93988b5f88833,ASYNC_MODE,"PROPERTY, CONFIGURATION","ASYNC_MODE is a pivotal configuration property within the system, serving as a top-level setting that dictates the asynchronous processing mode. It is set to either asyncio or threaded, with asyncio indicating that the system is configured to use asyncio for asynchronous operations. This setting is found in the Async Mode top-level configuration and is referenced across various sections, including entity extraction, summarization, and claim extraction strategies. ASYNC_MODE is crucial for defining how tasks are handled concurrently, enabling the system to operate in asynchronous mode and facilitate concurrent processing of tasks. It is a configuration field within community_reports, highlighting its significance in specifying settings related to asynchronous processing in the system.",482,,"['1b24101de07b1c195448240237b84b37' '3c66b7e86b3675fce14fe0047ae731aa'
 '53f1b5ad1d2f4ee5dfb53a8f1ff3ec14' '9cbd4e21339eeed5e22a638e52a094cb'
 'd27237468a1b9e89110eeeca8080f63c']","[-0.0196525   0.00672871 -0.05977657 ...  0.00523961  0.01500943
  0.04008332]"
e7b103a52e384e3e8bf14105223e7e82,BATCH_SIZE,"PROPERTY, CONFIGURATION","The entity ""BATCH_SIZE"" refers to an integer configuration parameter known as the batch size, which is crucial in determining the maximum number of items to be processed in a single batch for embeddings. This setting significantly influences the efficiency and resource usage of the system by specifying the size of batches for processing embeddings, ensuring optimal performance and resource management.",483,,['3c66b7e86b3675fce14fe0047ae731aa' 'd27237468a1b9e89110eeeca8080f63c'],"[ 0.04531195  0.00170488  0.00440245 ... -0.01322779 -0.01956282
 -0.00556369]"
3f1042452c254cecaf7189e89162adc8,BATCH_MAX_TOKENS,"PROPERTY, CONFIGURATION","The entity ""BATCH_MAX_TOKENS"" is an integer configuration parameter that plays a crucial role in managing computational resources and processing time within the context of embeddings. It specifies the maximum number of tokens that can be processed in a single batch, thereby controlling the batch size for embeddings. This setting ensures efficient use of resources and helps in optimizing the processing time by limiting the batch size to a manageable number of tokens.",484,,['3c66b7e86b3675fce14fe0047ae731aa' 'd27237468a1b9e89110eeeca8080f63c'],"[ 3.44638973e-02  5.36974939e-03 -3.52357747e-05 ... -9.20403097e-03
 -1.92514025e-02 -9.67359170e-04]"
fd31d549420744d1bd1a6b1112a9a6ba,TARGET,"PROPERTY, CONFIGURATION","The TARGET is a pivotal configuration parameter within the text-embedding process. It functions as a setting that dictates which specific set of embeddings should be emitted, either limiting the output to those deemed required or encompassing all available embeddings. This versatile parameter plays a crucial role in shaping the output of the embeddings, thereby impacting the overall text-embedding procedure. By adjusting the TARGET, users can tailor the output to meet their specific needs, whether it's a focused set of embeddings or a comprehensive collection.",485,,['3c66b7e86b3675fce14fe0047ae731aa' 'd27237468a1b9e89110eeeca8080f63c'],"[ 0.00853008  0.00139834  0.00949959 ... -0.02739289 -0.01342765
  0.01031635]"
f7ab348030714072a277682b51f7c588,SKIP,"PROPERTY, CONFIGURATION","The ""skip"" is a configuration parameter utilized in the text-embedding process. It manifests as a list of strings, each representing an embedding that should be excluded from processing. This feature enables customization and optimization of the output by allowing certain embeddings to be bypassed, catering to specific requirements or preferences in the data processing pipeline.",486,,['3c66b7e86b3675fce14fe0047ae731aa' 'd27237468a1b9e89110eeeca8080f63c'],"[ 0.01532227 -0.01279938 -0.00782547 ... -0.01135781 -0.00404725
  0.00162079]"
2139b0906dc541e094138a978d070416,STRATEGY,"PROPERTY, CONFIGURATION","The entity ""STRATEGY"" is a versatile and critical configuration property utilized in various text processing tasks. It serves as a dictionary setting that enables the full override of default strategies in entity extraction, summarization, claim extraction, and text embedding. This setting is pivotal for customizing the algorithms and rules applied to these processes, offering flexibility in how text is processed and embedded. By fully overriding the entity extraction process and text-embedding strategy, the ""STRATEGY"" entity empowers users to tailor the text processing methods to their specific needs, enhancing the precision and effectiveness of the analysis.",487,,"['3c66b7e86b3675fce14fe0047ae731aa' '9cbd4e21339eeed5e22a638e52a094cb'
 'abac77a5673e907cf8d65161c2612784' 'd27237468a1b9e89110eeeca8080f63c']","[-0.01432286  0.01018452 -0.00861491 ... -0.00679832  0.00392113
  0.03496396]"
ff5466607e5d4453b1d833629292f664,SIZE,"PROPERTY, CONFIGURATION","The entity ""SIZE"" refers to an integer configuration parameter that plays a crucial role in the processing of data. Specifically, it defines the maximum chunk size in tokens, which is instrumental in managing the size of text segments for processing. This setting ensures that the data is divided into manageable chunks, optimizing the efficiency and effectiveness of the processing tasks.",488,,['3c66b7e86b3675fce14fe0047ae731aa' 'd27237468a1b9e89110eeeca8080f63c'],"[ 0.0440242  -0.02007116  0.02468337 ... -0.04116272 -0.02532837
  0.00132054]"
71f95003936e46a98d90757ffd845d40,PARALLELIZATION,"CONFIGURATION, SETTING","Parallelization is a pivotal configuration property found in the top-level settings of various systems, particularly in entity extraction and community_reports. It serves as a critical parameter that dictates how tasks are processed in parallel, enabling the distribution of tasks across multiple processors or threads. This distribution is aimed at enhancing performance and efficiency by optimizing the concurrent processing of tasks. Parallelization is referenced in multiple sections of the configuration, underscoring its importance in managing and improving the system's processing capabilities.",489,,"['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14' '9cbd4e21339eeed5e22a638e52a094cb'
 'abac77a5673e907cf8d65161c2612784' 'd27237468a1b9e89110eeeca8080f63c']","[ 0.01685002 -0.01686223 -0.04109915 ... -0.00479037 -0.01515505
  0.01011525]"
bada987ea7da4c939393ee1c3d08ccd4,OVERLAP,"CONFIGURATION, SETTING","overlap is an integer setting that specifies the chunk overlap in tokens, which helps in maintaining context across adjacent chunks during the chunking process.",490,,['d27237468a1b9e89110eeeca8080f63c'],"[-0.00137684 -0.01780133 -0.00975874 ... -0.00926704 -0.03472232
 -0.00865741]"
d0a274e7934d446fb91847bb53a961a6,GROUP_BY_COLUMNS,"CONFIGURATION, SETTING","group_by_columns is a list of strings that specifies fields to group documents by before chunking, which can help in organizing and processing related documents together.",491,,['d27237468a1b9e89110eeeca8080f63c'],"[ 0.02816527 -0.03828637  0.01995587 ... -0.00065043 -0.003516
  0.03157748]"
0a799eab61bc4e6b884db6689f9c2c4a,CACHE,"CONFIGURATION, SETTING","""CACHE"" is a pivotal configuration section designed to outline the caching strategy for a pipeline. It enables the specification of the cache type, a critical factor in performance optimization and resource management within the pipeline. The cache types that can be defined under ""CACHE"" include file, memory, and blob, each catering to different storage and access requirements. Additionally, ""CACHE"" encompasses further parameters for detailed cache configuration, such as connection strings for accessing external storage and directories for specifying cache locations. This comprehensive control over caching aspects facilitates efficient data handling and retrieval, enhancing the overall performance and reliability of the pipeline.",492,,['d27237468a1b9e89110eeeca8080f63c' 'e01c546120a27319dcbdf7a6b89bab26'],"[ 0.01329847 -0.00212658 -0.00486766 ... -0.02282754 -0.00243617
  0.03467701]"
8c34cd494a63438dac219c1dc0f73100,STORAGE,"CONFIGURATION, SETTING","The STORAGE entity represents a critical configuration section within a system, specifically designed to manage and define the output strategy for data pipelines. This section encompasses various storage settings, enabling the selection of storage types, including file, memory, or blob. For blob storage, STORAGE facilitates the input of a connection string and container name, essential for establishing a connection to the blob storage service. When file storage is chosen, STORAGE allows for the specification of a base directory, relative to the root, for writing reports. This comprehensive configuration flexibility ensures that STORAGE can be tailored to meet the specific needs of different environments and use cases, optimizing data handling and output strategies.",493,,"['abac77a5673e907cf8d65161c2612784' 'd27237468a1b9e89110eeeca8080f63c'
 'e01c546120a27319dcbdf7a6b89bab26']","[-0.01275878  0.02054036  0.03807702 ... -0.01475225  0.00342148
  0.04161585]"
c6f428af0c5e4f629902fd5455bf19ac,REPORTING,"CONFIGURATION, SETTING","Reporting is a critical configuration section that manages settings associated with the generation, storage, and access of reports within the Motor Control and Drive Systems domain. This section encompasses various reporting types, such as file, console, or blob, and provides detailed instructions for each. For instance, when the blob type is selected, the reporting settings include a connection string and container name for proper data management. Additionally, the base directory for writing reports is specified relative to the root, ensuring organized and accessible report storage. Through these comprehensive settings, the reporting section facilitates efficient and tailored reporting functionalities, enabling users to customize and manage reports according to their specific needs.",494,,['abac77a5673e907cf8d65161c2612784' 'd27237468a1b9e89110eeeca8080f63c'],"[-0.02214368  0.00678207  0.00607107 ...  0.00416173 -0.00850758
  0.00060358]"
d1fd271d16c348019c2fcced762b35a2,STORAGE ACCOUNT BLOB URL,"PROPERTY, CONFIGURATION",The storage account blob URL is a configuration property used to specify the URL of the Azure Storage account blob. It is used in blob storage type configurations.,495,,['abac77a5673e907cf8d65161c2612784'],"[-0.00467143  0.01017837  0.00942197 ... -0.04194988  0.01004709
  0.02855943]"
ffa128c9c0c84d39bad1bba8cfa4adc5,FIELDS,"CONCEPT, CONFIGURATION","Fields represent the specific configuration options or parameters within a given section, such as storage or reporting.",496,,['abac77a5673e907cf8d65161c2612784'],"[-0.01566149 -0.03071517  0.00113284 ... -0.01287118  0.01340191
  0.01346665]"
058f66cc356b43cc9433bd3c8d57fa46,CONNECTION STRING,"PROPERTY, CONFIGURATION","The Connection String, a crucial configuration property specific to blob storage type, is employed to designate the Azure Storage connection string. This property facilitates the establishment of a link to blob storage, enabling seamless interaction and management of data within the Azure environment.",497,,['a3e5bacdf64bcaf080a04c7dd8218484' 'abac77a5673e907cf8d65161c2612784'],"[ 0.00381018  0.01046018  0.02002527 ... -0.01986806 -0.00179428
  0.03740606]"
ff74091eaba246698fcae59c21eec828,BASE DIR,"PROPERTY, CONFIGURATION","Base Dir is a configuration property that specifies the base directory to write reports to, relative to the root.",498,,['abac77a5673e907cf8d65161c2612784'],"[-0.01413923 -0.01525447  0.01933867 ...  0.01694856 -0.01647788
  0.01413476]"
f6cbbf1b8f4b48a28a16e4dd8976b9bb,ASYNC MODE,"PROPERTY, CONFIGURATION","Async Mode is a configuration property used in entity extraction, specifying whether to process text asynchronously.",499,,['abac77a5673e907cf8d65161c2612784'],"[-0.02483364  0.02329984 -0.04462796 ... -0.03143521  0.00459504
  0.03067751]"
757ca40654d5476aa949a26b733be8d4,PROMPT,"PROPERTY, CONFIGURATION","Prompt is a configuration property used in entity extraction, specifying the prompt file to use for guiding the text analysis.",500,,['abac77a5673e907cf8d65161c2612784'],"[ 0.01230488 -0.00872062 -0.02737862 ... -0.03844079 -0.00225955
  0.0341158 ]"
539d55e7c42e44b59d98f59fae3e0ee1,ENTITY TYPES,"PROPERTY, CONFIGURATION","Entity Types is a configuration property used in entity extraction, specifying the types of entities to identify.",501,,['abac77a5673e907cf8d65161c2612784'],"[-0.02611341  0.02202651 -0.01719147 ... -0.03028861 -0.00538094
  0.01601954]"
3785eeadea9042bfb2e50f16c0397a12,MAX GLEANINGS,"PROPERTY, CONFIGURATION","Max Gleanings is a configuration property used in entity extraction, specifying the maximum number of gleaning cycles to use.",502,,['abac77a5673e907cf8d65161c2612784'],"[ 0.00689425  0.01556036 -0.00296311 ... -0.01755172  0.00390664
  0.04765902]"
48cd97f2297143e09d61ff2a8542c0c5,SUMMARIZE DESCRIPTIONS,"CONCEPT, CONFIGURATION","Summarize Descriptions is a configuration section that deals with settings for summarizing descriptions, including the LLM (Language Model), parallelization, async mode, and prompt.",503,,['abac77a5673e907cf8d65161c2612784'],"[ 0.02738183 -0.02658091 -0.01867234 ... -0.01085173 -0.00017609
  0.03045419]"
ff95eb0d5f7f49b782027d5c7ae3c3fe,CONTAINER NAME,,"The CONTAINER NAME is a crucial configuration property, specifically designed for blob storage in the Motor Control and Drive Systems domain. This property, applicable exclusively to blob type storage, determines the container that will be utilized for storing blob data. By defining the CONTAINER NAME, users can effectively manage and access their blob storage resources, ensuring optimal data handling and retrieval within their systems.",504,,['a3e5bacdf64bcaf080a04c7dd8218484' 'abac77a5673e907cf8d65161c2612784'],"[-0.00506543  0.00472756  0.04246994 ...  0.00242485  0.01165781
  0.00560799]"
086da554db5b4ad5806aedeb0024197c,PROMPT STR,"CONFIGURATION, SETTING","Prompt STR is a pivotal configuration field within the community_reports framework, serving a dual role in specifying the prompt file for both report generation and a range of AI-driven processes. As a string value, it points to a file that is crucial for entity extraction, summarization, and claim extraction tasks. This setting is fundamental in defining the initial input or guidance for the AI or machine learning models engaged in these activities, ensuring that the models are accurately directed and that the reports generated are comprehensive and relevant. By configuring Prompt STR, users can tailor the input parameters to meet specific requirements, enhancing the precision and effectiveness of the AI models in processing and analyzing data.",505,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14' '9cbd4e21339eeed5e22a638e52a094cb'],"[-0.01785804 -0.02512061 -0.01272074 ... -0.02318117 -0.02191088
  0.01756767]"
216ee8a907a0466a88b27f8ada19ffa0,ENTITY_TYPES,"CONFIGURATION, SETTING",entity_types is a list of strings that defines the types of entities to identify during the entity extraction process. This setting is crucial for specifying the categories of information to be recognized and extracted from the text.>,506,,['9cbd4e21339eeed5e22a638e52a094cb'],"[-0.02014638  0.00217054  0.00753685 ... -0.01033424 -0.0124951
 -0.00181389]"
6fefb317687d4ac98efe39a52f3e190f,MAX_GLEANINGS,"CONFIGURATION, SETTING",max_gleanings is an integer setting that determines the maximum number of gleaning cycles to use in the entity extraction process. This setting is important for controlling the depth and thoroughness of the information extraction from the text.>,507,,['9cbd4e21339eeed5e22a638e52a094cb'],"[ 0.01762748  0.00607554  0.007955   ...  0.00346472 -0.00989392
  0.04583061]"
320d9d91238948a8be67972ccceab878,SUMMARIZE_DESCRIPTIONS,"PROCESS, FUNCTION","summarize_descriptions is a process or function that involves summarizing the descriptions of entities. It utilizes the llm (language model), parallelization, and async_mode settings, and has its own strategy for summarization. This process is essential for generating concise and informative summaries of entity descriptions.>",508,,['9cbd4e21339eeed5e22a638e52a094cb'],"[ 0.02479025 -0.00516834 -0.00139313 ...  0.00582993  0.01015827
  0.01878424]"
bdcbcccadd474b3bbe9a8f56c811bab4,MAX_LENGTH,"CONFIGURATION, SETTING","MAX_LENGTH is a crucial configuration field found within the community_reports settings. It serves as an integer-based limit, specifying the maximum number of output tokens per summarization or report. This setting is essential for controlling the length of the generated text, ensuring that the report output remains within acceptable and manageable limits. By defining MAX_LENGTH, users can effectively manage the size of their reports, making the information more digestible and easier to handle.",509,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14' '9cbd4e21339eeed5e22a638e52a094cb'],"[ 0.01291231 -0.01649427  0.00943087 ... -0.01600068  0.02794751
 -0.00481442]"
f127fc4d87f94794be89134406ba0694,CLAIM_EXTRACTION,"PROCESS, FUNCTION","claim_extraction is a process or function that involves identifying and extracting claims from text. It has a boolean setting 'enabled' to toggle its functionality, and utilizes the llm, parallelization, and async_mode settings. This process is essential for identifying assertions or statements of fact within the text.>",510,,['9cbd4e21339eeed5e22a638e52a094cb'],"[-0.00576603  0.01367534 -0.03364333 ... -0.0045242   0.01007998
  0.03174793]"
c27966a4e3be434686454204ac7b3ab4,COMMUNITY_REPORTS,"PROCESS, FUNCTION","The ""community_reports"" is a pivotal configuration section and process within the system, designed to manage and generate comprehensive reports based on data from various community sources. This dual-function entity includes several customizable fields for optimization, such as LLM (likely referring to Large Language Model), parallelization, async_mode, prompt, max_length, max_input_length, and strategy dict settings. These settings enable the process to operate efficiently and effectively, tailoring the report generation to specific needs. The ""community_reports"" process itself leverages the aforementioned settings, particularly LLM, parallelization, and async_mode, to compile and analyze data. Its unique strategy for report generation ensures that the output is insightful and valuable for understanding community dynamics and identifying potential collaboration opportunities or knowledge gaps.",511,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14' '9cbd4e21339eeed5e22a638e52a094cb'],"[-0.00521039  0.01121161 -0.0430087  ...  0.00266034 -0.02082326
  0.02775744]"
dab39f92d0ed468c80699f28c05c45fa,GLEANINGS INT,"PROPERTY, CONFIGURATION",gleanings int is a configuration parameter that specifies the maximum number of gleaning cycles to use in the system. It is an integer value.,512,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14'],"[ 0.02007411 -0.00414164  0.00013474 ... -0.01710764 -0.00612123
  0.0368649 ]"
3076f330d121489aa50964ce54a3b1ac,STRATEGY DICT,"PROPERTY, CONFIGURATION","The ""STRATEGY DICT"" is a versatile configuration setting within the system, designed to provide comprehensive control over various strategies, including graph embedding and claim extraction. This dictionary enables users to fully customize and override the default strategies, accommodating specific requirements or preferences. By containing a range of settings and rules, the STRATEGY DICT empowers users to tailor the system's behavior to better suit their needs, enhancing flexibility and adaptability in different contexts.",513,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14' 'b70cb2eda62c6afad9e8d22daafe61cc'],"[-0.02154686 -0.01106992 -0.01200971 ...  0.00994647  0.01644143
  0.0308379 ]"
c8e5d3afdcb54c8589e280f0c4a87417,MAX_INPUT_LENGTH,"PROPERTY, CONFIGURATION",max_input_length is a configuration field within community_reports that specifies the maximum number of input tokens to use when generating reports. It is an integer value that limits the size of the input for report generation.,514,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14'],"[ 0.00950758  0.00494707 -0.00265723 ... -0.00890282  0.00838821
 -0.02191945]"
f3d30627e19245649e497ab49bf0fa30,CLUSTER_GRAPH,"PROPERTY, CONFIGURATION","cluster_graph is a configuration section that includes various fields for managing cluster graphs, such as max_cluster_size, strategy dict, and other settings related to graph clustering.",515,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14'],"[-0.00474032  0.02252067 -0.00510425 ...  0.00158975  0.04414885
 -0.00479827]"
e3f1098c3d984bc7b5f30b9c0101f7a6,MAX_CLUSTER_SIZE,"PROPERTY, CONFIGURATION",max_cluster_size is a configuration field within cluster_graph that specifies the maximum cluster size to emit. It is an integer value that limits the size of clusters in the graph.,516,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14'],"[ 0.02325249  0.00451709  0.01221274 ... -0.00639061  0.03460846
 -0.02950876]"
24b4a5f4db67418cbfa08c5316f0ab51,EMBED_GRAPH,"PROPERTY, CONFIGURATION","embed_graph is a configuration section that includes various fields for managing graph embeddings, such as enabled, num_walks, walk_length, window_size, iterations, random_seed, and strategy dict settings.",517,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14'],"[-0.00597572  0.02046061 -0.04266318 ...  0.00471635  0.01476723
  0.02135164]"
e4b707e3e6964197855b82fc66ef59e7,ENABLED BOOL,"PROPERTY, CONFIGURATION","The ""ENABLED BOOL"" is a critical configuration property within the system, specifically within the embed_graph feature. This boolean value acts as a toggle, determining the activation or deactivation of certain functionalities. When set to true, it enables features such as UMAP layouts and graph embeddings, facilitating the visualization and analysis of complex networks. Conversely, when set to false, these features are disabled, affecting the system's capability to perform detailed network analysis and visualization tasks. The ""ENABLED BOOL"" plays a pivotal role in managing the system's feature set, allowing users to customize their experience and optimize resource usage based on their specific needs.",518,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14' 'b70cb2eda62c6afad9e8d22daafe61cc'],"[-0.01076582  0.00435972 -0.01922178 ...  0.01789536  0.01004883
  0.01750377]"
109b8be5a8ee4180a1465cd23f019d7b,NUM_WALKS,"PROPERTY, CONFIGURATION",num_walks is a configuration field within embed_graph that specifies the node2vec number of walks. It is an integer value that determines the number of walks performed in the graph for node2vec embeddings.,519,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14'],"[ 0.03068556  0.03348979 -0.04604581 ...  0.00917785 -0.00086677
  0.00501299]"
49f771e31a0c4b35bc39e389f3623509,WALK_LENGTH,"PROPERTY, CONFIGURATION",walk_length is a configuration field within embed_graph that specifies the node2vec walk length. It is an integer value that determines the length of each walk in the graph for node2vec embeddings.,520,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14'],"[ 0.0202105   0.03335093 -0.01577823 ... -0.01668037  0.01153786
 -0.01256117]"
aa946d4379694a74ba0da37e69d2810a,WINDOW_SIZE,"PROPERTY, CONFIGURATION",window_size is a configuration field within embed_graph that specifies the node2vec window size. It is an integer value that determines the size of the window for context in node2vec embeddings.,521,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14'],"[ 0.0410043  -0.00171195  0.00176886 ...  0.01714308 -0.00149734
 -0.00983   ]"
268446fc52a54fd2837f73aeb3e0b74f,ITERATIONS,"PROPERTY, CONFIGURATION",iterations is a configuration field within embed_graph that specifies the node2vec number of iterations. It is an integer value that determines the number of iterations for node2vec embeddings.,522,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14'],"[ 0.01424363  0.00340877 -0.00931058 ... -0.00588743  0.02423563
 -0.00113537]"
f6ddfa8491ff40d2839bb5b2e105df22,RANDOM_SEED,"PROPERTY, CONFIGURATION",random_seed is a configuration field within embed_graph that specifies the node2vec random seed. It is an integer value that determines the seed for the random number generator used in node2vec embeddings.,523,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14'],"[-0.00688671  0.04540676 -0.0014946  ...  0.03575103  0.03568346
 -0.01223641]"
db1295504da645b69d9786d54f233fed,UMAP,"PROPERTY, CONFIGURATION","UMAP, or Uniform Manifold Approximation and Projection, is an advanced algorithm utilized for dimension reduction and data visualization. In the specific context provided, UMAP is referenced as a versatile configuration option within a software or system. This option allows users to enable or disable UMAP layouts for data visualization, offering greater control over how complex data sets are represented. The ""umap"" configuration section encompasses various fields, including an enabled boolean flag and additional settings, all of which are geared towards managing and customizing UMAP visualization to suit specific analytical needs. This feature is particularly valuable for professionals in fields such as Social Network Analysis and Motor Control and Drive Systems, where understanding the structure and dynamics of data is crucial for identifying key influencers, collaboration opportunities, and knowledge gaps.",524,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14' 'b70cb2eda62c6afad9e8d22daafe61cc'],"[-0.00290359 -0.00043228 -0.00237085 ... -0.025409   -0.01365547
 -0.01606815]"
6ff4ed0dda4f4158af37be99f505565f,SNAPSHOTS,"PROPERTY, CONFIGURATION","Snapshots is a configuration section within the Motor Control and Drive Systems domain that encompasses a variety of settings for managing and generating different types of snapshots. These snapshots include graphml, raw entity, and top-level-node snapshots, which serve as crucial tools for data preservation and analysis. The entity, SNAPSHOTS, is central to the management of these configuration options, enabling users to control the creation and maintenance of snapshots for various purposes within the specialized professional network. By leveraging the SNAPSHOTS configuration, users can identify collaboration opportunities, address knowledge gaps, and better understand the structure and dynamics of the Motor Control and Drive Systems domain.",525,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14' 'b70cb2eda62c6afad9e8d22daafe61cc'],"[ 0.00073164  0.0081088  -0.00344486 ...  0.00117453  0.03454245
  0.02507239]"
5d398b88ee4242a59c32feb188683ec3,GRAPHML,"PROPERTY, CONFIGURATION",graphml is a configuration field within snapshots that specifies whether to emit graphml snapshots. It is a boolean value that determines if graphml snapshots are generated.,526,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14'],"[-0.00272714 -0.02189364 -0.02125959 ...  0.00654898  0.03152753
  0.04382474]"
0a784e00c9464bd3aeb830b908f73170,RAW_ENTITIES,"PROPERTY, CONFIGURATION",raw_entities is a configuration field within snapshots that specifies whether to emit raw entity snapshots. It is a boolean value that determines if raw entity snapshots are generated.,527,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14'],"[-0.02539998  0.00909391 -0.01378541 ...  0.02336747  0.04108977
  0.02346946]"
b0966a0f455e44229e6c9705d57bfca9,TOP_LEVEL_NODES,"PROPERTY, CONFIGURATION",top_level_nodes is a configuration field within snapshots that specifies whether to emit top-level-node snapshots. It is a boolean value that determines if top-level-node snapshots are generated.,528,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14'],"[ 0.00917828 -0.03479346 -0.00511169 ...  0.02566474  0.04724137
  0.01357282]"
99761e9b89cc4060be3ed6b34532e7ff,ENCODING_MODEL,"PROPERTY, CONFIGURATION","The encoding_model is a configuration setting within the Motor Control and Drive Systems domain, serving as a crucial parameter for text encoding processes. This entity is a string value that specifies the text encoding model to be utilized. By default, the encoding_model is set to cl100k_base; however, it can be adjusted to accommodate various models based on the specific requirements of the text encoding task. This flexibility allows for optimized encoding methods tailored to different applications within the field, enhancing the efficiency and accuracy of text processing tasks.",529,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14' 'b70cb2eda62c6afad9e8d22daafe61cc'],"[ 0.00223539 -0.00262265  0.03758702 ...  0.00637115 -0.03638443
  0.00173282]"
8130a1a82bde46048952cf147690e630,SKIP_WORKFLOWS,"PROPERTY, CONFIGURATION","The ""skip_workflows"" is a crucial configuration property utilized in the execution of pipelines within systems that manage workflows. This property enables the specification of a list of workflow names that are to be skipped during pipeline execution. It serves as a mechanism for enhancing efficiency by bypassing unnecessary or problematic workflows, thereby optimizing the overall process flow. The skip_workflows field is implemented as a list of strings, each string representing the name of a workflow that should be excluded from the system's operational sequence. This feature is particularly beneficial in scenarios where certain workflows are redundant or require troubleshooting, allowing for a streamlined and more effective pipeline execution.",530,,['53f1b5ad1d2f4ee5dfb53a8f1ff3ec14' 'b70cb2eda62c6afad9e8d22daafe61cc'],"[-0.01390891  0.00397128 -0.02410609 ... -0.00996025 -0.0015475
  0.02985225]"
79c99026b7ef4946b9b8e0be841fd4c5,NODE2VEC RANDOM SEED,"PROPERTY, CONFIGURATION","The node2vec random seed is a configuration parameter that determines the initial conditions for the node2vec algorithm, which is used for generating embeddings in graph structures. It is crucial for reproducibility and can affect the resulting embeddings.",531,,['b70cb2eda62c6afad9e8d22daafe61cc'],[0.00652587 0.02995652 0.02170541 ... 0.00838287 0.04299297 0.00711161]
fdcb1673254842f1935f53d0c38c467e,GRAPHML BOOL,"PROPERTY, CONFIGURATION","The graphml bool is a configuration property that controls whether graphml snapshots are emitted. Graphml is a file format for graphs and networks, used for data exchange and visualization.",532,,['b70cb2eda62c6afad9e8d22daafe61cc'],"[ 0.00854651 -0.01166283  0.00736689 ...  0.0205026   0.0287095
  0.04150943]"
dcb3f4cc8abc46faabc193d9885e91d0,RAW_ENTITIES BOOL,"PROPERTY, CONFIGURATION",The raw_entities bool is a configuration property that determines if raw entity snapshots are emitted. Raw entity snapshots capture the state of entities in their raw form for later analysis.,533,,['b70cb2eda62c6afad9e8d22daafe61cc'],"[-0.01662102  0.01229122 -0.00101335 ...  0.03827598  0.0274737
  0.02799123]"
3295be59128d451bb720c6688adc1e0b,TOP_LEVEL_NODES BOOL,"PROPERTY, CONFIGURATION",The top_level_nodes bool is a configuration property that specifies whether top-level-node snapshots are emitted. These snapshots capture the state of the top-level nodes in the system.,534,,['b70cb2eda62c6afad9e8d22daafe61cc'],"[ 0.01980419 -0.02997082  0.01153735 ...  0.03241838  0.03718152
  0.01913751]"
aca3eb8924ac494486fe0bfe892f7f2e,INDEXING ENGINE EXAMPLES,"PROPERTY, EXAMPLES",Indexing Engine Examples are a set of examples provided in the examples directory that demonstrate how to use the Indexing Engine with custom configuration. These examples are useful for learning and adapting the engine to various use-cases.,535,,['b70cb2eda62c6afad9e8d22daafe61cc'],"[-0.01522134  0.00804448  0.02596589 ...  0.00775346  0.0339153
  0.00876565]"
66689accdd974295b7eb779e43578748,EXTENDS,"PROPERTY, CONFIGURATION","The ""EXTENDS"" property, also referred to as a configuration directive, is a versatile feature designed to enhance the modularity and flexibility of configuration management. It enables users to extend or override existing configurations, making it possible to include or modify settings from other sections or files. This directive is particularly useful in pipeline configuration files, where it facilitates the inheritance of settings from one or more base configurations, streamlining the process of managing complex configurations and ensuring consistency across different sections or files. By leveraging the ""EXTENDS"" directive, users can efficiently update and customize configurations while maintaining the integrity of the base settings.",536,,['b70cb2eda62c6afad9e8d22daafe61cc' 'e01c546120a27319dcbdf7a6b89bab26'],"[-0.00413789  0.01186873 -0.00096561 ... -0.03282734  0.02719312
  0.00474738]"
6b49c78aa1524609ab7aa74aeaa3e01d,RUN.PY,"FILE, CODE","run.py is a Python script file that is used to run examples, typically found in the examples directory of a project. It can be executed using the Python interpreter with the PYTHONPATH environment variable set to the project's root directory.",537,,['e01c546120a27319dcbdf7a6b89bab26'],"[ 0.03132771  0.00554601 -0.0193653  ...  0.02020858 -0.00778633
  0.03008449]"
7ff31ce54f424f0bbb297b0b3ba7c757,POETRY SHELL,"COMMAND, ENVIRONMENT",poetry shell is a command used to activate a virtual environment with the required dependencies for a project. It is often used in conjunction with the Python API and pipeline configuration files to ensure that the correct environment is set up for running examples.,538,,['e01c546120a27319dcbdf7a6b89bab26'],"[ 0.00177785  0.01315215  0.01013573 ...  0.01184505  0.02504814
 -0.01113319]"
bac51e00d486420c8e91e824d8e17411,PYTHONPATH,"ENVIRONMENT VARIABLE, PATH",PYTHONPATH is an environment variable that specifies the directory where Python looks for modules and packages. Setting PYTHONPATH to the project's root directory ensures that the Python interpreter can find and import the necessary modules and scripts when running examples.,539,,['e01c546120a27319dcbdf7a6b89bab26'],"[ 0.0311587   0.00698342 -0.0363895  ... -0.01827148 -0.00942755
  0.0211023 ]"
4adee3aad6524a4aa4c4711c1ee05e64,ROOT_DIR,"CONFIGURATION, PATH","root_dir is a configuration directive that sets the root directory for the pipeline. All data inputs and outputs are assumed to be relative to this path, which is crucial for specifying the correct location of data files and output directories.",540,,['e01c546120a27319dcbdf7a6b89bab26'],"[ 0.0060163   0.00194134  0.00204864 ... -0.00552011 -0.01566161
  0.0169991 ]"
d034e4fd8ac849278e658daad1a1f033,STORAGE TYPE,"PROPERTY, CONFIGURATION","The Storage Type is a configuration property that determines the type of storage to use for data. The options are file, memory, and blob. This property is essential for specifying how data will be stored and accessed within the system.>(""entity""",541,,['763b51b68ecc9b69bc8014cf6f59fd33'],"[-0.02616948  0.00261453  0.02039911 ... -0.02316634  0.00359543
  0.00215142]"
091e998370dd42d1b05ab0fcf6595a7e,REPORTING TYPE,"PROPERTY, CONFIGURATION","The Reporting Type is a configuration property that specifies the type of reporting to use, with options including file, memory, and blob.",542,,['a3e5bacdf64bcaf080a04c7dd8218484'],"[-0.0200014  -0.0083313  -0.01365345 ... -0.00731336  0.00815374
  0.01969673]"
1e6cabc18fab4c048281fd29d3044438,BASE DIRECTORY,"PROPERTY, CONFIGURATION","The Base Directory is a configuration property (type: file only) that defines the base directory to store the reports in, relative to the config root.",543,,['a3e5bacdf64bcaf080a04c7dd8218484'],"[-0.0146079  -0.00201422  0.02165907 ...  0.0212731  -0.01824333
  0.00136001]"
dc08f6d7398b4b798a3bdccf508a2ad4,WORKFLOW NAME,"PROPERTY, CONFIGURATION","The Workflow Name is a property used to reference a specific workflow in other parts of the config, establishing dependencies between workflows.",544,,['a3e5bacdf64bcaf080a04c7dd8218484'],"[ 0.01814237  0.01195546 -0.0097766  ... -0.02752305 -0.01854366
  0.04569471]"
1c7fd5af8d8041e186eae2431fc627cd,STEPS,"PROPERTY, CONFIGURATION",Steps are the DataShaper operations that a workflow comprises. Steps can define inputs in the form of workflow:<workflow_name> to establish dependencies on the output of other workflows.,545,,['a3e5bacdf64bcaf080a04c7dd8218484'],"[-0.02042766  0.01203446 -0.01499839 ... -0.05479069  0.00132935
  0.03709288]"
b16eda56dcec40f2b3e109fb9246bee3,INPUT TYPE,"PROPERTY, CONFIGURATION","The Input Type is a configuration property that specifies the type of input to use, with options including file or blob.",546,,['a3e5bacdf64bcaf080a04c7dd8218484'],"[-0.01152893  0.00930343  0.01479795 ... -0.03053325  0.00373359
  0.00406543]"
43c68f9a86654a32a2215e23957ed184,FILE TYPE,"PROPERTY, CONFIGURATION","The File Type is a field that discriminates between different input types, with options including csv and text.",547,,['a3e5bacdf64bcaf080a04c7dd8218484'],"[-0.01964899 -0.0125053   0.03503754 ... -0.0012247  -0.01427287
 -0.01909002]"
1ba06fe2e86140a59bbc4f4e969d0f71,WORKFLOW2,"WORKFLOW, PROCESS","workflow2 is a process that includes steps to derive data, with dependencies on other workflows, specifically workflow1. It operates on columns such as col1 and col2.",548,,['76d9dcb9a27c2caea1f46bb5050851c6'],"[ 0.00167284  0.02475468 -0.00033036 ... -0.03207771 -0.02669549
  0.04027499]"
36caa0a230c8422c8acb4dc62e35bb32,WORKFLOW1,"WORKFLOW, PROCESS","workflow1 is a process that serves as a source for workflow2, establishing a dependency through the derive step.",549,,['76d9dcb9a27c2caea1f46bb5050851c6'],"[-0.00910344  0.03419186 -0.0131861  ... -0.04642048 -0.01900334
  0.03100802]"
09940fed9d154504948bba2df1789a50,DERIVE,"ACTION, PROCESS",derive is an action or process step within workflow2 that uses col1 and col2 as inputs and has a dependency on workflow1.,550,,['76d9dcb9a27c2caea1f46bb5050851c6'],"[-0.02875869  0.02652225 -0.00896375 ... -0.03454415 -0.03210194
  0.0311359 ]"
4d6608557eed49368a6d09c7c5c664c5,TIMESTAMP_COLUMN,"PROPERTY, DATA_COLUMN","The timestamp_column is a property in the CSV data that contains the timestamp of the data entries. It is formatted according to the timestamp_format specified in the configuration. The format used is ""%Y%m%d%H%M%S"".",551,,['3900b87693f02c43b4294e38647eb7cd'],"[ 0.01388982  0.02229984 -0.00407825 ...  0.00922912 -0.03039973
 -0.00174712]"
eb7c93eeb9dc41aab57d29e97ebb4951,TIMESTAMP_FORMAT,"PROPERTY, DATA_FORMAT","The timestamp_format is a property that defines the format of the timestamps in the timestamp_column. It is specified as ""%Y%m%d%H%M%S"", which represents the year, month, day, hour, minute, and second in the timestamp.",552,,['3900b87693f02c43b4294e38647eb7cd'],"[ 0.00652985  0.04096437  0.00082441 ... -0.0245428  -0.03918131
 -0.01203768]"
3b6e2ac584b64847b53828c9d779fed3,SOURCE_COLUMN,"PROPERTY, DATA_COLUMN","The source_column is a property that indicates the column containing the source or author of the data. It is specified as ""author"".",553,,['3900b87693f02c43b4294e38647eb7cd'],"[ 0.00676145 -0.00876986  0.01384557 ...  0.0071291   0.01332585
  0.00218248]"
e9b68002e035447baae848208cea5503,TEXT_COLUMN,"PROPERTY, DATA_COLUMN","The text_column is a property that indicates the column containing the text of the data. It is specified as ""message"".",554,,['3900b87693f02c43b4294e38647eb7cd'],"[ 0.021319   -0.02365597  0.01683569 ...  0.04519738  0.01216396
 -0.018649  ]"
fe18353546824ca98294ce4be7b96e02,AUTHOR,"PERSON, ROLE","The Author is the person or entity responsible for creating or originating the data. The author's name is stored in the 'author' column of the CSV file. The author's role could be a writer, a researcher, or any other individual or organization contributing to the data. The specific author for this data is not directly provided in the text but is referenced through the 'author' column in the CSV file.",555,,['6839baed839d7a5e837af1da93e462e5'],"[-0.00141877 -0.02417002 -0.00051799 ... -0.01991465  0.02621509
  0.00371262]"
0e9740e25f5a460c81318336e00ac880,MESSAGE,"TEXT, COMMUNICATION","The Message is the content or text of the data that is being communicated. It is stored in the 'message' column of the CSV file. The message could be a written document, a note, or any form of textual communication. The specific content of the message is not provided in the text but is referenced through the 'message' column in the CSV file.",556,,['6839baed839d7a5e837af1da93e462e5'],"[ 0.0206985  -0.02449217  0.02277612 ...  0.00565272  0.01263337
  0.0135244 ]"
b7cd9a62710849778fdadced0d754687,DATE,"TIME, DATE","The Date is the timestamp associated with the data, indicating when the data was created or recorded. It is stored in the 'date(yyyyMMddHHmmss)' column of the CSV file. The date format is specified as '%Y%m%d%H%M%S', which represents the year, month, day, hour, minute, and second. The specific date for this data is not directly provided in the text but is referenced through the 'date(yyyyMMddHHmmss)' column in the CSV file.",557,,['6839baed839d7a5e837af1da93e462e5'],"[ 0.04336992  0.01428456  0.01589779 ... -0.01520159 -0.04134845
  0.00415019]"
432a6b4962544200949421a96a405142,POST PROCESS,"PROCESS, DATA_MANIPULATION","The entity ""POST PROCESS"" refers to a series of operations that are executed on data after it has been extracted from a CSV file and prior to its utilization in a workflow. These post-process steps are crucial for data preparation and can encompass various actions such as filtering, transformation, and other forms of data manipulation to ensure the data is suitable for the workflow requirements. Specifically, one of the post-process steps involves filtering the data based on the 'title' column, where only records with the value 'My document' are selected for further processing. This filter is implemented using a filter verb that precisely targets the 'title' column with the specified value, ensuring that only relevant data is processed in the subsequent workflow stages.",558,,['6839baed839d7a5e837af1da93e462e5' '765d8a78606fe81a03a0da4f7ff231fa'],"[-0.01702976 -0.00495822  0.01681032 ... -0.0284928  -0.02197266
  0.03318864]"
d6700b360ac141d282cdb567414bf4ce,CSV FILE PATTERN,"PROPERTY, REGEX","The CSV File Pattern is a regular expression used to match CSV files, specifically looking for the format that includes day and author information. The pattern is: {2})-(?P<day>\d{2})_(?P<author>[^_]+)_\d+\.csv$.",559,,['765d8a78606fe81a03a0da4f7ff231fa'],"[ 0.02255474  0.02435919  0.0393827  ...  0.02102276  0.00980581
 -0.0063696 ]"
c1b40a4039b44061a358e098867f7412,FILE FILTER,"PROPERTY, FILTER","The File Filter is a set of criteria used to further filter files based on named groups from the CSV File Pattern. It includes filters for year, month, and potentially day. Currently, it filters files for the year 2023 and month 06.",560,,['765d8a78606fe81a03a0da4f7ff231fa'],"[ 0.03752907 -0.00761867  0.04615059 ... -0.00348989 -0.03334956
  0.01217969]"
4643a7a319674adfb732b6f6122c7c64,CONFIGURATION TEMPLATE,"PROPERTY, TEMPLATE","The Configuration Template is a template for a .env file used in the Indexing Pipeline execution. It includes settings for LLM (Language Model), API key, API base, API version, and text generation settings. The LLM type is set to ""azure_openai_chat"".",561,,['765d8a78606fe81a03a0da4f7ff231fa'],"[-0.01187157  0.00073455  0.00712446 ... -0.0305564   0.02335433
 -0.00182625]"
46e8056fb2ec4811ab33cb34a0dc9fb3,GRAPHRAG_API_BASE,"CONFIGURATION, SETTING","GRAPHRAG_API_BASE is a critical configuration property that serves a dual purpose within the system. Primarily, it designates the base URL for the LLM (Language Model) service API, guiding the system to the endpoint where requests to access the LLM service are sent. The placeholder value ""http://<domain>.openai.azure.com"" is indicative of the actual domain that should be specified, making this property indispensable for directing the system to the correct LLM service endpoint. Additionally, GRAPHRAG_API_BASE is a configuration setting that specifically points to the base URL for the GraphRAG API, a detail of particular significance for Azure OpenAI users. It must be set to the domain of the Azure OpenAI service to ensure that all API requests are correctly directed to the intended endpoint. This setting is mandatory for Azure OpenAI users, as it facilitates the seamless integration and operation of the system with the Azure OpenAI service.",562,,['3da10b454f926a257b9fdf5d2487c0a5' '8ac79ce92be1254dfda9a10eb54ab703'],"[-0.00290587  0.03568168 -0.00517652 ... -0.02203592 -0.04571737
  0.04087215]"
8b57a9f43a1942a49b58cf881835f974,GRAPHRAG_API_VERSION,"CONFIGURATION, SETTING","GRAPHRAG_API_VERSION is a critical configuration property that specifies the API version to be used when interacting with the Azure OpenAI service, particularly when accessing the LLM (Language Model) service API. By default, it is set to ""api_version,"" which serves as a placeholder for the actual API version. This setting is essential for Azure OpenAI users as it ensures compatibility and correct functionality when making API calls to the GraphRAG service. GRAPHRAG_API_VERSION determines which version of the API the system will use to access the LLM service, thereby playing a pivotal role in maintaining compatibility between the system and the LLM service.",563,,"['3da10b454f926a257b9fdf5d2487c0a5' '7b45dafa74553d3899e2291a3c9fb86e'
 '8ac79ce92be1254dfda9a10eb54ab703']","[ 0.01286114  0.03937384 -0.00913447 ... -0.01423807 -0.03568678
  0.03032339]"
f78b01b0d93948c283644ec58f7be74a,GRAPHRAG_LLM_DEPLOYMENT_NAME,"CONFIGURATION, SETTING",GRAPHRAG_LLM_DEPLOYMENT_NAME is a configuration setting that specifies the name of the deployment for the language model being used. It is set to 'gpt-4-turbo-preview' in the provided configuration. This setting is crucial for identifying the specific model deployment to be used for text generation.,564,,['3da10b454f926a257b9fdf5d2487c0a5'],"[ 0.04680227 -0.00383108  0.00374884 ... -0.00385633 -0.0204601
  0.02012471]"
8dbe8f9867e4448f998416c18923eac4,GRAPHRAG_LLM_MODEL_SUPPORTS_JSON,"CONFIGURATION, SETTING","GRAPHRAG_LLM_MODEL_SUPPORTS_JSON is a configuration property that plays a crucial role in determining the compatibility of the language model with JSON data. This setting, which is set to True by default in the provided configuration, signifies that the model is capable of processing and generating JSON input and output. The capability to handle JSON data is essential for defining the format of the input data that the model can effectively process, thereby enabling a wider range of applications and data interoperability.",565,,['3da10b454f926a257b9fdf5d2487c0a5' '7b45dafa74553d3899e2291a3c9fb86e'],"[ 0.02420313  0.01066495 -0.0194688  ... -0.02237445 -0.03576418
  0.0034882 ]"
fe8ea8bf1395434393e04e8f7a33025f,GRAPHRAG_INPUT_TYPE,"CONFIGURATION, SETTING","GRAPHRAG_INPUT_TYPE is a pivotal configuration property that dictates the nature of input data to be processed by the system. It can be configured to ""file"" for file-based input, indicating that the system expects data in a file format, or set to ""text"" for processing textual data. This setting is essential for defining the format of the input data, which is critical for text generation or embedding tasks. The GRAPHRAG_INPUT_TYPE property plays a significant role in configuring the input data source, ensuring that the system processes data in the correct format.",566,,['3da10b454f926a257b9fdf5d2487c0a5' '8ac79ce92be1254dfda9a10eb54ab703'],"[-0.01127713 -0.00253231  0.01718317 ... -0.02785897 -0.01903251
 -0.00560253]"
7d58b089bfc549e8951e91ad62541119,GRAPHRAG_INPUT_FILE_TYPE,"PROPERTY, CONFIGURATION","GRAPHRAG_INPUT_FILE_TYPE is a configuration property that specifies the type of files to be processed, set to ""text"" for text files. It determines the format of the input files that the system will handle. The value ""text"" indicates that the system is configured to process text files. This property is essential for specifying the file type that the system should expect and process.>",567,,['8ac79ce92be1254dfda9a10eb54ab703'],"[-0.00277532  0.01004086  0.03981149 ... -0.02071408 -0.00956999
 -0.009859  ]"
1fa6d3118bd846c8837b5fa9fb78f262,GRAPHRAG_INPUT_FILE_PATTERN,"PROPERTY, CONFIGURATION","GRAPHRAG_INPUT_FILE_PATTERN is a configuration property that specifies the pattern for matching input files, set to "".*\.txt$"". It determines which files will be selected for processing based on their names. The value "".*\.txt$"" indicates that the system is configured to process files with a .txt extension. This property is crucial for filtering the input files based on their names.>",568,,['8ac79ce92be1254dfda9a10eb54ab703'],"[ 0.01790689  0.02449812  0.05400481 ...  0.00465006 -0.00671962
 -0.01780649]"
62c65bbae33c4ee9a21b61f6f454c4b4,GRAPHRAG_INPUT_SOURCE_COLUMN,"PROPERTY, CONFIGURATION","GRAPHRAG_INPUT_SOURCE_COLUMN is a configuration property that specifies the column name in the input data that contains the source information. It determines which column in the input data should be used for source information. The value ""source"" indicates that the system is configured to use the ""source"" column for source information. This property is essential for identifying the source of the input data.>",569,,['8ac79ce92be1254dfda9a10eb54ab703'],"[ 0.00360452  0.0029498   0.01651226 ... -0.03098886 -0.02812549
  0.0004235 ]"
30b7034c4468473f98ee18d00ee73b33,GRAPHRAG_LLM_API_KEY,"PROPERTY, CONFIGURATION","GRAPHRAG_LLM_API_KEY is a configuration property that holds the API key required for authentication when using the Azure OpenAI service. It is set to ""your_api_key"" as a placeholder, indicating that a valid API key should be provided by the user.>",570,,['7b45dafa74553d3899e2291a3c9fb86e'],"[ 0.03590281  0.04667402 -0.01200918 ... -0.02102191 -0.04096664
  0.04463528]"
00f78b85e5b84999a810e311e540037b,GRAPHRAG_LLM_API_VERSION,"PROPERTY, CONFIGURATION","GRAPHRAG_LLM_API_VERSION is a configuration property that specifies the API version to be used when interacting with the Azure OpenAI service for language model requests. It is set to ""api_version"" by default and is crucial for compatibility and functionality.>",571,,['7b45dafa74553d3899e2291a3c9fb86e'],"[ 0.01821844  0.04456813 -0.0051699  ... -0.02099119 -0.03785331
  0.03957722]"
3e460d9f011d4b0b9ccaae7b6a5202de,HRAG_LLM_DEPLOYMENT_NAME,"PROPERTY, CONFIGURATION","HRAG_LLM_DEPLOYMENT_NAME is a configuration property that specifies the name of the deployment for the Large Language Model (LLM) in the Human-in-the-Loop Request Augmentation Gateway (HRAG). It is currently set to None, indicating that no specific deployment name is provided.>",572,,['9aff9243c57cabca574b35438bf31a50'],"[ 0.01959777  0.00539354 -0.02204785 ...  0.00957409  0.01516588
  0.02510587]"
9d98dece22eb401aa1a5ce9c88c603f0,GRAPHRAG_LLM_MAX_TOKENS,"PROPERTY, CONFIGURATION","GRAPHRAG_LLM_MAX_TOKENS is a configuration property that specifies the maximum number of tokens allowed for a request to the Large Language Model (LLM) in the Human-in-the-Loop Request Augmentation Gateway (HRAG). It is set to 4000, indicating that the maximum number of tokens for a request is 4000.>",573,,['9aff9243c57cabca574b35438bf31a50'],"[ 0.05523893  0.01764218  0.00015262 ... -0.00311551 -0.00425659
  0.02341459]"
81446ea789b24eaf9eab02dc07c3d984,GRAPHRAG_LLM_REQUEST_TIMEOUT,"PROPERTY, CONFIGURATION","GRAPHRAG_LLM_REQUEST_TIMEOUT is a configuration property that specifies the timeout duration for a request to the Large Language Model (LLM) in the Human-in-the-Loop Request Augmentation Gateway (HRAG). It is set to 180, indicating that the request will time out after 180 seconds.>",574,,['9aff9243c57cabca574b35438bf31a50'],"[ 0.03962107  0.02993526 -0.01312677 ... -0.01334297 -0.01976866
  0.02311757]"
79f4b1c1b2be4cf7aa828846e20a4eb6,GRAPHRAG_LLM_THREAD_STAGGER,"PROPERTY, CONFIGURATION","GRAPHRAG_LLM_THREAD_STAGGER is a configuration property that specifies the stagger time between threads for processing requests to the Large Language Model (LLM) in the Human-in-the-Loop Request Augmentation Gateway (HRAG). It is set to 0.3, indicating that there will be a 0.3-second stagger between threads.>",575,,['9aff9243c57cabca574b35438bf31a50'],"[ 0.04909139  0.03815742 -0.01037101 ... -0.01957898 -0.03338735
  0.02497881]"
de04830d6e414fd5b39a9e90769d9452,GRAPHRAG_LLM_CONCURRENT_REQUESTS,"PROPERTY, CONFIGURATION","GRAPHRAG_LLM_CONCURRENT_REQUESTS is a configuration property that specifies the number of concurrent requests allowed to the Large Language Model (LLM) in the Human-in-the-Loop Request Augmentation Gateway (HRAG). It is set to 25, indicating that 25 concurrent requests are allowed.>",576,,['9aff9243c57cabca574b35438bf31a50'],"[ 0.04000433  0.02624867 -0.02306032 ... -0.01036308 -0.00795398
  0.02858405]"
69db426b97714835bf4937180774787a,GRAPHRAG_LLM_TPM,"PROPERTY, CONFIGURATION","GRAPHRAG_LLM_TPM is a configuration property that specifies the target tokens per minute for requests to the Large Language Model (LLM) in the Human-in-the-Loop Request Augmentation Gateway (HRAG). It is set to 0, indicating that no specific target tokens per minute is set.>",577,,['9aff9243c57cabca574b35438bf31a50'],"[ 0.02888626  0.04387793 -0.00602118 ... -0.02349594 -0.05786936
  0.02017362]"
9c7bc862339d4a5bb21ee5154d9b33bb,GRAPHRAG_LLM_RPM,"PROPERTY, CONFIGURATION","GRAPHRAG_LLM_RPM is a configuration property that specifies the target requests per minute for requests to the Large Language Model (LLM) in the Human-in-the-Loop Request Augmentation Gateway (HRAG). It is set to 0, indicating that no specific target requests per minute is set.>",578,,['9aff9243c57cabca574b35438bf31a50'],"[ 0.02899732  0.03110327  0.00246347 ... -0.01873263 -0.03653223
  0.01359176]"
17bad53a0ebe4569839e5e151ff78593,GRAPHRAG_LLM_MAX_RETRY_WAIT,"PROPERTY, CONFIGURATION","GRAPHRAG_LLM_MAX_RETRY_WAIT is a configuration property that specifies the maximum wait time between retries for a request to the Large Language Model (LLM) in the Human-in-the-Loop Request Augmentation Gateway (HRAG). It is set to 10, indicating that the maximum wait time between retries is 10 seconds.>",579,,['9aff9243c57cabca574b35438bf31a50'],"[ 0.04522385  0.04229366 -0.02129908 ... -0.01551165 -0.00928533
  0.00849679]"
53d98f08e7c74158b7318357b6c660b3,GRAPHRAG_LLM_SLEEP_ON_RATE_LIMIT_RECOMMENDATION,"PROPERTY, CONFIGURATION","GRAPHRAG_LLM_SLEEP_ON_RATE_LIMIT_RECOMMENDATION is a configuration property that specifies whether the system should sleep when it receives a rate limit recommendation from the Large Language Model (LLM) in the Human-in-the-Loop Request Augmentation Gateway (HRAG). It is set to True, indicating that the system will sleep when it receives a rate limit recommendation.>",580,,['9aff9243c57cabca574b35438bf31a50'],"[ 0.04673407  0.03519819  0.00221828 ...  0.01046394 -0.0208444
  0.01912542]"
cd601f77419c403889aadeee591915b5,GRAPHRAG_EMBEDDING_API_KEY,"PROPERTY, CONFIGURATION","GRAPHRAG_EMBEDDING_API_KEY is a configuration property that specifies the API key for the embedding service in the Human-in-the-Loop Request Augmentation Gateway (HRAG). It is set to ""your_api_key"", indicating that a specific API key is provided for the embedding service.>",581,,['9aff9243c57cabca574b35438bf31a50'],"[ 0.02425694  0.03129837 -0.03484891 ... -0.0229692  -0.00432643
  0.00309391]"
0f564ebd53e940fba9d16674ac7bc038,GRAPHRAG_EMBEDDING_API_VERSION,"PROPERTY, CONFIGURATION","GRAPHRAG_EMBEDDING_API_VERSION is a configuration property utilized in the Human-in-the-Loop Request Augmentation Gateway (HRAG), specifically designed for Azure OpenAI users. This variable is set to ""api_version"", which denotes the designated API version for the embedding service. It comes into play when GRAPHRAG_API_VERSION is not defined, ensuring that embedding requests are processed with a specified API version, thereby maintaining consistency and compatibility in the system.",582,,['485c17007ccb3102887eaa47d6a6100f' '9aff9243c57cabca574b35438bf31a50'],"[ 0.00164374  0.02685221 -0.00758907 ... -0.03553158  0.00987334
  0.00379148]"
7deb75816e4f473480e0c79ae99b5bf4,APHRAG_API_KEY,"VARIABLE, CONFIGURATION",APHRAG_API_KEY is a configuration variable that is not set. It is likely used for authentication or access to certain services or APIs.>,583,,['485c17007ccb3102887eaa47d6a6100f'],"[ 0.02923556 -0.00243539 -0.0036775  ... -0.01332709  0.00177502
  0.00624735]"
7f85b181f1184f77aeb3ea2155cf4027,HRAG_EMBEDDING_THREAD_COUNT,"CONFIGURATION, SETTING","HRAG_EMBEDDING_THREAD_COUNT is a configuration setting that specifies the number of threads used for embedding operations. It is set to None, indicating that the default or system-determined number of threads will be used.",584,,['2b777e3d591ce1511a03abd1a6d8dc73'],"[-0.00150152 -0.00876204 -0.00735457 ... -0.01937614 -0.00110526
 -0.02619633]"
d148b2b2033048618f1a090a492a40a5,GRAPHRAG_EMBEDDING_THREAD_STAGGER,"CONFIGURATION, SETTING","GRAPHRAG_EMBEDDING_THREAD_STAGGER is a configuration setting that determines the stagger or delay between embedding threads. It is set to 50, indicating a 50 millisecond delay between starting threads.",585,,['2b777e3d591ce1511a03abd1a6d8dc73'],"[ 0.01689153  0.03051483 -0.02397318 ... -0.03216278 -0.03922755
  0.00466158]"
4d839a10353e4144a26563b0966721d5,GRAPHRAG_EMBEDDING_CONCURRENT_REQUESTS,"CONFIGURATION, SETTING","GRAPHRAG_EMBEDDING_CONCURRENT_REQUESTS is a configuration setting that specifies the number of concurrent requests for embedding operations. It is set to 25, indicating that up to 25 requests can be processed simultaneously.",586,,['2b777e3d591ce1511a03abd1a6d8dc73'],"[ 0.01865997  0.0182819  -0.03113061 ... -0.02808147 -0.01970237
  0.00509837]"
521a862bb196488389f17c0b0f4b6f4d,GRAPHRAG_EMBEDDING_TPM,"CONFIGURATION, SETTING","GRAPHRAG_EMBEDDING_TPM is a configuration setting that represents the transactions per minute for embedding operations. It is set to 0, indicating that there is no specific limit.",587,,['2b777e3d591ce1511a03abd1a6d8dc73'],"[ 0.01815137  0.03100035 -0.01236604 ... -0.03175782 -0.06182732
 -0.00097745]"
22ea3328fb6343f4ad2862495ea27640,GRAPHRAG_EMBEDDING_RPM,"CONFIGURATION, SETTING","GRAPHRAG_EMBEDDING_RPM is a configuration setting that represents the requests per minute for embedding operations. It is set to 0, indicating that there is no specific limit.",588,,['2b777e3d591ce1511a03abd1a6d8dc73'],"[ 0.00746497  0.01358093 -0.00445256 ... -0.02844332 -0.0396601
 -0.019778  ]"
3f9a2a2c1c0a424e8b4980ea9d48bdbe,GRAPHRAG_EMBEDDING_MAX_RETRY_WAIT,"CONFIGURATION, SETTING","GRAPHRAG_EMBEDDING_MAX_RETRY_WAIT is a configuration setting that determines the maximum wait time between retries for embedding operations. It is set to 10, indicating a 10-second maximum wait.",589,,['2b777e3d591ce1511a03abd1a6d8dc73'],"[ 0.02024834  0.03117978 -0.02408042 ... -0.02321084 -0.01702919
 -0.02100828]"
aa2ec452728a4703ae1bdabe85b6c079,GRAPHRAG_EMBEDDING_SLEEP_ON_RATE_LIMIT_RECOMMENDATION,"CONFIGURATION, SETTING","GRAPHRAG_EMBEDDING_SLEEP_ON_RATE_LIMIT_RECOMMENDATION is a configuration setting that indicates whether the system should sleep or pause when rate limits are reached during embedding operations. It is set to True, indicating that the system will sleep.",590,,['2b777e3d591ce1511a03abd1a6d8dc73'],"[ 0.02643614  0.03223357  0.00138024 ...  0.00520634 -0.02869482
 -0.00184201]"
c5ddb31e0a9c4b2683e4631283dd505b,GRAPHRAG_INPUT_ENCODING,"CONFIGURATION, SETTING","GRAPHRAG_INPUT_ENCODING is a configuration setting that specifies the encoding used for input data. It is set to utf-8, indicating that the system uses UTF-8 encoding for input data.",591,,['2b777e3d591ce1511a03abd1a6d8dc73'],"[-0.00686328 -0.00783949  0.01353734 ... -0.02710947 -0.03183109
 -0.00176337]"
07d8eeb549044ac88d2e788c146a0ef1,GRAPHRAG_CHUNK_SIZE,"CONFIGURATION, SETTING","GRAPHRAG_CHUNK_SIZE is a configuration setting that determines the size of data chunks for processing. It is set to 1200, indicating that data is processed in chunks of 1200 units.",592,,['2b777e3d591ce1511a03abd1a6d8dc73'],"[ 0.0300338  -0.01161608  0.0184881  ... -0.02807739 -0.04648163
 -0.00177601]"
47df2815030c4f1c99facd5cf2482526,GRAPHRAG_CHUNK_OVERLAP,"CONFIGURATION, SETTING","GRAPHRAG_CHUNK_OVERLAP is a configuration setting that specifies the overlap between data chunks. It is set to 100, indicating that there is a 100-unit overlap between chunks.",593,,['2b777e3d591ce1511a03abd1a6d8dc73'],"[ 0.02133228  0.01186057  0.0121576  ... -0.01843702 -0.02750773
 -0.00165985]"
ae521508bdc244f99c4fce4ab5214c79,GRAPHRAG_CHUNK_BY_COLUMNS,"CONFIGURATION, SETTING","GRAPHRAG_CHUNK_BY_COLUMNS is a configuration setting that indicates the column(s) used for chunking data. It is set to id, indicating that data is chunked based on the 'id' column.",594,,['2b777e3d591ce1511a03abd1a6d8dc73'],"[ 0.01790278 -0.01734876  0.01882074 ... -0.026031   -0.00622963
  0.02162613]"
6315b4bf135c40358823ed7e4e4060e2,GRAPHRAG_ENTITY_EXTRACTION_MAX_GLEANINGS,"CONFIGURATION, SETTING","GRAPHRAG_ENTITY_EXTRACTION_MAX_GLEANINGS is a configuration setting that determines the maximum number of gleanings or entities extracted. It is set to 1, indicating that only one entity will be extracted.",595,,['2b777e3d591ce1511a03abd1a6d8dc73'],"[ 0.02059971  0.02851407 -0.01148953 ... -0.02914671 -0.01944971
  0.03671483]"
33905debec1a45ecae1c65daac1d854c,GRAPHRAG_ENTITY_EXTRACTION_ENTITY_TYPES,"CONFIGURATION, SETTING","GRAPHRAG_ENTITY_EXTRACTION_ENTITY_TYPES is a pivotal configuration property designed to delineate and specify the categories of entities to be extracted within a given context. This setting ensures the identification and extraction of entities falling under the categories of organization, person, event, and geo, thereby facilitating a comprehensive analysis and understanding of the relationships and dynamics among these entities in various domains and scenarios. By setting GRAPHRAG_ENTITY_EXTRACTION_ENTITY_TYPES to include organization, person, event, and geo, the system is optimized to recognize and categorize these specific types of entities, enhancing the precision and relevance of the extracted information.",596,,['2b777e3d591ce1511a03abd1a6d8dc73' 'cde833db73c46ca28f08e35195134441'],"[-0.0029343   0.00167656 -0.02157919 ... -0.03925525 -0.02724028
  0.0437637 ]"
bfbe904780fe47daad1a04126b12923c,GRAPHRAG_SUMMARIZE_DESCRIPTIONS_MAX_LENGTH,"CONFIGURATION, SETTING","GRAPHRAG_SUMMARIZE_DESCRIPTIONS_MAX_LENGTH is a configuration property that determines the maximum length of summarized descriptions. Currently set to 500, this setting ensures that all descriptions are summarized to a concise limit of 500 characters, facilitating clear and succinct communication within the system.",597,,['2b777e3d591ce1511a03abd1a6d8dc73' 'cde833db73c46ca28f08e35195134441'],"[ 0.03633956 -0.03136965  0.02782833 ... -0.03621273  0.00125335
 -0.01594846]"
0614f00e932c4cd0b53928053811ebc1,GRAPHRAG_CLAIM_EXTRACTION_DESCRIPTION,"CONFIGURATION, SETTING","GRAPHRAG_CLAIM_EXTRACTION_DESCRIPTION is a configuration property pivotal in the domain of threat analysis. This setting specifically delineates the criteria for the type of claims or facts to be extracted, ensuring that any information that could potentially be relevant to threat analysis is captured. The description for claim extraction, as defined by GRAPHRAG_CLAIM_EXTRACTION_DESCRIPTION, is set to ""Any claims or facts that could be relevant to threat analysis,"" highlighting its comprehensive approach to identifying pertinent data points in the analysis process.",598,,['2b777e3d591ce1511a03abd1a6d8dc73' 'cde833db73c46ca28f08e35195134441'],"[ 0.01085595 -0.0031966  -0.02609177 ... -0.02395425  0.02136403
  0.0117859 ]"
9ef487dd0b574b108c60a56d6a2f146c,GRAPHRAG_CLAIM_EXTRACTION_PROMPT_FILE,"CONFIGURATION, SETTING","The GRAPHRAG_CLAIM_EXTRACTION_PROMPT_FILE is a configuration property within the system, designed to specify the file that should be utilized for claim extraction prompts. Currently, this setting is configured as None, which signifies the absence of a designated file for this purpose. This configuration property plays a crucial role in the claim extraction process, enabling flexibility in choosing the appropriate prompts file, although at present, no specific file is being employed.",599,,['2b777e3d591ce1511a03abd1a6d8dc73' 'cde833db73c46ca28f08e35195134441'],"[ 0.01422539 -0.00301673 -0.02859775 ... -0.03818455  0.01620915
  0.0257815 ]"
4067269e7f6943cdbc299ce02b7eadbd,GLEANINGS,"PROPERTY, CONFIGURATION","GLEANINGS is a configuration property with a value of 1, indicating a setting or a state in the system related to data processing or analysis.>",600,,['cde833db73c46ca28f08e35195134441'],"[-0.01389203 -0.00512997  0.01384649 ... -0.00796369 -0.00919359
  0.04158932]"
094a736ba43c4da48c556437f47f88d1,GRAPHRAG_CLAIM_EXTRACTION_MAX_GLEANINGS,"PROPERTY, CONFIGURATION","GRAPHRAG_CLAIM_EXTRACTION_MAX_GLEANINGS is a configuration property that sets the maximum number of gleanings for claim extraction, currently set to 1.>",601,,['cde833db73c46ca28f08e35195134441'],"[ 0.02488891  0.01991099 -0.01890941 ... -0.02865945  0.01289607
  0.02169301]"
563c2af32bb3476299e9b24a646097ab,GRAPHRAG_COMMUNITY_REPORT_MAX_LENGTH,"PROPERTY, CONFIGURATION","GRAPHRAG_COMMUNITY_REPORT_MAX_LENGTH is a configuration property that sets the maximum length for community reports, currently set to 1500.>",602,,['cde833db73c46ca28f08e35195134441'],"[ 0.0239362   0.00687351 -0.00309393 ... -0.02452612 -0.00769084
 -0.00313366]"
d59b49eb94ce442d89907e90c5d3a44e,GRAPHRAG_STORAGE_TYPE,"PROPERTY, CONFIGURATION","GRAPHRAG_STORAGE_TYPE is a configuration property that specifies the type of storage system to use, currently set to file.>",603,,['cde833db73c46ca28f08e35195134441'],"[-0.01211172  0.00873109  0.01976016 ... -0.02102254  0.00712514
  0.00347871]"
8ea7cef407df48098046551e303e1c64,GRAPHRAG_STORAGE_CONNECTION_STRING,"PROPERTY, CONFIGURATION","GRAPHRAG_STORAGE_CONNECTION_STRING is a configuration property that provides the connection string for the storage system, currently set to None.>",604,,['cde833db73c46ca28f08e35195134441'],"[-0.01983607  0.01248337  0.0057385  ... -0.02687811 -0.00460394
  0.01072327]"
186e60d2176547bf84e5bf87bd16bb40,GRAPHRAG_STORAGE_CONTAINER_NAME,"PROPERTY, CONFIGURATION","GRAPHRAG_STORAGE_CONTAINER_NAME is a configuration property that specifies the name of the storage container, currently set to None.>",605,,['cde833db73c46ca28f08e35195134441'],"[-0.00713115 -0.00867243  0.01729077 ... -0.00953116  0.00785873
 -0.0033832 ]"
e65017091c8d4c7daa45b6c8414e0465,GRAPHRAG_STORAGE_BASE_DIR,"PROPERTY, CONFIGURATION","GRAPHRAG_STORAGE_BASE_DIR is a configuration property that indicates the base directory for the storage system, currently set to None.>",606,,['cde833db73c46ca28f08e35195134441'],"[-0.01944299  0.01149253  0.02208981 ...  0.00625728 -0.01253307
  0.00439111]"
a0f326b9597b49dda6563e9208316117,GRAPHRAG_CACHE_TYPE,"PROPERTY, CONFIGURATION","GRAPHRAG_CACHE_TYPE is a configuration property that specifies the type of cache system to use, currently set to file.>",607,,['cde833db73c46ca28f08e35195134441'],"[ 0.00478035  0.01986678  0.00280631 ... -0.02149013 -0.00067702
  0.00529255]"
bff3db70f9af4f2c87a93df48ecbb6bc,GRAPHRAG_CACHE_CONNECTION_STRING,"PROPERTY, CONFIGURATION","GRAPHRAG_CACHE_CONNECTION_STRING is a configuration property that provides the connection string for the cache system, currently set to None.>",608,,['cde833db73c46ca28f08e35195134441'],"[-0.00163672  0.0140556  -0.01890139 ... -0.02492744 -0.01260981
  0.00556497]"
bf91f36307cb43e1ab1e967cb3ba8274,GRAPHRAG_CACHE_CONTAINER_NAME,"PROPERTY, CONFIGURATION","GRAPHRAG_CACHE_CONTAINER_NAME is a configuration property that specifies the name of the cache container, currently set to None.>",609,,['cde833db73c46ca28f08e35195134441'],"[ 0.00845274 -0.00934015 -0.00986483 ... -0.00806769  0.00291179
 -0.00564424]"
cd58a8740ba54d86a77db9bb9544ef0d,GRAPHRAG_CACHE_BASE_DIR,"PROPERTY, CONFIGURATION","GRAPHRAG_CACHE_BASE_DIR is a configuration property that specifies the base directory for the cache system. It is pertinent to note that this setting is currently configured as None, which indicates the absence of a specifically defined base directory for caching purposes. This configuration property plays a crucial role in managing the caching mechanism, allowing for the potential designation of a dedicated directory to optimize cache operations. However, with its current setting of None, no particular directory is being utilized as the base for caching, suggesting that default system behaviors or other fallback mechanisms might be in place for cache management.",610,,['79d4b8574baf3734b60b969b66326b2e' 'cde833db73c46ca28f08e35195134441'],"[ 0.00718535  0.00438414 -0.00925459 ...  0.00595304 -0.03314647
  0.0175118 ]"
e96d3475d43b42a781b297ae7e650afe,GRAPHRAG_REPORTING_TYPE,"PROPERTY, CONFIGURATION","GRAPHRAG_REPORTING_TYPE is a configuration property within the system, designed to determine the specific reporting mechanism that will be utilized. Currently, GRAPHRAG_REPORTING_TYPE is set to 'file', which signifies that all reporting activities will be executed through the creation and management of files. This setting ensures that data and reports are stored and accessed in a structured format, facilitating ease of use and management for users interacting with the system's reporting functionalities.",611,,['79d4b8574baf3734b60b969b66326b2e' 'cde833db73c46ca28f08e35195134441'],"[-0.01668259 -0.0066845   0.0054301  ... -0.01190175 -0.00539763
  0.01608255]"
1ce76a5547854d458878bd445f0ccbd6,GRAPHRAG_REPORTING_CONNECTION_STRING,"PROPERTY, CONFIGURATION","GRAPHRAG_REPORTING_CONNECTION_STRING is a configuration property utilized to specify the connection string for the reporting system. This setting is pivotal for establishing the reporting functionality within the system. Currently, GRAPHRAG_REPORTING_CONNECTION_STRING is set to None, which signifies that no particular connection string has been designated for reporting purposes. This configuration setting remains undefined, suggesting that the reporting system may not be fully operational or integrated until a valid connection string is provided.",612,,['79d4b8574baf3734b60b969b66326b2e' 'cde833db73c46ca28f08e35195134441'],"[-0.00944909 -0.00700062 -0.01864144 ... -0.01284908 -0.02976013
  0.0048928 ]"
11e4325f59394ff1bc89892f79288702,GRAPHRAG_REPORTING_CONTAINER_NAME,"PROPERTY, CONFIGURATION","GRAPHRAG_REPORTING_CONTAINER_NAME is a configuration property utilized for specifying the name of the reporting container within a system. This setting is pivotal for defining the container that will be used for reporting purposes. Currently, GRAPHRAG_REPORTING_CONTAINER_NAME is set to None, which indicates that no specific container name has been designated for reporting. This configuration setting allows for flexibility in managing and organizing reporting functionalities within the system, ensuring that reports can be directed to a specified container when needed.",613,,['79d4b8574baf3734b60b969b66326b2e' 'cde833db73c46ca28f08e35195134441'],"[-0.01039796 -0.01703091 -0.00231728 ...  0.00581439 -0.00464148
 -0.00238637]"
71743537a07c440ea1710a269da8b538,GRAPHRAG_REPORTING_BASE_DIR,"PROPERTY, CONFIGURATION","GRAPHRAG_REPORTING_BASE_DIR is a configuration property utilized within the system, which designates the base directory for the reporting mechanism. Currently, this setting is configured as None, suggesting that no particular base directory has been explicitly defined for the reporting functionalities. This configuration property plays a crucial role in determining the location where reports are generated and stored, and its current setting to None implies that the system may either use a default location or require a directory to be specified on a case-by-case basis for report generation.",614,,['79d4b8574baf3734b60b969b66326b2e' 'cde833db73c46ca28f08e35195134441'],"[-0.01659609 -0.0114142   0.00840769 ...  0.0152554  -0.03282065
  0.01429759]"
1389192ce5464be6b3b5749bc9536709,GRAPHRAG_NODE2VEC_ENABLED,"PROPERTY, CONFIGURATION","GRAPHRAG_NODE2VEC_ENABLED is a configuration property that specifies the status of the Node2Vec algorithm within the system. Currently, GRAPHRAG_NODE2VEC_ENABLED is set to False, indicating that the Node2Vec algorithm is not activated. This setting is crucial for controlling the application of the Node2Vec algorithm in social network analysis, particularly in mapping complex relationships and identifying key influencers within communities related to Motor Control and Drive Systems. When GRAPHRAG_NODE2VEC_ENABLED is set to True, it enables the system to utilize Node2Vec for analyzing the structure and dynamics of specialized professional networks, facilitating the identification of collaboration opportunities and knowledge gaps in the field. However, with the current setting of False, the system is not employing the Node2Vec algorithm for these purposes.",615,,['79d4b8574baf3734b60b969b66326b2e' 'cde833db73c46ca28f08e35195134441'],"[ 0.00338229  0.04099625 -0.01394263 ...  0.00308866  0.01582032
  0.02304614]"
b349041c0be64c62b964ab1234e055e6,GRAPHRAG_NODE2VEC_NUM_WALKS,"PROPERTY, CONFIGURATION","GRAPHRAG_NODE2VEC_NUM_WALKS is a configuration property pivotal in the application of the Node2Vec algorithm within the context of Social Network Analysis. This setting determines the number of walks, or traversals, the algorithm will undertake through the network to learn the structure and relationships. Currently, GRAPHRAG_NODE2VEC_NUM_WALKS is set to 10, signifying that the algorithm will perform 10 walks to capture the network's dynamics effectively. This parameter is crucial for optimizing the learning process and ensuring that the algorithm can adequately model the complex relationships within specialized professional networks, such as those found in the Motor Control and Drive Systems domain. By adjusting GRAPHRAG_NODE2VEC_NUM_WALKS, one can influence the depth and breadth of the network analysis, facilitating the identification of key influencers, collaboration opportunities, and knowledge gaps in the field.",616,,['79d4b8574baf3734b60b969b66326b2e' 'cde833db73c46ca28f08e35195134441'],"[ 0.05270856  0.05428028 -0.01609655 ... -0.00274667 -0.0078875
  0.01786224]"
969e1ea0b1e443a68e9a65dfef91d161,APHRAG_CACHE_CONTAINER_NAME,"CONFIGURATION, SETTING","APHRAG_CACHE_CONTAINER_NAME is a configuration setting that specifies the name of the container for caching purposes. It is currently set to None, indicating that no specific container name has been defined.>",617,,['79d4b8574baf3734b60b969b66326b2e'],"[ 0.0222187  -0.01689125  0.00037089 ... -0.00857037  0.0118158
 -0.00211748]"
8e09e7cfea7d405db8b22ae2f836ccb1,GRAPHRAG_NODE2VEC_WALK_LENGTH,"CONFIGURATION, SETTING","GRAPHRAG_NODE2VEC_WALK_LENGTH is a configuration setting that specifies the length of each walk for the Node2Vec algorithm. It is currently set to 40, indicating that each walk will have a length of 40.>",618,,['79d4b8574baf3734b60b969b66326b2e'],"[ 0.04735333  0.04212745  0.01622707 ... -0.03313577  0.00222001
  0.00888317]"
490583524d394bf79289c5fe34f7dcf1,GRAPHRAG_NODE2VEC_WINDOW_SIZE,"CONFIGURATION, SETTING","GRAPHRAG_NODE2VEC_WINDOW_SIZE is a configuration setting that specifies the window size for the Node2Vec algorithm. It is currently set to 2, indicating that the window size is 2.>",619,,['79d4b8574baf3734b60b969b66326b2e'],"[ 0.04649659  0.01502448  0.02675897 ...  0.00596111 -0.01359183
 -0.00202465]"
d7db38bb599c42cab7066f3fdd282282,GRAPHRAG_NODE2VEC_ITERATIONS,"CONFIGURATION, SETTING","GRAPHRAG_NODE2VEC_ITERATIONS is a configuration setting that specifies the number of iterations for the Node2Vec algorithm. It is currently set to 3, indicating that the algorithm will be run for 3 iterations.>",620,,['79d4b8574baf3734b60b969b66326b2e'],"[ 0.04684104  0.01954418  0.01983853 ... -0.01772908  0.00380061
  0.01640331]"
efd87a59d01e47c8adc02f63ef2c5c3e,GRAPHRAG_NODE2VEC_RANDOM_SEED,"CONFIGURATION, SETTING","GRAPHRAG_NODE2VEC_RANDOM_SEED is a configuration setting that specifies the random seed for the Node2Vec algorithm. It is currently set to 597832, indicating that this number will be used as the random seed.>",621,,['79d4b8574baf3734b60b969b66326b2e'],[0.00977219 0.04313464 0.02461486 ... 0.00792485 0.00741251 0.00771527]
80e3ce3de41e4601823a333e22b7bb3f,GRAPHRAG_SNAPSHOT_GRAPHML,"CONFIGURATION, SETTING","GRAPHRAG_SNAPSHOT_GRAPHML is a configuration setting that specifies whether to take a snapshot in GraphML format. It is currently set to False, indicating that no GraphML snapshot will be taken.>",622,,['79d4b8574baf3734b60b969b66326b2e'],"[ 0.01068474 -0.01589299  0.00613948 ... -0.00769539  0.01290995
  0.04460359]"
50eabc166e8944a49197e79c32f27597,GRAPHRAG_SNAPSHOT_RAW_ENTITIES,"CONFIGURATION, SETTING","GRAPHRAG_SNAPSHOT_RAW_ENTITIES is a configuration setting that specifies whether to take a snapshot of raw entities. It is currently set to False, indicating that no snapshot of raw entities will be taken.>",623,,['79d4b8574baf3734b60b969b66326b2e'],"[-0.00410238  0.01283104  0.01208567 ... -0.00782046  0.01676758
  0.03847864]"
5197a3fb02ef4677abd1900aa87e4efa,GRAPHRAG_SNAPSHOT_TOP_LEVEL_NODES,"CONFIGURATION, SETTING","GRAPHRAG_SNAPSHOT_TOP_LEVEL_NODES is a configuration setting that specifies whether to take a snapshot of top-level nodes. It is currently set to False, indicating that no snapshot of top-level nodes will be taken.>",624,,['79d4b8574baf3734b60b969b66326b2e'],"[ 0.02709848 -0.02820984  0.01467594 ...  0.00845564  0.0193127
  0.02763723]"
887f444240bb474da23cdfb6abf7a998,GRAPHRAG_ASYNC_MODE,"CONFIGURATION, SETTING","GRAPHRAG_ASYNC_MODE is a configuration setting that specifies the asynchronous mode to be used. It is currently set to 'asyncio', indicating that asyncio will be used for asynchronous operations.>",625,,['79d4b8574baf3734b60b969b66326b2e'],"[-0.00734196  0.01695663 -0.03546255 ... -0.01154351 -0.00198521
  0.02362515]"
5d29053f2ce74442aa1855b327ef3bb7,GRAPHRAG_ENCODING_MODEL,"CONFIGURATION, SETTING","GRAPHRAG_ENCODING_MODEL is a configuration property within the domain of Social Network Analysis and Motor Control and Drive Systems, specifically designed to specify the encoding model for graph representation. Currently, it is set to 'cl100k_base', a particular model that will be utilized for encoding purposes. This setting ensures that the structure and dynamics of specialized professional networks can be accurately captured, facilitating the identification of collaboration opportunities and knowledge gaps in the field. The use of 'cl100k_base' as the encoding model under GRAPHRAG_ENCODING_MODEL highlights a preference for a specific level of detail and complexity in graph representation, which is crucial for understanding the intricate relationships within the Motor Control and Drive Systems community.",626,,['1b24101de07b1c195448240237b84b37' '79d4b8574baf3734b60b969b66326b2e'],"[ 0.0249248  -0.00458859  0.02400686 ... -0.01006726 -0.03070423
  0.00924042]"
7e40cd12839a4577a95e33d785147a31,GRAPHRAG_MAX_CLUSTER_SIZE,"CONFIGURATION, SETTING","GRAPHRAG_MAX_CLUSTER_SIZE is a configuration property within the system, specifically set to 10. This setting dictates the maximum size of a cluster in the graph representation, ensuring that no cluster exceeds 10 elements. This limitation is crucial for managing the complexity and scale of clusters within the graph, maintaining an optimal structure for analysis and processing.",627,,['1b24101de07b1c195448240237b84b37' '79d4b8574baf3734b60b969b66326b2e'],"[ 0.02945831  0.01303008  0.02635542 ... -0.01796336  0.01141604
 -0.00935648]"
8fe58de8a04f4f8f807c77fb41829a3a,GRAPHRAG_ENTITY_RESOLUTION_ENABLED,"CONFIGURATION, SETTING","GRAPHRAG_ENTITY_RESOLUTION_ENABLED is a configuration property within the system, currently set to False. This setting indicates that entity resolution is disabled in the graph representation, meaning that the system is not actively resolving or merging entities that may represent the same underlying object or concept. With entity resolution disabled, the graph may contain duplicate nodes or edges that could potentially be merged if this feature were enabled. This configuration setting is crucial for controlling the complexity and accuracy of the graph representation in the context of social network analysis or other graph-based data processing tasks.",628,,['1b24101de07b1c195448240237b84b37' '79d4b8574baf3734b60b969b66326b2e'],"[-0.00886316  0.01394794 -0.0163972  ...  0.00388545 -0.00659697
  0.01772695]"
a9f50861273c4bb697d868a9d049d392,GRAPHRAG_SKIP_WORKFLOWS,"CONFIGURATION, SETTING","GRAPHRAG_SKIP_WORKFLOWS is a configuration property within the system, currently set to None. This setting indicates that no workflows are being skipped in the graph representation, as no specific workflows have been defined to be excluded from the processing. This configuration allows for the control and customization of which workflows are considered in the graph generation process, ensuring comprehensive and tailored graph representations based on the needs of the user or system requirements.",629,,['1b24101de07b1c195448240237b84b37' '79d4b8574baf3734b60b969b66326b2e'],"[ 0.00719411  0.02199857 -0.02334806 ... -0.01744858 -0.00565442
  0.02825605]"
be4820f29fd942b282049fa49697b4ed,GRAPHRAG_UMAP_ENABLED,"CONFIGURATION, SETTING","GRAPHRAG_UMAP_ENABLED is a configuration property within the system, currently set to False. This setting indicates that UMAP (Uniform Manifold Approximation and Projection), a dimension reduction technique used for visualizing high-dimensional data, is disabled in the graph representation. As a result, alternative methods might be employed for data visualization and analysis in the context of Motor Control and Drive Systems domain, potentially impacting the way complex relationships and network structures are understood and interpreted.",630,,['1b24101de07b1c195448240237b84b37' '79d4b8574baf3734b60b969b66326b2e'],"[-0.00427016  0.01518254 -0.02242108 ... -0.03115808 -0.0078326
 -0.02753995]"
6deaefe707f84b3dbda979dea0d095ac,DOCUMENT,"DOCUMENT, DATA","A Document, in the context of the text processing pipeline, serves as the primary container for information, typically representing individual rows in a CSV or standalone .txt files. These documents are crucial as they form the basis for further analysis and processing. They have a versatile relationship with TextUnits, which are smaller, analyzable segments of text. In a standard scenario, a one-to-many relationship exists, where a single Document can be broken down into multiple TextUnits. However, the relationship can also be many-to-many in specific instances, such as when analyzing short documents like Tweets or chat logs, where information from multiple documents might be combined to create a single, more comprehensive TextUnit for analysis. This flexibility in relationship structure allows for a nuanced and detailed examination of text data, catering to various types of documents and analytical needs.",631,,['81f57cf867ea246ad9a6e794ed613375' '85e50a4d70697a2c4420e7a9fc82f22d'],"[ 0.02020228 -0.02392722  0.02224657 ...  0.02847662  0.02571783
  0.01601718]"
d053ea9432a24fb192e8d6aa993b0caa,TEXTUNIT,"TEXT, DATA","A TextUnit represents a segment of text that serves as the fundamental unit for analysis and processing within the pipeline. These chunks, which can be configured in terms of size, overlap, and adherence to data boundaries, are derived from Documents. A common configuration involves setting the CHUNK_BY_COLUMNS parameter to 'id', establishing a 1-to-many relationship between documents and TextUnits, as opposed to a many-to-many relationship. TextUnits are processed individually for various tasks, including graph extraction, entity and relationship extraction, and other analytical operations. Each TextUnit undergoes text-embedding before being passed to the subsequent phase of the pipeline for deeper analysis. This approach ensures that the text is broken down into manageable pieces, facilitating more detailed and efficient processing.",632,,"['10d01d36390b307a63fd5bc97d8682c0' '81f57cf867ea246ad9a6e794ed613375'
 '85e50a4d70697a2c4420e7a9fc82f22d']","[ 0.01970447 -0.02511847  0.01423965 ...  0.00297179  0.01792682
  0.01988439]"
a3e683d294ed42a28d60d09a36cbeb54,ENTITY,"ENTITY, DATA","ENTITY is a significant concept, object, or subject extracted from a text unit during the Graph Extraction phase. These entities represent people, places, events, or other relevant subjects within the text and are characterized by a name, type, and description. They are information elements that hold substantial meaning and are crucial for understanding the structure and dynamics of the text. ENTITY serves as a representation of the significant aspects of the text, enabling a deeper analysis and comprehension of the content.",633,,['81f57cf867ea246ad9a6e794ed613375' '85e50a4d70697a2c4420e7a9fc82f22d'],"[ 0.03209184 -0.00229262 -0.00997919 ...  0.01215595  0.00664604
  0.03115717]"
39887ca8567141d5b857b87a2bca4086,RELATIONSHIP,"RELATIONSHIP, DATA","In the context of Social Network Analysis, a Relationship is a significant connection that exists between two entities. These relationships are meticulously generated from the covariates, reflecting the underlying variables that influence the nature of the connections. They serve as the links that bind entities together, representing the interactions and associations that are present within the network. Relationships are a crucial component extracted during the Graph Extraction phase, playing a pivotal role in shaping the structure of the graph that is being constructed from the analyzed text. This process ensures that the graph accurately reflects the complex dynamics and relationships within the Motor Control and Drive Systems domain, enabling a deeper understanding of the network's structure and facilitating the identification of collaboration opportunities and knowledge gaps.",634,,['81f57cf867ea246ad9a6e794ed613375' '85e50a4d70697a2c4420e7a9fc82f22d'],"[ 0.01848399  0.0306885  -0.0174986  ...  0.00295359 -0.00236384
  0.03213461]"
8df8563ab0394ee9a91b89dea7d59404,COVARIATE,"PROPERTY, DATA","Covariate, a key component in the analysis of textual data, specifically within the realm of claim information, is described as a type of extracted data that encapsulates statements about various entities. These entities might be associated with specific timeframes, adding a temporal dimension to the information. Covariates serve a crucial role in furnishing context and additional details about the entities mentioned in the text, thereby enriching the understanding of the relationships and dynamics within the data. This information is pivotal for anyone seeking to analyze or interpret claim-related documents, as it helps in identifying the nuances and specifics tied to the entities in question.",635,,['493f38f41b89e767fc23d84e1fa5ba20' '85e50a4d70697a2c4420e7a9fc82f22d'],"[ 0.03303963 -0.02327665  0.01374615 ... -0.01333308 -0.00021808
  0.00112448]"
12398f70065143839d812fd42ac4b2e7,COMMUNITY REPORT,"REPORT, DATA","The ""Community Report"" is a comprehensive document that emerges following the creation of entities within the Motor Control and Drive Systems domain. This report is generated through a sophisticated process of hierarchical community detection, which meticulously analyzes and categorizes the entities based on their relationships and influence within the community. Each ""Community Report"" offers detailed insights and summaries tailored to every community within the hierarchical structure, providing a deep understanding of the dynamics, collaboration opportunities, and knowledge gaps present in the specialized professional network. This enables stakeholders to identify key influencers, potential collaborators, and areas for further exploration, enhancing the overall connectivity and productivity within the Motor Control and Drive Systems domain.",636,,['493f38f41b89e767fc23d84e1fa5ba20' '85e50a4d70697a2c4420e7a9fc82f22d'],"[-0.00066703  0.03386802 -0.02968431 ... -0.00536231 -0.0051169
 -0.01125374]"
74d43d20f251441baf8e3db64fedca43,DEFAULT CONFIGURATION WORKFLOW,"PROCESS, WORKFLOW","The Default Configuration Workflow is a series of steps that transform text documents into the GraphRAG Knowledge Model. It includes major phases such as Network Visualization, Document Processing, Community Summarization, Graph Augmentation, Graph Extraction, and Compose TextUnits.",637,,['493f38f41b89e767fc23d84e1fa5ba20'],"[-0.0026826   0.00699552 -0.00231653 ... -0.03322248 -0.00542645
  0.03417054]"
1b7a22f76f7741e8b140bdc3d8856d76,NETWORK VISUALIZATION,"PHASE, PROCESS",Network Visualization is a phase in the workflow where the network of entities and their relationships are visualized in a graph format.,638,,['493f38f41b89e767fc23d84e1fa5ba20'],"[ 0.01832123  0.01678598 -0.02183779 ... -0.00874021  0.0213539
  0.03940259]"
b823ba1bfe944fa9887edd8faf8a5f17,DOCUMENT PROCESSING,"PHASE, PROCESS","Document Processing is a critical phase in the workflow dedicated to transforming and analyzing documents to fit into the GraphRAG Knowledge Model. This phase is responsible for creating the Documents table for the knowledge model through a series of steps. These steps include augmenting documents to enrich their content, linking them to TextUnits for detailed analysis, and calculating the average embeddings to represent the documents numerically. This comprehensive process ensures that documents are thoroughly processed and prepared for further analysis within the GraphRAG Knowledge Model.",639,,"['3e292d936b7efa377ba9530456cfd888' '493f38f41b89e767fc23d84e1fa5ba20'
 '827fd80da359cf05b091c24e465dd05d']","[ 0.02910774 -0.02252546 -0.00324332 ... -0.04036996 -0.03322043
  0.06267905]"
d0bfb473fdc64643954cdb4675e2f389,COMMUNITY SUMMARIZATION,"PHASE, PROCESS","Community Summarization is a comprehensive process that plays a crucial role in understanding the structure and dynamics of specialized professional networks, such as those found in the Motor Control and Drive Systems domain. This process involves the generation and summarization of community reports, embedding communities, and emitting community tables, all of which aim to provide a high-level understanding of the graph at various levels of granularity. By summarizing the characteristics and insights of a community, often derived from social network analysis or community detection algorithms, Community Summarization enables the identification of key influencers, collaboration opportunities, and knowledge gaps within the field. This phase in the workflow ensures that the insights and reports generated are insightful and useful for further analysis and decision-making.",640,,"['493f38f41b89e767fc23d84e1fa5ba20' '5b2968b8f1c891d47ecbe641c3391663'
 '6f92ce3fcd05dd5697ded83586f7bc08']","[ 0.02949923  0.02722562 -0.01915789 ... -0.02013502 -0.02913452
  0.02281952]"
a4db1b2a9c3e4d2d838725f8166c36b4,GRAPH AUGMENTATION,"PHASE, PROCESS","Graph Augmentation is a critical phase in the workflow of Social Network Analysis, particularly within specialized professional networks such as the Motor Control and Drive Systems domain. This process follows the extraction of entities and relationships and involves enhancing the graph with additional information and relationships, thereby enriching the understanding of the community structure. Through Graph Augmentation, the graph is not only expanded but also deepened, allowing for a more comprehensive analysis of the dynamics and connections within the network. This phase is essential for identifying key influencers, mapping complex relationships, and uncovering collaboration opportunities and knowledge gaps in the field.",641,,['493f38f41b89e767fc23d84e1fa5ba20' 'd44248ff7b7bfd969a7208eb3d6e2a78'],"[ 0.01874137  0.03866932 -0.02056978 ... -0.02384061  0.01162876
  0.02431455]"
8dae140578c841ae9373cbc607c4a6e6,GRAPH EXTRACTION,"PHASE, PROCESS","Graph Extraction is a critical phase in the pipeline of text analysis, where each TextUnit undergoes a meticulous process to extract graph primitives. This phase employs sophisticated methods, including the use of entity_extract and claim_extract verbs, to identify and isolate key components such as Entities, Relationships, and Claims from the raw text. The objective is to transform the textual data into a structured format, resulting in the creation of a subgraph for every TextUnit. These subgraphs comprehensively list the entities and relationships discovered within the text, facilitating a deeper understanding of the text's structure and dynamics. Graph Extraction is an essential step in the workflow, enabling the analysis of complex relationships and the identification of key influencers within the text's context.",642,,"['10d01d36390b307a63fd5bc97d8682c0' '493f38f41b89e767fc23d84e1fa5ba20'
 '81f57cf867ea246ad9a6e794ed613375']","[ 0.01395623  0.00067995 -0.03859127 ... -0.01040564  0.00495947
  0.04607011]"
b215cc33cf40434f87f284ff8f3506a4,COMPOSE TEXTUNITS,"PHASE, PROCESS","Compose TextUnits is the first phase in the workflow where input documents are transformed into TextUnits, which are chunks of text used for graph analysis.",643,,['493f38f41b89e767fc23d84e1fa5ba20'],"[ 0.0124034  -0.02832254  0.01716537 ... -0.00892822  0.02562915
  0.00099475]"
c1ff9d8e1b8745d6860c34ce26122d79,UMAP DOCUMENTS,"PROPERTY, INFORMATION","Umap Documents is a sophisticated process that specializes in mapping documents into a lower-dimensional space, primarily a 2D representation, for the purpose of visualization and analysis. This process leverages UMAP (Uniform Manifold Approximation and Projection) dimensionality reduction technique to generate a 2D representation that effectively visualizes the intricate relationships between documents. Umap Documents enables users to discern patterns, clusters, and connections that might not be apparent in high-dimensional data, making it an invaluable tool for understanding the structure and dynamics of document sets in various domains.",644,,['493f38f41b89e767fc23d84e1fa5ba20' '56506e2d064c0732efa3cf418057edfd'],"[-0.00061194 -0.00735994  0.02087923 ... -0.03205721 -0.00431122
  0.0084205 ]"
9d1e6ca9ae8e4e068fb74631a633b20b,UMAP ENTITIES,"PROPERTY, INFORMATION","Umap Entities is a sophisticated process that specializes in mapping complex entities into a lower-dimensional space, specifically a 2D representation, to facilitate both visualization and analysis. This method employs UMAP (Uniform Manifold Approximation and Projection) dimensionality reduction, a cutting-edge technique that generates a concise yet comprehensive view of the relationships between entities. By transforming high-dimensional data into a 2D format, Umap Entities enables users to easily identify patterns, clusters, and connections that might not be apparent in the original data set. This process is invaluable for understanding the structure and dynamics of specialized professional networks, identifying collaboration opportunities, and pinpointing knowledge gaps in fields such as Motor Control and Drive Systems. Through Umap Entities, entities can be visualized in a way that highlights their interconnections, making it an essential tool for Social Network Analysis.",645,,['493f38f41b89e767fc23d84e1fa5ba20' '56506e2d064c0732efa3cf418057edfd'],"[ 0.01239346  0.02391637  0.02143503 ... -0.01909104 -0.016448
  0.01837475]"
1d7b0deca7674777bf76c163ac065845,NODES TABLE,"PROPERTY, INFORMATION","The Nodes Table contains information about the nodes in the graph, including their layout and relationships.",646,,['493f38f41b89e767fc23d84e1fa5ba20'],"[ 0.00094279 -0.01042259 -0.01056485 ...  0.02619618  0.02342848
  0.01239375]"
03afe9988f864c9fa501bfbf043f74c0,LINK TO TEXTUNITS,"PROPERTY, INFORMATION","Link to TextUnits is a pivotal process in Document Processing that facilitates the connection between documents and their constituent text units. This process is instrumental in establishing a clear relationship between documents and text-units, enabling a detailed analysis and deeper understanding of document structure. As a property in the workflow, Link to TextUnits plays a crucial role in graph representation, ensuring that nodes are accurately connected to their corresponding TextUnits. This process is executed after the creation of text-units in the initial phase of the workflow, ensuring that each document is seamlessly linked to its relevant text components. Through this process, the intricacies of document composition and structure can be thoroughly explored, making it an essential component in the analysis and processing of textual data.",647,,"['3e292d936b7efa377ba9530456cfd888' '493f38f41b89e767fc23d84e1fa5ba20'
 '827fd80da359cf05b091c24e465dd05d']","[ 0.00115076 -0.01654582  0.0182696  ...  0.00487847  0.03232276
  0.02331613]"
4084f614af494fa8ab73095fb5b6b07b,DOCUMENT EMBEDDING,"PROPERTY, INFORMATION","Document Embedding is a sophisticated process and property that transforms documents into numerical vectors for analysis and comparison. This transformation is achieved by averaging the embeddings of document slices, with weights determined by the token-count. The resulting vector representation facilitates a deeper understanding of the relationships between documents, making it an invaluable tool for network visualization and analysis. This method enables the identification of patterns, similarities, and connections within a set of documents, enhancing the ability to uncover insights and knowledge gaps in specialized professional networks such as the Motor Control and Drive Systems domain. By leveraging Document Embedding, experts can more effectively identify collaboration opportunities and key influencers within their community, thereby fostering innovation and knowledge sharing.",648,,['493f38f41b89e767fc23d84e1fa5ba20' '827fd80da359cf05b091c24e465dd05d'],"[-5.10770036e-03  6.72405658e-05  1.58221927e-02 ...  3.90778587e-04
 -3.18276919e-02  2.40845401e-02]"
3ce25564af6e47f390a0b16b6f9433a1,DOCUMENT GRAPH CREATION,"PROPERTY, INFORMATION",Document Graph Creation is a process that creates a graph representation of the documents and their relationships.,649,,['493f38f41b89e767fc23d84e1fa5ba20'],"[ 0.00279852 -0.01194973  0.00506457 ... -0.0520405   0.01381458
  0.05500954]"
78213664d0eb45d1a9239ba4b85b10f7,DOCUMENT TABLES,"PROPERTY, INFORMATION","Document Tables contain information about the documents, including metadata and analysis results.",650,,['493f38f41b89e767fc23d84e1fa5ba20'],"[-0.00317046 -0.04400606  0.03299627 ...  0.00510892  0.0142016
  0.0416687 ]"
1226e4a4077b4b3a970db4d2509b590c,COMMUNITY EMBEDDING,"PROPERTY, INFORMATION","Community Embedding is a sophisticated process that transforms the intricate structure of communities into a lower-dimensional vector space, enabling both visualization and in-depth analysis. This representation is achieved by generating text embeddings from various components of community data, including the community report, its summary, and the title, to create a comprehensive vector representation. This vector space representation is not only useful for visualizing community dynamics but also serves as a powerful tool for machine learning tasks, such as clustering and classification, allowing for the identification of patterns and similarities among communities. Community Embedding, therefore, acts as a bridge between the complex social network data and the analytical capabilities of machine learning algorithms, facilitating a deeper understanding of community relationships and dynamics.",651,,"['3e292d936b7efa377ba9530456cfd888' '493f38f41b89e767fc23d84e1fa5ba20'
 '6f92ce3fcd05dd5697ded83586f7bc08']","[-1.60078853e-02 -4.16913349e-03 -2.81644687e-02 ... -4.49572726e-05
 -2.59168409e-02  2.30601244e-02]"
b4c7de7a824a4a71b9f52193d2f1a10d,COMMUNITY TABLES,"PROPERTY, INFORMATION","Community Tables are comprehensive data structures designed to systematically organize and present information about various communities. These tables encompass a wide range of details, including the identities of community members, the relationships that exist among them, and the distinct attributes that define each community. By consolidating this information, Community Tables serve as a valuable resource for understanding the structure, dynamics, and characteristics of different communities, thereby facilitating the identification of collaboration opportunities and knowledge gaps within the field.",652,,['493f38f41b89e767fc23d84e1fa5ba20' '6f92ce3fcd05dd5697ded83586f7bc08'],"[ 0.00973577 -0.01752704 -0.02056259 ...  0.0053846  -0.02006604
  0.01738994]"
b609f1939dae4c7383c7d199bb3c7dc3,GRAPH EMBEDDING,"PROPERTY, INFORMATION","Graph Embedding is a sophisticated technique pivotal in the domain of graph analysis and visualization. It serves as a critical step in the process, particularly as a subprocess of Phase 3: Graph Augmentation. The method involves the conversion of a graph into a vector space, where nodes are transformed into points and edges into distances between these points. This vector representation is generated using the Node2Vec algorithm, enabling a deeper understanding of the graph's implicit structure. The vector-space created not only facilitates various graph analysis tasks but also provides an additional dimension for searching related concepts during the query phase, enhancing the overall efficiency and effectiveness of graph-related operations.",653,,"['493f38f41b89e767fc23d84e1fa5ba20' '5b2968b8f1c891d47ecbe641c3391663'
 '6f92ce3fcd05dd5697ded83586f7bc08' 'a6bcb4514cb6de67e3d74ad0ea62452d']","[ 0.00441331  0.01229616  0.00327874 ... -0.00806414  0.00653299
  0.00023131]"
aeee2f443dfb4e3ea80af6ae1d9197ce,AUGMENTED GRAPH TABLES,"PROPERTY, INFORMATION","Augmented Graph Tables are sophisticated data structures designed to store comprehensive information about graphs. These tables not only hold the basic graph data but also incorporate enhanced details such as additional metadata and analytical results post augmentation. This augmentation process enriches the tables with extra entities and relationships, making them a valuable resource for in-depth graph analysis and understanding.",654,,['493f38f41b89e767fc23d84e1fa5ba20' '6f92ce3fcd05dd5697ded83586f7bc08'],"[ 0.01407727 -0.01019303  0.02251788 ... -0.01234718  0.03403205
  0.01223896]"
8c46d37bc26e4d4dbd37d6ee26867bc6,ENTITY & RELATIONSHIP EXTRACTION,"PROPERTY, INFORMATION","Entity & Relationship Extraction is a sophisticated process primarily utilized in the domains of natural language processing and information extraction. This process excels at identifying and mapping out entities, along with the relationships that exist between them, from various text-based or data sources. By doing so, it enables a deeper understanding of the structure and dynamics within specialized professional networks, such as those found in the Motor Control and Drive Systems domain. This understanding is crucial for identifying key influencers, collaboration opportunities, and knowledge gaps within the field. The process of Entity & Relationship Extraction is not limited to text analysis but can be applied to a wide range of data sources, making it a versatile tool for data analysis and information retrieval.",655,,['493f38f41b89e767fc23d84e1fa5ba20' '6f92ce3fcd05dd5697ded83586f7bc08'],"[-0.01214372  0.03097626 -0.03804383 ... -0.00948438 -0.02218228
  0.02482652]"
58a8fa7f29e347bdb9689b70b065a779,ENTITY & RELATIONSHIP SUMMARIZATION,"PROPERTY, INFORMATION","Entity & Relationship Summarization is a process that consolidates and provides a concise overview of the key entities and their interactions identified within a dataset or text. This method is crucial for understanding the structure and dynamics of specialized professional networks, enabling the identification of collaboration opportunities and knowledge gaps in fields such as Motor Control and Drive Systems. By mapping complex relationships and pinpointing key influencers, Entity & Relationship Summarization facilitates a deeper comprehension of the network's composition and facilitates informed decision-making.",656,,['493f38f41b89e767fc23d84e1fa5ba20' '6f92ce3fcd05dd5697ded83586f7bc08'],"[ 0.02568569  0.03614802  0.01002787 ...  0.01450139 -0.00999692
  0.02633969]"
fae3fe31deb141ab93143ac411f1eaaa,ENTITY RESOLUTION,"PROPERTY, INFORMATION","Entity Resolution is a critical process in data management that identifies and merges duplicate or similar entities in a dataset, enhancing data quality and consistency. This process is designed to resolve entities that represent the same real-world object, concept, or entity but may have different names. Initially, the implementation of Entity Resolution was destructive, merging entities into a single entity and updating their relationships. However, future implementations aim to be non-destructive, allowing end-users the flexibility to undo indexing-side resolutions and add their own resolutions. This optional process in the pipeline takes a conservative, non-destructive approach to ensure that no valuable information is lost, making it a robust solution for maintaining data integrity.",657,,"['10d01d36390b307a63fd5bc97d8682c0' '493f38f41b89e767fc23d84e1fa5ba20'
 '6f92ce3fcd05dd5697ded83586f7bc08' 'd44248ff7b7bfd969a7208eb3d6e2a78']","[-0.00980225  0.02925442 -0.01194691 ...  0.01120525 -0.02120723
  0.05005188]"
a2cb46c226b94831853a5d28c5d94b0a,GRAPH TABLES,"PROPERTY, INFORMATION","Graph Tables are sophisticated data structures designed to represent graph data comprehensively. They encapsulate a wealth of information, including nodes, edges, and various attributes, making them invaluable tools for graph analysis and visualization. By storing details about the graph's composition and properties, Graph Tables enable a deeper understanding of the relationships and dynamics within the graph, facilitating more effective analysis and interpretation of complex networks.",658,,['493f38f41b89e767fc23d84e1fa5ba20' '6f92ce3fcd05dd5697ded83586f7bc08'],"[ 0.01682704 -0.02189903  0.01587352 ...  0.020355    0.01748113
  0.00942908]"
d3511ecd27cd4166bdb39e757e275300,DOCUMENTS,"PROPERTY, INFORMATION","Documents, in the context of the workflow and knowledge model, are individual units of text or data that undergo transformation and analysis. These documents serve as the primary input in the workflow, where they are processed and structured to extract valuable information. The Documents table, a critical data structure created during the Document Processing phase, encapsulates metadata and content details about the documents, facilitating their management and analysis within the knowledge model. This table is essential for maintaining the integrity and accessibility of the documents throughout the workflow, ensuring that all relevant data is captured and utilized effectively.",659,,"['493f38f41b89e767fc23d84e1fa5ba20' '6f92ce3fcd05dd5697ded83586f7bc08'
 '827fd80da359cf05b091c24e465dd05d']","[ 0.0263028  -0.03398126  0.01476816 ...  0.00311457 -0.01980647
  0.06643294]"
de3b561f5cce4c83bccb39180e362c97,TEXT UNITS,"PROPERTY, INFORMATION","Text Units represent the fundamental segments of text that are utilized for analysis and processing within text analysis workflows. These units are typically extracted from documents and serve as the foundational elements for subsequent analysis or information extraction processes. As the core components in text analysis, Text Units play a crucial role in enabling detailed examination and manipulation of textual data.",660,,['493f38f41b89e767fc23d84e1fa5ba20' '6f92ce3fcd05dd5697ded83586f7bc08'],"[ 0.01415679 -0.03206355 -0.00586995 ...  0.02766298  0.00450892
  0.00354132]"
5bfefaa0fce04002851733337bed714c,EMBED,"PROPERTY, INFORMATION","Embed is a versatile process primarily utilized in the domains of machine learning and natural language processing. It transforms information or data into a numerical or vector representation, facilitating analysis and comparison. This conversion enables the handling of complex data types, making it an essential tool for extracting meaningful insights from various data sources.",661,,['493f38f41b89e767fc23d84e1fa5ba20' '6f92ce3fcd05dd5697ded83586f7bc08'],"[-0.03328312  0.00408975 -0.03652072 ... -0.00610588 -0.0148302
 -0.00150524]"
b5fed5609f154df58c6a9f74e55fc0ba,DATAFLOW OVERVIEW,"PROPERTY, INFORMATION","The Dataflow Overview is a comprehensive depiction of the flow of data and processes within a system or workflow, spanning from the initial input to the final output. It serves as a valuable tool for understanding the sequence of operations and transformations that data undergoes as it moves through the system. This overview is crucial for gaining insights into the dynamics of data processing, identifying potential bottlenecks, and optimizing the efficiency of the workflow. By visualizing the dataflow, stakeholders can better comprehend how data is manipulated and how various processes interact, enabling them to make informed decisions regarding system improvements and data management strategies.",662,,['493f38f41b89e767fc23d84e1fa5ba20' '6f92ce3fcd05dd5697ded83586f7bc08'],"[-0.00491618  0.01811394 -0.00870208 ... -0.00136001 -0.00196533
  0.0389978 ]"
91ae5251eaab4c08afe6cd4cbefcaa6b,PHASE 1: COMPOSE TEXTUNITS,"PROCESS, ANALYSIS","Phase 1: Compose TextUnits is the initial step in a workflow where input documents are transformed into TextUnits, which are chunks of text used for graph extraction techniques and as source references for extracted knowledge items.",663,,['6f92ce3fcd05dd5697ded83586f7bc08'],"[ 0.02295233 -0.02379213  0.00817604 ... -0.01522244  0.02066954
 -0.00158087]"
bbdd53a15e99452a9deff05d1de2d965,CLAIM,"CLAIM, INFORMATION_STATEMENT",Claims are statements or assertions extracted from the text during the Graph Extraction phase. They represent the assertions made within the text and are a component of the graph being built.,664,,['81f57cf867ea246ad9a6e794ed613375'],"[-0.00279239 -0.0153278  -0.01158817 ... -0.0061147   0.02759316
  0.00406229]"
532bf54d5a924ff48aee254970efb914,GRAPH SUMMARIZATION,"PROCESS, INFORMATION SUMMARIZATION","Graph Summarization is a process that consolidates multiple subgraphs into a single graph by merging entities and relationships with the same name and type, creating arrays of their descriptions for a comprehensive view.",665,,['10d01d36390b307a63fd5bc97d8682c0'],"[ 0.03815535  0.00827301  0.00076487 ... -0.0055984   0.01513562
  0.04594782]"
2489232bd2bb492babe00617e7290282,COVARIATES,"ARTIFACT, DATA","Covariates, the primary artifacts emitted from the Claim Extraction & Emission process, are significant components within the domain of analysis. These entities represent positive factual statements that are meticulously evaluated and come with defined time-bounds, ensuring their relevance and accuracy within specific periods. Despite a slight variation in the descriptions provided, it is clear that Covariates are the outcome of a specialized extraction process, highlighting their importance in maintaining the integrity and temporal relevance of claims within the field.",666,,['a6bcb4514cb6de67e3d74ad0ea62452d' 'd44248ff7b7bfd969a7208eb3d6e2a78'],"[ 0.04145728  0.00244157 -0.00125123 ... -0.02859515 -0.00435773
  0.028808  ]"
d2ed972353af4d1db74702638bfdbb58,CLAIM EXTRACTION & EMISSION,"PROCESS, WORKFLOW","Claim Extraction & Emission is a process where claims are extracted from the source TextUnits. These claims are positive factual statements with an evaluated status and time-bounds, and they are emitted as a primary artifact called Covariates.",667,,['a6bcb4514cb6de67e3d74ad0ea62452d'],"[-0.00579311 -0.00797549 -0.01713461 ... -0.02148885  0.00958886
  0.01782023]"
575befc8d64c47eb95af8b1096e02963,PHASE 3: GRAPH AUGMENTATION,"PHASE, PROCESS",Phase 3: Graph Augmentation is a process where the graph of entities and relationships is augmented with additional information to understand their community structure. This is done through Community Detection and Graph Embedding.,668,,['a6bcb4514cb6de67e3d74ad0ea62452d'],"[ 0.03244123  0.01927344 -0.02716157 ... -0.02991261  0.0027894
  0.03036407]"
d6e6366617e04b0ba6732fd1d2d76429,GRAPH TABLES EMISSION,"SUBPROCESS, DATA EMISSION","Graph Tables Emission is a critical subprocess that falls under Phase 3: Graph Augmentation. This process is characterized by the emission of the final entities and relationships in a tabular format. It is initiated once the text fields of these entities and relationships have been text-embedded, marking the culmination of the graph augmentation steps. This subprocess ensures that the enriched data, post-augmentation, is systematically organized and presented in a structured manner, facilitating easier analysis and understanding of the network's dynamics.",669,,['5b2968b8f1c891d47ecbe641c3391663' 'a6bcb4514cb6de67e3d74ad0ea62452d'],"[ 0.00691098  0.00176206  0.0215923  ... -0.01394505  0.00792441
  0.01387768]"
b4c4354c8edb40db984942799fe0c8b1,NODE2VEC ALGORITHM,"ALGORITHM, TOOL","Node2Vec is an algorithm used for generating vector representations of nodes in a graph, facilitating the understanding of the graph's structure and enabling vector-space search for related concepts.",670,,['5b2968b8f1c891d47ecbe641c3391663'],"[-0.00121261  0.01962008 -0.00509062 ...  0.02451744  0.03741652
  0.005452  ]"
170507a64973429f818067b80506d428,COMMUNITY TABLES EMISSION,"ACTION, PROCESS",Community Tables Emission is the process of generating and outputting the Communities and CommunityReports tables as part of the workflow.,671,,['3e292d936b7efa377ba9530456cfd888'],"[-0.03212511  0.01693691 -0.02857877 ... -0.02118739 -0.01885845
  0.02367816]"
fd9b298e6aea4685bbb2064b05fcda79,AUGMENT,"ACTION, PROCESS","Augment, a crucial process in the Document Processing domain, specializes in enhancing documents by incorporating supplementary information. This augmentation enriches the content and context of the documents, making them more informative and valuable. Specifically, when the workflow is processing CSV data, Augment adds extra fields to the Documents output. These additional fields are designed to align with the existing columns on the incoming CSV tables, thereby expanding the dataset without compromising its integrity. Through this process, Augment facilitates a more comprehensive understanding of the information contained within the documents, enabling better analysis and decision-making.",672,,['3e292d936b7efa377ba9530456cfd888' '827fd80da359cf05b091c24e465dd05d'],"[-4.84526483e-03 -7.55997375e-04 -7.78321992e-05 ... -3.68739255e-02
  3.41497064e-02  3.85421477e-02]"
eeecb159cc8a4c8989f8da0f3df09f2a,AVG. EMBEDDING,"PROPERTY, MEASUREMENT","Avg. Embedding is a critical property calculated during Document Processing, which encapsulates the essence of a document through a vector representation. This representation is derived by averaging the embeddings of various slices within the document, providing a comprehensive summary of its content. The Avg. Embedding algorithm facilitates the analysis of implicit relationships between documents, making it an invaluable tool for network visualization and other analytical purposes. By generating a vector that reflects the document's characteristics, Avg. Embedding enables a deeper understanding of document interconnectivity and supports the identification of patterns and trends within document networks.",673,,['3e292d936b7efa377ba9530456cfd888' '827fd80da359cf05b091c24e465dd05d'],"[ 0.00092081  0.02239124  0.00012633 ... -0.00346126 -0.03820067
  0.02564753]"
70f22b1d7336492dbade94b8edefe457,DOCUMENT TABLE EMISSION,"ACTION, PROCESS","Document Table Emission represents a critical phase in the document processing workflow. It involves the emission of the Documents table into the knowledge model, enabling the document data to be readily accessible for subsequent processing or analysis. This process is pivotal as it facilitates the generation and output of the Documents table, ensuring that the information contained within is prepared and structured for further utilization. Through Document Table Emission, the intricacies of document data are transformed into a format that supports advanced analysis and integration into broader knowledge systems.",674,,['3e292d936b7efa377ba9530456cfd888' '827fd80da359cf05b091c24e465dd05d'],"[-0.00615723 -0.01589735  0.03513852 ...  0.00084998 -0.029093
  0.04829107]"
66e098dc431146e19fc4bc2ea37efbd9,AUGMENT WITH COLUMNS (CSV ONLY),"ACTION, PROCESS","Augment with Columns (CSV Only) is a specialized function designed for enhancing the Document Processing workflow, particularly when handling CSV data. This feature enables the addition of extra fields to the Documents output, leveraging the information present in the incoming CSV tables. Configuration is necessary to utilize this function effectively, ensuring that the added fields are relevant and useful. The process is exclusive to CSV data, making it a valuable tool for enriching document outputs with additional context and detail.",675,,['3e292d936b7efa377ba9530456cfd888' '827fd80da359cf05b091c24e465dd05d'],"[ 0.02840712  0.00103534  0.01642513 ... -0.03909008  0.02731007
  0.03456442]"
932e213c57134098a07073febd51dcc2,COMMUNITIES,"TABLE, DATA STRUCTURE","The Communities table is a data structure that holds information about various communities, likely in the context of a knowledge model or database.",676,,['827fd80da359cf05b091c24e465dd05d'],"[-0.01241977 -0.03271218 -0.0486041  ...  0.01997527 -0.01512978
  0.01717191]"
9593428ad36746ae8af6d8ce639834ef,COMMUNITYREPORTS,"TABLE, DATA STRUCTURE","The CommunityReports table is a data structure that contains reports or data related to communities, possibly including statistics, summaries, or other relevant information.",677,,['827fd80da359cf05b091c24e465dd05d'],"[-0.03626738 -0.01505438 -0.03553561 ...  0.03010352  0.01217227
  0.00414834]"
1bcaeb58479d42a6963a073c09f3f397,DOCUMENTS TABLE EMISSION,"FUNCTION, PROCESS","Documents Table Emission is a critical function or process that involves integrating and emitting the Documents table into the knowledge model. This process makes the document data accessible for subsequent processing or analysis, enabling the representation of documents within the model. By facilitating the incorporation of document data, Documents Table Emission plays a pivotal role in ensuring that the knowledge model is comprehensive and can support various analytical tasks.",678,,['56506e2d064c0732efa3cf418057edfd' '827fd80da359cf05b091c24e465dd05d'],"[-0.0224732  -0.01874665  0.03089051 ... -0.00012107 -0.03567338
  0.04348916]"
1ef0c1c59ce946668ccf1a6a4f5ab7cc,PHASE 6: NETWORK VISUALIZATION,"PHASE, PROCESS","Phase 6: Network Visualization is a critical phase in the workflow dedicated to the visualization of high-dimensional vector spaces within the context of existing graphs. This phase focuses on transforming complex relationships between documents and entities into a comprehensible network format, thereby facilitating a deeper understanding of the connections and dynamics within the data. Through this phase, the visualization of intricate networks becomes accessible, enabling users to discern patterns, clusters, and key influencers that might not be evident in raw data. This process is essential for identifying collaboration opportunities, knowledge gaps, and the structure of specialized professional networks, particularly in domains like Motor Control and Drive Systems, where mapping complex relationships is crucial for innovation and advancement.",679,,['56506e2d064c0732efa3cf418057edfd' '827fd80da359cf05b091c24e465dd05d'],"[ 0.02790566  0.00294778  0.00443225 ... -0.00400063 -0.00461579
 -0.00117133]"
d734746e3d6146f780af91827e578dfd,ENTITY-RELATIONSHIP GRAPH,"CONCEPT, GRAPH","The Entity-Relationship graph is a logical graph that represents the relationships between entities and their attributes, providing a structured view of the data.",680,,['56506e2d064c0732efa3cf418057edfd'],"[ 0.00877665  0.02553079 -0.01015061 ...  0.0289281   0.00296013
  0.01753647]"
21ed913271614cbeb1b754cdbbef13af,DOCUMENT GRAPH,"CONCEPT, GRAPH","The Document graph is a logical graph that represents the relationships between documents, providing a structured view of the document space.",681,,['56506e2d064c0732efa3cf418057edfd'],"[ 0.02053192 -0.00762332  0.03642841 ...  0.01310451  0.01452991
  0.04048118]"
1505dfebbfb04652b0ba57de1a251d67,NODES TABLE EMISSION,"ACTION, PROCESS","Nodes Table Emission is the process of emitting a table of nodes, which includes information about whether the node is a document or an entity, and the UMAP coordinates for visualization.",682,,['56506e2d064c0732efa3cf418057edfd'],"[-0.02467488 -0.02087508  0.00447729 ... -0.00964969 -0.01186892
  0.02829891]"
907ec65076e5494a8631efffb81b3178,NETWORK VISUALIZATION WORKFLOWS,"CONCEPT, PROCESS","Network Visualization Workflows are the processes and steps taken to visualize high-dimensional vector spaces within graphs, enabling a 2D representation of the graph and the understanding of relationships between nodes.",683,,['56506e2d064c0732efa3cf418057edfd'],"[ 0.00804384  0.01135853  0.00017354 ... -0.01221021  0.02884763
  0.03746941]"
2dc7f6b230db452190a09643ca3d5ec0,DISCRIMINATOR,"PROPERTY, CLASSIFICATION",The Discriminator is a property that classifies whether a node represents a document or an entity in a data structure. It is a binary indicator that helps in distinguishing between different types of nodes within a system.,684,,['2011f03f21e526cf9277c27bf3e68242'],"[-0.02800214 -0.00658226 -0.01120387 ...  0.03210783 -0.0279235
  0.01030632]"
c20ecfc93b3a4875ade5c92cfe4b94a1,UMAP COORDINATES,"PROPERTY, LOCATION","UMAP (Uniform Manifold Approximation and Projection) Coordinates are a set of values that represent the location of a node in a reduced dimensional space. They are used for visualizing high-dimensional data in a lower-dimensional format, typically for the purpose of data exploration and machine learning tasks.",685,,['2011f03f21e526cf9277c27bf3e68242'],"[ 0.00644051 -0.00370327  0.01574588 ... -0.04020264 -0.00704133
 -0.02482489]"
4bc7dc91ede345dfb63d7d4f7ac3554f,GRAPHRAG INDEXER CLI,"SOFTWARE, TOOL","The GraphRAG Indexer CLI is a command-line interface tool that enables no-code usage of the GraphRAG Indexer, facilitating the indexing process for data projects without the need for programming. It provides various options for configuring the indexing process.>",686,,['f239de6498e0f471bf418974c00f1e36'],"[ 0.00406857  0.01454906  0.00473999 ... -0.03257774  0.0030674
  0.00510116]"
0b2b815c9f834aaaac0c341097def9ba,CLI ARGUMENTS,"PROPERTY, CONFIGURATION","CLI Arguments are parameters that can be passed to the GraphRAG Indexer CLI to customize its behavior. These include options for verbosity, specifying the root directory, initializing the project, resuming a previous run, custom configuration, progress reporting, and output formats.>",687,,['f239de6498e0f471bf418974c00f1e36'],"[ 0.03036396  0.00103517  0.01758033 ... -0.03412589 -0.02356859
  0.00986656]"
424ae71c56024094a02e6fd9bfcfbb04,VERBOSE,"PROPERTY, CONFIGURATION","The verbose argument, when added, increases the amount of logging information during the execution of the GraphRAG Indexer CLI.>",688,,['f239de6498e0f471bf418974c00f1e36'],"[ 0.02918899  0.02259289  0.00479193 ... -0.04097407 -0.00841516
  0.02340145]"
400d10f2ee1d49be9a66efa34dada0e6,INIT,"PROPERTY, CONFIGURATION",The init argument initializes the data project directory at the specified root with bootstrap configuration and prompt-overrides.>,689,,['f239de6498e0f471bf418974c00f1e36'],"[ 0.02193164  0.00788826  0.01971028 ... -0.00815522 -0.00396624
  0.01277791]"
91deb9f152264e958d106d481ff2e1ee,RESUME,"PROPERTY, CONFIGURATION","The resume argument, when specified with a timestamp, allows the pipeline to resume a prior run. The parquet files from the prior run are loaded as inputs, and the workflows that generated those files are skipped.>",690,,['f239de6498e0f471bf418974c00f1e36'],"[ 0.04617754  0.0043286   0.00099385 ... -0.00926163 -0.00540684
 -0.00319516]"
586cf02da9494088aed9b3419725638f,CONFIG,"PROPERTY, CONFIGURATION",The config argument allows opting out of the Default Configuration mode and executing a custom configuration specified in a config file.>,691,,['f239de6498e0f471bf418974c00f1e36'],"[-0.00864086 -0.01244722 -0.01102483 ... -0.01202223 -0.0246107
  0.0074814 ]"
229d85a2783e4a2991f17d2ab5750af7,REPORTER,"PROPERTY, CONFIGURATION","The reporter argument specifies the progress reporter to use during the execution of the GraphRAG Indexer CLI. The default is rich, and valid values include rich, print, and none.>",692,,['f239de6498e0f471bf418974c00f1e36'],"[ 4.23797267e-03  1.40712205e-02 -1.22014303e-02 ... -1.15675628e-02
  1.96372364e-02 -6.69086730e-05]"
b7f97d1909a3433abef8ca8e9334fafa,EMIT,"PROPERTY, CONFIGURATION","The emit argument specifies the table output formats for the GraphRAG Indexer CLI. It can include types such as json, csv, and parquet.>",693,,['f239de6498e0f471bf418974c00f1e36'],"[-0.01243715  0.00051155  0.00822942 ... -0.03373072  0.02728508
 -0.03531647]"
b7fdfffc38b94bf7872eabe9b022c8fd,TIMESTAMPED OUTPUT FOLDER,"PROPERTY, FOLDER","The Timestamped Output Folder is a property that specifies the folder where the output of the process is stored, named with a timestamp, for example, ""20240105-143721"".",694,,['919cb44d9688a14bf48fa7c98163ed81'],"[ 0.00194954  0.01353551  0.00281268 ... -0.01251101 -0.01448979
  0.01129006]"
6242e0c237a348908d0256ea790a0211,PROGRESS REPORTER,"PROPERTY, REPORTER","The Progress Reporter is a property that specifies the type of progress reporter to use during the process. The default is 'rich', but it can be changed to 'print' or 'none' using the --reporter flag.",695,,['919cb44d9688a14bf48fa7c98163ed81'],"[-0.02707121 -0.00835901 -0.03616099 ... -0.01638931  0.01952794
  0.0018478 ]"
7cc9f26737e1442595e53253e98015ef,TABLE OUTPUT FORMATS,"PROPERTY, FORMATS","The Table Output Formats is a property that specifies the formats in which the pipeline should emit the table output. The default is 'parquet', but it can be changed to 'csv' or 'json' using the --emit flag, with formats separated by commas.",696,,['919cb44d9688a14bf48fa7c98163ed81'],"[-0.02681726 -0.01501774  0.02299158 ... -0.0361414   0.02376536
 -0.02853147]"
1868fec1493643208dbdcad7bc97dfa0,CACHING MECHANISM,"PROPERTY, MECHANISM",The Caching Mechanism is a feature that can be disabled using the --nocache flag. This is useful for debugging and development but should not be used in production as it can affect performance.,697,,['919cb44d9688a14bf48fa7c98163ed81'],"[ 0.01284066 -0.01026893 -0.0235868  ... -0.02159713 -0.0014445
  0.0309631 ]"
