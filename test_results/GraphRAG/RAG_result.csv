Question,RAG Answer
"- How does Graph RAG enhance the capabilities of Large Language Models (LLMs) in reasoning about complex information?
用中文回答。","## Graph RAG如何增强大型语言模型（LLMs）处理复杂信息的能力？

Graph RAG（Graph Retrieval-Augmented Generation）采用了一种独特的方法来增强LLMs在处理复杂信息时的能力，尤其是在需要从各部分信息中提炼出合成洞见和对大范围文本数据的全貌理解上展现出了显著的改进。有别于传统的RAG（Retrieval-Augmented Generation）方法，Graph RAG利用LLMs构建知识图谱，此图谱基于输入的语料库，同时结合社区摘要和图机器学习的输出来在查询时增强提示。这种方法的核心优势在于图的自然模块化能够为全局摘要提供数据分区。

Graph RAG允许模型在查询时跨越多个数据点，通过它们共享的属性进行连接，从而为回答复杂的、多跳（multi-hop）问题提供了新途径。此方法的关键步骤包括从源文档中提取文本块，然后从这些文本块中识别和提取图谱节点和边的实例。随后，对这些实例级摘要进行进一步的概括，以形成单个描述性文本块，代表各图谱元素（即实体节点、关系边和主张协变量）。这一多阶段过程确保了从文本中获取的完整性和一致性，即便是面对同一实体在文本中出现的多种形式，LLMs也可以理解并将其归纳为相同的图谱元素，从而保持图的模块化优势和避免不必要的重复。

Graph RAG的另一个显著优点是其在处理完整概念摘要（即使是针对大范围数据集或长文档）时的效率和效果。在与源文本摘要进行的比较中，Graph RAG展现出在相同的关键指标——全面性和多样性上，以更低的令牌成本（token cost）实现了受青睐的性能。例如，在对位（head-to-head）比较中，对于源级（C0）社区摘要，Graph RAG的令牌成本较之Naive RAG减少了超过97%，而对于中间和较低级别的摘要，Graph RAG则比文本摘要方法更优，同时在全面性和多样性上胜过Naive RAG的几率分别为72%和62%。

然而，构建和维护图谱指数需要在获取信息的详细程度和效率间做出权衡。较长的文本块能减少LLMs的调用次数，但在提取过程中可能会经历召回率下降，尤其是对于较长的LLM上下文窗口。更短的文本块虽然能保持较高召回率，但会影响处理速度和系统效率。在Graph RAG中，这一平衡是通过多次提炼实现的，在初步的实例提取后，LLMs会判断是否遗漏了实体信息，留下反馈的机会，确保即使是大型文本段，也不会牺牲提取的质量。

## 关于Graph RAG的开放讨论

### 限制与评估方法的挑战

目前，我们评估Graph RAG效果的方式仅涉及特定级别的感性理解问题，针对两类大约100万令牌的文本数据集。为了完整理解Question-Answering系统的性能变化，需对不同问题类型、数据类型及数据集大小进行深入研究。此外，验证感性理解问题和目标度量是否与最终用户需求相符，以及对“自我检查”（如SelfCheckGPT）方法的马鹿制造率（fabrication rates）的比较，也是评估过程中需要改进的方向。

### 构建图谱索引的考量

实施Graph RAG时，一个基本的设计决策是在从源文档中提取文本时，选择适当的粒度。很长的文本块会减少LLM调用以提取图谱各元素，但召回率可能会随LLM上下文窗口变长而下降。系统通过多次提炼策略来保持与源文本相提并论的精确度及召回率的平衡，允许在保持大文本块的优势下，不会牺牲提取质量或引入噪音影响。这对于维护图谱的一致性与准确性，扮演了重要角色。

## 技术先进性和多样性

Graph RAG与既有技术相比，不仅在其多阶段处理和全局摘要优势上，还有其在迭代问答过程中展现的高效和效能，保持了在Comprehensiveness（72%胜率）和Diversity（62%胜率）上优于Naive RAG的水平。与开源软件相关联，Langchain和LlamaIndex库都对图数据库如Neo4j和Nebula Graph提供支持，但这并没有自然的模组化以供Global Summarization。Graph RAG在全面性和多样性指标上表现出色，且降低了令牌成本，使之在各种复杂的感性问题上更为卓越。

尽管Graph RAG在多份研究中展现出了领先优势和对提问多样性的支持，研究者们还需解决如何最佳化和调整不同LLM使用的元素提取例程，以确保在保留细节的同时有优秀的表现。系统的设计者需考量受上下文限制"
"- What are the unique capabilities of Graph RAG in handling global sensemaking questions compared to a naive RAG baseline?
用中文回答。","## 图表RAG解决全局感知问题的独特能力

### 高效的迭代问答方法
图表RAG（Graph RAG）对于处理全局感知问题，特别是在涉及多次迭代同一数据集查询的情况下，提供了一种极其高效的方法。与普通的全局方法相比，仅使用顶级社区（c0）的摘要就能减少超过97%的上下文令牌。尽管与完全依赖外部数据源的其他全球方法相比，性能略有下降，但这种方法在全面性和多样性方面显示出显著的优势。在全面性方面，图表RAG的胜率高达72%，而在多样性方面胜率达到62%，均超越了单纯的RAG方法。

### 提供详细实例的能力
对LLM（语言模型）的即时使用，分析表明，图表RAG在处理感知问题时，能够有效地提供具体的例子、引用和参考文献，这一点被证明对帮助用户达到一个有根据的理解至关重要。这一点比仅仅从文本中提取信息的归纳方法（TS）和语义搜索RAG（SS）更优。

### 图表和LLM的组合
图表RAG的独特之处在于，它利用LLM创建基于输入语料库的知识图谱，这一图谱连同社区摘要和图机器学习的输出一并用于答复各类问题。通过使用图的自然模块性来划分数据以实现全球摘要，图表RAG提供了针对大规模数据集和复杂信息要求进行推理的显著改进。这一综合能力表现出了超越基准RAG的智能或掌握度，从而在解决上述类别问题时，优于先前应用于该领域的其他方法。

### 头对头对比结果
在直接的对比中，图表RAG在应对不同级别的图社区（c0、c1、c2、c3）和文本总结方法（TS）以及朴素的“语义搜索”RAG方法（SS）时，持续取得最佳成绩。尽管对于某些情况，需要平衡查询的全面性和详尽性与特定文本的细节，但当前分析说明了图表RAG在回忆相关实体和关系时的优势。

### 活动驱动的问题生成
为了评估RAG系统的全局感知效果并避免以具体的文本细节为目标的问题，该研究采用了基于活动的方法来自动生成测试问题。通过从简短的数据集描述中要求LLM为预定量的潜在用户及与之关联的任务生成一定数量的需了解整体内容的感知问题，这种方法确保了问题的高阶性质，同时避免了对特定文本内容的熟悉性。

### 与传统RAG的差异
图表RAG与传统的RAG方法在解决问题所需的知识类型和使用方式上有所不同。传统RAG方法通常依赖于将文档转化为文本，然后将其分割成片段，最后将这些片段嵌入向量空间。相反，图表RAG利用了图的自然模块性，这使得数据更高效地被分区并进行全局摘要。

### 目标度量和限制
尽管图表RAG在对两个大小约为100万个令牌的语料库的测试中表现良好，但该评估方法仍未全面覆盖所有感知问题种类和数据类型。未来的研究将扩展到各种类型的问题、数据，并针对不同的数据集大小探究其性能的变动，旨在创建一个更为完整和具有代表性的评估框架。此外，为了优化图表RAG系统，分析其构建图索引过程中的折衷点以及调节元素抽取提问也是必要的步骤。

### 结论
总之，图表RAG在处理需要广泛理解数据集全局特性的迭代认知问题时，证明了其相对于朴素RAG基线方法的独特能力。使用较低级别社区的摘要（如c0）不仅在召回性能上表现出色，而且在资源效率和结果多样性方面也取得了平衡。这一方法还保留了连接基本事实的能力，从而有助于生成更全面的答案。随着时间的推移，进一步调优图表RAG的实现和参数调整，将有助于提升更多领域的感知和总结效果。"
"- In what ways does Graph RAG use a self-generated graph index to improve retrieval and analysis of information?
用中文回答。","## Graph RAG 的优势和工作流程

### 优势概述

Graph RAG（Retrieval-Augmented Generation）利用自动生成的知识图谱作为索引，与传统的基于向量相似度的 RAG 方法相比，它在复杂信息推理方面展现出显著的改进。这种方法不仅能连接分散的信息点，还能对大规模文档集或单个大型文档中的语义概念进行整体理解。Graph RAG 通过创建知识图谱，结合社区概要和图机器学习输出，在查询时增强提示信息，从而支持全文本集合的人类洞察力。结果表明，Graph RAG 在答案的全面性和多样性方面超过了朴素的 RAG 基线，同时在令牌成本方面也很有竞争力。

### 工作流程及技术细节

#### 1. **源文档到文本块**

源文档首先被细分为文本块以进行处理。这一分割的粒度对随后的信息提取至关重要。文本块越长，从每个块中提取信息所需的 LLM（Large Language Model）调用就越少，但较长的上下文窗口会导致召回率下降（Kuratov 等人，2024；Liu 等人，2023）。例如，在 HotpotQA 样本数据集上，使用 600 令牌的文本块几乎可以提取两倍于使用 2400 令牌块的实体引用数量。虽然提取更多参考是好事，但任何提取过程都需在召回和精确度之间找到平衡。

#### 2. **文本块到元素实例**

每个文本块接下来被处理以识别和提取图的节点和边实例。这是创建知识图谱的关键步骤。Graph RAG 在这一阶段使用 LLM，且在多次测试中，这些模型能够从单个文本块中提取多个实体。

#### 3. **知识图谱构建**

元素实例被用来构建知识图谱，该图谱反映了整个文集的结构和关系。图的自然模块性被用于数据的分割，以便进行全局概要分析，这一过程支持了跨文档的分析。

#### 4. **社区概要和图索引**

为根级社区创建的概要作为索引的一部分，可以以较低的令牌成本提供优于朴素 RAG 的性能，并在与(mapStateToProps,社区-免费方法)的比较中保持竞争力。这些概要和图索引为查询时的高级检索提供了支持，使得从广阔的信息集合中能够快速高效地获取答案。

#### 总结

Graph RAG 通过建立自动生成的知识图谱和使用社区级别的概要，能够以更精准和全面的方式检索和分析信息。与朴素 RAG 方法相比，这种方法能够处理更为复杂的问题，同时保持较低的计算成本。尽管仍存在一些局限性，如对不同数据集大小、问题类型和数据类型的适应性有待进一步研究，但 Graph RAG 为基于 LLM 的信息检索提供了新的高效解决方案。

此外，Graph RAG 与 LLM 交互中的自适应模板生成也是一大亮点，它利用输入数据和 LLM 生成的知识图谱的域适应模板，从而在随后的索引运行中产生更佳的成果，这是推荐的高级使用案例。而手动配置则作为一种高级功能，更适合特定需求的用户。

最后，Graph RAG 的开放源代码实施（即将在 https://aka.ms/graphrag 上发布）与 LLM 为基础的信息检索工具提供了模组化和迭代的检索和生成策略，这使得多文档摘要和多跳问答的组合应用变得可能，进一步彰显了其在信息处理上的多功能性与灵活性。

通过使用自动生成的带语义结构的知识图谱，Graph RAG 还能够提供一个既精准又高效的检索环境，使得从海量数据中寻找关联信息变得更加直接和高效，特别适合需要全局检索和多层查询的高级疑问回答。这种方法不仅提高了检索的效率，还降低了计算成本，让大规模文本数据集的信息检索变得更为可行和经济。总体而言，Graph RAG 利用自动生成的知识图谱索引，实现了对广阔信息源的高效检索和高精度洞察，为基于大型语言模型的信息检索领域带来了革新性的思维模式。"
"- How does Graph RAG demonstrate scalability advantages over traditional source text summarization?
用中文回答。","### 图表RAG的可扩展性优势

#### 图表RAG方法概述与管道

图表RAG方法通过将高水准的数据流分解为源文件、文本片段、元素实例识别以及总结这几个步骤，充分利用了数据的自然模组性来实现整体数据的总结。在这个方法中，每一阶段都涉及了关键设计参数、技术以及实施细节，允许系统更高效地处理并总结大规模的文本数据。

#### 文本分块

文本从源文件中被分割成较小的片段，每个片段将会被传递给相应的LLM提示来提取图表索引的各个元素。虽然使用较长的文本片段可以减少LLM的调用次数，但是它可能降低在长上下文窗口中LLM的召回效果。平衡召回率与精确度对于目标活动来说至关重要，很多参考在600与2400词长的分块的情况下可以明显地看到。

#### 元素实例抽取

该步骤的基线要求是，从每个文本片段的源文本识别并抽取出图表节点和边的实例。这一过程高效地构建出从文本数据到知识图表的映射，使得系统能够从整体上精确地理解和回应查询。

#### 不同级别的社区总结

图表RAG在不同的总结层次（从高到低）上展现出效率优势。例如，对于中等和低级别的社区总结（C1到C2），图表RAG所需的上下文词数减少了26%到33%；而对于最高级别的社区总结（C0），所需的上下文词数减少了超过97%。即使在某种程度上的性能下降，图表RAG在整体上提供了比其他全球方法更高效的查询回答，尤其是在面临需要多次全球查询的数据集时，优势更加明显。

#### 结论

图表RAG结合了知识图谱生成、LLM支持的检索增强生成(RAG)与针对人类求解过程的全局查询聚焦总结（QFS），通过利用文本数据的自然跟上的模组性，允许系统以较低的token成本，处理和总结整个文本语料库。虽然在某些情况下，图表免费的全局源文本总结方法也展现出了竞争性结果，但选用图表RAG则依赖于多个因素的考量，例如计算预算、预期的每个数据集生命周期查询数量，以及对图表索引其他方面价值的认可（包括通用社区总结和使用其他相关的图表RAG方法）。

这种可扩展性不仅仅局限于文本摘要的效率，更促进了更全面和多元的响应，以及低token成本执行符合用户需求的后续操作的可能，最终促进人类的理解与求解过程。图表RAG凭借着其效率与性能的平衡，成为了企业大规模文本数据中的有力选择，尤其在那些需要频繁地、全球性的、针对性提问的场景中。面对待解析数据集的大小、查询类型以及问题本质的变化时，图表RAG依旧展现出了强大的适应性与潜力，值得进一步的探索与应用。
图表RAG的可扩展性优势无关通用的LLM能力，而是由其特定的设计和高效处理技术所驱动。这种方式不仅减轻了LLM在大规模数据集上的负担，还确保了重要信息的捕获和高效摘要，使得整个系统的性能更为出色。此外，图表RAG还通过多级社区汇总为用户提供了一种高效且有深度的理解途径，特别是能够快速定位信息，以较低的token成本获取全局视角。这种独特的优势使得图表RAG在处理大型数据集或对多文档情境下的理解求解时，成为更优选的技术方案。"
"- What is the relationship between Graph RAG and community summaries in the context of self-memory for generation-augmented retrieval?
用中文回答。","在实施Graph RAG系统的背景下，社区摘要起着一种自记忆(selfmem)的作用，这与生成增强检索(GAR)紧密相关。具体来说：

1. **自记忆(selfmem)和生成增强检索(GAR)：**
   - 自记忆是一种策略，其中系统利用先前生成的内容或数据来改善后续的生成循环。在Graph RAG中，社区摘要被创建并作为一种自记忆被储存。这些摘要是对社区内各元素（节点、边和协变量）的结构化描述。
   - 生成增强检索(GAR)是指利用外部数据来提高大型语言模型(LLM)的检索和生成能力。这通常因为LLM的上下文窗口有限，而社区摘要正好解决了这个问题，通过提供高度浓缩的信息片段，即使在LLM的限制下，它们仍然可以有效检索和利用。

2. **Graph RAG和社区摘要的结合：**
   - Graph RAG将社区摘要当作一种模块，用于后续的检索和生成策略。在每个社区的最低层级（即叶子层级），它首先将元素的摘要按照重要性排序，然后以迭代的方式添加到LLM的上下文窗口中，直到达到令牌限制。
   - 对于更高层级的社区，如果所有元素摘要都能符合LLM的上下文窗口大小，则同样按步骤处理；否则，它会根据摘要的综合源节点和目标节点度数进行子社区级别的排名，这有助于确定哪些子社区的内容对于全球查询最具有代表性。

3. **社区摘要的效能和价值：**
   - 根据我们对不同Graph RAG方法的评估，使用社区摘要（尤其是在根级别）可以显著减少LLM处理所需的时间代价，与naive RAG相比，高和低层级的社区摘要减少了26-33%的上下文令牌，而根级别的摘要则减少了超过97%的令牌。
   - 尽管与单纯的源文本全球方法相比，Graph RAG的性能稍有下降，但它仍然在综合性和多样性方面具有优势，特别是在naive RAG上，其胜率分别为72%和62%。这表明，Graph RAG仍然能够提供更全面和多样的答案，同时具有更高的效率。

4. **赋予用户能力**：
   - 通过提供具体例子、引用和来源，Graph RAG进一步帮助用户理解和推断数据。这可能通过优化元素提取提示来强化，以确保在索引中保存更多细节。
   - 根据我们的评估，Graph RAG相比于naive RAG和仅使用源文本摘要方法，在综合性和多样性上表现更优。这就使得对于那些需要多次对同一个数据集进行全局查询的情景，基于根级社区的总结在增强检索能力的同时，保持了较高水平的详实程度和答案的差异性，而且以极低的令牌成本做到这一点。

综上所述，Graph RAG通过整合社区摘要的自记忆效应，不仅强化了LLM的检索和生成能力，也有效提升了系统的综合性和多样性表现。这种自记忆机制通过动态生成的社区层次结构，为增强用户的理解力提供了坚实的基础，使得系统在处理大规模数据集时的检索效能达到最大化。同时，这种结合减少了LLM上下文窗口大小的限制，为用户提供了一个可以高效多次查询的全球数据索引。自记忆和生成增强检索在Graph RAG中的融合，代表着一种在资源有限条件下实现更高质量检索和生成效率的创新方法，也启示了未来RAG系统在迭代和动态操作方面的潜在优化方向。"
"- How does Graph RAG's federated retrieval-generation strategy enable distributed and collaborative retrieval and generation?
用中文回答。","### Graph RAG的分层索引与总结

Graph RAG采用了一种独特的分层索引构建策略，其中的自然模块化特性允许系统对全球范围的文本数据进行综合总结和检索。与传统的基于向量相似性的RAG（retrieval-augmented generation）系统相比，Graph RAG利用了深层语言模型（LLMs）和知识图谱技术，将语料库中的实体构建为图谱，再为密切相关的实体组预生成社区总结。这些总结不仅作为自记忆(selfmem)用于后续的生成循环，同时也支持并行生成社区答案，这是一种类似于迭代或联邦检索生成(iter-retgen/feb4rag)的策略。

在回答用户问题时，每个社区总结用于生成部分回应，所有这些部分回应再次被汇总为对用户问题的最终回应。这种方法特别适用于需要处理分散在大量文本中的信息的全球性质的问题，能够提供更全面和多样化的生成答案，与基本的RAG方法相比，Graph RAG在1百万个词范围内的数据集中，特别是在与复杂的现实世界问题相关的连贯性和多样性上的提升了答案的质量。

### 分布式与协作检索生成

Graph RAG的联邦检索-生成策略确保了数据的分布式管理和协作检索。系统的核心在于利用LLMs生成知识图谱，之后针对图谱中的各个社区或实体组创建总结。这些社区总结是Graph RAG运用的核心组件，它们允许不同“分区”或“模块”（即实体相关的社区）在不知道整个语料库内容的情况下独立生成有意义的回答。

这种方法有效地克服了LLMs在处理大规模文本时的局限性，因为它们的有限上下文窗口可能无法处理整个数据集的细节。通过生成社区级别的总结，Graph RAG确保了即便面对庞大的数据集，系统也能保持较高的检索和生成效率，而无需将整个文本库加载到模型的上下文中。由于LLMs可以直接访问这些总结，查询的生成部分变得更加集中，可以针对特定实体或概念的直接上下文生成连贯的回复。

此外，Graph RAG支持“Roll-up”和“Drill-down”操作，这为用户提供了从各个级别（如上层的社区总结）逐步细化信息检索的途径，可以通过更高层次的总结快速得到概览，随后通过钻取实体社区的细节获得更深入的理解。这一特性强烈证明了Graph RAG如何利用其图谱结构，以分布式的方式汇聚和分发信息，从而促进灵活和高效的检索-生成任务。

### 与开放源码社区的交互

Graph RAG与开源社区的互动是通过诸如Langchain和Llamaindex等支持多种图数据库的库实现的，这些库在Neo4j、Nebula Graph等格式中提供丰富的功能。尽管某些图基RAG应用可以创建和利用知识图谱进行推理，它们并未采用像Graph RAG那样用于全局总结的自生成图索引。Graph RAG的这种自然模块化特性使其成为在大规模文本语料库上进行全局检索和生成的理想选择，尤其是在多个LLMs之间共享和构建图谱相关总结以增强整体性能的情况下。

Graph RAG的这一策略不仅支持动态的检索-生成周期，对于理解较高层次的概念和跨文档的信息关联也非常有效。系统利用LLMs捕捉实体间复杂的关系，并生成超出了从任何单一文档中直获取的综合报告。这种模块化设计促进了在不同的LLMs之间进行协作检索，使得信息的处理更加高效和准确，提升了系统处理复杂信息的能力，同时也增强了答案的全面性和多样性。

### 未来工作

Graph RAG表示出了其潜在的模块化和灵活性，可在未来的发展中适应更复杂的应用场景。现有的策略不仅适用于并发的信息检索，还能在必要时与模型上下文结合，提供有嵌入性（embedding-based）的匹配和详尽回答。该系统的迭代和联邦特性旨在进一步克服规模庞大的真实世界数据带来的挑战，而其“上卷”操作可能会在社区层次结构的更多层级上实施，以涵盖更广泛的主题和细节。最终，“钻下”机制将帮助用户深入探索高层次社区总结中包含的信息线索，使得人类的全局层面的信息理解得以加强并改进。在实际应用中，这可能意味着改进处理现实世界问题的能力，特别是在涉及跨文档因果关系的场景中。

### 结论和讨论

Graph RAG基于其分层索引和概括的特点，实现了分发式协作信息检索和生成。借助LLMs创建实体图谱，并从中产生社区总结，使系统能全局检索及生成答案，在理解大规模文本集合方面比基本RAG有显著的优势。Graph RAG的“联邦”检索-生成策略支持了跨模型和跨网络的高效检索，这意味着源自每个""分区""的独立信息总结可以用于更广泛的文本集合上，从而产生综合而全面"
"- What are the similarities between Graph RAG and multi-document summarization techniques in handling multiple documents or data sources?
用中文回答。","### 图形 RAG 与多文档摘要技术处理多个文档和数据源的相似之处

在处理多个文档或数据源时，**Graph RAG** 方法与**多文档摘要技术**之间存在一些显著的相似之处，这些相似点主要体现在它们对文档集的组织、管理和生成摘要信息的方式上。以下是这些相似之处的详细讨论：

#### 1. **分块和分层索引**
- **Graph RAG** 和**多文档摘要技术**都在处理大量文本数据时采用分块或分层索引的方式。Graph RAG 将源文档分割为较小的文本块，以适应大型语言模型（LLM）的上下文限制。多文档摘要技术可能将文档集合分解成更小的单位，如段落或句子，并对这些单元进行单独处理或分层组织，以提高摘要创建的效率和性能。
- 两种方法中，分块或分层索引有助于管理和优化大的数据集或文本集合，确保系统可以有效地处理每个文档的特定部分，并减少资源消耗。

#### 2. **信息的聚合和总结**
- **Graph RAG** 与**多文档摘要技术**都涉及从多个文档中提取信息并进行聚合。Graph RAG 通过构建一个实体-关系图来实现这一点，包括实体、关系和社区报告。这些报告提供了由 LL M 提取的实体和关系的总结信息，使得系统可以对整个文档集合有较高的认知。
- **多文档摘要技术**也涉及聚合文档集中的信息，往往通过识别关键句子或段落，提取共同主题和独立事实，然后生成一个代表整个文档集合的摘要，确保摘要的全面性和多样性。

#### 3. **实体和关系的管理**
- **Graph RAG** 权重管理实体和关系，而**多文档摘要** 则重在句子和段落级别的信息。Graph RAG 使用 LLM 识别文档块中的实体、关系和主张，并将它们合并到子图中，最后生成层次分明的实体和关系网络。这种技术可以有效的记取实体和关系的信息，并从多个角度对信息进行总结。
- **多文档摘要技术** 在多个文档中识别句子和段落的相似性，使用词频、共现以及其他文本指标（如 Textrank）来选择关键句子进行摘要，既能抓取主要信号，又能保证摘要中的多样性和广泛性。

#### 4. **高级检索与生成**
- **Graph RAG** 与**多文档摘要技术** 都考虑了高级检索和生成机制，以解决单纯 rag（检索增强生成）系统的局限。Graph RAG所做的迭代和动态检索-生成的模式，可以通过社区级汇总或其他子图级别的内容生成答案。这种方法允许系统利用多层索引和摘要来生成更高质量的检索环节，提供更深入的理解。
- **多文档摘要技术** 采用了类似的策略，例如， grouping-based multi-document summarization 技术和 hierarchical multi-document summarization 技术，先将相关文档或段落进行分组或层次化处理，再进行细粒度的摘要和生成，提高了摘要的精确性并减少了提取成本。
  
总结来说，尽管**Graph RAG** 与**多文档摘要技术** 在具体实现细节和特定目标上不同，但两种方法都关注文档分块、信息聚合与总结、实体和关系管理以及通过多层次检索与生成增强摘要的效率和质量。在处理多个文档时，它们都试图降低检索和生成的成本，提供更丰富和多样化的摘要内容，这使得它们在文本数据的处理流程中体现出高度的互补性。"
"- How does Graph RAG compare to multi-hop question answering techniques in addressing complex questions?
用中文回答。","### 图表RAG与多跳问题解答技术的对比

在处理复杂问题方面，**Graph RAG** 显示出了与多跳问题解答技术（Multi-hop Question Answering Techniques）相比的独特优势。多跳问题解答是一种先进的技术，它允许系统在多个相关文档或数据源之间进行反复的问答，从而逐步提炼出全面且细节丰富的答案（Wang et al., 2023b）。这类技术在处理要求深入理解多个文档的联系并从中抽取深层信息的问题时表现尤为突出。例如，**SURGE** 和 **Fabula**（Kang et al., 2023; Ranade and Joshi, 2023）都利用了子图来支持多跳问题解答，同时使用了叙事模板来将复杂事件总结成易于理解的故事形式。

### Graph RAG的特点

然而，**Graph RAG** 方法与众不同。它不仅支持多跳问题解答，还利用了自然的图形模块性来对数据进行分组，进而构建更高效的问题解答系统。Graph RAG的主要优势在于能够以更高的归纳性和多样性回答涉及全局理解的问题，与**Naïve RAG**相比，在理解近1百万个单词的语料库的完整性（72%的胜利率）和多样性（62%的胜利率）上表现出色。

### 全局对比的优势

对于问题的解答，Graph RAG通常依赖于数据集的模块社区，也就是不同层次的社区总结（C0-C3）。这些总结越高级（C0即为根级社区总结），在回答过程中需要的上下文代币（tokens）就越少——根级社区在某些情况下甚至减少了超过97%的代币需求（Ram et al., 2023）。这表明，Graph RAG在提供全局视图上下文中表现出极高的效率。

### 综述能力

Graph RAG的综述能力，特别是其能够提供具体例子、引用和注释的能力，被证明是帮助用户实现基于完整信息理解的决定性关键。这一点通过临时的LLM分析佐证了（Manakul et al., 2023）多跳问题解答的实质，即问题不仅跨越单个文档，还深入到文档间的关系，因此Graph RAG的提升不仅在于对单个文本块的处理，还在于对连接多个文本实体的图表的理解及综述。

### 综述能力的一个实证提示

Graph RAG的综述能力上的提升可能与系统的索引方式有关。与传统的Naïve RAG相比，Graph RAG在构建索引时会先提取实体和它们之间的关系，生成实体知识图谱，然后再对紧密相关的实体群体生成预响应——社区总结。这种方法不仅允许系统在不超出LLM上下文窗口的情况下处理大量文本，还允许在回答问题时将多个社区总结汇聚起来，给出更具有广度和深度的响应。

### 结论

总而言之，**Graph RAG** 在回答需要全球理解的问题时提供了更有效的解决方案，它不仅优于多跳问题解答中常见的Naïve RAG方法，还保留了处理高度复杂和全局性问题的能力，这是多跳问题解答技术所追求的核心目标。通过利用图形的自然模块性和预生成社区总结，**Graph RAG** 可以以更少的代币需求，更高效地融合和理解多个文档的关联，从而生成更全面和多样的答案。

### 未来工作

尽管Graph RAG在现有实施中显示出了显著的改进，但未来的工作仍然需要进一步探索在不同规模数据集和不同问题类型上的性能变化。例如，评估其在不同数据量和多种询问方法下的效果将有助于更好地了解该方法的实际适用范围和局限性。且需要通过实际用户反馈和更细致的假设检查GPT（如SelfCheckGPT）来验证Graph RAG在防止事实捏造方面的效率，进一步完善体系的稳定性和准确性。"
"- What is the process involved in the Graph RAG indexing pipeline, and how does it facilitate data indexing tasks?
用中文回答。","## Graph RAG Indexing Pipeline过程与数据索引任务的促进

### 一、Graph RAG知识模型

Graph RAG系统的核心在于将索引引擎的输出与一个我们称之为Graph RAG知识模型的结构对齐。此模型为底层数据存储技术提供了一种抽象，同时为Graph RAG系统提供了一致的接口，便于查询和数据交互。这意味着，在一般情况下，Graph RAG索引器的输出会被加载到数据库系统中，而查询引擎则会使用知识模型数据存储类型与数据库进行交互。

### 二、Datashaper工作流

Graph RAG的索引管道基于Datashaper，一个开源的、用于定义数据管道、模式和相关资产的库。Datashaper提供了一个核心资源类型——工作流。工作流被描述为一系列步骤，我们称这些步骤为动词。每个动词命名的步骤都有一个配置对象，它们涵盖了关系数据库概念，如选择、删除、连接等。动词会将输入表转换，转换后生成的表继续在管道中传递。

### 三、Graph RAG 索引功能

#### 1. 文档 → 文本块

Graph RAG索引过程中的基本设计决策是确定输入文本从源头文档中切分的粒度。更长的文本块减少了从每个块提取信息所需的LLM调用次数，但会召回率降低，尤其是在LLM的上下文窗口更长的情况下。平衡召回率和精确度对于目标活动很重要。

#### 3. 文本块 → 元素实例

对于这一阶段，我们的基本要求是识别并从每个源文本块中提取图的节点和边实例。提取过程应在多个层级上生成社区检测和总结，包括来自原始文本的实体、关系和主张的提取，还包括社区层次的检测和总结。

#### 4. 模型设计和执行

Graph RAG涵盖了从数据中提取实体、关系和主张，进行社区检测，生成社区总结和报告，将实体嵌入到图向量空间，以及将文本块嵌入到文本向量空间等环节。这些处理可以使用多种格式输出和存储，如JSON或Parquet，也可以通过Python API进行手动处理。

### 四、Graph RAG 与基准RAG的比较

Graph RAG是一种超越基准RAG(基于向量相似性检索)的LLM增强技术，目的是改进LLM在处理复杂信息情况下的问答性能。Graph RAG使用LLM创建基于输入语料库的知识图谱，图谱与社区总结和图机器学习输出结合使用，用于在查询时间增强提示信息。

### 五、结论

Graph RAG在回答需要从不同类型信息中连接信息的问题以及对大量数据集合进行整体理解时表现出色，其性能超越了其他常见的LLM增强技术。通过详细的工作流程和资源类型理念，Graph RAG系统构建了一个既有深度又有广度的数据索引模型，帮助更好地答理和理解复杂数据。"
"- How does the Indexer in Graph RAG process and prepare data for efficient search and retrieval?
用中文回答。","## Graph RAG的Indexer如何处理和准备数据以实现高效的搜索和检索？

Graph RAG的Indexer是一种数据管道和转换套件，专为从非结构化文本中提取有意义、结构化的数据而设计。这一过程是利用LLM（Language Model）进行的。

### 默认配置模式下的数据处理流程

在默认配置模式下，Graph RAG Indexer输出的数据与Graph RAG知识模型（Graph RAG Knowledge Model）保持一致。知识模型是一个抽象层，用于底层数据存储技术，并且为Graph RAG系统提供了一个标准的交互界面。Graph RAG Indexer的数据通常会被加载到数据库系统中，Graph RAG的查询引擎会使用模型来与数据库进行交互。

### 关键工作流程

Graph RAG的索引管道基于开源数据处理库Datashaper构建。Datashaper允许用户以一种声明性的方式表达数据管道、模式（schema）和相关资产，在JavaScript和Python中皆有实现，并且还设计有拓展至其他语言的能力。工作流程（Workflow）是Datashaper中的核心资源类型之一，它通过一系列的步骤（称之为动词），将输入数据表转换为输出数据表。例如，一个简单的Datashaper工作流可能包含从原始文本中提取实体、关系和声明，执行群体检测、生成多层级的群体摘要和报告以及构建实体与声明的向量嵌入等步骤。

### LLM协助下的知识模型构建

Graph RAG利用LLM来创建知识图谱。这一过程包含但不限于以下关键步骤：

1. **知识抽取**：首先从原始文本中分割出较小的文字片段（文本块）。较长的文本块虽然需要较少的LLM调用来提取，但是如果过长，则可能导致LLM上下文窗口的回忆能力下降。一个合理的判断是，尽管获取更多的参考信息通常效果更好，但在提取过程中需要取得召回率和精确度之间的平衡。例如，从HotpotQA样本数据集中，使用600个标记长度的文本块几乎提取到两倍于使用2400个标记长度的实体参考信息。
2. **实体和关系信息的处理**：这一阶段的基线要求是为每个文本块识别和提取图节点和图边缘的实例。更具挑战性的任务，如对抽取到的信息进行排序或进行KWIC（元词在中，Key Word In Context）形式的文本显现，这要依赖于更复杂的算法和序列模型，如Transformer（见Graph T5和Graph Toolformer）和RNN（见GRU）。Graph T5通过图转换的mask LM任务并结合两阶段解码实现。然而，要让Graph RAG达到预期的性能，除了处理能力以外，如何巧妙地设计数据管道和LLM交互过程也是一个至关重要的要素。
3. **下游输入**：Graph RAG的输出可以以多种格式进行存储，包括JSON、parquet甚至也可以通过Python API进行手工处理。Graph RAG的查询引擎可以从这些输出中，使用知识模型来有效地推理和回答关于复杂信息的问题。
4. **自定义管道和配置**：虽然提供了一条标准的管道，旨在从原始文本中提取实体、关系以及声明，执行群体检测并生成社区等级的摘要和报告。但是，如果用户有自己特别的需求，还可以通过自定义管道和配置，对数据处理的过程进行调整和优化。

Graph RAG在处理大块数据，进行全局推理和复杂信息检索方面，对比传统的Baseline RAG以及使用图技术的其他方法，都达到了优秀的性能。特别是对于那些需要在同一个数据集上进行多次全局查询的场景，根级别群体的摘要在Graph RAG的知识图谱索引中提供了高效的索引机制，相比基本的RAG方法拥有显着优势，同时也具有与其他全局检索法媲美的性能，但成本却更低。在即将到来的基于Python的Graph RAG开源实现中，默认配置的Prompts是最简单的方法，适用于大多数的使用场景。但是，也提供了高级的手动配置能力，可以让用户根据自己的需求对特定的步骤和LLM交互方式进行详细调整。对于大多数用户来说，更推荐的使用方式是运行自动模版功能（Auto Templating），因为这允许系统创建Domain adaptive的模版以生成知识图谱，能带来更好的效果。

总之，Graph RAG的Indexer设计了一套全面的框架，通过LLM进行文本实体和关系的识别，并搭配Datashaper来构建工作流程和自定义配置，从而能够有效地抽取和转化原始文本中的信息，为高效的检索和分析提供了基础。"
"- What is the role of the CLI (Command Line Interface) in executing tasks using the poetry tool in Graph RAG?
用中文回答。","在配置和执行Graph RAG的任务中，CLI（命令行界面）和Poetry扮演了重要角色。

### 了解CLI与Poetry的协同工作

Graph RAG，作为一个数据管道和转换套件，设计用于从非结构化文本中使用大语言模型（LLMs）提取有意义的、结构化的数据。当涉及到代码环境设置和依赖性管理时，Poetry作为Python包管理工具的使用是至关重要的。它不仅帮助管理Python的依赖库，保证项目运行的环境一致性，还通过构建隔离环境以避免项目之间的依赖冲突。这让开发者在配置开发环境时更高效、更可靠。

### CLI在Graph RAG中的应用步骤

要运行Graph RAG引擎，首先要确保正确设置了开发环境，具体步骤已经在要求章节中详细描述。一旦环境就绪，CLI通过Poetry运行，成为了执行关键任务的桥梁。

- **配置和宗城市：**在默认配置模式下，通过CLI运行Graph RAG非常直接。只需简单的命令如`poetry run poe cli --root <data_root>`即可启动流程。这里`<data_root>`的参数表示你数据的根目录路径。
  
- **自定义宗城市：**如果需要更精细的控制，CLI也可以使用自定义管道模式。通过在命令中加入特定的配置文件路径，例如`poetry run poe cli --config your_pipeline.yml`，你可以为项目配置一系列定制化的工作流程步骤和LLM的调用参数。

### 从Node环境到Python环境的转变

虽然Graph RAG也支持通过Node环境使用`yarn`执行相同任务（如`yarn run:index --root <data_root>`），但使用Python和Poetry的优势更为明显。Python作为Graph RAG的基石，确保了系统的稳定性和扩展性，而Poetry则使得管理依赖性和虚拟环境变得简单。

### CLI的生命周期脚本与多用途执行

CLI不仅限于执行Graph RAG的索引和查询任务，它还通过Poetry管理多类脚本，包括测试、构建、静态检查、格式化和修复等。例如：

- `poetry run poe test_unit`用于运行单元测试。
- `poetry build`则会构建一个可分发的包，如轮子文件（wheel file）。
- `poetry run poe fix`则应用任何可自动化的修复，通常是代码格式的修复。

总的来说，CLI与Poetry的结合，极大地简化了Graph RAG项目的设置、运行和维护，使得开发者能够更专注于数据处理和模型训练，而不是环境配置和依赖管理。这是构建和使用Graph RAG的关键步骤，确保了项目的高效性和可维护性。
  
在设置开发环境和构建Graph RAG的流程时， Poetry通过CLI脚本提供了丰富的命令选项，使开发者可以轻松管理项目的生命周期。不论是运行索引引擎、查询数据、构建包、执行测试还是修复代码，CLI与Poetry的集成都为项目的每一个阶段提供了坚实的支持，大大提高了开发者的效率和项目的可靠性。"
"- How does the Language Learning Model (LLM) contribute to the functions of summarization, entity resolution, and claim extraction in Graph RAG?
用中文回答。","在Graph RAG系统中, 语言学习模型(LLM)扮演了多种关键角色, 主要涉及对文本的分析和提取, 以生成对实体, 关系和主张的深入理解. 

### 文档到文本块转换：
输入文本首先被拆分成一系列的“文本单元”, 这些文本单元是后续分析的基本单位. 在这一阶段, LLM通过处理每个独立的文本单元, 提取其中包含的实体和关系信息, 同时还能识别出各种可能的主张. 为了确保分析的全面性, LLM使用基于logit bias的评估方法, 特别地, 设置高bias (如100)迫使模型准确地判断是否丢失了某些实体. 若模型指向有信息遗漏, 我们将启动额外的提取循环, 提醒LLM许多实体可能在以前的提取中被忽略.

### 实体和关系实例化到总结：
获得初步的实体和关系实例后, LLM的任务继续升级. 它不仅需要识别和描述这些实体, 关系, 还要进行总结, 将每项实体和关系的多个实例聚合成一个简练的描述. 这一分段总结工作的目的一方面是减少噪声, 另一方面是由LLM创建独立而有意义的概念文字摘要. 尽管模型可能以不同格式抽取对同一实体的参考, 造成实体冗余, 但由于我们采用层级性实体社区检测和总结的方法, 且LLM具有理解变体名字的能力, 这一问题得以调节.

### 实体合并(实体消歧):
尽管LLM的实体识别和总结能力为我们提供了灵活性, 但还不能保证识别出的实体完全吻合于现实世界中的实际对象. 因此, 采用实体解析步骤, 以识别具有不同名称但代表同一现实实体的实体. 这一实体解析在默认情况下是未启用的, 以此避免信息丢失. 当前的实体解析是通过给LLM一系列实体, 并询问是否该合并哪些实体来实现. 实现合并后, 这些相同实体被融合, 并更新与其相关的所有关系. 

### 主张提取与发射：
主张是来源文本单元中具有可评估状态和时间界限的正面事实性陈述. 通过一个独立的工作流程, LLM能够从文本单元中提取这些主张, 并将它们作为一项主要成果, 即称为协变量. 在对主张完成精确的描述和提取后, LLM便将这部分数据加入图谱中, 为图谱提供了更为丰富的语义信息.

### 图谱增强：
当图谱中的实体和关系被定义得足够清楚时, 接下来的任务是对图谱进行增强, 以便深入理解这些实体的社区结构. 此时, LLM参与通过层次Leiden算法实现社区检测, 以创建实体的层次社区结构. 该方法需要Liu等人研究发现的相似位点来明确不同的社区边缘. 图增强中, 我们还利用了图嵌入技术, 通过对实体进行节点可视化实现对它们的层次性理解和分类.

每个步骤都由LLM完成, 从处理“文档”提供“细粒度文本芯片”, 到“实体和关系实例化”后生成描述, 再到“主张提取与发射”. 所有环节都旨在尽可能减少Token的使用, 使Graph RAG对使用者在回答问题时保持高效率和广泛涵盖的视角.

采用各种层级化的索引和总结, 以及细节导向的“自我补全”引出遗漏实体的方式, Graph RAG维持了对完全实体和上下文关联的搜索能力. 这使得GraphRAG在存储大量实体和关系描述的情况下, 也能够迅速响应广泛的询问.

### 总结：
总之, 通过处理每段文本, 并采纳逐步细化的层级策略, LLM在提取实体, 关系, 主张的过程中发挥着核心作用. 它不仅创造描述这些不同组件的单一总结, 还能够对复杂的实体关系进行“答案统计和解析”, 最终为Graph RAG提供了一个精细, 全面的文本理解和关联搜索能力。需要注意的是, 这一技术在信息查询和解析方面是极其经济的, 仅为原始文本文献所需的token数量的26%-33%。同时, 通过利用社区摘要及其图谱的特点来进一步优化搜索和索引, LLM在Graph RAG中的应用显著提升了系统的效能。"
"- What is the significance of Question Generation in enhancing data exploration and conversation flow in the Query Engine?
用中文回答。","## 问题生成在查询引擎中的重要性

问题生成功能在增强数据探索和对话流程方面起着至关重要的作用。它能够基于用户已经提出的查询，生成一系列的新问题，为数据的更深层次探索提供线索。例如，在询问某一个实体后，问题生成可以通过挖掘与该实体相关的信息，提出后续问题，帮助用户了解实体间的关联，从而清晰地掌握数据集的细微差别和深层次结构。

这种功能的实现主要依赖于结合知识图谱的结构化数据与输入文档的非结构化数据。这意味着问题生成不仅能够理解具体的实体，还能把握其与数据集中其他实体之间的联系。这些数据记录被融入一个LLM（Language Model）的提示中，用于生成具有重要信息含量的候选后续问题。

## 问题生成如何促进有效对话

在多轮对话中，问题生成确保了连续性与深度。它能够根据之前的问答，动态生成新的、相关的问题，这种对话增强机制让更多的实体、关系和主题进入对话的视野，从而使得整个查询过程更加丰富和有教育意义。

例如，如果用户第一次询问关于“chamomile”的问题，问题生成可能会提出关于chamomile与其它植物之间的关系、chamomile常见的用途、以及与chamomile相关的科学研究等后续问题。这种逐层深入的对话流能够帮助用户逐渐构建对数据集的综合理解，而不只是孤立地获取信息。

## 实体为基础的问题生成

实体为基础的问题生成更专注于对特定实体的探索。它利用相同上下文构建方法，整合实体、关联、协变量、社群报告和文本片段，以便于按时建立上下文，生成与数据集内容相关的高质量问题。这种方法特别适合在多文档或多数据源的场景下，为用户提供连贯的、相关性强的问题建议，促进了数据集的全面理解。

### 问题生成的配置

问题生成有以下关键参数：LLM（用于响应生成的OpenAI模型对象）、Context_Builder（用于从各种知识模型对象集合中准备上下文数据）、System_Prompt（用于生成候选问题的提示模板）、LLM_Params（用于LLM调用的额外参数）、Context_Builder_Params（用于Context_Builder在构建问题生成上下文时的额外参数）以及Callbacks（可选回调函数，用于提供自定义事件处理器）。

通过这些参数，用户可以灵活地调整问题生成的策略，以便更好地符合特定数据集和查询场景的需求，比如，改变LLM的温度参数可以控制生成问题的随机性和创造性，而调整Context_Builder_Params则有助于筛选出最相关的实体和关系，从而生成更具深度和洞察力的问题。

## 结论

问题生成是查询引擎中一种强大且实用的功能。它不仅能够提升数据探索的效率和乐趣，还能帮助用户构建连贯的对话，逐渐深化对数据集内容的理解。通过将实体、关系和文本片段的智能化组合，问题生成为用户提供了一个动态的、富有互动性的数据探索环境。"
"- How does the Graph Index play a pivotal role in the Graph RAG approach for efficient querying and analysis of relationships between entities?
用中文回答。","## 关于Graph Index在Graph RAG中的核心作用

Graph Index是Graph RAG（Retrieve-Augmented Generation结合图论）方法中的一个重要组成部分，对于在庞大文本语料库中进行高效查询和关系分析起到关键作用。Graph RAG方法在创建知识图谱索引上有着独到的见解，主要是通过连接实体及其关系的自然模态来分割数据，以实现全局总结的“分而治之”（divide and conquer）策略。以下详细阐述Graph Index在Graph RAG中的作用：

### 实体和关系的提取与社区检测

- **实体和关系提取**：Graph Index首先从原始文本中提取实体（如人物、地点或事件）及其之间的关系（如工作关系、家庭关系等）。这是一个至关重要的步骤，因为实体和关系构成了知识图谱的基础。
- **社区检测**：接下来，会在实体上执行社区检测，目的是划分出在图论空间中相互关联的实体集合。这些社区根据Leiden算法（一种用于大规模复杂网络的社区检测算法）来确定，它们涵盖了图谱中的所有节点，从而支持更深度的分析。

### 社区层次的总结

- **创建社区总结**：Graph Index会为Leiden层次结构中的每个社区生成类似报告的总结。这种总结不仅独立使用时极具价值，可以理解数据集的全局结构和语义，还可以用于响应全局查询。
- **组织总结**：总结的生成按照以下方式进行：
  - **叶级社区**：会优先级排序社区元素（节点、边和协变量）的总结，然后依次添加到大语言模型（LLM）的上下文中，直到达到令牌限制。排序策略是：按节点总度（即整体重要度）递减的顺序，添加描述源节点、目标节点、链接的协变量和边的信息。
  - **更高层级社区**：如果所有元素总结均能在上下文窗口的令牌限制内，则对所有元素进行总结，否则需要对子社区进行排序，生成最相关的信息。

### 索引的利用

Graph Index的创建使得在查询时间可以增强提示，这样可以显著提高回答复杂信息推理相关问题的性能。使用基于Graph Index的总结和社区报告，可以连接不同文本间的点，提供对整个文本文档集合的综合性及多样性回答，从而支持人类的推理或感知过程。这些基于图的索引化输出，结合Graph RAG其他部分（如实体关系图的生成），使得系统既能处理大量事件情节子图的序列化（通过叙事模板），又能在多重关系中导航。

### 计算与查询效率

即便是对于那些需要多次查询的相同数据集场景，根级别的社区总结在实体基础的图论索引中提供了数据索引，其相比智能RAG基线在计算成本上更经济，同时又能保持全球方法的竞争性性能。Graph Index通过更有效地管理计算预算和预期查询次数，为用户提供了一种权衡选项。

## 最后总结

Graph Index在Graph RAG中对于连接数据碎片以及跨大规模数据集提供合成见解方面表现出色。每一个实体和关系都为图谱添加了有意义的结构，而基于图的全局社区总结则让用户能够更好地理解数据集的宏观视图。这种方法克服了传统的向量相似性为基础的RAG技术的局限性，允许系统不仅回答问题，还解决了需要理解大量数据集中概念的关键挑战。因此，Graph Index不仅在查询和分析时提供更高的效率，还能为用户提供更全面、更深入的数据洞察。"
"- What are the limitations of the current evaluation approach for Graph RAG, and what future work is suggested to address these limitations?
用中文回答。","### 当前Graph RAG评估方法的局限性及未来工作的建议

#### 局限性概述
Graph RAG的当前评估方法主要限于考察特定类别的sensemaking问题，即寻求理解复杂信息时的问题，以及针对大约1百万个token的两个数据集。这种评估范围的局限意味着，我们尚未全面理解该方法在不同类型的问答、数据以及各种数据集大小上的性能表现。例如，实际应用中可能会遇到语音转文字后的数据、图像描述或非文本性数据源，这些都需要额外的研究来确定Graph RAG的有效性。同时，目前的评估没有使用类似SelfCheckGPT的方法（Manakul等人，2023）来明确比较fabrication rates，即方法生成的答案中有多少是基于事实的，这对于确保Graph RAG在所有场景下的可靠性是必要的。

#### 未来工作建议
为解决这些局限性，未来的工作建议如下：

1. **扩大问题类型和数据类型的研究**：应进行更广泛的实验以涵盖不同领域和格式的信息，包括但不限于技术文档、社交媒体帖子、学术论文和新闻文章，以及包含多模态数据（如图像和音频）的数据集。

2. **细致考察数据集大小的影响**：Graph RAG在小和中等数据集上的性能优异，但需要研究在大规模数据集上如何维持高效和精准的特性。这可能涉及到优化算法以更有效地处理大量复杂信息。

3. **改进方法的评估指标**：应开发更细致、更全面的评估指标，包括但不限于fabrication rates的直接测量。还应探索与人类评价员的比较，确保算法的逻辑和答案的可理解性。

4. **迭代改进知识图谱构建和查询机制**：在图索引的基础上，可以精炼算法，使它们在处理更局部的查询或通过混合RAG方案结合嵌入匹配和社区报告检索时更加高效。

5. **增强与终端用户需求的贴合度**：Graph RAG应进一步融入用户反馈，通过实际应用中的迭代测试来优化，确保算法的输出能够直接满足终端用户在自然语言处理任务中的需求，如理解特定企业文档或行业报告。

6. **开发和测试扩展机制**：“滚雪球”操作可以跨社区层次结构的更多层级进行扩展，通过“钻取”机制来跟随更高层级社区摘要中蕴含的信息线索，这将帮助用户更深入地探查数据集，从而提供更加针对性和上下文丰富的回答。

综合而言，虽然Graph RAG的现有评估表明该方法在complexity理解和提供详细信息方面具有显著优势，但研究还要继续深入，以确保其在更广阔的应用场景中的有效性和效率，同时增强与其他技术（如LLM和多模态数据处理）的协同效应用。"
"- How does the decision to invest in building a graph index depend on the value obtained from other aspects of the graph index in Graph RAG?
用中文回答。","在Graph RAG中，投资构建图索引的决策取决于几个关键因素，这些因素来自图索引的其他方面，可以提供额外的价值。下文将详细探讨这些因素：

### 计算预算
构建和维护一个图索引需要一定的计算资源，包括存储和处理大量文本以生成图数据结构的开销。如果可用的计算预算有限，那么评估构建图索引的成本效益就显得尤为重要。图索引的生成、更新以及查询算法的运行可能会消耗大量资源。因此，如果计算预算紧张，可能需要权衡图索引带来的好处和它对资源的需求。

### 预期查询数量
构建图索引的一个重要考量是预计每个数据集在有生之年的查询次数。如果一个数据集将频繁地被查询，那么构建图索引的代价可能会被长期节省的查询时间和提高的查询精度所抵消。另一方面，如果数据集的查询频率较低，那么构建图索引的初始成本可能比节省的查询成本更显著，这时可能需要更仔细地评估图索引的长期价值。

### 图索引的其他益处
Graph RAG的图索引不仅仅是用于回答具体问题的工具，它还提供了其他方面的好处。例如：

- **社区概况与摘要**：索引可生成通用的社区总结，这些总结可以提供对数据集的高层次理解，而不仅仅是对单个查询的响应。这在进行趋势分析、主题检测或数据集的概览分析时非常有用。
- **其他图相关的RAG方法**：Graph RAG集成了各种使用图结构的RAG方法。这包括检索衍生的图指标、事件剧情子图的序列化、以及利用图注解和查询匹配的本地RAG方法等。如果这些方法为特定的用例或查询类型提供了额外的优势，那么投资构建图索引就会更加值得。
- **图注解或层次社区结构**：图索引和从图中提取的注解可以为理解和解释复杂信息提供帮助。同时，分层次的社区结构可以提供不同粒度的信息，为深度分析和“钻取”操作提供支持。这些功能可能在涉及多层次分析或需要根据信息“香味”进行探索性查询时非常有用。

### 结论
投资构建图索引的决策在Graph RAG系统中依赖于计算资源、查询频率和图索引带来的额外价值。不同的因素会根据具体情况而改变，使得决策过程需要对这些因素进行综合考虑。如果图索引的其他方面可以显著增强数据集的理解、查询效率和数据的利用能力，那么构建和维护该索引的代价是值得的。然而，对于计算资源有限或数据集查询较少的场景，决策者需要慎重评估投资的必要性和预期收益，以确保图索引的建设符合整体成本效益分析。"
"- What is the relationship between Graph RAG and source texts in terms of summarization and question answering effectiveness?
用中文回答。","在评估Graph RAG和源文本在总结和问答有效性方面的关系时，我们发现Graph RAG与基于文本的源文本总结相比，提供了显著的改进，尤其是减少了必要令牌的数量，同时也保持了对用户理解广泛问题和主题至关重要的总结的全面性和多样性。Graph RAG方法建立在现有LLM之上，通过创建和维护实体知识图来增强模型的能力。它使用社区检测算法将图形分割成紧密相关的实体社区，然后为这些社区生成总结，为用户提供更高层次的架构，以理解和回答其查询（图1）。

### Graph RAG与源文本总结
Graph RAG使用两种方法来提高总结和问答的效率：

1. **令牌成本减少**：Graph RAG采用的根级社区总结（C0）能以超过97%的更少令牌提供与源文本总结可比的知识层面。这意味着它可以高效地保存输出长度，减少处理大量语料库所需的计算资源。

2. **信息的保留与检索**：与直译RAG相比，Graph RAG在全面性（72%的胜率）和多样性（62%的胜率）方面显示出优势。由于其利用图的自然模块化和社区检测算法，Graph RAG能够以较低的令牌成本高效地保留和检索相关细节（例如，具体实例、引用和注释），这是LLM推理中至关重要的具体知识来源。Graph RAG在信息检索的过程中能够保持更好的召回率和精度，为用户构建更深入的理解框架。

### 性能比较
评估表明，所有解决全局查询的方法——尤其是Graph RAG的中间层和较低层社区总结，其总结的全面性和多样性与源文本总结相当，而所需的令牌却更少。这有助于创建一个既包含详细信息又能有效处理的图索引，这在面对数百万个令牌的复杂数据集时尤为重要。

此外，Graph RAG在应对需要多次全局查询的场景时特别有效，一根级社区总结就提供了一个数据索引，其性能与其它全局方法相匹敌，而所需的令牌成本却大为降低。Graph RAG不仅在跟踪细粒度信息方面优秀，同时能更有效地利用资源来支持迭代性问答和感知构建活动。

### 限制与潜力
尽管目前的评估确定了在特定规模和特定问题类别的数据集上Graph RAG的效能，但其在不同数据类型、数据集大小和问讯类型之间的表现还需要进一步探索。评估方法的局限性和建议进行的前瞻性工作旨在探索Graph RAG方法的全面潜力，特别是在满足人类需求理解和跨领域解读的范围。此外，开发的令牌调优和社区总结生成策略将进一步增强Graph RAG的性能，使其更加灵活和适应用户需求，维持较低的计算成本同时提升信息的保留和检索效率。"
"- How are community summaries derived from source texts, and what is their purpose in providing a concise representation of the original content?
用中文回答。","## 社区摘要的生成及其目的

社区摘要是在保持原始内容核心信息的前提下，从源文本中提炼出的精炼表示。其生成过程包含以下几个步骤：

### 叶级社区 (Leaf-Level Communities)
1. **元素摘要优先级排序**：首先，依据节点的度数（重要性）对社区边（edges）进行排序，度数越大则摘要优先级越高。
2. **迭代添加至上下文窗口**：然后，逐步将排序后的边以及相关联的源节点、目标节点、边上的协变量描述添加到LLM（大型语言模型）的上下文窗口中，直到达到指定的令牌上限。这确保了生成的摘要包含社区内最重要和最相关的节点与边信息。

### 高层级社区 (Higher-Level Communities)
1. **元素摘要适配性判断**：若所有叶级社区元素摘要的总令牌数在上下文窗口的令牌上限内，则直接沿用叶级社区的方法，生成社区内的元素摘要。
2. **摘要优化与替代**：若总令牌数超出限制，将根据元素摘要的令牌数对子社区进行排序。接着，以降序方式迭代地用较短的子社区摘要替换较长的元素摘要，直至符合上下文窗口的令牌要求。这种方法确保了摘要能够覆盖社区的关键信息，同时不会超出模型处理的令牌上限。

社区摘要的**目的**：
- **理解全局结构与语义**：社区摘要有助于以更高层的视角理解数据集的全局结构和语义，为用户提供关于整体内容的主题概述。
- **优化信息检索**：通过将多层级的模块化社区描述提炼为摘要，可以有效促进信息的快速检索及理解。
- **助力查阅与探索**：用户可从高层摘要概览切入，根据兴趣查看更详细的子主题摘要。

综上，社区摘要的生成是一种基于重要性排序和摘要优化的方法，旨在以较小的信息代价实现对原始复杂数据集关键信息的完整表述和快速理解，极大地提升了LLM处理大规模数据集时的效率和信息覆盖范围。这对于在有限上下文中提供全面、多元的回答，有着重要的作用。"
"- What is the role of the .env file in storing environment variables referenced in the settings.yaml file for Graph RAG?
用中文回答。","在使用Graph RAG时，`.env` 文件扮演着一个至关重要的角色，用于存储系统运行所必需的环境变量。这些环境变量在 `settings.yaml` 文件中被引用，以便在运行Graph RAG管道或执行其他操作时动态地插入特定的值。例如，`graphrag_api_key` 变量，在初始化项目时创建的 `.env` 文件中定义，它可以被用作向Graph RAG提供OpenAI API或Azure OpenAI端点所需的API密钥。

当您加载了 `.env` 文件，系统在解析 `settings.yaml` 文件时，可以使用 `$ {env_var}` 的语法将定义在 `.env` 文件中的环境变量值插入其配置文档中的适当位置。这种机制允许您在不直接修改配置文件的情况下修改敏感数据或动态更新设置，这在开发和生产环境中都非常有用。

默认配置模式（使用 JSON/YAML）
默认配置模式为Graph RAG用户提供了简单的配置方案，使系统开箱即用。您可以通过以下几种方式主要设置Graph RAG：

- 通过初始化命令轻松配置（推荐）
- 使用环境变量的纯环境变量配置
- 通过使用具有 $ {env_var} 语法的JSON或YAML文件进行深层控制配置。

初始化Graph RAG
为了开始使用Graph RAG，您需要先配置系统。推荐的使用初始化命令的方式最为简单。它会在指定目录中创建 `.env` 和 `settings.yaml` 文件，包含运行系统所需的所有必要配置设置。同时，该命令还会输出Graph RAG使用的默认LLM（语言模型）提示。您可以对这些文件进行修改，以根据您的数据和需求调整提示或设置。

自定义配置模式
自定义配置模式是一个更高级的使用场景，需要您对系统功能进行更精细的调控。与默认配置模式相比，大部分用户会倾向于仅使用`.env` 文件和默认的 `settings.yaml` 文件。但是，如果您有特定需求，自定义配置允许您在 Python 代码或 YAML 文件中表达详细的配置选项。在自定义配置模式下，您可以通过覆盖默认设置或定义更具体的细节来更改系统的参数，为您的数据和需求提供更个性化的服务。

使用Graph RAG CLI（命令行界面）
在成功初始化项目后，Graph RAG CLI 是一个可以用于运行查询、索引和自定义LLM提示的工具。使用CLI时，系统会应用在初始化过程中设置的配置，使用您更新的 `.env` 和 `settings.yaml` 文件中的变量和设置。您可以将CLI视为与系统交互的简化界面，它允许您通过简单的命令执行复杂的操作。

总之，`.env` 文件是Graph RAG系统的一个关键组成部分，它用于存储环境变量，这些变量在整个配置流程中起着至关重要的作用。通过维护和自定义这些配置文件中的变量，您可以轻松地更改系统行为、适应数据特性或集成新的API密钥，从而简化配置流程，并为您的项目提供所需的灵活性和安全性。虽然对于新手用户推荐保持在默认配置，但自定义配置模式下，有经验的用户可将 `.env` 和其他自定义配置文件用于更复杂的设置。请务必弄清楚适合您的项目所需的最合适的配置方法和流程。"
"- How does the settings.yaml file store configuration settings necessary for the operation of Graph RAG?
用中文回答。","### 图形 RAG 的 settings.yaml 配置文件详解

`settings.yaml` 文件是 Graph RAG 操作中的核心组成部分，它包含了一系列配置参数，用于指导 Graph RAG 执行数据索引和后续查询的流程。初始化 Graph RAG 时，通过 `python -m graphrag.index --init` 命令，系统会在指定目录下创建 `settings.yaml` 以及 `.env` 文件，用以存储环境变量和系统设置。

`settings.yaml` 文件大致分为以下几个关键部分：

1. **环境变量**
   - 首先，`settings.yaml` 文件引用 `.env` 中的环境变量。例如自动填充的 `graphrag_api_key`，它是 OpenAI API 或 Azure OpenAI 端点所需的 API 密钥。

2. **主配置节**
   - 此文件存储了涉及 Graph RAG 索引引擎的主配置节，包括有关聊天和嵌入端点的详细信息。例如，Azure OpenAI 用户需要在 `settings.yaml` 中设置以下变量：

   ```yaml
   type: azure_openai_chat # 或者为 azure_openai_embedding 用于嵌入 API
   api_base: https://<instance>.openai.azure.com
   api_version: 2024-02-15-preview
   deployment_name: <azure_model_deployment_name>
   ```

3. **默认配置**
   - 使用默认配置模式是大多数用户开始使用 Graph RAG 最简便的方式。通过创建一个 `config.json` 或 `config.yml` 文件在数据项目根目录中即可实现。如果同时存在 `.env` 文件，会加载文件中定义的环境变量，然后在配置文档中使用 $ { env_var } 语法进行访问和替换。

4. **提示配置**
   - `settings.yaml` 文件还控制了用于生成知识图谱的 LLM（语言模型）提示。用户可以修改这些默认提示，甚至运行自动提示调整命令以生成适应数据的新提示。
   
5. **缓存控制**
   - 文件中可设置是否使用缓存机制。默认情况下，Graph RAG 会将结果缓存起来，但如果在开发和调试阶段，可以使用 `--nocache` 选项禁用缓存。
   
6. **索引管道设置**
   - 通过 `settings.yaml` 文件，用户可以调整多个设置，用以优化索引管道流程，如输入数据大小、使用的模型以及文本块大小等。
   
7. **输出和展示**
   - 索引引擎的输出会被配置在这个文件中。通常，完成索引后，你将在指定输出目录找到一系列 Parquet 文件，这些文件包含了索引数据。

### 小结

如要深入使用 Graph RAG 或修改其默认行为，就必须对 `settings.yaml` 文件内各个配置节进行自定义设置。使用默认配置时，仅需修改 `.env` 文件中的环境变量。在自定义模式下，用户则可通过编辑 `settings.yaml` 文件来指定模型、API 版本、数据目录等重要的配置详细信息。对于更复杂的需求，如高级提示配置以及索引管道的参数微调，都可在这相同文件中找到相应的配置说明。

在配置完成后，只需执行 `python -m graphrag.index --root /path/to/ragtest`，即可启动索引过程，并且在短时间内，具体针对输入数据量，通过 `""@path/to/ragtest/output/<timestamp>/artifacts""` 目录下的 Parquet 文件，工具将对数据进行处理和建模。针对查询引擎的运行，也可以通过 `python -m graphrag.query \\ - - root /path/to/ragtest \\ - - method global \\ "" what are the top themes in <input data>"" ` 命令进行高程度的自定义查询。

### 最终用户操作指南

对于新用户或初次配置的场景，推荐使用 `--init` 命令。但是，对于那些希望深入探索或针对特定需求调整工作流程的高级用户，提供丰富且详细的配置选项，确保 Graph RAG 可以适应各种使用场景。无论初学者还是熟练的用户，`settings.yaml` 文件都是一个无缝集成和执行所有必要配置的关键部分。"
"- What is the significance of Global Search in the Graph RAG process for reasoning about holistic questions concerning the entire corpus?
用中文回答。","## Graph RAG中的Global Search的重要性

在Graph RAG（基于图的可检索增强生成）过程中，全局搜索（Global Search）扮演了一个非常关键的角色，尤其是当我们需要对涉及整个文档集的高级问题进行推理时。全局搜索的方法能够通过在所有生成的社区报告上执行搜索，从而获取到对整个数据集的理解，从而生成更全面的答案。这种策略是资源密集型的，但它对于理解数据集整体主题和关键实体尤其有效。

### 背景

Graph RAG将非结构化文本转换为结构化数据，通过实体识别、关系提取、社区检测等一系列步骤，最终形成知识图谱。这些社区报告是从知识图谱中生成的，它们总结了特定社区或群体内的实体、关系和属性，从而提供对整个数据集的细分级别理解。

### 全局搜索的运作机制

全局搜索并非仅仅依赖于文本的相似度，而是利用了所有AI生成的社区报告，通过一个映射-归约（Map-Reduce）过程来搜索。这种方法充分利用了图的自然模组性，根据问题的需要检索适量的数据。对于涉及整个文档集合的问‌题，这种方法能够获取准确而全面的上下文，既涵盖关键词信息，又不遗漏重要的细节。

### 性能优势

与基于文本的原始RAG方法相比，全局搜索下的Graph RAG在许多情况下表现更优。根据初步的评估，在理解和回答全局意义的问题时，Graph RAG方法在答案的全面性和多样性方面显示出实质性的改进，同时在效率上也更为突出。与类似方法相比较，根级别社区（C0）的Graph RAG要求的上下文标记数量减少了97%以上，为迭代问题回答提供了高效的方法，同时保留了处理数据集全面性时的优势。

### 总结

全局搜索是Graph RAG处理高层次、数据集范围的问题的关键方法。它不仅提高了搜索的效率，而且生成了更全面、更具有多样性且与问题紧密相关的答案。对于那些需要深入理解整个文档集的问题，利用Graph RAG的全局搜索可以提供显著的性能提升和成本节约。

尽管当前评估中，Graph RAG的全局搜索方法在少数情况下与基于文本的全局方法性能相当，但综合性能、全面性和回答问题的效率，这种方法是更加优选的。随着Graph RAG系统的不断发展和优化，预计将在更广泛的问题类型、数据类型和数据集规模上展示出其独特的优势。

## 限制与未来方向

至今为止，Graph RAG的评估仅覆盖了特定类型的问题和大约百万级别的文本范围。要进一步验证其在不同用户体验和具体目标查询中的效能，需要进行更深入和全面的研究。比如，可以考虑使用类似selfcheckGPT的方法来对генeration结果的准确性进行更细致的调查，以了解可能存在的偏差或错误。此外，关于图谱在何种情形下比文本能更优地捕捉数据集精髓的进一步实证研究也极为重要。

在这个概念验证阶段，虽然Graph RAG的技术路线图已经非常清晰，但系统仍在持续进化，我们期待它能够提供更加精确和自然的查询回答。对于正在尝试理解大规模文档集或知识库中隐藏模式和结构的用户来说，Graph RAG是一个强大的工具。随着它的发展，无疑将为基于RAG的系统中带来更深层次的理解和更丰富多样的交互体验。"
"- How does Graph RAG employ the global search method to process user queries using LLM-generated community reports as context data?
用中文回答。","## 全局搜索方法概述

Graph RAG（基于图的检索增强生成）的全局搜索方法是一个数据流过程，它利用LLM（大型语言模型）生成的社区报告作为用户查询的上下文数据。这些社区报告是从图的社区层次结构的特定层级中抽取出来的，这些报告详细地概述了大规模数据集的多个主题和概念。以下是如何使用这些社区报告进行全局搜索的详细步骤：

### 1. 数据准备阶段（Map 阶段）
- **多批社区报告的整合**：从社区层次结构中提取的社区报告会被组合成一个大的数据集。这些报告内容丰富，覆盖了不同的领域或子主题。
  
- **文本分块与响应生成**：每个社区报告会被分割成预定义大小的文本块。这些文本块随后用于生成名为“中间响应”的数据，每个中间响应包括一系列要点，每个要点旁边附有一个数值评级，用来衡量其重要性。
  
- **并行处理**：map 阶段还涉及并行处理多个文本块的中间响应，通过调控`concurrent_coroutines`参数控制任务的并行度。这可以显著提高响应生成的效率。

### 2. 聚合与筛选阶段（Reduce 阶段）
- **筛选关键信息**：从map阶段生成的中间响应中，通过过滤算法挑选出最重要的要点。这能确保最终生成的响应中包含用户最需要的信息。
  
- **汇总上下文**：筛选出的关键信息点会被聚合，然后用于构建一个更紧凑的、特定主题的上下文。这部分上下文会被用来生成最终的用户查询回答。
  
- **用户查询响应**：最终，这个包含精选关键信息的上下文会被用作基础，通过预先设定的系统提示模板，LLM根据用户查询和可选的会话历史生成最终响应。

## 如何优化全局搜索方法的性能
全局搜索的响应质量强烈受到用于社区报告的社区层级选择的影响。以下是层级选择在不同情况下带来的差异：

- **层级选择的重要性**：选取较低层级的社区报告层级，可以提供更详细的报告和更全面的上下文。然而，这也会增加最终响应生成的耗时和资源消耗，因为它涉及处理更多的社区报告数据。
  
- **适应性调整**：通过在Graph RAG的`GlobalSearch`类中配置不同的参数（如`llm`、`context_builder`、`map_system_prompt`），可以定制搜索的方式，从而调整中高级响应的重要性、处理并行度及事件流的回调处理。

## 效果示例和对比

### 基于Graph RAG的比较
通过利用Graph RAG的全局搜索方法，试验研究表明，与基于向量相似性的RAG（检索增强生成）方法相比，Graph RAG在处理需要跨多个信息片段或大文档数据集的主题理解和综合洞察的任务上表现出显著优势。此外，Graph RAG在回答与连接图中实体有关的问题时，能够更高效地利用上下文标记，降低了与低层级社区汇总相比的97%以上的消耗（在c0层级），仅在性能上稍有减让而保持了更高的全面性和多样性。

### 功能调整和未来改进
Graph RAG的方法可以根据用户需求和场景进行调整。例如，优化元素抽取提示可能有助于在保留图中的更多细节和信息（相比之下，原有的RAG方法可能弱化具体例子、引用和来源的利用）时，调整模型的召回率和精度。此外，运用Graph RAG进行全局搜索在会话历史中提取实体，发现与输入相关联的实体及其深入信息，可以提供相关文本块和中间层社区报告以创建响应。

总之，Graph RAG的全局搜索和本地搜索方法，都致力于提升LLM回答特定和综合性问题的能力，同时考虑了效率、复杂性理解以及全面性指标。通过调整层级选择和参数配置，可以优化结果，以更好地适应不同的查询需求和场景。随着对方法的持续改进，Graph RAG旨在提供更高效的处理能力和更深度的主题洞察。"
"- What is the role of the prompts/ directory in storing default prompts that can be modified or new ones generated through the Auto Prompt Tuning command in Graph RAG?
用中文回答。","在Graph RAG中，`prompts/`目录扮演了存储默认提示字符串的角色，这些提示字符串被用于驱动系统进行知识图谱的生成。默认情况下，该目录内包含了几个设计精良的提示字符串，旨在适应广泛的知识发现场景。用户可以根据自己的具体需求修改这些默认提示字符串，或者通过运行Auto Prompt Tuning命令来生成更加针对性的新提示字符串。

### Auto Prompt Tuning命令的使用
Auto Prompt Tuning是一个可选但强烈推荐的功能，它能够为知识图谱的生成创建领域适应的模板。此命令会根据输入数据，将其分割为大小由参数`chunk size`定义的文本块（单位），然后从中挑选文本块来生成最终的提示字符串。命令主要包括以下选项：

- `- - root`：项目数据的根目录。
- `- - domain`：数据所属的领域，例如“环保新闻”。
- `- - method`：用于挑选文本块的方法，可以是随机（`random`）、头部文本块（`top`）或者是所有文本块（`all`）。
- `- - limit`：用于Auto Prompt Tuning的文本块数量限制。
- `- - language`：数据所用的语言。
- `- - max - tokens`：每一次语言模型调用的令牌数量上限。
- `- - chunk - size`：文本块的大小。
- `- - no - entity - types`：若指定，将不在生成的模板中包含实体类型信息。
- `- - output`：生成提示字符串的输出目录，默认为`prompts/`。

### Auto Prompt Tuning后的环境变量修改
在Auto Prompt Tuning运行后，推荐用户修改以下环境变量，确保在Index Run中使用到新的提示字符串：
- `graphrag_entity_extraction_prompt_file`：实体提取提示字符串的文件路径。
- `graphrag_community_report_prompt_file`：社区报告生成提示字符串的文件路径。
- `graphrag_summarize_descriptions_prompt_file`：实体或关系描述总结的提示字符串文件路径。

这些变量的默认值应指向`prompts/`目录内的相应文件。

### 额外的提示定制
除了Auto Prompt Tuning，用户也可以通过修改`prompts/`目录下的文本文件来自定义提示字符串。Graph RAG利用`{ token _ name }`格式的令牌替代，其中部分提示源令牌如下：
- 输入文本（`input _ text`）：用于处理的输入正文。
- 实体类型（`entity _ types`）：实体类型列表。
- 元组分隔符（`tuple _ delimiter`）：用于元组内值的分隔。
- 记录分隔符（`record _ delimiter`）：用于分隔元组实例。
- 完成分隔符（`completion _ delimiter`）：表示生成结束的标识。

### 总结
总而言之，`prompts/`目录中的默认提示字符串为Graph RAG的默认行为提供了基础支持，用户可以通过修改这些提示字符串或运行Auto Prompt Tuning命令以适应特定数据集和需求，从而提高知识图谱的生成质量。通过控制环境变量和修改提示文件，用户可以灵活地调整系统的行为来获得最佳的图谱生成效果。"
"- How does Graph RAG's performance compare to Baseline RAG in managing intricate data and reasoning about private datasets?
用中文回答。","### Graph RAG相较于Baseline RAG的性能优势

Graph RAG（基于图的检索增强生成）作为一种先进的技术，相较于Baseline RAG（即基于向量相似性的简单检索增强生成）在管理复杂信息和推理私有数据集时表现显著优越。Graph RAG利用知识图谱赋能模型，有效解决了Baseline RAG在连接点间的挑战，即当回答问题需要从分散信息中通过共享属性建立联系以综合新见解时，Baseline RAG存在明显的弱点。

### 知识图谱提高模型理解能力

知识图谱的使用使得Graph RAG在理解汇总概念、处理大量数据集合或单一的大型文档时，具有全局视野和深入洞察的能力，即使没有直接训练这些特定信息，模型也能展现出高水准的理解力和推理能力。这一技术优势使得Graph RAG能够弥补Baseline RAG在全局理解上的缺陷，提供更全面和多样的问题答案，同时在构建查询时的令牌成本方面展现出高效性。

### 高性能和高效性

在对Graph RAG进行全面测试的结果显示，相对于Baseline RAG，Graph RAG在回答那些需要模型理解复杂信息结构和推理问题上，使用了较少的上下文令牌，具体而言，在root级社区摘要（C0）上，Graph RAG的令牌成本减少了超过97%。而性能上的适度牺牲，使得Graph RAG成为迭代问题回答中的高效解决方案，同时保持对Baseline RAG在答案全面性和多样性上的优势。这意味着Graph RAG不仅能够理解问题，还能从不同的角度和深入层面提供解答。

### 相关工作回顾

细数现有RAG（Retrieval-Augmented Generation）技术的进展，Graph RAG不仅借鉴了事件图检索（如SURGE和Graph-Transformer）的迭代和多层次回答策略，还与其他技术如LangChain、LlamaIndex的图数据库支持有所交集，尽管这些系统未利用图的自然模块化进行全局摘要，Graph RAG在这方面独具特色。

### 总结与局限性探讨

Graph RAG在数据密集型问题和私有数据推理方面展现出过人优势，但目前的评估仅局限于一定类别的概念理解问题及百万级别文本语料库。为了深入了解其在不同问题类型、数据类型和数据集大小上的适应性，以及如何平衡图谱构建的成本和价值，未来的研究还需要通过更多的实证分析来验证Graph RAG的效能与适用范围。

通过限制实验和进行全面的性能对比，可以看出Graph RAG在处理复杂推理和全局理解问题时，显著提升了模型能力和回答质量，同时在高效性上也优于Baseline RAG。这些发现为基于LLM（Large Language Models）的工具提供了新方向，以实现对私有数据集的高效和准确理解。"
"- What is the role of GPT-4 Turbo in generating knowledge graphs from text data in Graph RAG?
用中文回答。","### Graph RAG中的GPT-4 Turbo角色：生成知识图谱

在Graph RAG方法中，GPT-4 Turbo扮演了核心角色，用于从原始文本数据构建知识图谱。Graph RAG是一种层次化的、结构化的检索增强生成（RAG）方法，它主要通过以下步骤实现：

1. **提取文本单元**：首先，将输入文档分割为多个文本单元，这些单元是随后处理的基本单位，长度可以根据特定需求调整。文本单元的大小会影响到实体识别和关系抽取的效率和准确性。

2. **实体、关系和主张提取**：每个文本单元都通过GPT-4 Turbo进行分析，以识别和提取图谱的三个核心组件：实体、关系以及主张（若适用）。在这个步骤中，实体和关系通常被同时抽取，而主张则可能在专门的流程中被抽离出来。

3. **子图合并和总结**：提取的实体和关系随后被合并形成子图。如果多个文本单元提到了同一个实体或关系，它们的描述会被合并，以创建一个包含所有不同信息的数组。之后，GPT-4 Turbo被用于将数组中的描述总结为单个描述，以实现更紧凑、更具概括性的图谱。

4. **实体解析**：在该步骤中，GPT-4 Turbo用于识别和解析那些实际代表同一实体但名称不同的情况，确保知识图谱的精确性和一致性。尽管这是一个可选步骤（默认不启用），但通过LLM（如GPT-4 Turbo）进行实体解析，可以使图谱更全面地反映现实世界实体的多个命名。

GPT-4 Turbo在上述过程中是不可或缺的，它不仅能够从文本中抽取出丰富的实体和关系，还能够实现对这些信息的有效总结，从而使知识图谱更加高效、准确和有用。通过使用GPT-4 Turbo构建图谱，Graph RAG方法相比于仅依赖文本摘录的RAG技术，能提供对复杂信息集更深层的见解和理解。

### 总结

GPT-4 Turbo在Graph RAG中担任了生成知识图谱的角色，它通过高效地从文本数据中提取实体、关系和主张，并对提取结果进行总结和解析，构建出了对原始数据具有综合性和多元化的图谱。此图谱进一步被用作检索和生成流程的一部分，增强了RAG在深度推理和理解复杂文本集方面的能力。与传统RAG方法相比，Graph RAG显示出在回答涉及多步逻辑和理解大量语料库或单一大量文档的综合概念的问题时的显著优势。GPT-4 Turbo的运用是Graph RAG实现这些技术提升的关键环节。

### 未涉及的领域

根据数据表中的信息，GPT-4 Turbo在生成知识图谱方面的应用已得到了详细说明。然而，对于其他方面的利用，如知识图谱的遍历与查询、基于图谱的多跳推理等，数据表没有提供具体细节。这些是GPT-4 Turbo经过进一步开发和实验应用的潜在方向，特别是在更高级别的图谱操作和多模态信息处理上。

### 结论

GPT-4 Turbo是Graph RAG方法中构建知识图谱的核心技术，从原始文本数据中抽取实体、关系和主张，到生成集中精炼的描述和实体解析，全方位提升了信息获取的效率与准确性。此方法不仅优化了RAG在处理复杂信息集上的表现，同时增强了对综合概念的理解和表达能力。尽管GPT-4 Turbo在多个环节被使用以增强图谱的构建，但有关其在更广泛领域的应用尚需进一步探索。"
"- How does the Microsoft Research Blog Post provide information about Graph RAG and its applications?
用中文回答。","## Graph RAG 概述与应用

在最近的微软研究博客文章中，Graph RAG 在多个方面被详细探讨。Graph RAG（ Расширенное Генерирование с Восстановлением Информации на Графах ）结合了知识图谱和大型语言模型（LLM）来应对文档数据超越LMM上下文范围问题的挑战。Graph RAG 采用LMM 抽取语料库中的实体和关系，用于生成一个知识图谱，此图谱主要用于回答查询时作为上下文的补充。

### Graph RAG 的独特之处

Graph RAG 与其他RAG（ Retrieval-Augmented Generation ）方法不同的关键在于它利用图的自然模块化来分割数据进行全局摘要，而不仅仅是提取基础文本。这一改进使得Graph RAG 在遍历同一数据集的多次全局查询时，能够比其他方法更高效地进行。在文本数据量增大(如 hotpotqa 数据集)时，Graph RAG 在提取实体引用方面显示出了相对其他方法更高的性能。

### Graph RAG 对比原始RAG 的优势

原始RAG 通常会出现连接信息点困难的情况，在处理需要多跳推理的问题时存在着根本缺陷，而在回答需要全局理解的问题组合时变得更加明显。Graph RAG 的知识图谱索引能够通过其固有的结构在信息的搜集整合、关系抽取和概念构建上呈现出超出常规RAG 的卓越表现。

在同一个数据集连续查询的情况下，与同类型方法相比，Graph RAG 在答案的完整性和多样性方面具有很高的优势。而且，其使用成本更低。在最高效的情况下，使用根级别汇总后的Graph RAG 过程可以将上下文令牌成本减少97%以上，而与源文本摘要相比，其性能仅略有下降。这意味着信息量大、涵盖广泛的汇总资源能够以较低的代价进行迭代式问答，这是人类寻求解惑过程的基本特征。

### Graph RAG 的工作流和设计参数

在Graph RAG 的工作流中，源文档先被拆分为文本块，随后这些文本块被传递给一系列LLM 提示以提取图索引的各个要素。提出的细化设计参数之一是文本块的粒度，这是抽取输入文本的基本决策过程。文本块的长度需在召回率和精确率之间找到平衡。从测试结果来看，在单次抽取环节，相较于较大的文本块，较小的文本块（600字节的文）能够提取两倍的实体引用，使提取过程更加全面。

### 与现有相关工作的对比

Graph RAG 从多角度改进了RAG 系统，如利用域适应性模板自动分配描述生成知识图谱。与现有方法如贝基的GATOR 和 G-ReT.REeVER 或者 ext İki PaBits h 等相比，Graph RAG 不仅更灵活地处理复杂众多的数据类型，而且在多样性、时间效率和效果等方面具有显著优势。最终结果是在解决困难的连贯性理解问题时，Graph RAG 的问答系统可以超越LLM 和其他RAG 方法，提供更高质量的见解和发散方向。

除了这些特定优点，Graph RAG 的应用范围还覆盖了多类型事件-情节子图的串行化手段的优化和支持。这使得提问和答问过程不仅局限于文档内部，亦能够在整个图数据库中自由游走。Graph RAG 还提供了易于理解和实用的开放源代码Python实现，该实现目前针对两种规模的图自底而上和迭代归纳方法进行了优化和应用，并可应用于1万字以上的文本量。

Graph RAG 是一个新兴的前沿工作领域，出现了多种不同的概念和方向。未来的研究将着重于探索这些方法在不同语料库和问题类型上的影响，深化Graph RAG 系统在实用性、可操作性和环境适应性等方面的发展。在与原始RAG 方法的对比中，微软研究的Graph RAG 展示了其在问答能力上的卓越性能，为增强自动驾驶能力提供了智能和解释功能。"
"- What resources are available in the GitHub Repository for developers who want to access and contribute to the Graph RAG project?
用中文回答。","在Graph RAG项目的GitHub仓库中，开发人员可以访问一系列资源以开始使用和贡献代码。下面是一些关键资源的概述以及如何使用它们的指示：

### 1. **Poetry安装与项目依赖**

项目基于Python 3.10到3.12，使用Poetry进行包管理。开发人员可以通过以下命令安装依赖项：

```bash
poetry install
```

为了运行数据索引引擎，可以使用以下命令：
```bash
poetry run poe index
```
### 2. **Azurite资源仿真**

单元和烟雾测试使用了Azurite来模拟Azure资源。如果已经在全局安装了Azurite，直接在终端运行`azurite`命令即可。否则，需要运行：
```bash
./scripts/start-azurite.sh
```
Azurite的文档提供了更多关于安装和使用的信息。

### 3. **生命周期脚本管理**

Poethepoet为Python包提供了生命周期脚本管理功能。可用的脚本包括：
- `poetry run poe index`：运行索引CLI。
- `poetry run poe query`：运行查询CLI。
- `poetry build`：构建分布工件，如轮子文件。
- `poetry run poe test`：执行所有测试。
- `poetry run poe test_unit`：执行单元测试。
- `poetry run poe test_integration`：执行集成测试。
- `poetry run poe test_smoke`：执行烟雾测试。
- `poetry run poe check`：对包进行静态检查，包括格式化、文档格式化、 linting、安全模式、类型检查等。
- `poetry run poe fix`：对包应用自动修复，通常仅限于格式化修复。

### 4. **配置与初始化命令**

要开始使用Graph RAG，需要进行系统配置。初始化命令`python -m graphrag.index --init --root_path`可以在指定目录中创建必要的配置文件。`root_path`默认为当前目录。以下是创建的文件类型：
- `settings.yaml`：包含Graph RAG配置设置的文件。
- `.env`：环境变量文件。
- `prompts/`：默认的LLM（大型语言模型）提示文件夹。可以根据需要进行修改或通过自动提示调整命令生成适应数据的提示。

### 5. **索引和查询Python库**

Graph RAG项目提供了一个Python库，支持索引和查询操作。该库基于自动生成的图索引以及实体和文档之间的层次关系。此库在预处理数据生成图结构方面尤其有效，并支持人类对大量文本语料库的理解。

### 6. **自适应和手动配置**

项目提供了默认的LLM提示，设计用于抽数和关系。自适应模板生成（auto templating）则从输入数据和LLM交互中创建更符合域的模板，用于知识图谱的生成。虽然手动配置是一种更高级的用例，但多数用户应该使用自适应功能，以达到更佳的结果。

### 7. **更多信息和学习资源**

- **最初评价结果**：Graph RAG相对于naive RAG基线、全面性和多样性答案方面初始评价显示出重大改进。与使用map-reduce源文本总结的全局方法相比，获得了有利结果。
- **开源代码库**：Graph RAG的开源实现、source documents和text-chunks处理、graph Raspi.Generation和Query-Augmented Generation的一些相关研究。这可以帮助开发人员了解Graph RAG的运行原理及其在不同数据集和情境中的效果。

通过这些资源，开发人员可以开始探索Graph RAG项目的功能，理解其架构和设计决策，以及进行自己的贡献和扩展。建议所有用户在开始使用前，先运行自动提示调整命令以优化他们的数据。配置文档提供了执行索引运行所需的详细指南，为理解项目提供了基本入口。"
"- What research papers and documentation related to Graph RAG can be found in the GraphRAG Arxiv repository?
用中文回答。","在GraphRAG的Arxiv资料库中，虽然没有直接列出所有相关的研究论文，但提供了若干关键的参考和说明，涉及Graph RAG方法的详细阐述和其实现细节。以下是从资料中收集到的信息概览：

### GraphRAG方法概述
GraphRAG（Graph Retrieval-Augmented Generation）使用知识图谱来增强LLM（Large Language Model）在处理复杂信息时的问题解答能力。这是一个重要的进展，旨在解决传统的RAG方法在连接分散信息、处理大规模数据集合上的局限性。

### Indexer子系统
与图相关的资料库工作主要集中在图指数创建和使用LLM处理图数据。这包括利用LLM进行图谱创建（Trajanoska等，2023）和图谱补全（Yao等，2023），以及从源文本中提取因果图（Ban等，2023; Zhang等，2024）。GraphRAG方法利用自动生成的图指数，这使得它在处理多轮问题（Multi-Hop Question Answering）以及在大规模数据集上的表现上优于其他方法。

### Query子系统
GraphRAG还利用图结构的子集或衍生的图指标作为调查对象，这在G-Retriever（He等，2024）、Graph Toolformer（Zhang，2023）等工作中有所体现。叙事输出如SURGE（Kang等，2023）和通过Fabula（Ranade和Joshi，2023）将事件-情节子图利用叙事模板进行序列化，表明了方法在增强LLM输出时的潜力。然而，GraphRAG利用了图的自然模块性，将数据分割成多个社区，这样可以进行更全局的_summarization_——这是前述系统所不具备的。

### 其他技术方向与评估
资料库还提到了图数据库在Langchain和Llamaindex库中的应用，支持包括Neo4j和Nebula Graph格式在内的知识图谱创建与推理。GraphRAG的方法到目前为止仅在约1百万标记的两个语料库上评估了一定类别的问题，需要更多研究来理解和验证不同问题类型、数据类型、数据集大小的性能。

### 评价与局限性
在不同方法的对比中，Graph RAG在许多情况下显示出最佳的头与头结果。尽管如此，这种方式在构建图指数时存在权衡，需要在LLM调用数量、提取召回率和摘要文本的间距成本之间找到平衡。同时，评价到目前为止仅限于某些类别的理解问题，和有限的语料库大小。

### 结论
GraphRAG Arxiv资料库涉及前沿研究，如图谱创建和LLM应用，更具体来说，Graph RAG的方法展现出令人印象深刻的性能，在理解和概括源文本的复杂信息上尤其突出。然而，这些研究和方法仍然处在发展阶段，并且其应用范围和潜在局限性需要进一步探究。对于有兴趣探索这一领域的研究人员和开发者，可以深入阅读相关的参考文献和技术文档，以获得更多信息和灵感。 stylize 了回答以符合要求的文本样式，同时保持回答的准确性和完整性。"
"- How does the Solution Accelerator package provide a user-friendly end-to-end experience with Azure resources for quickstarting the Graph RAG system?
用中文回答。","在开始使用Graph RAG（检索增强生成）系统时，解决方案加速器包确实提供了一个用户友好的端到端体验，尤其当涉及到Azure资源时。为了理解这一点，我们可以通过以下几个步骤来深入探讨这个包是如何简化和加速Graph RAG系统集成的。

### 解决方案加速器包的端到端体验
解决方案加速器包主要通过以下几个方面简化了Graph RAG系统的使用：

1. **预配置的环境和资源**：加速器包预先配置了必要的环境变量和Azure资源，这样你就不需要从头开始设置复杂的配置。这包括Graph RAG API密钥，以及用于数据索引、查询处理和机器学习输出的必要Azure服务。

2. **自动化设置脚本**：通过运行`graphrag.index --init --root ./ragtest`等脚本，可以自动创建必要的环境文件（如`.env`）和配置文件（如`settings.yaml`），并注入所需的配置变量，这样你就不用手动编辑这些文件了。

3. **模板化和自适应调优**：包还包含了模板化和自适应调优功能，可以更高效地生成知识图谱。例如，`graph rag with intermediate- and low-level community summaries`可以确保在处理大型数据集时，通过总结关键社区信息来减少令牌成本，提高回答的全面性和多样性。

### 集成Graph RAG与Azure资源
在使用加速器包与Azure资源进行集成时，以下步骤简化了此过程：

- **安装Graph RAG**：可以通过运行`pip install graphrag`命令简便地安装Graph RAG库，无需进行复杂的软件包管理和版本兼容性检查。
- **设置数据输入**：创建输入数据目录，如`mkdir -p ./ragtest/input`，并准备样本数据文件，如通过`curl`命令获取的《圣诞颂歌》文本。这部分主要是为接下来的索引过程做准备。
- **索引构建流程**：运行如`python -m graphrag.index --root ./ragtest pipeline`的命令，自动执行一系列复杂的索引流程，包括实体和关系的提取、描述生成、声明提取以及社区报告自动生成。所有这些都可以通过单个命令按照预先配置好的流程自动完成，减少了手动处理多个步骤的需求。
- **查询引擎使用**：通过执行`python -m graphrag.query --root ./ragtest --method global ""What are the top themes in ... `的命令，可以立即开始使用索引数据集来回答问题。这里的`--method global`参数指示查询引擎在整个数据集上进行全局搜索，寻找最相关的答案。

### 结论
总之，为了快速启动Graph RAG系统，解决方案加速器包通过自动化配置、处理和查询步骤，极大地减少了用户手动设置和管理资源的复杂度。它不仅提供了与Azure资源无缝集成的路径，而且还通过自适应调优和高级搜索技术，优化了调用Ai模型的成本和结果质量。更重要的是，它为用户提供了一个平台，即便是对知识图谱或AI技术不太熟悉的人也可以快速上手，通过简单的命令开始利用Graph RAG系统增强其自然语言处理应用程序。对于那些正在寻求将私有数据集与AI生成内容结合的企业，解决方案加速器是一个值得尝试的强大工具。"
"- What is the purpose of the Get Started Guide in familiarizing users with the features and functionalities of Graph RAG?
用中文回答。","在熟悉Graph RAG的特点和功能方面，开始指南起着至关重要的作用。Graph RAG是一种创新的信息检索工具，旨在通过检索增强的生成（Retrieval-Augmented Generation, RAG）技术，改进大型语言模型（Large Language Models, LLMs）在处理复杂信息时的问题解答性能。具体而言，Graph RAG利用LLMs来从输入的文本语料库创建知识图谱，并结合社区摘要和图机器学习（Graph Machine Learning, GML）输出，来增强查询时间的提示。这种方法可以显著提高那些需要连接信息点和对大量数据集的综合理解类问题的回答质量。

开始指南是用户进入Graph RAG世界的第一站，它为用户提供了全面的指导和实际的说明，帮助用户理解并熟悉Graph RAG的核心流程。首先，指南会详细介绍如何将输入语料库切分成一系列可分析的单元（即textunits），这是整个Graph RAG过程的基础，可以为后续步骤提供细粒度的引用。接着，它会解释如何使用LLM从textunits中提取所有实体、关系和关键主张，这是构建知识图谱的重要一环。之后，利用Leiden算法对图进行层次聚类，生成图谱，图谱的可视化呈现比如每个颜色的圆圈代表不同的实体社区，圆圈的大小则与实体的度数相关，能让用户生动地了解到社区的结构。再之后，开始指南将指导用户如何生成从底层向上的社区摘要，以便对数据集有一个综合的理解。

另外，开始指南还提供两种主要查询模式的详细说明，帮助用户了解如何根据问题的性质使用正确的查询模式，以获取最优结果。第一种模式是全局搜索，适用于需要对整个语料库有全面了解和推理的问题，这种问题会调用社区摘要信息。第二种模式是局部搜索，适用于针对具体实体的问题，将扩展到实体的邻居和相关概念。

最后，但同样重要的是，开始指南还强调了根据用户特定数据集进行提示调优（Prompt Tuning）的重要性。使用Graph RAG不经过调优，可能无法获得最佳结果。因此，指南将强烈建议用户按照说明中的提示调优指南，来优化和微调Graph RAG的提示，从而达到最好的结果。

通过遵循开始指南，用户能够顺利启动Graph RAG的使用，并充分利用其在回答复杂问题和处理大型数据集方面的优势。此外，指南还介绍了为什么Graph RAG优于naive RAG方法，以及它相比其他全球方法的优势，比如所需更少的上下文令牌和更高效率的迭代问题解答能力。总之，开始指南帮助用户理解Graph RAG的设计理念，学习如何巧妙地利用其功能，以及如何定制化使用以满足特定数据集的特殊需求。在Graph RAG的学习路径上，开始指南是必备的第一步。"
"- How does the Query package facilitate user interaction with indexed data and conducting searches within the knowledge graph in Graph RAG?
用中文回答。","## Graph RAG 中 Query 包如何实现用户与索引数据的交互和知识图谱内的搜索

Graph RAG 的查询包为用户提供了一个强大的接口，允许他们与用自然语言模型处理和组织的文本数据进行交互，并在知识图谱中执行详细搜索。这一包特别适用于对复杂信息进行推理时的需求，实质上与传统的仅基于向量相似度的检索增强生成（RAG）技术相比，Graph RAG 提供了显著增强的问答性能。

### 局部搜索

局部搜索机制是 Query 包的一部分，用于解决需要深入了解具体实体的情况。例如，如果你问：""Scrooge 是谁？他有哪些主要的关系？""。局部搜索会识别出与 'Scrooge' 相关的知识图谱实体，这些实体作为访问点，用于进一步提取如相关实体、关系、实体属性和社区报告等细节信息。此外，它还会找出与识别实体相关的输入文档中的相关文本块。后处理过程包括对这些候选数据源进行排序和过滤，适应预先定义的上下文窗口大小，从而生成用户查询的响应。

### 全局搜索

全局搜索方法是 Query 包的另一个关键功能，它对整个知识图谱进行搜索以理解数据集合的整体概况。例如提出一个全面的问题：""这个故事的主导主题是什么？""。全局搜索在单一语境中考虑了所有从AI生成的社区报告，通过 MapReduce 的方式处理这些信息，可以在需要理解文档集合全体意义的场合中得到优质的回答，尽管这种方法在计算上较为昂贵。

### 配置方法

为了适应不同的需求和场景，Query 包提供了配置选项，用户可以通过设置 `localsearch` 类的关键参数进行自定义：

- `llm`：定义了用于生成回答所用的 OpenAI 模型对象。
- `context_builder`：确定了如何从多个知识模型对象集合中准备上下文数据。
- `system_prompt`：用于生成搜索响应的提示模板，有一个默认模板可用。
- `response_type`：描述期望输出类型和格式的自由形式文本，例如多段文字或多页报告。

### 知识处理和输入要求

为了确保数据的正确处理和利用，Graph RAG 的索引包在将无结构文本转换成有意义的结构化数据时发挥着关键作用。它能：

- 从原始文本中识别实体、关系和声明。
- 对实体进行社区检测。
- 生成不同层级的社区概要和报告。
- 将实体嵌入到图向量空间中。
- 将文本块嵌入到文本向量空间中。

这些变换和提取的结构化数据可以存储在多种格式中，如 JSON 或 Parquet，也可以手动处理。然而，最重要的是，在配置 Graph RAG 时，用户必须具备一个适当的开发环境，具体要求请参阅 ""入门"" 指南的 ""要求"" 部分。

### 定制化和开放性

Graph RAG 的索引管道是可配置的，这增加了其灵活性和适用度。它基于 Datashaper，一个开源库，提供了一种以统一模式表达数据管道、模型和相关资源的方法。Datashaper 的使用不仅限于索引处理，还可以根据需要扩展到支持其他语言的文本处理操作，如从数据库中选择、丢弃、连接数据等。

Graph RAG 探索了地球上最常见的数据模式，这些模式在多种图数据库中得到支持。通过利用图结构的自然模块化来分组数据，Graph RAG 为全球性的摘要提供建立了一个基准。目前，尽管在一系列具有挑战性的问题上已经展示了其优势，但更多的研究仍然需要涵盖不同问题类型、数据类型和数据集大小的性能变化，以及与最终用户的验证。

综上所述，Graph RAG 的 Query 包通过提供局部和全局搜索机制结合自定义参数设置，使得用户能够以智能和有效的方式探索和理解知识图谱中未见数据的细微和多样化信息。"
"- What is the role of the Solution Accelerator package in enhancing the user experience by providing advanced RAG capabilities in Graph RAG?
用中文回答。","在提供的文档中，并没有直接提及“Solution Accelerator”包以及它在增强Graph RAG中用户体验的具体作用。不过，根据Graph RAG的技术和设计思路，我们可以推断Solution Accelerator包可能扮演了一个关键角色，集成了一系列高级的RAG（Retrieval Augmented Generation）能力，从而极大地提升了用户在处理复杂信息或者进行迭代问答过程中的效率和效果。

### Graph RAG 方法的核心优势

Graph RAG，一种由Microsoft Research提出的创新技术，其设计目的是克服传统RAG方法在处理大数据集和长文档时的局限性。通过构建基于输入语料库的知识图谱，Graph RAG为用户提供了一种更全面、更精细的信息检索机制。这种方法特别在需要连接实体之间关系、构建合成见解、或进行整体语义概念理解的情况下表现突出，通过较少的LLM（Large Language Models）调用提供更丰富、更精准的检索结果，而不会受到LLM上下文窗口长度的限制。

### Graph RAG中RAG能力的增强

在Graph RAG的架构下，RAG能力的增强主要体现在以下几个方面：

1. **Comprehensiveness and Diversity**：与其他全局方法相比，Graph RAG在压缩上下文的同时保持了输出的全面性和多样性。对于某些特定问题，通过使用中间和低级别社区总结，Graph RAG甚至在成本更低的情况下实现了与源文本摘要相似的性能。
2. **Efficiency**：在支持迭代问答场景时，Graph RAG的方法相比其他全局RAG方法更高效，通常所需的上下文token数量远远减少。
3. **Entity and Relationship Extraction**：在将源文档转换为文本块后，Graph RAG进一步通过LLM模型识别和提取图中的节点（实体）和边（关系）。这一步的精细化调整对于构建高质量的知识图谱至关重要。

### Solution Accelerator包可能的作用

考虑到Graph RAG的优势及方法，我们可以合理推测“Solution Accelerator”包的作用在于以下几个方面：

- **Prompt Tuning**：提供一系列预置的prompt，用于优化LLM模型在实体关系提取、社区总结生成等方面的表现。同时，可能支持自定义和手动配置，让用户能够根据具体需求和领域知识调整prompt。
- **Community Summarization and Synthesis**：处理和创建不同层级（从根到低）的社区摘要，这些摘要用于增强查询时的上下文，使得LLM模型能够更准确地回应用户查询。这种多层次的总结机制是Graph RAG独有的特性，能够显著提高检索效率和效果。
- **Query Engine Enhancement**：改进查询引擎，使得基于图谱的知识查询能够更精准，响应时间更短。这可能涉及到查询优化算法的使用，确保即使处理大量信息，用户也可以得到即时、准确的返回结果。
- **Efficient Scaling and Integration**：设计用于高效处理和集成不同来源和量级的数据，确保系统在不同场景下都能保持高效运行。这可能涉及数据流管理和并行处理策略，以应对不同规模的数据集。

总的来说，“Solution Accelerator”包很可能是Graph RAG系统中一系列增强功能的集成，它通过提供最先进的prompt设计、数据处理和查询优化策略，有效提升了用户在进行自然语言处理任务时的交互体验和查询效果。然而，具体细节需要参考更全面的技术文档或实际产品用例以获得精确解释。"
"- How does Graph RAG outshine Baseline RAG in question-and-answer efficiency and reasoning skills, especially in connecting disjointed information fragments?
用中文回答。","## Graph RAG vs Baseline RAG: Enhancing Question-and-Answer Efficiency and Reasoning Skills

Graph RAG, a variant of Retrieval-Augmented Generation (RAG), utilizes knowledge graphs to equip Large Language Models (LLMs) with superior capabilities when addressing complex information queries. Unlike Baseline RAG, which is predominantly based on vector similarity for retrieving information, Graph RAG excels in connecting disjointed information fragments, a significant limitation of the Baseline approach.

### Connecting Disjointed Information: A Key Advantage of Graph RAG

Baseline RAG struggles with forming complete narratives or insights when the answer requires traversing disparate pieces of information through their shared characteristics. When an LLM is tasked with answering questions that demand comprehensive understanding or synthesized insights from non-adjacent, loosely connected data points, Baseline RAG often falls short. This is due to its reliance on text embeddings and vector retrieval, which might not capture the semantic or relational depth needed for multi-hop reasoning.

On the other hand, Graph RAG establishes a knowledge graph from an input corpus, enabling the LLM to understand the relationships between different entities and their attributes. This graph acts as a mapping of the entire dataset, allowing LLMs to retrieve relevant information based on hierarchical connections and summarizations. With Graph RAG, questions that once required the LLM to ""connect the dots"" between non-residing data points can now be answered more effectively and efficiently.

### Enhancements in Performance for Specific Question Types

Graph RAG's efficiency is demonstrated not just in connecting unrelated data, but also when applied to specific types of questions within two corpora—the podcast and the news datasets. Through an evaluation of 125 activity-centric questions for each dataset, Graph RAG consistently outperformed variants of Baseline RAG in metrics such as comprehensiveness (72% win rate) and diversity (62% win rate). The evaluation approach was centered on head-to-head comparisons using an LLM as an evaluator, focusing on qualities valuable for sensemaking activities.

Among the six conditions compared—Graph RAG (C0 to C3) and Baseline RAG methods including Text Summarization (TS) and Naïve Semantic Search (SS)—Graph RAG demonstrated clear wins across metrics designed to assess the detail, originality, and understanding of global summarization tasks. For instance, experimenting on a hierarchical index with various levels of community summarization (C0 for root-level, C1 for high-level, C2 for intermediate-level, and C3 for low-level summaries), Graph RAG revealed its ability to provide detailed answers covering all aspects of the questions, a metric defined as 'comprehensiveness'. This comprehensive coverage is partly attributed to its hierarchical index, which helps in addressing questions with progressively detailed answers from the root level upwards.

Moreover, Graph RAG performed better in providing diverse answers that did not merely rephrase existing information, indicated by the 'diversity' metric. Its graph index construction through generic prompts tuned for the domain's specific attributes facilitates this diversity. This process involves entity and relationship extraction within a context window of 600 tokens, with the number of gleanings dependent on the dataset (1 for the podcast dataset and 0 for the news dataset). The natural modularity of graphs supports global data summarization in a way not replicated by competing systems or Baseline RAG.

### Limitations and Future Directions

Though Graph RAG achieves significant improvements, the current evaluation is limited to specific question types for two corpora around 1 million tokens in size. More research is needed to assess performance across a broader range of question types, data types, and dataset sizes. Additionally, it's important to evaluate Graph RAG's fabrication rates and validate the sensemaking questions and target metrics with end users. Comparing fabrication rates using methods such as SelfCheckGPT could offer deeper insights into the LLM's capacity for accuracy.

Finally, while Graph RAG represents a novel variant of RAG, other graph-based approaches are emerging from the research community. Knowledge graphs are being created using LLMs in formats compatible with systems like Neo4j and Nebula Graph. However, these systems do not utilize graphs for global summarization as Graph RAG does, pointing to the need for further exploration in leveraging graph structure for enhanced LLM performance in diverse data environments.

In conclusion, Graph RAG's refined approach to information retrieval and augmentation promises a significant leap in handling complex questions that require multi-hop reasoning and comprehensive understanding. With targeted evaluation and refinement, Graph RAG could become a cornerstone for modern data analysis and support critical sensemaking activities."
"- What is the significance of the Leiden technique in hierarchical clustering of the graph for Graph RAG's visualization and analysis of entities and their communities?
用中文回答。","## Graph RAG 社区检测的 Leiden 技术的重要性综述

### 实体社区的层次结构识别

Leiden 算法在 Graph RAG 方法中扮演关键角色，用于生成实体的层次社区结构。Graph RAG 的目标之一在于为用户理解整个图表提供手段。通过构建实体的层次社区，Leiden 算法使得我们可以以互斥和集体全包含的方式覆盖图表的节点，从而实现自上而下的全域总结。这意味着我们能够从宏观层面审视图表，逐层剖析，直至具体实体的细节。

### Leiden 层次聚类的细节

Leiden 算法逐级应用到图表上，直到达到社区规模的阈值。这种方法能够揭示图表中实体社区的层级关系，从而在不同级别上理解图表结构和浏览相关概念。Leiden 算法的优势在于它对大规模图的有效处理，使我们可以直观地获取各等级的社区情况，为总结和可视化提供了灵活的视角。

### Leiden 和 Leaf-层级社区

在叶层次的社区中，Leiden 算法会根据节点的总体显著性（即连接度）对关系边进行优先级排序。这些排序通过结合源节点和目标节点的度来完成，确保总结的焦点放在图表中最重要的实体上。这种总结和优先化机制确保了用户可以快速获取关于图表关键信息的概述。

### 高级社区的处理

对于更高级别的社区，Leiden 算法则以更全面的方式进行处理，如果所有元素总结都在上下文窗口的令牌限制内，则将它们添加，进行详尽的总结。这确保了高层级上可能获得的一般范围的综述，既提供了清晰的全局视角，又不至于丢失太多细节。如果元素的总和超出了限制，那么它将按叶级别的方式进行处理。

### Leiden 层次社区在全域查询中的作用

社区的层次结构不仅在全域总结中发挥作用，还在分区数据以响应全域查询时提供了策略。通过对每个社区和其成员进行总结，结合各级别上下文，Graph RAG 方法能够在不遗漏任何细节的情况下提供指向有关实体的信息和概念的导航路径。这有助于全面理解数据集，在查询时为 LLM 上下文窗口提供补充材料或数据，支持推理和回答。

### Leiden 和自动总结增强

Leaf-层级和更高级别社区的总结以 LLM 为基础进行生成，实现了自动的、语义聚焦的总结，对全域查询的响应和对数据集的概览至关重要。这些总结通常能够纳入相关概念的嵌入和其他 ML 输出，进一步增强了查询时的逻辑推理和回答的全面性和多样性。

### 贸易OFF和全局总结的意义

虽然 Graph RAG 方法在这方面表现出色，但与纯基于文本的摘要方法相比，它也带来了建立图形索引的成本。但是，全局总结相较于单独的文本总结，其价值在于提供了对数据集全域结构的高层次理解，允许用户通过整体角度浏览和分析数据。这些汇总信息提供了对全局和局部查询模式的理解，以及上下文窗口中用于总体总结的相关数据的自顶向下探索关键。

- 在全局搜索中，社区汇总使得实体间概念关系清晰化，支持了对整个语料库的理性询问。
- 在局部搜索中，实体周边概念和相关链接网络为对特定主题细节的深入了解提供了基础。

综上所述，Leiden 技术在 Graph RAG 中提供了功能强大的层级社区费尔，使全局和局部查询能够以高度灵活和深入的方式执行。在不同层面上的社区汇总为用户提供了一种理解数据多重层次结构的手段，这在面对极其庞大和复杂的信息集合时尤为关键。因此，Leiden 的层次聚类和总结过程是 Graph RAG 平台提供全面而准确的全域电子响应和深层概念理解的基石。

## 结论
使用 Leiden 算法的层次聚类在 Graph RAG 视觉化和理解实体社区中起著举足轻重的作用。它对大规模数据集有效，有助于深度的全域摘要和在不同粒度层次上的数据探索，使平台在面对复杂和庞大的信息集时性能更佳，更全面、响应更迅速。"
"- How does Graph RAG slice up the input corpus into TextUnits, and what is the role of these TextUnits in the process of entity and relationship extraction?
用中文回答。","在Graph RAG工作的初始阶段, 文档被切割成多个称为""TextUnits""的文本块。这一流程, 即将源文档转换为可处理的文本单元, 是整个提取过程的基石, 支持后续对实体、关系乃至主张的识别和提取。

### TextUnits的生成:决定粒度

- **默认设置**:Graph RAG的默认配置将文档按边界进行切分。这意味着会有严格的1对多关系, 即每份文档都可以转换成多个TextUnits, 且与原始文档保持一致的切分。此方式适用于大部分文档长度, 但可能在处理极短文档如微博或聊天记录时效果不佳。

- **动态调整**:用户可以根据需求调整切割粒度, 例如通过设置`chunk_by_columns`参数为`id`, 改变TextUnits和文档之间的关系结构。通常, 文本单元的大小为300个标记, 但在一些实例中, 如使用单一""Glean""步骤时, 可将这个值增至1200。通过Glean步骤, 可以从先前提取的TextUnits中获取更多信息。然而, 文本块过长可能导致召回率降低, 输出质量下降。

### 文本单元在实体和关系抽取中的作用

TextUnits是Graph RAG中进行实体和关系抽取的单元。每个TextUnit将被传递到专门为从源文本中提取图的节点和边设计的LLM(Large Language Model)提示集合:
- **实体与关系抽取:** 在这一阶段, Graph RAG会对每个文本单元进行分析, 利用LLM来识别并提取关系图的基本元素, 包括实体与它们之间的关系, 以及主张。这些提取出的实体和关系最终会形成一系列的子图, 每个子图对应一个文本单元。
- **实体和关系的合并:** 文本单元切分后, 相同实体(名称和类型)或关系(源和目标)将被合并, 形成描述数组。例如, 如果多个文本单元提到同一实体, 这实体的描述将被合并成一个描述列表, 同理对于关系描述也是如此。
- **提取后处理:** 这些子图随后将集合整合，为每个文本中的实体和关系附上从其原始文本中收集到的描述汇总。

通过这些过程, Graph RAG利用TextUnits作为处理单元, 精确而高效地在文本集合中识别实体和关系, 并将其应用于构造最终的实体关系图和文档图, 支持后续阶段如图总结和连接解决更加灵活, 更加符合知识发现和文档理解的深层需求。

### 总结

- TextUnits扮演收集和汇总信息的角色, 在Graph RAG中, 它们是提取实体和关系的基本构建模块, 通过指定大小和重叠策略, 可以影响提取质量, 进而影响最终的图索引的构建。
- 使用Graph RAG时, 选择合适的TextUnit大小对于平衡输出细节和提取精度至关重要。粒度设定需谨慎, 考虑到不同场景的适用性以及所需的查询效率与数据表征质量。"
"- How does Graph RAG utilize the LLM-generated knowledge graph to organize data into semantic clusters and summarize themes for responding to user queries?
用中文回答。","### Graph RAG 的工作原理

**Graph RAG** 技术是一项针对大型语言模型（LLM）的创新方法，用于构建知识图谱，提升LLM在回答涉及复杂信息的问题时的表现力。以下是Graph RAG如何利用LLM生成的知识图谱将数据组织成语义集群并总结主题以响应用户查询的详细步骤：

#### 1. **构建图索引**

- **初始文本分割**：Graph RAG首先将输入语料库（即私有数据集）分割成一系列的文本片段（TextUnits），这些片段作为后续分析的基本单位，同时在输出结果中提供精细的引用。
- **信息抽取**：接下来，使用LLM来抽取文本片段中的所有实体、关系和关键主张。这一过程能够将文本的结构化信息准确地转化为知识图谱节点和边。
- **图谱构建**：基于抽取出的实体、关系和主张，构建一个知识图谱。该图谱可以可视化为一系列实体节点，其中节点大小表示实体的度（连接其他节点的数量），节点颜色表示所属的社区（基于相似性和关联性）。

#### 2. **划分层次结构与社区生成**

- **层次聚类**：采用层次聚类法（Leiden算法）对图谱进行分割，形成不同的层级结构。这有助于理解数据的多级组织模式，从而在不同层次上产生更细致的理解。
- **社区识别**：各个实体根据其属性和关联性分组在不同社区中，社区形成了图谱的语义集群。
- **总结社区**：从每个社区底部向上生成摘要，这利于整体理解数据集内的不同主题和模式。LLM用于生成每个社区的概述，包括社区内的关键实体、关系和主张。

#### 3. **查询时的使用**

- **全局与局部查询模式**：查询时，图谱结构与预先生成的社区摘要被用来增强LLM的上下文窗口。查询模式包括：
    - **全局搜索**：针对需要理解整个语料库的全局性问题，利用社区摘要进行推理，生成综合性强且多角度的答案。
    - **局部搜索**：对于特定实体的详细问题，由该实体连接的所有近邻节点和相关概念进行搜索，提供专业和聚焦的解析。

#### 4. **提升效果**

- **微调**：使用Graph RAG处理数据时，预设的查询模式和处理方法可能不会立即达到最佳效果。Graph RAG建议用户遵循其文档中的提示调优指南，以更精细地调整流程，提升输出质量。

### 结论

总结而言，**Graph RAG** 通过LLM生成的知识图谱和综合的图机器学习技术，将数据组织成具有内在语义的一系列社区集群。在全球搜索模式中，Graph RAG使得模型能够理解整体概念，而局部搜索模式增强了对具体细节的洞察力。通过层次化的索引结构和预生成的社区摘要，用户可以获得更全面、深入的问题答案，且答案多样性与数据集规模二者均有所保证。

这些步骤和初步评估主要集中在处理包含约100万单词的语料库。随着研究的深入，Graph RAG 的表现和适用问题类型、数据类型以及数据集规模之间的关系需要进一步探索。然而，Graph RAG 技术已显示出其在处理复杂问答回答方面，相较于现有技术的巨大提升。
Graph RAG 引入的自然模块化特性使得可以对图数据进行全局摘要，进一步增强了模型应对大规模数据时的性能和理解能力。这种创新的方案不仅拓展了LLM的能力边界，同时也为私有数据集的分析提供了新的视角，有望在多个领域产生深远的影响。
在即将到来的开源实现中，Python将充当关键技术栈的一部分，使得Graph RAG成为主流的LLM工具中的一个亮点，为处理大量文档和推理中所需的理解提供了强大的支持。
通过这些具体步骤的实施，Graph RAG不仅能从私有文本数据集中归纳总结，还能在用户提出涉及多个数据层和广度问题时，给出准确的、富有深度的和全面的答案。

### 未来展望

鉴于**Graph RAG** 在目前评估中的成果，未来的研究和开发将专注于进一步优化其处理能力和应用范围。将加强对多样类型问题和数据类型的研究，特别是针对那些需要多功能、高效率和高质量数据处理的场景。同时，Graph RAG 提出的基于图谱的索引和预生成社区摘要的概念，为研究者和开发者提供了新的启示，即如何结合LLM和图谱技术以优化处理效率和分析效果。
随着开源版本的发布，Graph RAG将激发更多社区参与，共同探索和优化在其框架下的技术应用，最终实现一个更全面、更智能的解模范式，不仅在科学发现"
"- What are the steps involved in the Graph RAG process for extracting a knowledge graph from raw text and building a community hierarchy?
用中文回答。","### Graph RAG 过程步骤概述

Graph RAG 方法是一种从原始文本中抽取知识图谱以及构建社区层级的先进流程。以下是该过程所涉及的关键步骤：

1. **文档源 → 文本块**:
   - 输入文本最初从源文档中以一定粒度分割成文本块。这是基于 LL M 提取出图索引的元素而执行的初步分割。

2. **文本块 → 元素实例**:
   - 该步骤的基础要求是从每个源文本块中识别并抽取图结点和边的实例。LL M 用于这个实体和关系提取过程中。

3. **元素汇总 → 图社区**:
   - 在完成元素实例提取后，建立加权图，其中权重代表发现关系实例的规范化计数。使用社区检测算法（如 Leiden 算法）以构建一个覆盖图中结点的分层社区结构。

4. **图社区 → 社区概览**:
   - 为每个检测到的社区生成类似于报告的描述。这能帮助理解每个社区所包含的独特信息。

5. **社区报告生成 → 报告汇总**:
   - 通过 LL M 进一步压缩每个社区报告，得到要点汇总。这确保了所有信息均以简洁的形式呈现，并且便于面对较大数据集时快速理解。

6. **社区嵌入**:
   - 此阶段生成社区的向量表示形式，即使用社区报告、社区报告要点汇总和社区报告标题创建文本嵌入。

7. **社区表格生成**:
   - 在向量表示生成后，向 Graph RAG 存储中写入社区和社区报告表格。

8. **图元素汇集和描述**:
   - 利用汇集好的图元素，创建描述层次，其中记录了每个实体的特性和关系。

9. **文档处理**:
   - 最后在文档层面处理，这涉及创建文档表，记录关系表格，进行文档嵌入等步骤，其中文本单元概念反过来有助于链接多个文档。

### 层级组织的影响与考虑

Graph RAG 的关键优势之一在于它对节点的同质性和大图框架中分区数据进行全局总结的能力。尤其在解模糊化阶段中（Entity Resolution），多样的实体名称能通过该步骤找出代表同一实体的同质节点。

Graph RAG 的流程从原始文档提取，到文本块，再到元素实例，最终形成图社区，每一步都注重信息的整合与优化。图社区报告和总结的创建使得人类用户和系统均能快速洞察社区结构的特征。通过总结从各个方向上对信息进行综合，有效避免了在处理大规模文本数据集时通常会出现的信息过载问题，使得查询处理和信息获取更加直观、高效。

Graph RAG 方法在基于 LL M 的知识抽取场景中发挥了重要作用，同时也证明了其在处理具有多元特征和复杂关系的数据集方面的灵活性与效率。通过分层社区结构和总结，该方法为用户提供了从宏观到微观层次上的知识检索和理解能力，极大地拓展了基于图的知识检索系统的能力界限。

请注意，Graph RAG 方法虽已展现出强大的功能，但构建图索引时仍然存在一些权衡。例如，原始文本分割的精细程度、实体解模糊化策略和能否以高或低层次的社区视角生成概述，都需在具体应用场景中细心考虑。"
"- How does Graph RAG's global search method use community summaries to provide materials for the LLM context window when answering a question?
用中文回答。","### Graph RAG的全局搜索方法如何使用社区摘要为LLM上下文窗口提供材料以回答问题

在回答用户查询时，Graph RAG采用了层级社区结构，这意味着可以使用不同级别的社区摘要来生成最终答案，从而找到对通用理解和推断问题最合适的摘要详细信息和范围平衡点（参见第3节评估）。

#### 准备社区摘要

社区摘要首先被随机排序并分割成预定的令牌大小的片段。这有助于分散相关信息，使其在各个片段中均匀分布，避免将其集中在单个上下文中而导致潜在信息丢失。

#### 地图到社区答案

接下来，Graph RAG独立并行地对每一个摘要片段生成中间答案。同时，LLM被要求为每一个生成的答案打分，范围是0到100，表示这个生成的答案对于回答目标问题的有用程度。对于评分为0的答案，将被过滤掉，不予考虑。

#### 再归约为全局答案

已经得到的中间社区答案按照有用性评分的顺序由高到低被排序。随后，这些答案被迭代地加入到一个新的上下文窗口中，直到达到令牌的上限。这样排序后的最终上下文包含从各种社区摘要中提取的最相关、最有用的信息片段。这个上下文被用于生成最终的全局答案，以全面回答用户的查询。

### 转化与比较

与天真的RAG和全局地图-归约源文本摘要相比，Graph RAG在综合性（72%的胜率）和多样性（62%的胜率）方面表现更优，同时降低了令牌的消耗成本（对于条件c0-c3，与源文本摘要相比降低了26%-33%；根级社区摘要c0则降低了超过97%的令牌）。Graph RAG的这一优势意味着它为迭代问答提供了高效的途径，适用于需要多轮问答的理解和分析活动，如情况下常出现的求索过程。

总的来说，Graph RAG以较低的计算资源要求，通过精心设计和层级化的索引，实现了与更复杂的检索和生成策略相当的综合性与多样性，为用户提供了一种理解复杂议题的有效方法。同时，能够有效地从社区级别的摘要中提取和生成具体示例、引用和文献出处，为用户提供更深入理解问题所需的证据与细节。

### 相关研究比较

与现有相关研究（如4.1节中提到的RAG系统，及其在克服天真的RAG系统弊端而设计的预检索、检索和后检索策略，分模块RAG系统等）相比，Graph RAG的社区摘要以及从这些摘要中平行生成社区答案的方法，融合了多文档摘要（Subsection 4.2）和多跳问答技术的理念。Graph RAG不仅在场景理解中产生了更高效、更具实践性且多元化的解决方案，也体现了其在理解大范围议题和问题集时的强大优势。Graph RAG所使用的层级索引和摘要方式，与使用文本嵌入向量空间的其他方法具有类似之处，如Raptor中提到的生成文本嵌入向量的层次索引。

通过以上分析，我们可以看到Graph RAG是一种以层次社区为基础的、专为大规模数据集而调整的索引和检索策略。当收集到的外部数据集超出了LLM的上下文窗口限制时，Graph RAG提供了一种具有创新性的解决方案，有助于平衡信息检索的召回和精确度，从而创造出有助于用户理解广泛议题的高价值答案。

### 总结

Graph RAG的全局搜索方法利用层级社区及其摘要，以及通过LLM评估各摘要片段对回答问题的实际作用，构建了一个高效、全面的摘要集合。这优化了从规定的大规模文档集回答问题的流程，减少资源消耗，同时保持高胜率的综合性与多样性。与天真的RAG方法或直接从源文本生成摘要的方法相比，Graph RAG提供了综合全面的数据见解，极大地促进了展开理解和回答问题的效率。"
"- What is the importance of fine-tuning prompts in Graph RAG for achieving the best possible results with specific data sets?
用中文回答。","在使用Graph RAG时，微调提示的重要性不容小觑。Graph RAG是一种结构化、层次化的检索增强生成方法，旨在从私有数据集中提取知识图谱，并构建社区层级，为这些社区生成摘要，进而利用这些结构执行基于知识图谱的检索增强生成（RAG）任务。然而，为了最大限度地提升Graph RAG在特定数据集上的表现，细致调节提示（prompts）变得至关重要。

### 提示微调：实现领域适应的关键

- **领域适应模板**：Graph RAG提供了创建领域适应模板的能力，用于生成知识图谱。这是可选的，但是强烈推荐执行该步骤，因为基于输入数据和语言模型（LLM）交互，自动生成模板能够为生成知识图谱提供更好的适配性，从而在特定领域或特定类型的问题上提升回答的准确性和深度。

- **默认值与定制**：虽然Graph RAG提供了默认的提示，但手动配置和自适应模板生成为用户提供了更全面的控制。通过调优，你可以使Graph RAG更加关注数据集的细节，提高召回率和精确度，特别是在涉及实体和关系的复杂提取时。

### 为什么应当微调提示

示例、引用和引文都是衡量推理能力的关键。对于希望达到知情理解的用户而言，能够提供这些细节的系统至关重要。尽管Graph RAG在综合性（comprehensiveness）和多样性（diversity）方面表现出色，微调元素提取提示可进一步保留细节，增强其优势，特别是在要求理解和合成大型数据集语义概念的场景下。

- **平衡召回与精确度**：通过调整提示，可以在确保提取实体和其他关键信息的同时，避免长LLM上下文窗口中常见的问题，即信息的召回率下降。微调能够优化语义搜索，确保每个文本文档被分割成适当大小的文本块，利于模型处理。

- **优化资源使用**：有效的提示微调能够减少所需的上下文令牌数，使Graph RAG比传统RAG策略更高效，尤其是对于需要迭代提问和回答的sensemaking活动。这种效率的提升不仅可以节省成本，还能够加速处理时间，提升用户体验。

- **提升回答的质量**：通过优化模型如何从文本中识别和提取节点和边的实例，可以改善回答的全面性和多样性，确保系统能够生成丰富且全面的回答，涵盖查询中的各个要素，而不只局限在收集相似位置的语义信息。

总之，通过微调提示，Graph RAG可以更精确地针对特定需求和数据集进行优化，带来更优质和深度的输出。无论是通过手动配置还是使用自适应生成，实现这一目标都使得开发者和用户能够更有效地利用Graph RAG的潜能，尤其是在复杂和特定领域的问题处理上。随着能力的提升，Graph RAG能更好地处理涉及多个实体和关系的多跳问题，以及支持企业级应用的高效知识管理和信息合成。"
"- How does the init command in Graph RAG create necessary configuration files and default prompts for initializing the workspace?
用中文回答。","### 初始化Graph RAG

Graph RAG的初始化是一个关键步骤，用于设置工作空间并创建必要的配置文件和默认提示。通过`init`命令，Graph RAG将创建以下文件于指定目录中，或在默认情况下，当前目录中：

#### settings.yaml - 配置设置文件

- **功能**：此文件包含用于Graph RAG的配置设置。它控制Graph RAG的行为，包括LLM（语言模型）调用和数据索引过程。
- **内容**：默认情况下，`settings.yaml`包含一些基本的配置项，如模型源、API端点等。
- **可定制性**：用户可以根据需要修改这个文件，从而改变管道的设置。

#### .env - 环境变量文件

- **功能**：`.env`文件包含运行Graph RAG管道所需的环境变量。这些变量被`settings.yaml`文件引用。
- **内容**：这个文件中包含一个环境变量`graphrag_api_key`，它用于OpenAI或Azure OpenAI API。默认值是一个占位符，需要用户用自己的API密钥替换。
- **可定制性**：用户可以在`.env`文件中设置其他环境变量，供配置文件使用。

#### prompts/ - LLM提示目录

- **功能**：`prompts/`目录包含Graph RAG中使用的LLM(语言模型)提示的默认集。这些提示用于指导模型处理和理解数据。
- **内容**：此目录中提供了多个默认提示，每个提示都是用于特定目的的，例如生成知识图谱或执行其他语言任务。
- **可定制性**：用户可以修改这些提示，以适应他们特定的数据集和需求。此外，用户还可以运行自动提示微调命令(`auto prompt tuning`)以生成更适合他们数据的提示。

### 接下来步骤

初始化之后，用户有例行的下一步可采取：

1. **运行自动提示微调**：推荐用户运行`prompt tuning`命令来优化为数据定制的提示。这可令索引过程更高效且更针对特定数据集。
2. **运行索引管道**：使用管道执行数据索引，将数据转换成知识图谱。这涉及加载输入数据，将其分割成文本单元，再执行一系列的操作来构建图谱。
3. **配置索引引擎**：使用Graph RAG API或Azure OpenAI API。在`.env`和`settings.yaml`文件中进行设置。

### 初始化命令使用

初始化命令的语法如下：

```
python -m graphrag.index --init --root {path}
```

在这里，`--init`选项用于命令初始化，而`--root`指定要初始化的目录。如果未提供`--root`路径，命令将会在当前目录中执行。

### 实践操作

考虑以下情景，用户已经配置了一个名为`.ragtest`的目录。为了在`.ragtest`目录中初始化Graph RAG工作空间，用户可以执行以下命令：

```
python -m graphrag.index --init --root ./ragtest
```

这将创建`.env`和`settings.yaml`文件，同时输出默认的LLM提示。

使用`settings.yaml`和`.env`设置好参数后，用户可以运行索引引擎。此过程可能需要一些时间以完成，持续时间依据输入数据的大小、所选模型及文本分块大小（这些参数可以在`.env`中调整）。

一旦索引过程结束，用户应该在`.ragtest/output/<timestamp>/artifacts`目录下看到一系列的Parquet文件，它们代表了处理后的数据。

### CLAQUER 及其功能

项目中使用了不同的CLI（命令行界面）应用程序，不同功能可以通过不同的CLI执行。例如：

- `index`：用于执行数据索引。
- `query`：用于执行查询。
- `prompt_tune`：用于执行自动提示微调。

此外，也有针对开发和测试的脚本。例如：

- `start_azurite.sh`：启动Azure资源的仿真器Azurite。
- `poe test`：执行不同的测试类型（单元、集成和烟雾测试）。
- `poe check`：执行一系列静态检查，例如格式化和安全性模式的检查。

```markdown
**注意**：请始终查阅官方的Guided Initialization和Configuration文档以获取最新和详细的信息。
```"
"- What are the options available when using the python -m graphrag.index command for initializing the directory with the necessary configuration files?
用中文回答。","当你使用 `python -m graphrag.index` 命令初始化目录以配置必要的文件时，有以下选项可用：

### 可选参数
- `--init`: 此选项用于初始化目录，创建必要的配置文件。
- `--root path`: 指定要初始化的根目录。默认值是当前目录。

### 命令示例
```python
python -m graphrag.index --init --root ./ragtest
```
这个命令会在指定的目录中创建以下文件：
1. **settings.yaml** - 图形 Rag 的配置设置文件。
2. **.env** - 环境变量文件。在 `settings.yaml` 文件中引用了这些变量。
3. **prompts/** - LLm 提示文件夹，其中包含默认的提示。你可以修改它们，或者使用自动提示调优命令生成更适应你数据的新提示。

### 后续步骤
初始化工作区后，你可以选择运行提示调优命令以调整提示以适应你的数据，或者直接开始运行索引流程以构建数据的向量表示。详情配置可以参考以下部分。

## 配置模式
### 默认配置模式
- **使用 JSON/YAML**：你可以通过在数据项目根目录下使用 config.json 或 config.yml 来配置默认模式。如果同时存在 .env 文件，它将会被加载，然后在配置文档中用的环境变量将可以用于替换用 `$ { env _ var }` 的语法配置的字段。

### 自定义配置模式
这是更高级的使用方式，主要用于进行更深入的控制。大多数用户可选择使用默认配置就足够了。

## 索引流程
### 执行管道
在配置完成之后，你可以使用 CLI 或 Python API 来运行管道：

**使用 CLI 执行**
```shell
# 通过 poetry 运行
poetry run poe cli --root <data_root>  # 使用默认配置模式

# 通过 node 运行
yarn run : index --root <data_root>  # 使用默认配置模式
```

**通过 Python API 执行**
```python
from graphrag.index import run_pipeline
from graphrag.index.config import Pipelineworkflowreference

workflows: list[Pipelineworkflowreference] = [
    Pipelineworkflowreference(steps=[
        {
            ""verb"": ""derive"",  # 内置谓词
            ""args"": {
                ""column1"": ""col1"",  # 来自上方
                ""column2"": ""col2"",  # 来自上方
                ""to"": ""col_multiplied"",  # 新列名
                ""operator"": ""*"",  # 将两列相乘
            },
        }
    ])]
# 使用 run_pipeline 功能执行工作流程
```

此流程将耗时，具体取决于输入数据的大小、所用模型以及文本块大小（可在 .env 文件中配置）。

### 查询引擎
了解如何使用查询引擎获取数据集的高级视图。例如，使用全局搜索进行概念性查询：
```python
python -m graphrag.query \\
    --root ./ragtest \\
    --method global \\
    ""What are the top themes in""
```
这将返回你的数据集的高级主题分析。

总之，`python -m graphrag.index` 命令有着如下作用：
1. 初始化目录，添加主要配置文件 `settings.yaml` 和 `.env`。
2. 创建默认路径下 LLm 的提示提示文件夹。
3. 能够微调索引化的提示，以更精准地生成知识图谱。
4. 运行索引流程，将数据集转换为可搜索的向量形式。
5. 支持查询引擎，允许进行复杂的数据查询，以揭示不同主题和概念关联。

完成这项配置后，你可以利用图形 Rag 来更高效地管理和探索自己的文本数据集。无论你是想仅简化设置过程，还是深潜到自定义配置中调整文本数据索引化的每一环节，这个工具都提供了大量选项来匹配不同级别的使用需求。
如果尝试手动配置或执行更高级的自定义配置操作，请参考相应的文档部分，以获取更多细节和指导。
- 配置文档：详细说明如何设置 chat 及 embeddings API。

然而，对于大多数用户而言，初始化命令（`python -m graphrag.index --init`）仍是首选，因为它能快速创建必需的配置文件和默认提示，使你能够快速开始进行索引操作及数据查询。提及的 .env 文件能通过环境变量来控制 LLM 调用，带来更简洁的配置逻辑和更高的灵活性。
上面，你学习了如何初始化 work 区、配置和运行索引管道、以及运行查询引擎，用户现在应该能够对自身数据集进行高效管理和探索。你可以选择简单设置"
"- What are the files created by the init command in the specified directory, and what is their significance in the Graph RAG system?
用中文回答。","在指定目录中，初始化命令将创建以下文件，这些文件在Graph RAG系统中起着关键的作用：

1. **settings.yaml**：这是Graph RAG的配置设置文件。它包含了系统运行所需的全部配置信息，如索引引擎的管道设置和Node2Vec算法的参数等。
2. **.env**：这是环境变量文件，其中定义的变量可在settings.yaml文件中用作Token替换。例如，API密钥、连接字符串和其他敏感信息都被存储在.env文件中，以确保安全性并便于管理。
3. **prompts/**：这是LLM（Language Model）的Prompts文件夹。它包含了Graph RAG默认使用的Prompts，用户可以对其进行修改，也可以通过运行自动Prompt调整命令，生成适应数据的新Prompts。

### 初始化操作的意义

初始化命令是开始使用Graph RAG的最简单方法，它提供了工作空间的必要配置。通过初始化命令，用户可以快速创建所需的文件结构，而无需手动创建或配置各个文件。初始化操作后，可以通过运行Prompt调整命令来调整Prompts，以适应数据，或者直接运行索引引擎流程以对数据进行索引。

### 下一步操作

一旦初始化完成，下一步通常是根据具体需求调整Prompts或配置文件，然后执行索引流程或查询操作。Graph RAG的索引流程会分析和处理多个文件，如实体类型文件、知识点描述文件等，以便生成和维护一个知识图谱用于后续的分析和报告。

### 安装与执行示例

#### 安装依赖项
要安装Graph RAG所依赖的Python库，需要使用Poetry，这是一个常用的Python包和虚拟环境管理器：
```shell
# 安装Python依赖项
poetry install
```

#### 执行索引引擎
```shell
poetry run poe index
```

或通过指定初始化时已配置的目录执行：
```shell
python -m graphrag.index --init --root ./ragtest
```

#### 执行查询
```shell
poetry run poe query
```
这些命令都提供了额外的参数选项，可以在选择性的情况下调整运行模式或配置细节。

### 总结

在Graph RAG系统中，初始化命令创建的这些文件是核心组成部分，它们不仅有助于快速搭建工作空间，而且还在维护和扩展系统的过程中起到了至关重要的作用。通过编辑settings.yaml和prompts目录，用户可以根据自身的需求定制索引和查询功能，从而有效利用从数据中提取到的知识点。"
"- How does the Prompt Tuning command in Graph RAG adapt prompts to specific data for better results in executing an Index Run?
用中文回答。","## Prompt Tuning 命令在 Graph RAG 中的工作原理

在Graph RAG中，**Prompt Tuning**命令是一个可选步骤，尽管如此，它对于提升知识图谱生成的准确性与相关性却是至关重要的。这个命令通过以下三个关键阶段来工作，将Prompts自适应地调整到你的特定数据上：

### 1. 加载输入数据

这一阶段，命令开始于从你的项目目录加载数据，这些数据是通过Index Run命令预先初始化的。此加载过程确保所有相关文本单元（即数据的细小部分）包含在接下来的分析中。

### 2. 数据分割

加载完数据后，命令会将它们分割成**文本单位**，亦即所谓的**数据块**。这种分割方式是为了在独立的、更小的上下文中运行一系列LLM（Language Model）调用，这样能够更精确地针对每个数据块制定Prompts。通常，Graph RAG提供默认的分割大小，但用户也可以根据数据的具体需要自行调整这个参数。

### 3. LLM 调用与模板替换

在数据被分割后，Prompt Tuning命令将运行一系列LLM调用来生成最终的Prompts。这个阶段涉及LLM模型和用户数据之间的交互，通过模型的智能能力，针对每个数据块生成最优的指令模板，也就是Prompts。此外，命令还使用模板替换策略来更好地细化这些Prompts，以便它们能准确地反映数据的具体内容。整个过程中，Graph RAG建议使用默认值，可这些参数都是可定制的，用户可以深入研究和调整，使自动Prompt生成算法更适应自己数据的特性。

提示：在使用Prompt Tuning命令前，请确保你已通过`graphrag.index --init`命令初始化了工作空间，此举会创建必要的配置文件和默认Prompts。具体操作细节可在初始化文档中找到。

## 目的与效果

- **目的**：Prompt Tuning设计的初衷在于，通过创建领域自适应模版，提升知识图谱生成过程的精确度和效率。特别是在处理专业领域或复杂信息时，该命令效果显著。

- **效果**：运行此命令后，生成的Prompts更加贴近数据精髓，促进LLMs更有效地从原始文本中抽取实体、关系与断言等信息。这不仅提升了知识图谱的质量，还为后续的社区检测、总结生成或图形机器学习输出等步骤打下了坚实的基础。

为了体验Prompt Tuning命令的魔力，你可以在命令行中执行以下命令：

```
python -m graphrag.prompt_tune [options]
```

将上述选项与你的具体需求相结合，进一步探索和微调此过程。记住，更好的Prompts意味着更优秀的知识图谱和更精确的数据洞察。

综上所述，Graph RAG中的Prompt Tuning命令采用智能、自适应的方法，确保LLMs在处理用户数据时能够生成最适合、最高效的Prompts。这一步骤虽然可选，但强烈推荐，因为它在提升知识图谱生成项目成果的质量上，起着关键作用。"
"- What are the prerequisites for running the automatic template generation in Graph RAG, and what is the significance of this process?
用中文回答。","### 自动模板生成的先决条件

在Graph RAG中，自动模板生成的先决条件主要有以下几点：

1. **工作区初始化**：在运行自动模板生成之前，确保已使用`graphrag . index - - init`命令初始化了工作区。这一步骤是必需的，因为它创建了配置文件和默认的提示语，为后续的模板生成奠定了基础。如果你的工作区没有经过初始化，自动模板生成将无法从现有的项目配置中提取必要的信息。具体初始化过程请参考""初始化文档""以获取更多详细信息。

2. **默认提示语的存在**：初始化命令还会在`prompts/`目录下生成默认的提示语文件，这些文件包括`entity_extraction . txt`和`community_report . txt`。这些默认提示语是系统自动生成的，旨在帮助Graph RAG更好地从文本中抽取节点和边信息，以及生成社区报告。

### 模板生成的含义

自动模板生成是Graph RAG的一个关键步骤，它基于输入数据自动生成了领域适应性模板，用于知识图谱的创建。这一过程虽然可选，但强烈建议执行，因为它能显著提升index运行时的结果质量。

模板生成的重要性和意义主要体现在以下几个层面：

1. **适应领域特定性**：通过自动模板生成，Graph RAG可以创建出更适合特定领域的模板。这意味着，在从文本中抽取实体或关系时，这些模板能更准确地捕捉到领域特有的概念和语义，从而生成更高质量的知识图谱。

2. **提高效率和效果**：模板生成算法通过加载输入数据、将其分割为文本单元（即""chunk size""定义的大小），然后执行一系列LLM调用和模板替换，最终生成用于文本处理的完整提示。这项工作可以提高查询的召回率和精确度，尤其是在较长文本的实体识别上，能显著提高实体参考的识别数量。

3. **算法探索和调整**：尽管建议使用脚本提供的默认值，但用户可以进一步探索和调整模板生成算法。自动模板生成参数如`chunk size`、`max tokens`等，是可以根据具体项目需求进行微调的，从而获得更优的配置。

综上，自动模板生成在Graph RAG中的作用不仅限于创建领域特定的模板，还提高了数据处理的效率和准确性。遵循这个步骤，不仅可以提升系统性能，还能更好地适应不同领域和规模的项目需求。"
"- How does the question generation function in Graph RAG work, and what is the methodology for generating the next set of candidate questions?
用中文回答。","### 问题生成功能如何在Graph RAG中运作？

Graph RAG的**问题生成功能**旨在自动化生成一类特定的问题，这类问题需要对整个数据集有高层次的理解而不是具体文本的细节。给定数据集的简短描述，系统使用大型语言模型（LLM）来识别潜在的用户群体及其各自的任务。接着，对于每一对（用户，任务），LLM将生成一系列新问题，旨在促使用户对数据集进行全面理解。

### 问题生成的流程

#### 1. 用户与任务识别
- **用户识别**：LLM首先识别n个潜在的用户群体，这些用户群体可能对数据集有不同层次的需求或兴趣。
- **任务分配**：随后为每个用户分配n个任务，这些任务可能是数据探究、特定实体理解或数据分析等。

#### 2. 问题生成
- **上下文构建**：采用在局部搜索中使用的同一上下文构建方法，问题生成功能提取与优先级相关的结构化（如实体、关系、协变量）和非结构化数据（如社区报告和文本块）。
- **多维度数据整合**：先从知识图谱中获取实体信息，再从输入文档中获取相应的数据，确保问题的生成与数据中的关键信息和主题紧密相关。
- **LLM响应**：将这些信息整合到单一的LLM提示中，生成候选跟进行问题，这些问题旨在捕捉数据中最重要的信息或最紧迫的主题。

### 配置与使用参数

问题生成功能的**关键配置**参数包括：
- **LLM**：用于生成候选问题的OpenAI模型对象。
- **context_builder**：用于从知识模型对象的集合中准备上下文数据的构造对象。
- **system_prompt**：默认的提示模板，用于生成问题的生成，可以根据具体需求进行自定义。
- **llm_params**：调用LLM时传递的附加参数，如温度、最大标记数等，以控制模型的生成行为。
- **context_builder_params**：构建上下文数据时传递给context_builder对象的附加参数，以便更精细化控制数据的抽取和排序。
- **callbacks**：可选的回调函数，用于提供事件处理，如LLM完成事件的流式响应。

### 总结反馈

通过将问题生成与图谱和文本数据的整合，Graph RAG不仅能产生与具体实体相关的问题，还能促进对数据集全局主题的理解。这种方法的巧妙在于利用LLM的上下文多样性，从而生成能够支持深入了解数据和促进进一步数据分析的高质量问题。此外，与naive RAG（语义搜索）相比，Graph RAG在效率上具有显著优势，要求更少的上下文令牌（对于根级社区摘要，几乎减少97％的令牌），同时在效率与性能之间的权衡上，难以察觉的下滑换取了查询回答的全面性和多样性上的胜利。

问题是，当前的评估仅仅从有限角度考虑了两个数据集以及一定的问题类型和数据类型。为了全面理解Graph RAG在各种应用场景中的潜力，需要后续研究进一步探讨其对不同问题类型的处理能力，对各类型数据集的适应性和反应效率在不同数据集大小下的表现差异。

### 与RAG方法和开源软件的关联

Graph RAG的问题生成技术与现有的RAG系统和方法有相似之处，但也有明显的创新点。例如，它借鉴了提取知识图谱以及文本分割、聚类等迭代或层次化方法的思想，但没有其他方法或系统使用自动生成的图谱指数这样的核心设计。Graph RAG的优势在于，能够利用图的天然模态性对数据进行全球总结，并适应多元问题的解答需求，提供更高效、全面且多样化的服务体验。

总之，Graph RAG的问题生成功能凭借其独特的技术路线，在促进数据全局理解和深度分析方面展现出了卓越的能力。进一步的开发和研究有望使其成为处理大规模数据集和复杂问题的有力工具，推动人们更高效地通过查询理解世界。"
"- What are the limitations of the current evaluation approach for Graph RAG, and what future work is suggested to address these limitations?
用中文回答。","### 当前Graph RAG评估方法的局限性

当前对Graph RAG（基于图谱的检索与生成增强）方法的评估仅围绕特定类别的理解型问题展开，这些问题主要在大约1百万个token的两个语料库上进行测试。这种评估方法存在以下局限性：

- **问题类型与数据类型的多样性不足**：评估集中在特定的理解型问题上，未充分涵盖不同类型的问答和数据类型，例如事实性问题、专业文档、或更大规模的数据集。
- **理解用户需求的验证缺失**：目前方法尚未与最终用户验证所选择的感性理解问题和目标度量是否符合实际需求。
- **可创新性局限**：评估未考虑将额外技术如selfcheckgpt用于测量技术生成结果的创新性，自我检查能力是评估模型性能的关键指标之一。

### 针对局限性的未来工作建议

为了有效应对上述局限性，研究者提出了以下未来工作方向：

- **扩展评估范围**：有必要探索Graph RAG在各式问题类型、数据类型和数据集大小上的表现差异，以确保方法的健壮性和适应性。
- **用户参与验证**：通过用户研究验证感性理解问题和选择的度量，确保它们能够准确反映和满足用户的实际需求和体验。
- **技术创新**：研究使用selfcheckgpt等工具来评估生成内容的创新性，从而考察模型是否能够提供新颖的见解，尤其是对于需要横跨异构信息提供合成洞察的问题。
- **方法优化**：尽管在头对头比较中Graph RAG表现最优，但其构建图谱索引的费用与潜在收益之间的权衡需进一步评估，这包括计算预算、每个数据集预期的查询次数，以及其他图谱相关RAG方法的价值。
- **探索更多应用**：支持Graph RAG的图谱索引、丰富的文本注释和层次化的社区结构提供了许多改进与适应的可能，例如更局部的RAG方法，将用户查询与图谱注释进行基于嵌入的匹配，以及结合基于嵌入匹配与社区报告的混合RAG方案，采用Map-Reduce机制进行总结。

这些方向旨在持续优化Graph RAG的性能，确保其能够有效地支持整个文本语料库上的人类理解活动，提升在复杂信息理解、细节覆盖、和效率方面的表现。"
"- How does the trade-off of building a graph index in Graph RAG depend on factors such as compute budget, expected number of lifetime queries, and value obtained from other aspects of the graph index?
用中文回答。","## Graph RAG中的图索引构建权衡

Graph RAG通过结合知识图谱生成、索引增强生成（RAG）和基于查询的摘要（QFS）来支持对整个文本语料库进行人类理解。然而，构建图索引的利弊取决于多个因素：

### 计算预算
构建图索引需付出计算成本。随着语料库的规模和复杂性的增加，构建和维护图索引所需的计算资源也会相应增加，会显著影响系统的总体成本。计算预算较低的情况下，可能倾向于选择轻量级的索引构建方法或更简单、更一般的检索技术。然而，当计算预算充足时，建立详细且全面的图索引被证明能带来更全面和多样化的答案，相较于基于地图-归约源文本摘要的整体方法，效果更佳，提示成本更低。

### 预期的查询数量
预期在整个生命周期中对数据集进行的查询次数也是决定是否构建图索引的关键因素。Graph RAG的树状数据索引和社区摘要展现出了面对同一数据集多次全局查询的优越性能，这意味着在需要大量查询的情境中，尽管初期的索引构建成本较高，但长远来看，图索引会在节省计算资源和改善答案质量上提供明显的优势。对于预期查询较少的场景，可能建立图索引就不那么划算，依赖于更简单的检索技术可能就足够。

### 图索引的附加价值
图索引的价值除了提供更佳的摘要质量和多样性，还体现在其他方面。图索引衍生出的通用社区摘要和与其他基于图的RAG方法的结合使得能够从不同的角度和层次理解整个语料库或社区。如果我们不单追求从源文本中提取事实，而是希望增强人类对数据的理解或表面其他深度学习模型难以捕捉的综合洞察力，那么构建图索引能带来显着效益。图索引能够更好地连接点，提供合成洞察，而这是简单的基于向量相似度的检索方法所办不到的。

Graph RAG的多种实现，如更局部的方法、以及基于源文本摘要和相似度检索的混合方法都还在发展中。这表明Graph RAG不是一成不变的，有许多可能性可用于改进和适应不同的用例和需求，从而帮助优化其在整个文本分析环境中的性能。越来越多的工作开始朝着这方向探索，这也为我们提供更多针对性的工具和策略来平衡这些权衡，以适应具体的应用场景和数据需求。"
"- What are the possibilities for refinement and adaptation of the graph index, rich text annotations, and hierarchical community structure in Graph RAG?
用中文回答。","## 可能性的探索：Graph RAG 的改进与适应

Graph RAG 方法通过结合知识图谱生成、检索增强生成（RAG）和查询聚焦总结（QFS），支持整个文本语料库的人类理解与分析。然而，根据目前的表现和研究趋势，存在丰富的机会来改善和自定义这一方法以满足特定需求与场景。让我们深入了解这些可能性：

### 更局部的 RAG 方法

通过使用嵌入相似性匹配用户查询和图注释，Graph RAG 可以更加本地化地执行。这种方法不仅能够减少对整个图形索引的依赖，还能提高查询效率，更有效地捕捉与用户询问直接相关的信息片段。

### 混合 RAG 方案

结合嵌入相似性匹配针对社区报告和 Map-Reduce 总结机制，有望生成一种混合 RAG 方案。在这种方案下，“汇总”操作可以在社区层级的更多层次中拓展，或者实现一种“向下钻取”方法，基于更高级别社区总结中蕴含的信息线索进行更深入的查询。

## 知识图谱与 LLMS 的融合

结合知识图谱和大型语言模型（LLMS）在网络检索增强生成（RAG）领域引起了广泛的研究兴趣。针对这一方向，多项进展得以实现，包括：

- **LLMS 与知识图谱创建**：使用 LLMS 提升知识图谱的生成，甚至自动完成其中缺失的部分。
- **因果图提取**：LLMS 被用于从源文本中挖掘背后的因果关系，生成更为细致的图形结构。
- **基于知识图谱的 RAG**：LLMS 从知识图谱中抽取子图，以支持事实性强且细节丰富的叙事输出。

## 社区总结的重要性与层次性

Graph RAG 使用 Leiden 层次算法来生成实体社区的层次结构，这有助于从不同的粒度级别理解语料库。社区总结是通过逐步添加优先排序的元素总结（如节点、边和共变量）到 LLMS 的上下文窗口中获得的，直到达到令牌限制。

- **叶级社区**：从叶级社区开始，重要性排序遵循节点度的降低顺序，添加源节点描述、目标节点描述、链接共变量和边本身的描述。
- **高级社区**：如果所有元素总结在上下文窗口的令牌限制内，同理进行总结；否则，对子社区进行排名，只包括那些最为关键的信息。

## 评估方法的局限与未来研究

尽管初步评估表明 Graph RAG 在全面性和多样性方面取得了实质性的提升，但这一评价方法仅限于对两类语料库（大约 100 万令牌）中的一类询问类型进行考察。为了更准确地反映出方法的优缺点，需要进行更广泛的测试，涵盖多种询问类型、不同类型的数据以及不同规模的数据集。

### Fabrication Rate 的考量

评估方法中尚未充分探讨的一个领域是 Fabrication Rate（伪造率）。采用类似 SelfCheckGPT 的策略进行比较，将进一步完善当前分析。

### 构建图形索引的成本效益分析

目前，我们观察到 Graph RAG 在与其它方法头对头的测试中表现最佳，但在一些情况下，基于图的全局文本总结方法表现得毫不逊色。决定是否投资构建图形索引需要考虑计算预算、预期数据集查询次数、以及从图索引其他方面（包括通用社区摘要和相关图拉格方法）获得的价值。

## 总结

Graph RAG 方法为处理整个文本数据集提供了一种创新且强大的工具，但其完整潜力尚未完全挖掘。通过本地化 RAG、混合索引机制以及对知识图谱与 LLMS 相结合的深入研究，未来的工作将致力于更精确、更高效和更适应特定用户需求的算法改进。同时，全面评估和验证方法的有效性，尤其是在不同数据集规模和类型下的表现，仍然是开放的研究问题。通过持续的探索和调优，Graph RAG 将能更紧密地与领域知识相结合，并为人类理解大文本集合提供强有力的辅助。"
"- How does the use of graphs in connection with LLMs and RAG contribute to knowledge graph creation, completion, and extraction of causal graphs from source texts?
用中文回答。","### 图与LLM及RAG的结合如何促进知识图谱的创建、完善及源文本中因果图的提取？

#### 知识图谱创建
在使用图与LLM的结合进行知识图谱创建方面，近期的研究（Trajanoska et al., 2023；Yao et al., 2023）表明，这种方法能够从源文档中提取实体和关系，构建出包含丰富信息与语义关联的图谱。通过LLM执行实体识别、关系提取等自然语言处理任务，可以自动构建出图谱结构，从而有效地组织和存储知识，提升后续检索与推理的效率。例如，在图谱构建的初期阶段，LLM用来进行实体和关系的识别，从文本单元中提取出原始数据，随后通过合并相同名称和类型的实体，实现数据的初步整合。

#### 知识图谱完善
此外，LLM还被用于知识图谱的完善（Yao et al., 2023）。通过将LLM作为增强检索的部分，它可以填充图谱中的缺失信息，使图谱更加完整。这就涉及到将图谱中已有的实体和关系与外部数据源中的信息进行关联和补全，有助于提升图谱的覆盖度和准确性。

#### 因果图提取
对于从源文本中提取因果关系图谱（Ban et al., 2023；Zhang et al., 2024），LLM同样发挥了关键作用。在这一过程中，LLM不仅能够识别出文本中的因果关系，还能生成影响事件序列的实体和关系，构建出反映潜在因果动态的图谱结构。这种因果关系图的创建有助于深入理解复杂事件的发展路径和影响机制，为分析和决策提供了坚实的基础。例如，在多轮提取后，尽管图谱的构建过程要求更高的数据粒度和精确度，但最终图谱能够提供更加全面且精准的因果关系理解。

#### 多角度应用
除了以上领域，对图谱的高级利用还包括创建RAG（Gao et al., 2023，Kaping et al., 2023）、检索图结构的部分（G-retriever，He et al., 2024）或基于图的度量作为查询对象（Graph Toolformer，Zhang, 2023）。这些方法不仅利用图谱来增强LLM的问答能力，还扩展了RAG的适用范围和功能。

### 讨论：自然图模性与数据总结的效率
图RAG方法与传统文本总结方法相比，突出了图的自然模性。在图谱构建过程中的实体和关系提取阶段，通过对文本单元进行精确划分，我们能更有效地利用LLM的计算资源。这种方法在保持图谱的全面性和多样性上表现优越，同时大幅度减少了所需处理的文本量，尤其是根级社区总结（C0）的情况下，其文本需求降低了97%以上。这表明，图RAG不仅能够高质量地构建图谱，还能在总结大规模数据时实现显著的性能提升和资源节约。

### 技术社区的发展与探索
技术社区目前正致力于开发和优化利用知识图谱扩展RAG的方法，如Microsoft Research的GraphRAG。GraphRAG使用LLM根据输入的语料库创建知识图谱，并结合社区总结和图机器学习输出来增强查询时的提示。这一方法展示了在处理复杂信息时的显著提升，特别是在实现互联互通和深度理解方面，对于回答需要跨过多重信息链接才能洞察的新综合性见解类问题，以及要求对大规模数据集进行整体理解的问题，GraphRAG表现出比其他方法更高的智能和掌握度，包括对单一大型文档的深入理解。

### 总结
通过LLM创建、完善和提取因果关系的知识图谱不仅提高了RAG的性能，还为理解和处理复杂的知识领域提供了新的视角。GraphRAG作为一种创新方法，充分利用了图的结构特性，实现了高效的数据总结和连贯的问答能力，为现有的文本关系处理技术提供了显著的提升。"
"- What are the directions already established in the use of graphs with LLMs and RAG, and how do they relate to advanced RAG approaches where the index is a knowledge graph?
用中文回答。","### 关于图与LLM和RAG的既定方向

**图与LLM结合的多种方向正在发展中**，它们包括使用LLM创建知识图谱（Tree of Clarifications, 2023; Yao等, 2023），以及从源文本中提取因果图（Ban等, 2023; Zhang等, 2024）。这些方向的目标是增强LLM对复杂信息的处理能力，尤其是在涉及隐私数据的场景下，如企业专有研究、业务文档或通信。

### 关于使用图作为RAG索引的先进方式

图谱作为RAG技术的一部分，通过将外部数据集与LLM的上下文窗口相结合，实现实体和关系的检索（Gao等, 2023）。当数据集的大小超过了LLM的容量，传统的RAG技术利用向量相似性作为搜索技术，这被称为基线RAG。然而，这种方法在连接分散的信息并提供新的综合洞察方面遇到难题。为了解决这一问题，**GraphRAG**作为一种新技术出现，它不像其他系统那样简单地将数据划分，而是**使用图的自然模块性来对数据进行全局总结**，并显着提升了回答特定类问题的性能（Sarthi et al., 2024; Kim et al., 2023）。

例如，GraphRAG在获取中间级和低级的社区总结时，不仅在相同指标上表现优异，还**显著降低了令牌成本**。与基线RAG相比，GraphRAG能够在回答需要对数据集全面理解或需要跨多个文档理解的问题时，更加高效。此外，微软研究的GraphRAG方法还能在处理需要迭代回答以体现理解过程的感知识别活动时，展现出高于其他技术的最佳性能（Kang et al., 2023）。

### 技术比较与结果

在研究结果中，GraphRAG通过减少所需**上下文令牌**的数量表现出色，尤其在使用根级社区总结（C0）时，上下文令牌的减少超过了97%。GraphRAG在全面性和多样性指标上分别以72%和62%的赢率胜出，证明了其在保留具体细节、引文和例证以帮助用户达到有见地理解方面的能力。

总体而言，这些既定的研究方向和GraphRAG的技术实施揭示了图生成与图索引方法在RAG领域的独特潜力，为处理复杂文档集和多阶段查询提供了一种新的、更有效的方式。不过，这些方法在实际应用中仍有待多类别问题和数据类型的支持，以及更广泛的用户验证，以评估其在不同场景下的表现（Zhang, 2023）。未来的研究将继续探索如何优化GraphRAG的性能，特别是在涉及更广泛的数据类型、更大范围的数据集大小，以及具体问题类型的评估时。

### 参考文献
- Nallm, Neo4j (2024)
- GraphRag, NebulaGraph (2024)
- Kim et al. (2023)
- Sarthi et al. (2024)
- Yao et al. (2023)
- Ban et al. (2023)
- Zhang et al. (2024)
- Zhang, 2023
- Gao et al. (2023)
- Kaping, Baek et al. (2023)
- Kuratov et al. (2024)
- Ranade and Joshi ((2023)

这些都是在图生成、搜索和关联技术中起着关键作用的研究文献和系统。"
"- How does Graph RAG lead to substantial improvements over a naive RAG baseline for both the comprehensiveness and diversity of generated answers for a class of global sensemaking questions?
用中文回答。","### Graph RAG相较于Naive RAG带来的显著改进

为了回答特定领域内的全球性质疑问题，Graph RAG采用了一种新颖的方法，即基于实体知识图构建索引。这种方法与传统的信息检索技术有着本质的不同，它旨在为用户提供一个更加全面和多样化的信息视图，而不仅仅是局限在单一或有限的文本片段内。

#### 方法细节
- **实体知识图构建：**首先，Graph RAG利用大型语言模型提取源文件中的实体，构建一个复杂的实体知识图。这一图结构不仅包含了单个实体，还展示了实体之间的相互关联。
- **社区总结预生成：**接下来，Graph RAG算法会生成紧密相关的实体群组（即社区）的总结。这些总结为后续的信息检索和回答生成提供了丰富的上下文背景。

### 改进的原因

- **上下文综合度提高：**由于Graph RAG使用整个社区的所有相关信息来生成部分响应，它能提供更加全面的细节，覆盖问题的各个方面。在展示结果时，所有部分响应会被再次汇总，形成最终的回应，从而达到了较高的信息覆盖度。
- **多样性的显著提升：**Graph RAG还以其能够生成多样化的回答而著称。它能同时提供多种角度的观点和实例，这在大型文档集合上尤其重要，因为它避免了单一来源的信息重复，增加了响应的内容丰富度和视角多样性。

#### 实验证据

针对具有100万单词级别的数据集进行的实验表明，Graph RAG相比于naive RAG（一个只简单加密文本块并将其嵌入向量空间中的方法），在回答生成任务的全面性和多样性表现上有着显著优势。通过采用基于LLM的评价指标进行头对头比较实验，结果显示Graph RAG在细节完整度（72%胜率）和回答的多样性方面（62%胜率）远超naive RAG。这意味着Graph RAG在处理全球性的问题时，可以更好地提取和融合跨文本的信息，提供一个更加丰富和多维的信息解读。

然而，尽管Graph RAG在这些问题上取得胜利，但它需要进行更加精细化的管理，尤其是关于调优元素抽取提示，来最大程度地保留回答中的实例、引用和具体细节，这些都是用户达到有依据的理解的关键。通过改进这些技术，我们有望将Graph RAG的性能提升到新的高度。在处理不同类型的查询、数据类型，以及数据集规模时，更多的研究需要验证Graph RAG的表现差异，以确保此方法的广泛适用性和效能。

总的来说，Graph RAG之所以能够在回答的全面性和多样性方面取得显著进步，主要依靠它采用的多阶段索引建设和社区总结预生成策略，这在自动化构建的实体知识图上尤为有效。通过Query-Focused Summarization任务，Graph RAG能够生成自然语言摘要，这不仅超越了仅限于检索或问答的局限，而且提供了更易于理解和消化的信息形式，特别适用于全球性的问题场景。

此外，Graph RAG也体现了与其他相关研究的不同之处，比如Graph Toolformer方法仅将图指标作为查询对象，而没有像Graph RAG那样利用图的自然模块性来部分数据；再如Fabula系统侧重于序列化提取的事件图，而Graph RAG则利用其自构造的图索引来实现更高效的知识抽提。这些硬核数据和方法比较，进一步强化了Graph RAG在实现高效且全面的感会问题解决方案时的独特能力。"
"- What is the role of community summaries in the graph-based index used for answering global queries in Graph RAG?
用中文回答。","## 社区摘要在图RAG中的作用

社区摘要在图RAG（基于图的检索增强生成）过程中扮演着至关重要的角色，尤其是涉及大型数据集时。这些摘要是在图的Leiden层次结构中生成的，每个社区的摘要独立于其他社区，它们不仅可以揭示数据集的全局结构和语义，对于理解数据集而无需特定问题也有价值。例如，用户可能在高层次扫描社区摘要，寻找主题兴趣，然后跟随链接到低层次的报告，获取每个子主题的更多细节。

### 叶层社区摘要

对于叶层社区（即图的末梢层），生成摘要的过程是优先级驱动的，逐渐添加各个元素（节点、边、协变量）的总结，直到接近或达到上下文窗口的标记限制。优先级基于边的总体显著性，考虑到边的源节点和目标节点的综合度数来排列。

### 更高层次社区摘要

在更高层次的社区，如果所有元素摘要均能适应上下文窗口的标记限制，那么直接总结所有包含在社区内的元素；如果标记容量不足，将采用与叶层社区类似的摘要生成方法，但只针对排名靠前的元素。

## 全局查询回答

社区摘要在使用图RAG回答全局查询的过程中作为一个分割逻辑的工具，通过汇总成员信息以独立和并行的方式生成部分回答。然后将这些部分回答进行融合，以构建最终的全球回答。这种方法结合了全局覆盖与局部精细度，利用LLM（大型语言模型）的强大力量以较低的标记成本实现对数据集的完整覆盖。

图RAG能够改进对常见检索增强生成（RAG）方法的理解和响应，尤其是在涉及大规模文本数据集时，它可以在保证整体性和多样性的同时极大提升生成答案的覆盖率和质量。尽管某些图外的全局性方法也能表现出色，但图RAG在结合社区结构和报告方面提供了独特的性能优势，特别是在涉及多次对同一数据集的全局查询场景中，它提供了优于朴素RAG而接近其他全局方法的解决方案，且具有更高效的信息成本。
在多个层面使用社区摘要（C0至C3）为图RAG提供了动态适应用户需求和上下文窗口限制的能力，无论数据集的复杂性如何，都能够提供准确且全面的答案。通过分层次处理，图RAG允许用户在不同深度上进行查询，最小化解析和抽取信息过程中的计算负载。

### 全局性方法对比较

尽早评估了图RAG性能，发现所有全局方法在全面性和多样性指标上均超越了朴素RAG。图RAG在使用中间层和低层社区摘要时，与源文本总结技术相比，展现了有利的结果。这表明图RAG不仅经济有效地管理大文本数据，还能够促进更深层次的人类理解。

### 发展和未来工作

构建图索引背后涉及的权衡和决定是由多种因素决定的，比如计算预算、每个数据集预期的查询次数以及从图索引的其他方面中获得的价值，如使用图相关的RAG方法。未来的改进方向包括：开发更本地化的RAG实现，通过嵌入基匹配用户查询和图注释；探索混合RAG方案，这些方案在应用图评估之前的社区报告中结合了嵌入基匹配；以及拓展“向上滚动”操作至图的社区层次结构中的更多水平，或作为“向下钻取”机制，该机制遵循上层社区摘要中存在的信息汇集。

图索引生成时的语义丰富性与图结构的自然模块性相结合，使得图RAG成为了针对复杂查询和海量文本数据的高效、全面回答引擎。这样的设计确保了即使是细分主题的变化，也不影响对关系紧密实体社区的理解，而LLM在这个过程中可识别和理解多样表达背后的共同实体。
这与传统知识图谱追求精炼和一致性形成鲜明对比，图索引则通过其报告式摘要能力体现了自己的价值，为数据的全局和局部理解提供了量身定制的视角。
左提和右提全文观看（如果设置存在）社区摘要，然后根据用户的问题汇聚这些摘要以生成完整且有深度的回答。这一流程有效地利用了图的层级结构，优化了回答的生成和理解，使得图RAG不仅在质量和性能方面表现出色，同时在处理大规模数据集的效率上具有显著优势。

## 总结

社区摘要贯穿于图RAG的整个工作流程，从叶层社区到更高级别的社区，其在理解数据集与回答复杂问题的过程中扮演了一个核心角色。无论是提高对大文本数据的理解，还是生成复杂而全面的回答，图RAG都依赖于这些社区摘要的有效生成和精细管理。
图RAG方法不仅继承了LLM在文本理解和生成上的优势，还进一步拓展了RAG在处理"
"- How are community summaries generated for leaf-level and higher-level communities in Graph RAG, and what is their significance in the process of answering global queries?
用中文回答。","### Graph RAG中社区摘要的生成方法及其对回答全球查询的显著性

在Graph RAG（基于图的检索增强生成）方法中，社区摘要的生成分为对叶级（leaf-level）社区和更高级别（higher-level）社区的处理，这些摘要的生成是基于数据集本身的结构和语义，对于理解数据集全局结构和语义至关重要。

#### 叶级社区摘要

叶级社区摘要生成的第一步是优先级排序。对于每一个社区中的边，按照两个节点的度（即连接数）之和降序排列，这种度的组合反映了边在图中的相对显着性。摘要生成具体步骤如下：

1. **优先级排序**：对于每一社区边，首先描述源节点、目标节点、连接的协变量（covariates），以及边的特性。这种描述是根据节点度的顺序进行的，优先处理更加中心的节点和边。

2. **迭代添加**：元素摘要（nodes, edges, covariates）会逐个加入到LLM（Large Language Model）的上下文窗口中，直到达到令牌限制。这一过程确保了信息的精选，并有助于上下文窗口中的信息对查询更具有回答的潜力。

#### 更高级别社区摘要

对于更高级别的社区，其摘要生成与叶级社区相似但更进了一步，以容纳更大的数据集。当所有元素摘要的大小超过了上下文窗口的令牌限制时，采取以下策略：

1. **子社区排名**：按照各子社区中的元素摘要令牌数量进行排名。子社区摘要较短，而元素摘要较长。

2. **逐步替代**：迭代将较长的元素摘要（来自子社区）替换成较短的子社区摘要，直到摘要适合在LLM的上下文窗口内。

#### 社区摘要的意义

社区摘要在回答全球查询过程中的作用是基于图的模态性和社区检测算法的能力，最终实现从一系列基于社区的局部响应到全球响应的转换。方法采用map-reduce策略，即通过各社区摘要独立并行地生成部分回答，随后将所有相关部分的回答合并，进行最终的全球化总结。

1. **上下文的层次化提供**：在不同层级的社区摘要中，用户可以逐级探究更深层次的信息。例如，可以发现并定位当前查询所相关的子主题或领域，之后向下联系以获得更具体的细节。

2. **优化信息结构**：叠叶子社区摘要与高阶社区摘要，提供了一种系统方法，以控制回答的整体结构、重点和深度。

3. **全局查询的解答**：社区摘要通过从不同层级汇总信息，提供了一个对全局查询的有效回答。对于需要内在模态性和全球视图的主题查询，Graph RAG证明了其优于单一的生成方法或传统的方法。

4. **策略对比**：我们通过实验评估了使用不同层级社区摘要（高、中、低级别；C0 - C3）的回答策略，以及将其与生成文本的局部总结（源文本总结；TS）和简单随机抽取文本的方法（朴素RAG；SS）进行比较。结果显示，在复杂查询的全面性和多样性方面，Graph RAG方法具有显著优势。特别地，使用中、低级别社区摘要的策略表明在可控的信息量下，可以提供相当或更优的表现，相比全量文本总结。

总之，Graph RAG中社区摘要的生成与使用，不仅提高了回答全球查询的能力，而且通过有层次的信息提取和总结，实现了对大型文本语料库的高效处理。其旨在优化并呈现从局部元素到全局视图的信息体系，有效辅助人类在大量数据上的推理与理解活动。
#### 未来工作
- Graph RAG的“汇总”操作可以扩展到社区层次结构中的更多级别，并可实施为更细致的“钻取”机制，跟踪高层社区摘要中所含信息。
- 也可结合嵌入式匹配和社区报告进行局部操作，随后运用map-reduce总结机制，创建一种混合型RAG方案，以增强查询处理的能力。"
"- How does the global search method in Graph RAG use community summaries to summarize themes when responding to a user query?
用中文回答。","### 全局搜索方法的概述
全局搜索方法在Graph RAG系统中利用预生成的社区报告作为关键的上下文数据。这些社区报告被分段成预定义大小的文本块，每个文本块都用于生成初步响应。初步响应包含一系列要点，每一点都附带一个数值评级，表示该点的重要性。

### 社区层次结构的作用
使用什么层次的社区层次结构获取社区报告直接影响最终响应的质量。更低层次的报告较为详细，可能为回答提供更丰富的信息和更全面的视角，但同时也可能因为涉及更多的社区报告而导致额外的时间和资源成本。全局搜索方法通过平衡这些因素来优化检索和总结的时间成本与信息完备性之间的关系。

### Map-Reduce机制
该方法采用Map-reduce模式进行操作。在Map阶段，每一篇社区报告都被分解为若干文本块，使用预设的系统提示模板为每个文本块生成初步响应。这个阶段的关键是为每个报告块确定最相关的点，并给出其重要性等级。在Reduce阶段，从初步响应中筛选并汇总最重要的点，这些点的聚合版被用于生成最终的响应。

### 选择合适的层次
选择合适的社区层次是一个策略性的决策，低层次的社区报告提供了细致的节点和边信息，可以对用户查询进行详尽回答。而高层次的社区报告则提供宏观的主题和模式，有助于从较广泛的角度解析查询。具体选择哪一层取决于查询的复杂性和上下文需求，以及对时间和资源的考量。

### 自记忆和迭代生成的结合
社区摘要在某种意义上充当自我记忆，用于后续的生成周期，类似于自记忆（SelfMEM）与生成增强检索（GAR）的结合，这与Graph RAG的多次迭代和动态循环检索生成机制有关。自助记忆在响应生成和未来检索中提高了效率和准确性。

### 多层模组
具体的层级选择影响检索效率和生成响应的效率。使用层次较高的社区报告，可以快速获取广泛的主题信息，而不需要展开大量细节。与此相反，选择层次较低的报告，则需要更多的时间构建完整且精细的响应，但由于详细的覆盖，信息可能更为全面。

### 平行生成和自顶向下的检索
Graph RAG的全局搜索方法支持平行生成从社区报告中形成的摘要，而这些摘要提供了对整个数据集结构的理解。通过利用Leiden算法产生的层次社区结构，加上查询优先级策略，可提供针对用户查询的自顶向下的检索和总结功能。

### 结论和建议
总体而言，全局搜索方法通过分而治之的策略，有效利用各个社区层级的数据来回答用户查询，平衡了信息深度和广度。建议新型用户先尝试高层级的社区报告，以快速理解数据集的主题和模式，而为需要细化内容的复杂查询，则应该选择较低的社区层级。始终要考虑到信息的全面性和响应时间之间的联盟，挑选最合适的社区摘要层次会帮助在成本和质量之间找到最佳平衡点。"
"- What are the scalability advantages of Graph RAG compared to source text summarization, and how does it offer a highly efficient method for iterative question answering?
用中文回答。","### 图表RAG方法的可扩展性优势

图表RAG（Retrieval-Augmented Generation，增强查找生成）方法相较于传统的源文本总结方法具有明显的可扩展性优势，尤其是在处理大规模文本数据集时。图表RAG的根级（C0）总结策略，对于那些需要频繁全局查询相同数据集的场景，表现得尤为突出。这种策略可以通过减少对LLM（Large Language Models，大规模语言模型）上下文窗口的token（通证）需求，实现高效性能，其所需token数量相较于源文本总结方法减少了97%以上，同时也比其他的全局方法需要的token少26%到33%。

### 在保持性能的同时降低token成本

图表RAG在提供完整和多样的答案方面，保持了72%和62%的胜率，这意味着它能够在保持与Naive RAG相比的优势时（如在全面性和多样性指标上），显著减少所需的token数量。这种方法对于在Sensemaking活动（即通过分析文档集合以获取更深层的理解和洞察）中持续进行问题回答特别有效。

### 支持查询聚焦性总结

图表RAG设计中支持查询聚焦性总结（QFS，Query-Focused Summarization），这使人类在处理整个文本集合时能够高效过滤和分析信息。与之前的QFS方法相比，本方法能处理更多的文本量，避免了典型RAG系统在处理大量文本时的缺陷。

### 效能和用户洞察

此外，对于图表RAG，效能（Empowerment）比较结果也显示出在与Naive RAG或非图表的RAG方法竞争时的波动表现，尤其在处理用户触达有据可依的理解方面。这得益于LLM能够提供具体示例、引用和文献资料，帮助用户达到更深度和完整的信息理解。通过调整元素提取提示，有可能在图表RAG的索引中保留更多信息细节。

### 设计和实施详细说明

以下是图表RAG方法的高阶数据流概述（图1）和实施流程的详细部分：

1. **文本切块**（图2）：源文档被拆分成一定长度的文本块。这是由于每个块将通过LLM提示提取图的节点和边的各种实例。块的长度需要平衡LLM的调用次数和回忆率，通常较小的块更有利于维护较高的精准度和回忆率。

2. **元素实例提取**：这一阶段的基线要求是识别和从各段文本中提取图节点和边的实例。LLM被用来创建实体知识图，进一步使用这些图来预生成紧密相关实体组的社区总结。

3. **社区总结**：每个根级社区（C0）的总结作为应对用户查询的起始点。如果存在更细粒度的社区（如C1、C2或C3），其总结也将用于生成部分回答，所有这些部分回答最终会被汇总成一个完整的回答。

4. **迭代问题回答的效率**：图表RAG的实施能够以较小的token数量成本实现高效的迭代问题回答，特别适合那些需要理解和综合大量文本信息的场景。这种方法在全面性和多样性方面均显示出优势，接近甚至有时优于全局查询方法的性能，但更经济实惠。

### 未来工作和局限性

当前评估仅限于约100万tokens规模文本集的特定类型的sensemaking问题。要深入了解图表RAG如何在多样化的问题类型、数据类型以及不同规模数据集上表现，还需要进一步的工作。此外，通过使用如SelfCheckGPT（一种检测LLM生成内容原创性和真实性的方法）评估生成答案中事实编造的比例，将有助于改进当前的分析。

总结来说，图表RAG通过优化token使用和预先生成多层次相关的社区总结，为整个文本集合的全局查询提供了高效和成本效益的解决方案，尤其是针对需要深入理解、综合分析和人类sensemaking活动的迭代问题回答场景。"
"- How does Graph RAG's performance compare to other global methods in terms of comprehensiveness and diversity, and what is the significance of these metrics in the context of answering global queries?
用中文回答。","## Graph RAG与其它全局方法的性能比较

在回答全局查询时，Graph RAG在全面性和多样性方面取得了显著的胜利，相对于其它全局方法具有明显的优势。在26-33%上下文减少的情况下，Graph RAG可以在比较温和的性能下降下提供高效的结果生成，这特别适用于迭代式问题回答，这是信息发掘活动的显著特点。当与天真的RAG方法比较时，Graph RAG的全面性（72%的胜率）和多样性（62%的胜率）优势尤为明显。

**全面性**（Comprehensiveness）和**多样性**（Diversity）这两个指标是重要的，因为它们衡量了系统是否能够覆盖查询的所有重要方面，并且是否能够提供一系列不同但相关的答案。对于全局查询，这通常意味着处理大量数据，并从中提炼实质性信息。
- 全面性保证了用户可以获得所有关键点，这对于对复杂信息集的理解尤其重要。
- 多样性提供了多个角度的洞察，这对于信息发掘和决策支持活动是有价值的，帮助用户获取不同层次的信息或不同的答案，确保理解的深度与广泛性。

### Empowerment Empirical比较

Empowerment比较显示了对于**全局方法**对比天真的RAG方法以及**Graph RAG方法**对比源文本总结的不同结果。在能力提供具体例子、报价和引用来帮助用户达到知情理解方面，通过自适应LLM的使用，Graph RAG方法展现了它的优势。然而，为了改善索引中细节的保留，对元素提取提示的微调可能需要进一步探索。

## 相关工作

Graph RAG方法在回答需要跨不同类型信息进行复杂推理的问题时表现出色，这超越了传统的基于向量相似性检索的方法，即所谓的基线RAG方法。基线RAG方法在处理需要在多个信息碎片之间进行关系理解的问题时遇到困难。特别是，它在要求对大量数据集合或独立大型文档进行全面理解的查询中性能欠佳。

### 开源软件与Graph RAG

Graph RAG方法与现有的开源软件，如LangChain和LlamaIndex，在概念上有区别。这些软件支持多种图数据库，包括基于Neo4j和Nebula Graph的数据集。尽管Graph RAG使用实体和关系图，以图结构的自然模块化为基础进行全局总结，但目前的系统尚未集成这一特性。

## 讨论

### 评价方法的局限性

到目前为止，Graph RAG的评估主要集中在两个大约百万个标记的语料库上，专门考察了特定类别的信息发掘问题。为了深化理解，还需要考虑不同问题类型、数据类型、数据集大小下的性能变化，以及验证目标指标与最终用户的具体需求。比较制造率，例如使用SelfCheckGPT等方法，也能完善现有分析。

### 建立图索引的权衡

Graph RAG方法在与其它技术的直接比较中通常表现出最佳结果。然而，在许多情况中，基于图方法的全局源文本总结同样实现了竞争性的性能，尤其是在低令牌成本的场景下。现实决策中，是否投入创建图索引应考虑计算预算、每个数据集的预期查询数量和从图索引其他方面（包括泛化社区总结和图相关RAG方法的使用）获取的价值。

## 结论

通过结合知识图生成、检索增强生成（RAG）和查询集中总结（QFS），Graph RAG展示了支持人类对整个文本语料库进行信息发掘的全局方法。除了在天真的RAG基线方面取得显著改进外，Graph RAG在这个领域的进展为处理复杂查询和大规模数据集提供了坚实的基础。随着未来的研发投入，Graph RAG有望进一步提炼其方法，提高处理全局查询的效率并扩大其在信息探索领域的应用范围。"
